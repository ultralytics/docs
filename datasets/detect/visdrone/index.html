 <!DOCTYPE html><html class="no-js" lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="Explore the VisDrone Dataset, a large-scale benchmark for drone-based image and video analysis with over 2.6 million annotations for objects like pedestrians and vehicles." name="description"/><meta content="Ultralytics" name="author"/><link href="https://docs.ultralytics.com/datasets/detect/visdrone/" rel="canonical"/><link href="../tt100k/" rel="prev"/><link href="../voc/" rel="next"/><link href="/" hreflang="en" rel="alternate"/><link href="/zh/" hreflang="zh" rel="alternate"/><link href="/ko/" hreflang="ko" rel="alternate"/><link href="/ja/" hreflang="ja" rel="alternate"/><link href="/ru/" hreflang="ru" rel="alternate"/><link href="/de/" hreflang="de" rel="alternate"/><link href="/fr/" hreflang="fr" rel="alternate"/><link href="/es/" hreflang="es" rel="alternate"/><link href="/pt/" hreflang="pt" rel="alternate"/><link href="/it/" hreflang="it" rel="alternate"/><link href="/tr/" hreflang="tr" rel="alternate"/><link href="/vi/" hreflang="vi" rel="alternate"/><link href="/ar/" hreflang="ar" rel="alternate"/><link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/><meta content="zensical-0.0.20" name="generator"/><title>VisDrone Dataset - Ultralytics YOLO Docs</title><link href="../../../assets/stylesheets/modern/main.d4922b3c.min.css" rel="stylesheet"/><link href="../../../assets/stylesheets/modern/palette.dfe2e883.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,500,500i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link href="../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<style data-doc-kind="true">.doc-kind{display:inline-flex;align-items:center;gap:0.25em;padding:0.21em 0.59em;border-radius:999px;font-weight:700;font-size:0.81em;letter-spacing:0.06em;text-transform:uppercase;line-height:1;color:var(--doc-kind-color,#f8fafc);background:var(--doc-kind-bg,rgba(255,255,255,0.12));}.doc-kind-class{--doc-kind-color:#039dfc;--doc-kind-bg:rgba(3,157,252,0.22);}.doc-kind-function{--doc-kind-color:#fc9803;--doc-kind-bg:rgba(252,152,3,0.22);}.doc-kind-method{--doc-kind-color:#ef5eff;--doc-kind-bg:rgba(239,94,255,0.22);}.doc-kind-property{--doc-kind-color:#02e835;--doc-kind-bg:rgba(2,232,53,0.22);}</style><meta content="VisDrone Dataset" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/datasets/detect/visdrone/" property="og:url"/><meta content="VisDrone Dataset" property="og:title"/><meta content="" property="og:description"/><meta content="https://img.youtube.com/vi/9ymyH4H1fG4/maxresdefault.jpg" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/datasets/detect/visdrone/" property="twitter:url"/><meta content="VisDrone Dataset" property="twitter:title"/><meta content="" property="twitter:description"/><meta content="https://img.youtube.com/vi/9ymyH4H1fG4/maxresdefault.jpg" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": ["Article", "FAQPage"], "headline": "VisDrone Dataset", "image": ["https://img.youtube.com/vi/9ymyH4H1fG4/maxresdefault.jpg"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2026-01-20 01:51:10 +0000", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "", "mainEntity": [{"@type": "Question", "name": "What is the VisDrone Dataset and what are its key features?", "acceptedAnswer": {"@type": "Answer", "text": "The VisDrone Dataset is a large-scale benchmark created by the AISKYEYE team at Tianjin University, China. It is designed for various computer vision tasks related to drone-based image and video analysis. Key features include:"}}, {"@type": "Question", "name": "How can I use the VisDrone Dataset to train a YOLO26 model with Ultralytics?", "acceptedAnswer": {"@type": "Answer", "text": "To train a YOLO26 model on the VisDrone dataset for 100 epochs with an image size of 640, you can follow these steps: For additional configuration options, please refer to the model Training page."}}, {"@type": "Question", "name": "What are the main subsets of the VisDrone dataset and their applications?", "acceptedAnswer": {"@type": "Answer", "text": "The VisDrone dataset is divided into five main subsets, each tailored for a specific computer vision task: These subsets are widely used for training and evaluating deep learning models in drone-based applications such as surveillance, traffic monitoring, and public safety."}}, {"@type": "Question", "name": "Where can I find the configuration file for the VisDrone dataset in Ultralytics?", "acceptedAnswer": {"@type": "Answer", "text": "The configuration file for the VisDrone dataset, VisDrone.yaml, can be found in the Ultralytics repository at the following link:\nVisDrone.yaml."}}, {"@type": "Question", "name": "How can I cite the VisDrone dataset if I use it in my research?", "acceptedAnswer": {"@type": "Answer", "text": "If you use the VisDrone dataset in your research or development work, please cite the following paper:"}}]}</script></head><body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" for="__drawer"></label><div data-md-component="skip"><a class="md-skip" href="#visdrone-dataset"> Skip to content </a></div><div data-md-component="announce"><aside class="md-banner"><div class="md-banner__inner md-grid md-typeset"><a class="banner-wrapper" href="https://docs.ultralytics.com/models/yolo26"><div class="banner-content-wrapper"><img alt="Ultralytics YOLO26" height="40" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/6967372a0d67914985d322e7_Ultralytics%20YOLO26%201.svg"/><p>Built End-to-End. Built for the Edge.</p></div></a></div></aside></div><header class="md-header md-header--shadow md-header--lifted" data-md-component="header"><nav aria-label="Header" class="md-header__inner md-grid"><a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a><label class="md-header__button md-icon" for="__drawer"><svg class="lucide lucide-menu" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 5h16M4 12h16M4 19h16"></path></svg></label><div class="md-header__title" data-md-component="header-title"><div class="md-header__ellipsis"><div class="md-header__topic"><span class="md-ellipsis"> Ultralytics YOLO Docs </span></div><div class="md-header__topic" data-md-component="header-topic"><span class="md-ellipsis"> VisDrone Dataset </span></div></div></div><form class="md-header__option" data-md-component="palette"><input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option"><div class="md-select"><button aria-label="Select language" class="md-header__button md-icon"><svg class="lucide lucide-languages" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m5 8 6 6M4 14l6-6 2-3M2 5h12M7 2h1M22 22l-5-10-5 10M14 18h6"></path></svg></button><div class="md-select__inner"><ul class="md-select__list"><li class="md-select__item"><a class="md-select__link" href="/" hreflang="en"> üá¨üáß English </a></li><li class="md-select__item"><a class="md-select__link" href="/zh/" hreflang="zh"> üá®üá≥ ÁÆÄ‰Ωì‰∏≠Êñá </a></li><li class="md-select__item"><a class="md-select__link" href="/ko/" hreflang="ko"> üá∞üá∑ ÌïúÍµ≠Ïñ¥ </a></li><li class="md-select__item"><a class="md-select__link" href="/ja/" hreflang="ja"> üáØüáµ Êó•Êú¨Ë™û </a></li><li class="md-select__item"><a class="md-select__link" href="/ru/" hreflang="ru"> üá∑üá∫ –†—É—Å—Å–∫–∏–π </a></li><li class="md-select__item"><a class="md-select__link" href="/de/" hreflang="de"> üá©üá™ Deutsch </a></li><li class="md-select__item"><a class="md-select__link" href="/fr/" hreflang="fr"> üá´üá∑ Fran√ßais </a></li><li class="md-select__item"><a class="md-select__link" href="/es/" hreflang="es"> üá™üá∏ Espa√±ol </a></li><li class="md-select__item"><a class="md-select__link" href="/pt/" hreflang="pt"> üáµüáπ Portugu√™s </a></li><li class="md-select__item"><a class="md-select__link" href="/it/" hreflang="it"> üáÆüáπ Italiano </a></li><li class="md-select__item"><a class="md-select__link" href="/tr/" hreflang="tr"> üáπüá∑ T√ºrk√ße </a></li><li class="md-select__item"><a class="md-select__link" href="/vi/" hreflang="vi"> üáªüá≥ Ti·∫øng Vi·ªát </a></li><li class="md-select__item"><a class="md-select__link" href="/ar/" hreflang="ar"> üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© </a></li></ul></div></div></div><div class="md-header__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div></nav><nav aria-label="Tabs" class="md-tabs" data-md-component="tabs"><div class="md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a class="md-tabs__link" href="../../.."> Home </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../modes/"> Modes </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../tasks/"> Tasks </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../models/"> Models </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../compare/"> Compare </a></li><li class="md-tabs__item md-tabs__item--active"><a class="md-tabs__link" href="../../"> Datasets </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../solutions/"> Solutions </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../guides/"> Guides </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../integrations/"> Integrations </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../platform/"> Platform </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../reference/__init__/"> Reference </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../help/"> Help </a></li></ul></div></nav></header><div class="md-container" data-md-component="container"><main class="md-main" data-md-component="main"><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0"><label class="md-nav__title" for="__drawer"><a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a> Ultralytics YOLO Docs </label><div class="md-nav__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../.."><span class="md-ellipsis"> Home </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../modes/"><span class="md-ellipsis"> Ultralytics YOLO26 Modes </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../tasks/"><span class="md-ellipsis"> Computer Vision Tasks Supported by Ultralytics YOLO26 </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../models/"><span class="md-ellipsis"> Models Supported by Ultralytics </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../compare/"><span class="md-ellipsis"> Model Comparisons: Choose the Best Object Detection Model for Your Project </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../"><span class="md-ellipsis"> Datasets </span></a><label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="true" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1"><label class="md-nav__title" for="__nav_6"><span class="md-nav__icon md-icon"></span> Datasets </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_6_2" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../"><span class="md-ellipsis"> Detection </span></a><label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="true" aria-labelledby="__nav_6_2_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_6_2"><span class="md-nav__icon md-icon"></span> Detection </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../african-wildlife/"><span class="md-ellipsis"> African-wildlife </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../argoverse/"><span class="md-ellipsis"> Argoverse </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../brain-tumor/"><span class="md-ellipsis"> Brain-tumor </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coco/"><span class="md-ellipsis"> COCO </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coco8/"><span class="md-ellipsis"> COCO8 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coco8-grayscale/"><span class="md-ellipsis"> COCO8-Grayscale </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coco8-multispectral/"><span class="md-ellipsis"> COCO8-Multispectral </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coco12-formats/"><span class="md-ellipsis"> COCO12-Formats </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coco128/"><span class="md-ellipsis"> COCO128 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../construction-ppe/"><span class="md-ellipsis"> Construction-PPE </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../globalwheat2020/"><span class="md-ellipsis"> GlobalWheat2020 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../homeobjects-3k/"><span class="md-ellipsis"> HomeObjects-3K </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../kitti/"><span class="md-ellipsis"> KITTI </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../lvis/"><span class="md-ellipsis"> LVIS </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../medical-pills/"><span class="md-ellipsis"> Medical-pills </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../objects365/"><span class="md-ellipsis"> Objects365 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../open-images-v7/"><span class="md-ellipsis"> OpenImagesV7 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../roboflow-100/"><span class="md-ellipsis"> RF100 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../signature/"><span class="md-ellipsis"> Signature </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../sku-110k/"><span class="md-ellipsis"> SKU-110K </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../tt100k/"><span class="md-ellipsis"> TT100K </span></a></li><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/><label class="md-nav__link md-nav__link--active" for="__toc"><span class="md-ellipsis"> VisDrone </span><span class="md-nav__icon md-icon"></span></label><a class="md-nav__link md-nav__link--active" href="./"><span class="md-ellipsis"> VisDrone </span></a><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#dataset-structure"><span class="md-ellipsis"> Dataset Structure </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#applications"><span class="md-ellipsis"> Applications </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#dataset-yaml"><span class="md-ellipsis"> Dataset YAML </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#usage"><span class="md-ellipsis"> Usage </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#sample-data-and-annotations"><span class="md-ellipsis"> Sample Data and Annotations </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#citations-and-acknowledgments"><span class="md-ellipsis"> Citations and Acknowledgments </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#what-is-the-visdrone-dataset-and-what-are-its-key-features"><span class="md-ellipsis"> What is the VisDrone Dataset and what are its key features? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-can-i-use-the-visdrone-dataset-to-train-a-yolo26-model-with-ultralytics"><span class="md-ellipsis"> How can I use the VisDrone Dataset to train a YOLO26 model with Ultralytics? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#what-are-the-main-subsets-of-the-visdrone-dataset-and-their-applications"><span class="md-ellipsis"> What are the main subsets of the VisDrone dataset and their applications? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#where-can-i-find-the-configuration-file-for-the-visdrone-dataset-in-ultralytics"><span class="md-ellipsis"> Where can I find the configuration file for the VisDrone dataset in Ultralytics? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-can-i-cite-the-visdrone-dataset-if-i-use-it-in-my-research"><span class="md-ellipsis"> How can I cite the VisDrone dataset if I use it in my research? </span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../voc/"><span class="md-ellipsis"> VOC </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../xview/"><span class="md-ellipsis"> xView </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_6_3" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../segment/"><span class="md-ellipsis"> Segmentation </span></a><label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_6_3_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_6_3"><span class="md-nav__icon md-icon"></span> Segmentation </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../segment/carparts-seg/"><span class="md-ellipsis"> Carparts-seg </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../segment/coco/"><span class="md-ellipsis"> COCO </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../segment/coco8-seg/"><span class="md-ellipsis"> COCO8-seg </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../segment/coco128-seg/"><span class="md-ellipsis"> COCO128-seg </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../segment/crack-seg/"><span class="md-ellipsis"> Crack-seg </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../segment/package-seg/"><span class="md-ellipsis"> Package-seg </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_6_4" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../pose/"><span class="md-ellipsis"> Pose </span></a><label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_6_4_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_6_4"><span class="md-nav__icon md-icon"></span> Pose </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../pose/coco/"><span class="md-ellipsis"> COCO </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../pose/coco8-pose/"><span class="md-ellipsis"> COCO8-pose </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../pose/dog-pose/"><span class="md-ellipsis"> Dog-pose </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../pose/hand-keypoints/"><span class="md-ellipsis"> Hand-keypoints </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../pose/tiger-pose/"><span class="md-ellipsis"> Tiger-pose </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_6_5" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../classify/"><span class="md-ellipsis"> Classification </span></a><label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_6_5_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_6_5"><span class="md-nav__icon md-icon"></span> Classification </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../classify/caltech101/"><span class="md-ellipsis"> Caltech 101 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/caltech256/"><span class="md-ellipsis"> Caltech 256 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/cifar10/"><span class="md-ellipsis"> CIFAR-10 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/cifar100/"><span class="md-ellipsis"> CIFAR-100 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/fashion-mnist/"><span class="md-ellipsis"> Fashion-MNIST </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/imagenet/"><span class="md-ellipsis"> ImageNet </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/imagenet10/"><span class="md-ellipsis"> ImageNet-10 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/imagenette/"><span class="md-ellipsis"> Imagenette </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/imagewoof/"><span class="md-ellipsis"> Imagewoof </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../classify/mnist/"><span class="md-ellipsis"> MNIST </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_6_6" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../obb/"><span class="md-ellipsis"> Oriented Bounding Boxes (OBB) </span></a><label class="md-nav__link" for="__nav_6_6" id="__nav_6_6_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_6_6_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_6_6"><span class="md-nav__icon md-icon"></span> Oriented Bounding Boxes (OBB) </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../obb/dota8/"><span class="md-ellipsis"> DOTA8 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../obb/dota-v2/"><span class="md-ellipsis"> DOTAv2 </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_6_7" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../track/"><span class="md-ellipsis"> Multi-Object Tracking </span></a></div><nav aria-expanded="false" aria-labelledby="__nav_6_7_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_6_7"><span class="md-nav__icon md-icon"></span> Multi-Object Tracking </label><ul class="md-nav__list" data-md-scrollfix=""></ul></nav></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../solutions/"><span class="md-ellipsis"> Solutions </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../guides/"><span class="md-ellipsis"> Guides </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../integrations/"><span class="md-ellipsis"> Integrations </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../platform/"><span class="md-ellipsis"> Platform </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../reference/__init__/"><span class="md-ellipsis"> Reference </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../help/"><span class="md-ellipsis"> Help </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#dataset-structure"><span class="md-ellipsis"> Dataset Structure </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#applications"><span class="md-ellipsis"> Applications </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#dataset-yaml"><span class="md-ellipsis"> Dataset YAML </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#usage"><span class="md-ellipsis"> Usage </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#sample-data-and-annotations"><span class="md-ellipsis"> Sample Data and Annotations </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#citations-and-acknowledgments"><span class="md-ellipsis"> Citations and Acknowledgments </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#what-is-the-visdrone-dataset-and-what-are-its-key-features"><span class="md-ellipsis"> What is the VisDrone Dataset and what are its key features? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-can-i-use-the-visdrone-dataset-to-train-a-yolo26-model-with-ultralytics"><span class="md-ellipsis"> How can I use the VisDrone Dataset to train a YOLO26 model with Ultralytics? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#what-are-the-main-subsets-of-the-visdrone-dataset-and-their-applications"><span class="md-ellipsis"> What are the main subsets of the VisDrone dataset and their applications? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#where-can-i-find-the-configuration-file-for-the-visdrone-dataset-in-ultralytics"><span class="md-ellipsis"> Where can I find the configuration file for the VisDrone dataset in Ultralytics? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-can-i-cite-the-visdrone-dataset-if-i-use-it-in-my-research"><span class="md-ellipsis"> How can I cite the VisDrone dataset if I use it in my research? </span></a></li></ul></nav></li></ul></nav></div></div></div><div class="md-content" data-md-component="content"><article class="md-content__inner md-typeset"><a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/datasets/detect/visdrone.md" rel="edit" title="Edit this page"><svg class="lucide lucide-file-pen" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"></path><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"></path></svg></a><a class="md-content__button md-icon" href="javascript:void(0)" onclick="copyMarkdownForLLM(this); return false;" title="Copy page in Markdown format"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></a><h1 id="visdrone-dataset">VisDrone Dataset</h1><p>The <a href="https://github.com/VisDrone/VisDrone-Dataset">VisDrone Dataset</a> is a large-scale benchmark created by the AISKYEYE team at the Lab of <a href="https://www.ultralytics.com/glossary/machine-learning-ml">Machine Learning</a> and Data Mining, Tianjin University, China. It contains carefully annotated ground truth data for various computer vision tasks related to drone-based image and video analysis.</p><p align="center"><br/><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="405" loading="lazy" src="https://www.youtube.com/embed/9ymyH4H1fG4" title="YouTube video player" width="720"></iframe><br/><strong>Watch:</strong> How to Train Ultralytics YOLO26 on the VisDrone Dataset | Aerial Detection | Complete Tutorial üöÄ
</p><p>VisDrone is composed of 288 video clips with 261,908 frames and 10,209 static images, captured by various drone-mounted cameras. The dataset covers a wide range of aspects, including location (14 different cities across China), environment (urban and rural), objects (pedestrians, vehicles, bicycles, etc.), and density (sparse and crowded scenes). The dataset was collected using various drone platforms under different scenarios and weather and lighting conditions. These frames are manually annotated with over 2.6 million bounding boxes of targets such as pedestrians, cars, bicycles, and tricycles. Attributes like scene visibility, object class, and occlusion are also provided for better data utilization.</p><h2 id="dataset-structure">Dataset Structure</h2><p>The VisDrone dataset is organized into five main subsets, each focusing on a specific task:</p><ol><li><strong>Task 1</strong>: Object detection in images</li><li><strong>Task 2</strong>: Object detection in videos</li><li><strong>Task 3</strong>: Single-object tracking</li><li><strong>Task 4</strong>: <a href="../../#multi-object-tracking">Multi-object tracking</a></li><li><strong>Task 5</strong>: Crowd counting</li></ol><h2 id="applications">Applications</h2><p>The VisDrone dataset is widely used for training and evaluating deep learning models in drone-based <a href="https://www.ultralytics.com/glossary/computer-vision-cv">computer vision</a> tasks such as object detection, object tracking, and crowd counting. The dataset's diverse set of sensor data, object annotations, and attributes make it a valuable resource for researchers and practitioners in the field of drone-based computer vision.</p><h2 id="dataset-yaml">Dataset YAML</h2><p>A YAML (Yet Another Markup Language) file is used to define the dataset configuration. It contains information about the dataset's paths, classes, and other relevant information. In the case of the Visdrone dataset, the <code>VisDrone.yaml</code> file is maintained at <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/VisDrone.yaml">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/VisDrone.yaml</a>.</p><div class="admonition example"><p class="admonition-title">ultralytics/cfg/datasets/VisDrone.yaml</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Ultralytics üöÄ AGPL-3.0 License - https://ultralytics.com/license</span>
<span></span>
<span></span><span class="c1"># VisDrone2019-DET dataset https://github.com/VisDrone/VisDrone-Dataset by Tianjin University</span>
<span></span><span class="c1"># Documentation: https://docs.ultralytics.com/datasets/detect/visdrone/</span>
<span></span><span class="c1"># Example usage: yolo train data=VisDrone.yaml</span>
<span></span><span class="c1"># parent</span>
<span></span><span class="c1"># ‚îú‚îÄ‚îÄ ultralytics</span>
<span></span><span class="c1"># ‚îî‚îÄ‚îÄ datasets</span>
<span></span><span class="c1">#     ‚îî‚îÄ‚îÄ VisDrone ‚Üê downloads here (2.3 GB)</span>
<span></span>
<span></span><span class="c1"># Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]</span>
<span></span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">VisDrone</span><span class="w"> </span><span class="c1"># dataset root dir</span>
<span></span><span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">images/train</span><span class="w"> </span><span class="c1"># train images (relative to 'path') 6471 images</span>
<span></span><span class="nt">val</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">images/val</span><span class="w"> </span><span class="c1"># val images (relative to 'path') 548 images</span>
<span></span><span class="nt">test</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">images/test</span><span class="w"> </span><span class="c1"># test-dev images (optional) 1610 images</span>
<span></span>
<span></span><span class="c1"># Classes</span>
<span></span><span class="nt">names</span><span class="p">:</span>
<span></span><span class="w">  </span><span class="nt">0</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pedestrian</span>
<span></span><span class="w">  </span><span class="nt">1</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">people</span>
<span></span><span class="w">  </span><span class="nt">2</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bicycle</span>
<span></span><span class="w">  </span><span class="nt">3</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">car</span>
<span></span><span class="w">  </span><span class="nt">4</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">van</span>
<span></span><span class="w">  </span><span class="nt">5</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">truck</span>
<span></span><span class="w">  </span><span class="nt">6</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tricycle</span>
<span></span><span class="w">  </span><span class="nt">7</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">awning-tricycle</span>
<span></span><span class="w">  </span><span class="nt">8</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bus</span>
<span></span><span class="w">  </span><span class="nt">9</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">motor</span>
<span></span>
<span></span><span class="c1"># Download script/URL (optional) ---------------------------------------------------------------------------------------</span>
<span></span><span class="nt">download</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span></span><span class="w">  </span><span class="no">import os</span>
<span></span><span class="w">  </span><span class="no">from pathlib import Path</span>
<span></span><span class="w">  </span><span class="no">import shutil</span>
<span></span>
<span></span><span class="w">  </span><span class="no">from ultralytics.utils.downloads import download</span>
<span></span><span class="w">  </span><span class="no">from ultralytics.utils import ASSETS_URL, TQDM</span>
<span></span>
<span></span>
<span></span><span class="w">  </span><span class="no">def visdrone2yolo(dir, split, source_name=None):</span>
<span></span><span class="w">      </span><span class="no">"""Convert VisDrone annotations to YOLO format with images/{split} and labels/{split} structure."""</span>
<span></span><span class="w">      </span><span class="no">from PIL import Image</span>
<span></span>
<span></span><span class="w">      </span><span class="no">source_dir = dir / (source_name or f"VisDrone2019-DET-{split}")</span>
<span></span><span class="w">      </span><span class="no">images_dir = dir / "images" / split</span>
<span></span><span class="w">      </span><span class="no">labels_dir = dir / "labels" / split</span>
<span></span><span class="w">      </span><span class="no">labels_dir.mkdir(parents=True, exist_ok=True)</span>
<span></span>
<span></span><span class="w">      </span><span class="no"># Move images to new structure</span>
<span></span><span class="w">      </span><span class="no">if (source_images_dir := source_dir / "images").exists():</span>
<span></span><span class="w">          </span><span class="no">images_dir.mkdir(parents=True, exist_ok=True)</span>
<span></span><span class="w">          </span><span class="no">for img in source_images_dir.glob("*.jpg"):</span>
<span></span><span class="w">              </span><span class="no">img.rename(images_dir / img.name)</span>
<span></span>
<span></span><span class="w">      </span><span class="no">for f in TQDM((source_dir / "annotations").glob("*.txt"), desc=f"Converting {split}"):</span>
<span></span><span class="w">          </span><span class="no">img_size = Image.open(images_dir / f.with_suffix(".jpg").name).size</span>
<span></span><span class="w">          </span><span class="no">dw, dh = 1.0 / img_size[0], 1.0 / img_size[1]</span>
<span></span><span class="w">          </span><span class="no">lines = []</span>
<span></span>
<span></span><span class="w">          </span><span class="no">with open(f, encoding="utf-8") as file:</span>
<span></span><span class="w">              </span><span class="no">for row in [x.split(",") for x in file.read().strip().splitlines()]:</span>
<span></span><span class="w">                  </span><span class="no">if row[4] != "0":  # Skip ignored regions</span>
<span></span><span class="w">                      </span><span class="no">x, y, w, h = map(int, row[:4])</span>
<span></span><span class="w">                      </span><span class="no">cls = int(row[5]) - 1</span>
<span></span><span class="w">                      </span><span class="no"># Convert to YOLO format</span>
<span></span><span class="w">                      </span><span class="no">x_center, y_center = (x + w / 2) * dw, (y + h / 2) * dh</span>
<span></span><span class="w">                      </span><span class="no">w_norm, h_norm = w * dw, h * dh</span>
<span></span><span class="w">                      </span><span class="no">lines.append(f"{cls} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\n")</span>
<span></span>
<span></span><span class="w">          </span><span class="no">(labels_dir / f.name).write_text("".join(lines), encoding="utf-8")</span>
<span></span>
<span></span>
<span></span><span class="w">  </span><span class="no"># Download (ignores test-challenge split)</span>
<span></span><span class="w">  </span><span class="no">dir = Path(yaml["path"])  # dataset root dir</span>
<span></span><span class="w">  </span><span class="no">urls = [</span>
<span></span><span class="w">      </span><span class="no">f"{ASSETS_URL}/VisDrone2019-DET-train.zip",</span>
<span></span><span class="w">      </span><span class="no">f"{ASSETS_URL}/VisDrone2019-DET-val.zip",</span>
<span></span><span class="w">      </span><span class="no">f"{ASSETS_URL}/VisDrone2019-DET-test-dev.zip",</span>
<span></span><span class="w">      </span><span class="no"># f"{ASSETS_URL}/VisDrone2019-DET-test-challenge.zip",</span>
<span></span><span class="w">  </span><span class="no">]</span>
<span></span><span class="w">  </span><span class="no">download(urls, dir=dir, threads=4)</span>
<span></span>
<span></span><span class="w">  </span><span class="no"># Convert</span>
<span></span><span class="w">  </span><span class="no">splits = {"VisDrone2019-DET-train": "train", "VisDrone2019-DET-val": "val", "VisDrone2019-DET-test-dev": "test"}</span>
<span></span><span class="w">  </span><span class="no">for folder, split in splits.items():</span>
<span></span><span class="w">      </span><span class="no">visdrone2yolo(dir, split, folder)  # convert VisDrone annotations to YOLO labels</span>
<span></span><span class="w">      </span><span class="no">shutil.rmtree(dir / folder)  # cleanup original directory</span>
</code></pre></div></div><h2 id="usage">Usage</h2><p>To train a YOLO26n model on the VisDrone dataset for 100 <a href="https://www.ultralytics.com/glossary/epoch">epochs</a> with an image size of 640, you can use the following code snippets. For a comprehensive list of available arguments, refer to the model <a href="../../../modes/train/">Training</a> page.</p><div class="admonition example"><p class="admonition-title">Train Example</p><div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="python" name="__tabbed_1" type="radio"/><input id="cli" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="python">Python</label><label for="cli">CLI</label></div><div class="tabbed-content"><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="c1"># Load a model</span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolo26n.pt"</span><span class="p">)</span>  <span class="c1"># load a pretrained model (recommended for training)</span>
<span></span>
<span></span><span class="c1"># Train the model</span>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s2">"VisDrone.yaml"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">)</span>
</code></pre></div></div><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Start training from a pretrained *.pt model</span>
<span></span>yolo<span class="w"> </span>detect<span class="w"> </span>train<span class="w"> </span><span class="nv">data</span><span class="o">=</span>VisDrone.yaml<span class="w"> </span><span class="nv">model</span><span class="o">=</span>yolo26n.pt<span class="w"> </span><span class="nv">epochs</span><span class="o">=</span><span class="m">100</span><span class="w"> </span><span class="nv">imgsz</span><span class="o">=</span><span class="m">640</span>
</code></pre></div></div></div></div></div><h2 id="sample-data-and-annotations">Sample Data and Annotations</h2><p>The VisDrone dataset contains a diverse set of images and videos captured by drone-mounted cameras. Here are some examples of data from the dataset, along with their corresponding annotations:</p><p><img alt="VisDrone dataset aerial drone imagery with object detection" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/visdrone-object-detection-sample.avif"/></p><ul><li><strong>Task 1</strong>: <a href="https://www.ultralytics.com/glossary/object-detection">Object detection</a> in images - This image demonstrates an example of object detection in images, where objects are annotated with <a href="https://www.ultralytics.com/glossary/bounding-box">bounding boxes</a>. The dataset provides a wide variety of images taken from different locations, environments, and densities to facilitate the development of models for this task.</li></ul><p>The example showcases the variety and complexity of the data in the VisDrone dataset and highlights the importance of high-quality sensor data for drone-based computer vision tasks.</p><h2 id="citations-and-acknowledgments">Citations and Acknowledgments</h2><p>If you use the VisDrone dataset in your research or development work, please cite the following paper:</p><div class="admonition quote"><div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="bibtex" name="__tabbed_2" type="radio"/><div class="tabbed-labels"><label for="bibtex">BibTeX</label></div><div class="tabbed-content"><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="nc">@ARTICLE</span><span class="p">{</span><span class="nl">9573394</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Zhu, Pengfei and Wen, Longyin and Du, Dawei and Bian, Xiao and Fan, Heng and Hu, Qinghua and Ling, Haibin}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Detection and Tracking Meet Drones Challenge}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">number</span><span class="p">=</span><span class="s">{}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{1-1}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">doi</span><span class="p">=</span><span class="s">{10.1109/TPAMI.2021.3119563}</span><span class="p">}</span>
</code></pre></div></div></div></div></div><p>We would like to acknowledge the AISKYEYE team at the Lab of Machine Learning and <a href="https://www.ultralytics.com/glossary/data-mining">Data Mining</a>, Tianjin University, China, for creating and maintaining the VisDrone dataset as a valuable resource for the drone-based computer vision research community. For more information about the VisDrone dataset and its creators, visit the <a href="https://github.com/VisDrone/VisDrone-Dataset">VisDrone Dataset GitHub repository</a>.</p><h2 id="faq">FAQ</h2><h3 id="what-is-the-visdrone-dataset-and-what-are-its-key-features">What is the VisDrone Dataset and what are its key features?</h3><p>The <a href="https://github.com/VisDrone/VisDrone-Dataset">VisDrone Dataset</a> is a large-scale benchmark created by the AISKYEYE team at Tianjin University, China. It is designed for various computer vision tasks related to drone-based image and video analysis. Key features include:</p><ul><li><strong>Composition</strong>: 288 video clips with 261,908 frames and 10,209 static images.</li><li><strong>Annotations</strong>: Over 2.6 million bounding boxes for objects like pedestrians, cars, bicycles, and tricycles.</li><li><strong>Diversity</strong>: Collected across 14 cities, in urban and rural settings, under different weather and lighting conditions.</li><li><strong>Tasks</strong>: Split into five main tasks‚Äîobject detection in images and videos, single-object and multi-object tracking, and crowd counting.</li></ul><h3 id="how-can-i-use-the-visdrone-dataset-to-train-a-yolo26-model-with-ultralytics">How can I use the VisDrone Dataset to train a YOLO26 model with Ultralytics?</h3><p>To train a YOLO26 model on the VisDrone dataset for 100 epochs with an image size of 640, you can follow these steps:</p><div class="admonition example"><p class="admonition-title">Train Example</p><div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="python_1" name="__tabbed_3" type="radio"/><input id="cli_1" name="__tabbed_3" type="radio"/><div class="tabbed-labels"><label for="python_1">Python</label><label for="cli_1">CLI</label></div><div class="tabbed-content"><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="c1"># Load a pretrained model</span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolo26n.pt"</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Train the model</span>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s2">"VisDrone.yaml"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">)</span>
</code></pre></div></div><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Start training from a pretrained *.pt model</span>
<span></span>yolo<span class="w"> </span>detect<span class="w"> </span>train<span class="w"> </span><span class="nv">data</span><span class="o">=</span>VisDrone.yaml<span class="w"> </span><span class="nv">model</span><span class="o">=</span>yolo26n.pt<span class="w"> </span><span class="nv">epochs</span><span class="o">=</span><span class="m">100</span><span class="w"> </span><span class="nv">imgsz</span><span class="o">=</span><span class="m">640</span>
</code></pre></div></div></div></div></div><p>For additional configuration options, please refer to the model <a href="../../../modes/train/">Training</a> page.</p><h3 id="what-are-the-main-subsets-of-the-visdrone-dataset-and-their-applications">What are the main subsets of the VisDrone dataset and their applications?</h3><p>The VisDrone dataset is divided into five main subsets, each tailored for a specific computer vision task:</p><ol><li><strong>Task 1</strong>: Object detection in images.</li><li><strong>Task 2</strong>: Object detection in videos.</li><li><strong>Task 3</strong>: Single-object tracking.</li><li><strong>Task 4</strong>: Multi-object tracking.</li><li><strong>Task 5</strong>: Crowd counting.</li></ol><p>These subsets are widely used for training and evaluating <a href="https://www.ultralytics.com/glossary/deep-learning-dl">deep learning</a> models in drone-based applications such as surveillance, traffic monitoring, and public safety.</p><h3 id="where-can-i-find-the-configuration-file-for-the-visdrone-dataset-in-ultralytics">Where can I find the configuration file for the VisDrone dataset in Ultralytics?</h3><p>The configuration file for the VisDrone dataset, <code>VisDrone.yaml</code>, can be found in the Ultralytics repository at the following link:
<a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/VisDrone.yaml">VisDrone.yaml</a>.</p><h3 id="how-can-i-cite-the-visdrone-dataset-if-i-use-it-in-my-research">How can I cite the VisDrone dataset if I use it in my research?</h3><p>If you use the VisDrone dataset in your research or development work, please cite the following paper:</p><div class="admonition quote"><div class="tabbed-set tabbed-alternate" data-tabs="4:1"><input checked="checked" id="bibtex_1" name="__tabbed_4" type="radio"/><div class="tabbed-labels"><label for="bibtex_1">BibTeX</label></div><div class="tabbed-content"><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="nc">@ARTICLE</span><span class="p">{</span><span class="nl">9573394</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Zhu, Pengfei and Wen, Longyin and Du, Dawei and Bian, Xiao and Fan, Heng and Hu, Qinghua and Ling, Haibin}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Detection and Tracking Meet Drones Challenge}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">number</span><span class="p">=</span><span class="s">{}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{1-1}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">doi</span><span class="p">=</span><span class="s">{10.1109/TPAMI.2021.3119563}</span>
<span></span><span class="p">}</span>
</code></pre></div></div></div></div></div><br/><br/><div class="git-info"><div class="dates-container"><span class="date-item" title="This page was first created on November 12, 2023"><span class="hover-item">üìÖ</span> Created 2 years ago </span><span class="date-item" title="This page was last updated on January 20, 2026"><span class="hover-item">‚úèÔ∏è</span> Updated 9 days ago </span></div><div class="authors-container"><a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (12 changes)"><img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/RizwanMunawar" title="RizwanMunawar (3 changes)"><img alt="RizwanMunawar" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62513924?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/UltralyticsAssistant" title="UltralyticsAssistant (1 change)"><img alt="UltralyticsAssistant" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/135830346?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/MatthewNoyce" title="MatthewNoyce (1 change)"><img alt="MatthewNoyce" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/131261051?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)"><img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/></a></div></div><div class="share-buttons"><button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https%3A%2F%2Fdocs.ultralytics.com%2Fdatasets%2Fdetect%2Fvisdrone%2F', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet </button><button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdocs.ultralytics.com%2Fdatasets%2Fdetect%2Fvisdrone%2F', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share </button></div><br/><h2 id="__comments">Comments</h2><div id="giscus-container"></div></article></div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div><button class="md-top md-icon" data-md-component="top" hidden="" type="button"><svg class="lucide lucide-circle-arrow-up" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><path d="m16 12-4-4-4 4M12 16V8"></path></svg> Back to top
</button></main><footer class="md-footer"><nav aria-label="Footer" class="md-footer__inner md-grid"><a aria-label="Previous: TT100K" class="md-footer__link md-footer__link--prev" href="../tt100k/"><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-left" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12 19-7-7 7-7M19 12H5"></path></svg></div><div class="md-footer__title"><span class="md-footer__direction"> Previous </span><div class="md-ellipsis"> TT100K </div></div></a><a aria-label="Next: VOC" class="md-footer__link md-footer__link--next" href="../voc/"><div class="md-footer__title"><span class="md-footer__direction"> Next </span><div class="md-ellipsis"> VOC </div></div><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-right" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 12h14M12 5l7 7-7 7"></path></svg></div></a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-copyright"><div class="md-copyright__highlight"><a href="https://www.ultralytics.com/" target="_blank">¬© 2026 Ultralytics Inc.</a> All rights reserved. </div> Made with <a href="https://zensical.org/" rel="noopener" target="_blank"> Zensical </a></div><div class="md-social"><a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg></a></div></div></div></footer></div><div class="md-dialog" data-md-component="dialog"><div class="md-dialog__inner md-typeset"></div></div><div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"annotate":null,"base":"../../..","features":["content.action.edit","content.code.annotate","content.code.copy","content.tooltips","toc.follow","navigation.top","navigation.tabs","navigation.tabs.sticky","navigation.prune","navigation.footer","navigation.tracking","navigation.instant","navigation.instant.progress","navigation.indexes","navigation.sections","content.tabs.link"],"search":"../../../assets/javascripts/workers/search.e2d2d235.min.js","tags":null,"translations":{"clipboard.copied":"Copied to clipboard","clipboard.copy":"Copy to clipboard","search.result.more.one":"1 more on this page","search.result.more.other":"# more on this page","search.result.none":"No matching documents","search.result.one":"1 matching document","search.result.other":"# matching documents","search.result.placeholder":"Type to start searching","search.result.term.missing":"Missing","select.version":"Select version"},"version":null}</script>
<script src="../../../assets/javascripts/bundle.8ffeb9c9.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ultralytics/llm@v0.1.8/js/chat.min.js"></script>
<script src="https://unpkg.com/tablesort@5.6.0/dist/tablesort.min.js"></script>
<script src="../../../javascript/extra.js"></script>
<script src="../../../javascript/giscus.js"></script>
<script src="../../../javascript/tablesort.js"></script>
<script>
            async function copyMarkdownForLLM(button) {
                const editBtn = document.querySelector('a[title="Edit this page"]');
                if (!editBtn) return;

                const originalHTML = button.innerHTML;
                const checkIcon = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19L21 7l-1.41-1.41L9 16.17z"></path></svg>';

                let rawUrl = editBtn.href.replace('github.com', 'raw.githubusercontent.com');
                rawUrl = rawUrl.replace('/blob/', '/').replace('/tree/', '/');

                try {
                    const response = await fetch(rawUrl);
                    let markdown = await response.text();

                    if (markdown.startsWith('---')) {
                        const frontMatterEnd = markdown.indexOf('\n---\n', 3);
                        if (frontMatterEnd !== -1) {
                            markdown = markdown.substring(frontMatterEnd + 5).trim();
                        }
                    }

                    const title = document.querySelector('h1')?.textContent || document.title;
                    const content = `# ${title}\n\nSource: ${window.location.href}\n\n---\n\n${markdown}`;

                    await navigator.clipboard.writeText(content);
                    button.innerHTML = checkIcon + ' Copied!';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                } catch (err) {
                    button.innerHTML = '‚ùå Failed';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                }
            }
            </script></body></html>