<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities." name="description"/>
<meta content="Ultralytics" name="author"/>
<link href="https://docs.ultralytics.com/reference/models/sam/predict/" rel="canonical"/>
<link href="../modules/utils/" rel="prev"/>
<link href="../../utils/loss/" rel="next"/>
<link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.12" name="generator"/>
<title>Reference for ultralytics/models/sam/predict.py</title>
<link href="../../../../assets/stylesheets/main.2afb09e1.min.css" rel="stylesheet"/>
<link href="../../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="predict" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="Ultralytics, SAM, Segment Anything Model, SAM 2, Segment Anything Model 2, image segmentation, real-time, prediction, AI, machine learning, Python, torch, inference" name="keywords"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/reference/models/sam/predict" property="og:url"/><meta content="predict" property="og:title"/><meta content="Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities." property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/reference/models/sam/predict" property="twitter:url"/><meta content="predict" property="twitter:title"/><meta content="Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities." property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "headline": "predict", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2024-11-26 19:38:23 +0800", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities."}</script></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#reference-for-ultralyticsmodelssampredictpy">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<div class="banner-wrapper">
<div class="banner-content-wrapper" onclick="window.open('https://docs.ultralytics.com/models/yolo11/')">
<p>Introducing</p>
<img alt="Ultralytics YOLO11" height="40" loading="lazy" src="https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/67d044caa316aa50fba40a08_Ultralytics_YOLO11_Logotype_Reverse.svg"/>
</div>
</div>
</div>
</aside>
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Ultralytics YOLO Docs
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
              predict
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg>
</label>
<input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../..">
  Home
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../quickstart/">
  Quickstart
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../modes/">
  Modes
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../tasks/">
  Tasks
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../models/">
  Models
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../datasets/">
  Datasets
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../solutions/">
  Solutions 🚀
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../guides/">
  Guides
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../integrations/">
  Integrations
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../hub/">
  HUB
        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../cfg/__init__/">
  Reference
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../help/">
  Help
        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
    Ultralytics YOLO Docs
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../..">
<span class="md-ellipsis">
    Home
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../quickstart/">
<span class="md-ellipsis">
    Quickstart
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../modes/">
<span class="md-ellipsis">
    Modes
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../tasks/">
<span class="md-ellipsis">
    Tasks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../models/">
<span class="md-ellipsis">
    Models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../datasets/">
<span class="md-ellipsis">
    Datasets
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../solutions/">
<span class="md-ellipsis">
    Solutions 🚀
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../guides/">
<span class="md-ellipsis">
    Guides
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../integrations/">
<span class="md-ellipsis">
    Integrations
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../hub/">
<span class="md-ellipsis">
    HUB
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_11">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_1" id="__nav_11_1_label" tabindex="">
<span class="md-ellipsis">
    cfg
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_1">
<span class="md-nav__icon md-icon"></span>
            cfg
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../cfg/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_2" id="__nav_11_2_label" tabindex="">
<span class="md-ellipsis">
    data
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_2">
<span class="md-nav__icon md-icon"></span>
            data
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/annotator/">
<span class="md-ellipsis">
    annotator
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/augment/">
<span class="md-ellipsis">
    augment
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/base/">
<span class="md-ellipsis">
    base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/converter/">
<span class="md-ellipsis">
    converter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/dataset/">
<span class="md-ellipsis">
    dataset
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/loaders/">
<span class="md-ellipsis">
    loaders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/split/">
<span class="md-ellipsis">
    split
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/split_dota/">
<span class="md-ellipsis">
    split_dota
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_3" id="__nav_11_3_label" tabindex="">
<span class="md-ellipsis">
    engine
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_3">
<span class="md-nav__icon md-icon"></span>
            engine
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/exporter/">
<span class="md-ellipsis">
    exporter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/predictor/">
<span class="md-ellipsis">
    predictor
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/results/">
<span class="md-ellipsis">
    results
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/trainer/">
<span class="md-ellipsis">
    trainer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/validator/">
<span class="md-ellipsis">
    validator
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_4" id="__nav_11_4_label" tabindex="">
<span class="md-ellipsis">
    hub
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_4">
<span class="md-nav__icon md-icon"></span>
            hub
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/auth/">
<span class="md-ellipsis">
    auth
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../hub/google/__init__/">
<span class="md-ellipsis">
    google
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/session/">
<span class="md-ellipsis">
    session
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5" id="__nav_11_5_label" tabindex="">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_5">
<span class="md-nav__icon md-icon"></span>
            models
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../fastsam/model/">
<span class="md-ellipsis">
    fastsam
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../nas/model/">
<span class="md-ellipsis">
    nas
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../rtdetr/model/">
<span class="md-ellipsis">
    rtdetr
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5_4" id="__nav_11_5_4_label" tabindex="0">
<span class="md-ellipsis">
    sam
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_4_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_11_5_4">
<span class="md-nav__icon md-icon"></span>
            sam
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../amg/">
<span class="md-ellipsis">
    amg
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../modules/blocks/">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    predict
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    predict
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Predictor
    </span>
</a>
<nav aria-label=" Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.generate">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> generate
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.pre_transform">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> pre_transform
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.preprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> preprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.prompt_inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> prompt_inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.remove_small_regions">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> remove_small_regions
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.reset_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> reset_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> set_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> set_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> setup_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_source">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> setup_source
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> SAM2Predictor
    </span>
</a>
<nav aria-label=" SAM2Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.prompt_inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> prompt_inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> set_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> SAM2VideoPredictor
    </span>
</a>
<nav aria-label=" SAM2VideoPredictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> add_new_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.init_state">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> init_state
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> propagate_in_video_preflight
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../utils/loss/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../yolo/classify/predict/">
<span class="md-ellipsis">
    yolo
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_6" id="__nav_11_6_label" tabindex="">
<span class="md-ellipsis">
    nn
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_6">
<span class="md-nav__icon md-icon"></span>
            nn
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nn/autobackend/">
<span class="md-ellipsis">
    autobackend
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../nn/modules/activation/">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nn/tasks/">
<span class="md-ellipsis">
    tasks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nn/text_model/">
<span class="md-ellipsis">
    text_model
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_7" id="__nav_11_7_label" tabindex="">
<span class="md-ellipsis">
    solutions
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_7">
<span class="md-nav__icon md-icon"></span>
            solutions
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/ai_gym/">
<span class="md-ellipsis">
    ai_gym
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/analytics/">
<span class="md-ellipsis">
    analytics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/config/">
<span class="md-ellipsis">
    config
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/distance_calculation/">
<span class="md-ellipsis">
    distance_calculation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/heatmap/">
<span class="md-ellipsis">
    heatmap
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/instance_segmentation/">
<span class="md-ellipsis">
    instance_segmentation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/object_blurrer/">
<span class="md-ellipsis">
    object_blurrer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/object_counter/">
<span class="md-ellipsis">
    object_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/object_cropper/">
<span class="md-ellipsis">
    object_cropper
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/parking_management/">
<span class="md-ellipsis">
    parking_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/queue_management/">
<span class="md-ellipsis">
    queue_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/region_counter/">
<span class="md-ellipsis">
    region_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/security_alarm/">
<span class="md-ellipsis">
    security_alarm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/similarity_search/">
<span class="md-ellipsis">
    similarity_search
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/solutions/">
<span class="md-ellipsis">
    solutions
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/speed_estimation/">
<span class="md-ellipsis">
    speed_estimation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/streamlit_inference/">
<span class="md-ellipsis">
    streamlit_inference
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/trackzone/">
<span class="md-ellipsis">
    trackzone
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/vision_eye/">
<span class="md-ellipsis">
    vision_eye
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_8" id="__nav_11_8_label" tabindex="">
<span class="md-ellipsis">
    trackers
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_8_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_8">
<span class="md-nav__icon md-icon"></span>
            trackers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/basetrack/">
<span class="md-ellipsis">
    basetrack
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/bot_sort/">
<span class="md-ellipsis">
    bot_sort
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/byte_tracker/">
<span class="md-ellipsis">
    byte_tracker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/track/">
<span class="md-ellipsis">
    track
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../trackers/utils/gmc/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_9" id="__nav_11_9_label" tabindex="">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_9_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_9">
<span class="md-nav__icon md-icon"></span>
            utils
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/autobatch/">
<span class="md-ellipsis">
    autobatch
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/autodevice/">
<span class="md-ellipsis">
    autodevice
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/benchmarks/">
<span class="md-ellipsis">
    benchmarks
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../utils/callbacks/base/">
<span class="md-ellipsis">
    callbacks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/checks/">
<span class="md-ellipsis">
    checks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/dist/">
<span class="md-ellipsis">
    dist
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/downloads/">
<span class="md-ellipsis">
    downloads
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/errors/">
<span class="md-ellipsis">
    errors
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/export/">
<span class="md-ellipsis">
    export
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/files/">
<span class="md-ellipsis">
    files
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/instance/">
<span class="md-ellipsis">
    instance
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/loss/">
<span class="md-ellipsis">
    loss
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/metrics/">
<span class="md-ellipsis">
    metrics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/ops/">
<span class="md-ellipsis">
    ops
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/patches/">
<span class="md-ellipsis">
    patches
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/plotting/">
<span class="md-ellipsis">
    plotting
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/tal/">
<span class="md-ellipsis">
    tal
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/torch_utils/">
<span class="md-ellipsis">
    torch_utils
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/triton/">
<span class="md-ellipsis">
    triton
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../help/">
<span class="md-ellipsis">
    Help
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Predictor
    </span>
</a>
<nav aria-label=" Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.generate">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> generate
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.pre_transform">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> pre_transform
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.preprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> preprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.prompt_inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> prompt_inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.remove_small_regions">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> remove_small_regions
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.reset_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> reset_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> set_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> set_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> setup_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_source">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> setup_source
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> SAM2Predictor
    </span>
</a>
<nav aria-label=" SAM2Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.prompt_inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> prompt_inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> set_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> SAM2VideoPredictor
    </span>
</a>
<nav aria-label=" SAM2VideoPredictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> add_new_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.init_state">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> init_state
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> propagate_in_video_preflight
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/reference/models/sam/predict.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<h1 id="reference-for-ultralyticsmodelssampredictpy">Reference for <code>ultralytics/models/sam/predict.py</code></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This file is available at <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/predict.py">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/predict.py</a>. If you spot a problem please help fix it by <a href="https://docs.ultralytics.com/help/contributing/">contributing</a> a <a href="https://github.com/ultralytics/ultralytics/edit/main/ultralytics/models/sam/predict.py">Pull Request</a> 🛠️. Thank you 🙏!</p>
</div>
<p><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.Predictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="../../../engine/predictor/#ultralytics.engine.predictor.BasePredictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.engine.predictor.BasePredictor&lt;/span&gt;'>BasePredictor</a></code></p>
<p>Predictor class for SAM, enabling real-time image segmentation with promptable capabilities.</p>
<p>This class extends BasePredictor and implements the Segment Anything Model (SAM) for advanced image
segmentation tasks. It supports various input prompts like points, bounding boxes, and masks for
fine-grained control over segmentation results.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.args">args</span></code></td>
<td>
<code><span title="SimpleNamespace">SimpleNamespace</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration arguments for the predictor.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.model">model</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The loaded SAM model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.device">device</span></code></td>
<td>
<code><span title="torch.device">device</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The device (CPU or GPU) on which the model is loaded.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.im">im</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed input image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.features">features</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Extracted image features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.prompts">prompts</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary to store various types of prompts (e.g., bboxes, points, masks).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.segment_all">segment_all</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to indicate if full image segmentation should be performed.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.mean">mean</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Mean values for image normalization.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.std">std</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Standard deviation values for image normalization.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.preprocess" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;preprocess&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.preprocess&lt;/code&gt;)'>preprocess</a></code></td>
<td>
<div class="doc-md-description">
<p>Prepares input images for model inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.pre_transform" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;pre_transform&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.pre_transform&lt;/code&gt;)'>pre_transform</a></code></td>
<td>
<div class="doc-md-description">
<p>Performs initial transformations on the input image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.inference&lt;/code&gt;)'>inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Performs segmentation inference based on input prompts.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.prompt_inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;prompt_inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.prompt_inference&lt;/code&gt;)'>prompt_inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Internal function for prompt-based segmentation inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.generate" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;generate&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.generate&lt;/code&gt;)'>generate</a></code></td>
<td>
<div class="doc-md-description">
<p>Generates segmentation masks for an entire image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.setup_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;setup_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.setup_model&lt;/code&gt;)'>setup_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Initializes the SAM model for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.get_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.get_model&lt;/code&gt;)'>get_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Builds and returns a SAM model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.postprocess" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;postprocess&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.postprocess&lt;/code&gt;)'>postprocess</a></code></td>
<td>
<div class="doc-md-description">
<p>Post-processes model outputs to generate final results.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.setup_source" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;setup_source&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.setup_source&lt;/code&gt;)'>setup_source</a></code></td>
<td>
<div class="doc-md-description">
<p>Sets up the data source for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.set_image" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;set_image&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.set_image&lt;/code&gt;)'>set_image</a></code></td>
<td>
<div class="doc-md-description">
<p>Sets and preprocesses a single image for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.get_im_features" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_im_features&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.get_im_features&lt;/code&gt;)'>get_im_features</a></code></td>
<td>
<div class="doc-md-description">
<p>Extracts image features using the SAM image encoder.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.set_prompts" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;set_prompts&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.set_prompts&lt;/code&gt;)'>set_prompts</a></code></td>
<td>
<div class="doc-md-description">
<p>Sets prompts for subsequent inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.reset_image" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;reset_image&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.reset_image&lt;/code&gt;)'>reset_image</a></code></td>
<td>
<div class="doc-md-description">
<p>Resets the current image and its features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.remove_small_regions" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;remove_small_regions&lt;/span&gt;
  &lt;span class="doc doc-labels"&gt;
      &lt;small class="doc doc-label doc-label-staticmethod"&gt;&lt;code&gt;staticmethod&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.remove_small_regions&lt;/code&gt;)'>remove_small_regions</a></code></td>
<td>
<div class="doc-md-description">
<p>Removes small disconnected regions and holes from masks.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"sam_model.pt"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)</span>
</code></pre></div>
<p>Sets up the Predictor object for SAM (Segment Anything Model) and applies any configuration overrides or
callbacks provided. Initializes task-specific settings for SAM, such as retina_masks being set to True
for optimal results.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>cfg</code>
</td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration dictionary containing default settings.</p>
</div>
</td>
<td>
<code><span title="ultralytics.utils.DEFAULT_CFG">DEFAULT_CFG</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>overrides</code>
</td>
<td>
<code><span title="Dict">Dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of values to override default configuration.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>_callbacks</code>
</td>
<td>
<code><span title="Dict">Dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of callback functions to customize behavior.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_imgsz</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">overrides</span><span class="o">=</span><span class="p">{</span><span class="s2">"imgsz"</span><span class="p">:</span> <span class="mi">640</span><span class="p">})</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_callback</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">_callbacks</span><span class="o">=</span><span class="p">{</span><span class="s2">"on_predict_start"</span><span class="p">:</span> <span class="n">custom_callback</span><span class="p">})</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span> 79</span>
<span> 80</span>
<span> 81</span>
<span> 82</span>
<span> 83</span>
<span> 84</span>
<span> 85</span>
<span> 86</span>
<span> 87</span>
<span> 88</span>
<span> 89</span>
<span> 90</span>
<span> 91</span>
<span> 92</span>
<span> 93</span>
<span> 94</span>
<span> 95</span>
<span> 96</span>
<span> 97</span>
<span> 98</span>
<span> 99</span>
<span>100</span>
<span>101</span>
<span>102</span>
<span>103</span>
<span>104</span>
<span>105</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the Predictor with configuration, overrides, and callbacks.</span>
<span></span>
<span></span><span class="sd">    Sets up the Predictor object for SAM (Segment Anything Model) and applies any configuration overrides or</span>
<span></span><span class="sd">    callbacks provided. Initializes task-specific settings for SAM, such as retina_masks being set to True</span>
<span></span><span class="sd">    for optimal results.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (dict): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (Dict | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        _callbacks (Dict | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example = Predictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = Predictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = Predictor(_callbacks={"on_predict_start": custom_callback})</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">overrides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">overrides</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="n">overrides</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">"segment"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"predict"</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">retina_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.generate">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">generate</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">generate</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">crop_n_layers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">crop_overlap_ratio</span><span class="o">=</span><span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span>
<span></span>    <span class="n">crop_downscale_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span></span>    <span class="n">point_grids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points_stride</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span></span>    <span class="n">points_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span></span>    <span class="n">conf_thres</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_offset</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">crop_nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation using the Segment Anything Model (SAM).</p>
<p>This method segments an entire image into constituent parts by leveraging SAM's advanced architecture
and real-time performance capabilities. It can optionally work on image crops for finer segmentation.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Input tensor representing the preprocessed image with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_n_layers</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of layers for additional mask predictions on image crops.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_overlap_ratio</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Overlap between crops, scaled down in subsequent layers.</p>
</div>
</td>
<td>
<code>512 / 1500</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_downscale_factor</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Scaling factor for sampled points-per-side in each layer.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>point_grids</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Custom grids for point sampling normalized to [0,1].</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points_stride</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of points to sample along each side of the image.</p>
</div>
</td>
<td>
<code>32</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points_batch_size</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Batch size for the number of points processed simultaneously.</p>
</div>
</td>
<td>
<code>64</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>conf_thres</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Confidence threshold [0,1] for filtering based on mask quality prediction.</p>
</div>
</td>
<td>
<code>0.88</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stability_score_thresh</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Stability threshold [0,1] for mask filtering based on stability.</p>
</div>
</td>
<td>
<code>0.95</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stability_score_offset</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Offset value for calculating stability score.</p>
</div>
</td>
<td>
<code>0.95</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_nms_thresh</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>IoU cutoff for NMS to remove duplicate masks between crops.</p>
</div>
</td>
<td>
<code>0.7</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Segmented masks with shape (N, H, W).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_scores</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Confidence scores for each mask with shape (N,).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_bboxes</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes for each mask with shape (N, 4).</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>  <span class="c1"># Example input image</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">boxes</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>296</span>
<span>297</span>
<span>298</span>
<span>299</span>
<span>300</span>
<span>301</span>
<span>302</span>
<span>303</span>
<span>304</span>
<span>305</span>
<span>306</span>
<span>307</span>
<span>308</span>
<span>309</span>
<span>310</span>
<span>311</span>
<span>312</span>
<span>313</span>
<span>314</span>
<span>315</span>
<span>316</span>
<span>317</span>
<span>318</span>
<span>319</span>
<span>320</span>
<span>321</span>
<span>322</span>
<span>323</span>
<span>324</span>
<span>325</span>
<span>326</span>
<span>327</span>
<span>328</span>
<span>329</span>
<span>330</span>
<span>331</span>
<span>332</span>
<span>333</span>
<span>334</span>
<span>335</span>
<span>336</span>
<span>337</span>
<span>338</span>
<span>339</span>
<span>340</span>
<span>341</span>
<span>342</span>
<span>343</span>
<span>344</span>
<span>345</span>
<span>346</span>
<span>347</span>
<span>348</span>
<span>349</span>
<span>350</span>
<span>351</span>
<span>352</span>
<span>353</span>
<span>354</span>
<span>355</span>
<span>356</span>
<span>357</span>
<span>358</span>
<span>359</span>
<span>360</span>
<span>361</span>
<span>362</span>
<span>363</span>
<span>364</span>
<span>365</span>
<span>366</span>
<span>367</span>
<span>368</span>
<span>369</span>
<span>370</span>
<span>371</span>
<span>372</span>
<span>373</span>
<span>374</span>
<span>375</span>
<span>376</span>
<span>377</span>
<span>378</span>
<span>379</span>
<span>380</span>
<span>381</span>
<span>382</span>
<span>383</span>
<span>384</span>
<span>385</span>
<span>386</span>
<span>387</span>
<span>388</span>
<span>389</span>
<span>390</span>
<span>391</span>
<span>392</span>
<span>393</span>
<span>394</span>
<span>395</span>
<span>396</span>
<span>397</span>
<span>398</span>
<span>399</span>
<span>400</span>
<span>401</span>
<span>402</span>
<span>403</span>
<span>404</span>
<span>405</span>
<span>406</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">crop_n_layers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">crop_overlap_ratio</span><span class="o">=</span><span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span>
<span></span>    <span class="n">crop_downscale_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span></span>    <span class="n">point_grids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points_stride</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span></span>    <span class="n">points_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span></span>    <span class="n">conf_thres</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_offset</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">crop_nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
<span></span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation using the Segment Anything Model (SAM).</span>
<span></span>
<span></span><span class="sd">    This method segments an entire image into constituent parts by leveraging SAM's advanced architecture</span>
<span></span><span class="sd">    and real-time performance capabilities. It can optionally work on image crops for finer segmentation.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): Input tensor representing the preprocessed image with shape (N, C, H, W).</span>
<span></span><span class="sd">        crop_n_layers (int): Number of layers for additional mask predictions on image crops.</span>
<span></span><span class="sd">        crop_overlap_ratio (float): Overlap between crops, scaled down in subsequent layers.</span>
<span></span><span class="sd">        crop_downscale_factor (int): Scaling factor for sampled points-per-side in each layer.</span>
<span></span><span class="sd">        point_grids (List[np.ndarray] | None): Custom grids for point sampling normalized to [0,1].</span>
<span></span><span class="sd">        points_stride (int): Number of points to sample along each side of the image.</span>
<span></span><span class="sd">        points_batch_size (int): Batch size for the number of points processed simultaneously.</span>
<span></span><span class="sd">        conf_thres (float): Confidence threshold [0,1] for filtering based on mask quality prediction.</span>
<span></span><span class="sd">        stability_score_thresh (float): Stability threshold [0,1] for mask filtering based on stability.</span>
<span></span><span class="sd">        stability_score_offset (float): Offset value for calculating stability score.</span>
<span></span><span class="sd">        crop_nms_thresh (float): IoU cutoff for NMS to remove duplicate masks between crops.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): Segmented masks with shape (N, H, W).</span>
<span></span><span class="sd">        pred_scores (torch.Tensor): Confidence scores for each mask with shape (N,).</span>
<span></span><span class="sd">        pred_bboxes (torch.Tensor): Bounding boxes for each mask with shape (N, 4).</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; im = torch.rand(1, 3, 1024, 1024)  # Example input image</span>
<span></span><span class="sd">        &gt;&gt;&gt; masks, scores, boxes = predictor.generate(im)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>  <span class="c1"># scope for faster 'import ultralytics'</span>
<span></span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
<span></span>    <span class="n">crop_regions</span><span class="p">,</span> <span class="n">layer_idxs</span> <span class="o">=</span> <span class="n">generate_crop_boxes</span><span class="p">((</span><span class="n">ih</span><span class="p">,</span> <span class="n">iw</span><span class="p">),</span> <span class="n">crop_n_layers</span><span class="p">,</span> <span class="n">crop_overlap_ratio</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">point_grids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">point_grids</span> <span class="o">=</span> <span class="n">build_all_layer_point_grids</span><span class="p">(</span><span class="n">points_stride</span><span class="p">,</span> <span class="n">crop_n_layers</span><span class="p">,</span> <span class="n">crop_downscale_factor</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">,</span> <span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">region_areas</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">crop_region</span><span class="p">,</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">crop_regions</span><span class="p">,</span> <span class="n">layer_idxs</span><span class="p">):</span>
<span></span>        <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">crop_region</span>
<span></span>        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">-</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y2</span> <span class="o">-</span> <span class="n">y1</span>
<span></span>        <span class="n">area</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">h</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">im</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="n">points_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">]])</span>  <span class="c1"># w, h</span>
<span></span>        <span class="c1"># Crop image and interpolate to input size</span>
<span></span>        <span class="n">crop_im</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">im</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">],</span> <span class="p">(</span><span class="n">ih</span><span class="p">,</span> <span class="n">iw</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>        <span class="c1"># (num_points, 2)</span>
<span></span>        <span class="n">points_for_image</span> <span class="o">=</span> <span class="n">point_grids</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">points_scale</span>
<span></span>        <span class="n">crop_masks</span><span class="p">,</span> <span class="n">crop_scores</span><span class="p">,</span> <span class="n">crop_bboxes</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span></span>        <span class="k">for</span> <span class="p">(</span><span class="n">points</span><span class="p">,)</span> <span class="ow">in</span> <span class="n">batch_iterator</span><span class="p">(</span><span class="n">points_batch_size</span><span class="p">,</span> <span class="n">points_for_image</span><span class="p">):</span>
<span></span>            <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_inference</span><span class="p">(</span><span class="n">crop_im</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span>            <span class="c1"># Interpolate predicted masks to input size</span>
<span></span>            <span class="n">pred_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">pred_score</span> <span class="o">&gt;</span> <span class="n">conf_thres</span>
<span></span>            <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="n">pred_mask</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">pred_score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span></span>
<span></span>            <span class="n">stability_score</span> <span class="o">=</span> <span class="n">calculate_stability_score</span><span class="p">(</span>
<span></span>                <span class="n">pred_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span><span class="p">,</span> <span class="n">stability_score_offset</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">stability_score</span> <span class="o">&gt;</span> <span class="n">stability_score_thresh</span>
<span></span>            <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="n">pred_mask</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">pred_score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span></span>            <span class="c1"># Bool type is much more memory-efficient.</span>
<span></span>            <span class="n">pred_mask</span> <span class="o">=</span> <span class="n">pred_mask</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span>
<span></span>            <span class="c1"># (N, 4)</span>
<span></span>            <span class="n">pred_bbox</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span></span>            <span class="n">keep_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">is_box_near_crop_edge</span><span class="p">(</span><span class="n">pred_bbox</span><span class="p">,</span> <span class="n">crop_region</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">iw</span><span class="p">,</span> <span class="n">ih</span><span class="p">])</span>
<span></span>            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">keep_mask</span><span class="p">):</span>
<span></span>                <span class="n">pred_bbox</span><span class="p">,</span> <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="n">pred_bbox</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">],</span> <span class="n">pred_mask</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">],</span> <span class="n">pred_score</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
<span></span>
<span></span>            <span class="n">crop_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">)</span>
<span></span>            <span class="n">crop_bboxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_bbox</span><span class="p">)</span>
<span></span>            <span class="n">crop_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_score</span><span class="p">)</span>
<span></span>
<span></span>        <span class="c1"># Do nms within this crop</span>
<span></span>        <span class="n">crop_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">)</span>
<span></span>        <span class="n">crop_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">)</span>
<span></span>        <span class="n">crop_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">crop_scores</span><span class="p">)</span>
<span></span>        <span class="n">keep</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">,</span> <span class="n">crop_scores</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">iou</span><span class="p">)</span>  <span class="c1"># NMS</span>
<span></span>        <span class="n">crop_bboxes</span> <span class="o">=</span> <span class="n">uncrop_boxes_xyxy</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">crop_region</span><span class="p">)</span>
<span></span>        <span class="n">crop_masks</span> <span class="o">=</span> <span class="n">uncrop_masks</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">crop_region</span><span class="p">,</span> <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span><span class="p">)</span>
<span></span>        <span class="n">crop_scores</span> <span class="o">=</span> <span class="n">crop_scores</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
<span></span>
<span></span>        <span class="n">pred_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">)</span>
<span></span>        <span class="n">pred_bboxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">)</span>
<span></span>        <span class="n">pred_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crop_scores</span><span class="p">)</span>
<span></span>        <span class="n">region_areas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">area</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">)))</span>
<span></span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">)</span>
<span></span>    <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pred_bboxes</span><span class="p">)</span>
<span></span>    <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">)</span>
<span></span>    <span class="n">region_areas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">region_areas</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Remove duplicate masks between crops</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">crop_regions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span></span>        <span class="n">scores</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">region_areas</span>
<span></span>        <span class="n">keep</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">crop_nms_thresh</span><span class="p">)</span>
<span></span>        <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">pred_masks</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">pred_bboxes</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">pred_scores</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">,</span> <span class="n">pred_bboxes</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Extracts image features using the SAM model's image encoder for subsequent mask prediction.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>554</span>
<span>555</span>
<span>556</span>
<span>557</span>
<span>558</span>
<span>559</span>
<span>560</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Extracts image features using the SAM model's image encoder for subsequent mask prediction."""</span>
<span></span>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span>
<span></span>        <span class="sa">f</span><span class="s2">"SAM models only support square image size, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="si">}</span><span class="s2">."</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_imgsz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">image_encoder</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.get_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_model</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Retrieves or builds the Segment Anything Model (SAM) for image segmentation tasks.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>439</span>
<span>440</span>
<span>441</span>
<span>442</span>
<span>443</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Retrieves or builds the Segment Anything Model (SAM) for image segmentation tasks."""</span>
<span></span>    <span class="kn">from</span><span class="w"> </span><span class="nn">.build</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_sam</span>  <span class="c1"># slow import</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">build_sam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">inference</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
<span></span>    <span class="o">**</span><span class="n">kwargs</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation inference based on the given input cues, using the currently loaded image.</p>
<p>This method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt
encoder, and mask decoder for real-time and promptable segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed input image in tensor format, with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes with shape (N, 4), in XYXY format.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Labels for point prompts, shape (N,). 1 = foreground, 0 = background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Low-resolution masks from previous predictions, shape (N, H, W). For SAM H=W=256.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>multimask_output</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to return multiple masks. Helpful for ambiguous prompts.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>*args</code>
</td>
<td>
<code><span title="Any">Any</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Additional positional arguments.</p>
</div>
</td>
<td>
<code>()</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>**kwargs</code>
</td>
<td>
<code><span title="Any">Any</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Additional keyword arguments.</p>
</div>
</td>
<td>
<code>{}</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output masks in shape (C, H, W), where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>An array of length C containing quality scores predicted by the model for each mask.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Low-resolution logits of shape (C, H, W) for subsequent inference, where H=W=256.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"sam_model.pt"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">]])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>167</span>
<span>168</span>
<span>169</span>
<span>170</span>
<span>171</span>
<span>172</span>
<span>173</span>
<span>174</span>
<span>175</span>
<span>176</span>
<span>177</span>
<span>178</span>
<span>179</span>
<span>180</span>
<span>181</span>
<span>182</span>
<span>183</span>
<span>184</span>
<span>185</span>
<span>186</span>
<span>187</span>
<span>188</span>
<span>189</span>
<span>190</span>
<span>191</span>
<span>192</span>
<span>193</span>
<span>194</span>
<span>195</span>
<span>196</span>
<span>197</span>
<span>198</span>
<span>199</span>
<span>200</span>
<span>201</span>
<span>202</span>
<span>203</span>
<span>204</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation inference based on the given input cues, using the currently loaded image.</span>
<span></span>
<span></span><span class="sd">    This method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt</span>
<span></span><span class="sd">    encoder, and mask decoder for real-time and promptable segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): The preprocessed input image in tensor format, with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List | None): Bounding boxes with shape (N, 4), in XYXY format.</span>
<span></span><span class="sd">        points (np.ndarray | List | None): Points indicating object locations with shape (N, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List | None): Labels for point prompts, shape (N,). 1 = foreground, 0 = background.</span>
<span></span><span class="sd">        masks (np.ndarray | None): Low-resolution masks from previous predictions, shape (N, H, W). For SAM H=W=256.</span>
<span></span><span class="sd">        multimask_output (bool): Flag to return multiple masks. Helpful for ambiguous prompts.</span>
<span></span><span class="sd">        *args (Any): Additional positional arguments.</span>
<span></span><span class="sd">        **kwargs (Any): Additional keyword arguments.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (np.ndarray): The output masks in shape (C, H, W), where C is the number of generated masks.</span>
<span></span><span class="sd">        (np.ndarray): An array of length C containing quality scores predicted by the model for each mask.</span>
<span></span><span class="sd">        (np.ndarray): Low-resolution logits of shape (C, H, W) for subsequent inference, where H=W=256.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_model(model_path="sam_model.pt")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image("image.jpg")</span>
<span></span><span class="sd">        &gt;&gt;&gt; results = predictor(bboxes=[[0, 0, 100, 100]])</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Override prompts if any stored in self.prompts</span>
<span></span>    <span class="n">bboxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"bboxes"</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">)</span>
<span></span>    <span class="n">points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"points"</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span></span>    <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"masks"</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>    <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"labels"</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">i</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">masks</span><span class="p">]):</span>
<span></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_inference</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">multimask_output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.postprocess">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">postprocess</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Post-processes SAM's inference outputs to generate object detection masks and bounding boxes.</p>
<p>This method scales masks and boxes to the original image size and applies a threshold to the mask
predictions. It leverages SAM's advanced architecture for real-time, promptable segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>preds</code>
</td>
<td>
<code><span title="Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The output from SAM model inference, containing:
- pred_masks (torch.Tensor): Predicted masks with shape (N, 1, H, W).
- pred_scores (torch.Tensor): Confidence scores for each mask with shape (N, 1).
- pred_bboxes (torch.Tensor, optional): Predicted bounding boxes if segment_all is True.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>img</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The processed input image tensor with shape (C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>orig_imgs</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>] | <span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The original, unprocessed images.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>results</code></td> <td>
<code><span title="List">List</span>[<a class="autorefs autorefs-internal" href="../../../engine/results/#ultralytics.engine.results.Results" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.engine.results.Results&lt;/span&gt;'>Results</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of Results objects containing detection masks, bounding boxes, and other
metadata for each processed image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">preds</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>445</span>
<span>446</span>
<span>447</span>
<span>448</span>
<span>449</span>
<span>450</span>
<span>451</span>
<span>452</span>
<span>453</span>
<span>454</span>
<span>455</span>
<span>456</span>
<span>457</span>
<span>458</span>
<span>459</span>
<span>460</span>
<span>461</span>
<span>462</span>
<span>463</span>
<span>464</span>
<span>465</span>
<span>466</span>
<span>467</span>
<span>468</span>
<span>469</span>
<span>470</span>
<span>471</span>
<span>472</span>
<span>473</span>
<span>474</span>
<span>475</span>
<span>476</span>
<span>477</span>
<span>478</span>
<span>479</span>
<span>480</span>
<span>481</span>
<span>482</span>
<span>483</span>
<span>484</span>
<span>485</span>
<span>486</span>
<span>487</span>
<span>488</span>
<span>489</span>
<span>490</span>
<span>491</span>
<span>492</span>
<span>493</span>
<span>494</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Post-processes SAM's inference outputs to generate object detection masks and bounding boxes.</span>
<span></span>
<span></span><span class="sd">    This method scales masks and boxes to the original image size and applies a threshold to the mask</span>
<span></span><span class="sd">    predictions. It leverages SAM's advanced architecture for real-time, promptable segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        preds (Tuple[torch.Tensor]): The output from SAM model inference, containing:</span>
<span></span><span class="sd">            - pred_masks (torch.Tensor): Predicted masks with shape (N, 1, H, W).</span>
<span></span><span class="sd">            - pred_scores (torch.Tensor): Confidence scores for each mask with shape (N, 1).</span>
<span></span><span class="sd">            - pred_bboxes (torch.Tensor, optional): Predicted bounding boxes if segment_all is True.</span>
<span></span><span class="sd">        img (torch.Tensor): The processed input image tensor with shape (C, H, W).</span>
<span></span><span class="sd">        orig_imgs (List[np.ndarray] | torch.Tensor): The original, unprocessed images.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        results (List[Results]): List of Results objects containing detection masks, bounding boxes, and other</span>
<span></span><span class="sd">            metadata for each processed image.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; preds = predictor.inference(img)</span>
<span></span><span class="sd">        &gt;&gt;&gt; results = predictor.postprocess(preds, img, orig_imgs)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># (N, 1, H, W), (N, 1)</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span></span>    <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="k">else</span> <span class="kc">None</span>
<span></span>    <span class="n">names</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">))))</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig_imgs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>  <span class="c1"># input images are a torch.Tensor, not a list</span>
<span></span>        <span class="n">orig_imgs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_torch2numpy_batch</span><span class="p">(</span><span class="n">orig_imgs</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">masks</span><span class="p">,</span> <span class="n">orig_img</span><span class="p">,</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">pred_masks</span><span class="p">],</span> <span class="n">orig_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
<span></span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>            <span class="n">masks</span><span class="p">,</span> <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="k">else</span><span class="p">:</span>
<span></span>            <span class="n">masks</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">scale_masks</span><span class="p">(</span><span class="n">masks</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">orig_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span>            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span>  <span class="c1"># to bool</span>
<span></span>            <span class="k">if</span> <span class="n">pred_bboxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>                <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">scale_boxes</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">pred_bboxes</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">orig_img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>            <span class="k">else</span><span class="p">:</span>
<span></span>                <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
<span></span>            <span class="c1"># NOTE: SAM models do not return cls info. This `cls` here is just a placeholder for consistency.</span>
<span></span>            <span class="bp">cls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>            <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">cls</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span></span>        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Results</span><span class="p">(</span><span class="n">orig_img</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">img_path</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span> <span class="n">boxes</span><span class="o">=</span><span class="n">pred_bboxes</span><span class="p">))</span>
<span></span>    <span class="c1"># Reset segment-all mode.</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.pre_transform">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_transform</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">pre_transform</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform initial transformations on the input image for preprocessing.</p>
<p>This method applies transformations such as resizing to prepare the image for further preprocessing.
Currently, batched inference is not supported; hence the list length should be 1.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List containing a single image in HWC numpy array format.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List containing the transformed image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If the input list contains more than one image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Single HWC image</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">transformed</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">pre_transform</span><span class="p">([</span><span class="n">image</span><span class="p">])</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformed</span><span class="p">))</span>
<span></span><span class="go">1</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>140</span>
<span>141</span>
<span>142</span>
<span>143</span>
<span>144</span>
<span>145</span>
<span>146</span>
<span>147</span>
<span>148</span>
<span>149</span>
<span>150</span>
<span>151</span>
<span>152</span>
<span>153</span>
<span>154</span>
<span>155</span>
<span>156</span>
<span>157</span>
<span>158</span>
<span>159</span>
<span>160</span>
<span>161</span>
<span>162</span>
<span>163</span>
<span>164</span>
<span>165</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">pre_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform initial transformations on the input image for preprocessing.</span>
<span></span>
<span></span><span class="sd">    This method applies transformations such as resizing to prepare the image for further preprocessing.</span>
<span></span><span class="sd">    Currently, batched inference is not supported; hence the list length should be 1.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (List[np.ndarray]): List containing a single image in HWC numpy array format.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (List[np.ndarray]): List containing the transformed image.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If the input list contains more than one image.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; image = np.random.rand(480, 640, 3)  # Single HWC image</span>
<span></span><span class="sd">        &gt;&gt;&gt; transformed = predictor.pre_transform([image])</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(len(transformed))</span>
<span></span><span class="sd">        1</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">im</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"SAM model does not currently support batched inference"</span>
<span></span>    <span class="n">letterbox</span> <span class="o">=</span> <span class="n">LetterBox</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="p">[</span><span class="n">letterbox</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">im</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.preprocess">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">preprocess</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">preprocess</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Preprocess the input image for model inference.</p>
<p>This method prepares the input image by applying transformations and normalization. It supports both
torch.Tensor and list of np.ndarray as input formats.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | <span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Input image(s) in BCHW tensor format or list of HWC numpy arrays.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>im</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed image tensor, normalized and converted to the appropriate dtype.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">preprocessed_image</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>107</span>
<span>108</span>
<span>109</span>
<span>110</span>
<span>111</span>
<span>112</span>
<span>113</span>
<span>114</span>
<span>115</span>
<span>116</span>
<span>117</span>
<span>118</span>
<span>119</span>
<span>120</span>
<span>121</span>
<span>122</span>
<span>123</span>
<span>124</span>
<span>125</span>
<span>126</span>
<span>127</span>
<span>128</span>
<span>129</span>
<span>130</span>
<span>131</span>
<span>132</span>
<span>133</span>
<span>134</span>
<span>135</span>
<span>136</span>
<span>137</span>
<span>138</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Preprocess the input image for model inference.</span>
<span></span>
<span></span><span class="sd">    This method prepares the input image by applying transformations and normalization. It supports both</span>
<span></span><span class="sd">    torch.Tensor and list of np.ndarray as input formats.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor | List[np.ndarray]): Input image(s) in BCHW tensor format or list of HWC numpy arrays.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        im (torch.Tensor): The preprocessed image tensor, normalized and converted to the appropriate dtype.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; image = torch.rand(1, 3, 640, 640)</span>
<span></span><span class="sd">        &gt;&gt;&gt; preprocessed_image = predictor.preprocess(image)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">im</span>
<span></span>    <span class="n">not_tensor</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">not_tensor</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_transform</span><span class="p">(</span><span class="n">im</span><span class="p">))</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fp16</span> <span class="k">else</span> <span class="n">im</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span></span>    <span class="k">if</span> <span class="n">not_tensor</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="p">(</span><span class="n">im</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span>
<span></span>    <span class="k">return</span> <span class="n">im</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.prompt_inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">prompt_inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">prompt_inference</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Performs image segmentation inference based on input cues using SAM's specialized architecture.</p>
<p>This internal function leverages the Segment Anything Model (SAM) for prompt-based, real-time segmentation.
It processes various input prompts such as bounding boxes, points, and masks to generate segmentation masks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Preprocessed input image tensor with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes in XYXY format with shape (N, 4).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2) or (N, num_points, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Point prompt labels with shape (N) or (N, num_points). 1 for foreground, 0 for background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Low-res masks from previous predictions with shape (N, H, W). For SAM, H=W=256.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>multimask_output</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to return multiple masks for ambiguous prompts.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If the number of points don't match the number of labels, in case labels were passed.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output masks with shape (C, H, W), where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Quality scores predicted by the model for each mask, with length C.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">prompt_inference</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>206</span>
<span>207</span>
<span>208</span>
<span>209</span>
<span>210</span>
<span>211</span>
<span>212</span>
<span>213</span>
<span>214</span>
<span>215</span>
<span>216</span>
<span>217</span>
<span>218</span>
<span>219</span>
<span>220</span>
<span>221</span>
<span>222</span>
<span>223</span>
<span>224</span>
<span>225</span>
<span>226</span>
<span>227</span>
<span>228</span>
<span>229</span>
<span>230</span>
<span>231</span>
<span>232</span>
<span>233</span>
<span>234</span>
<span>235</span>
<span>236</span>
<span>237</span>
<span>238</span>
<span>239</span>
<span>240</span>
<span>241</span>
<span>242</span>
<span>243</span>
<span>244</span>
<span>245</span>
<span>246</span>
<span>247</span>
<span>248</span>
<span>249</span>
<span>250</span>
<span>251</span>
<span>252</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prompt_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Performs image segmentation inference based on input cues using SAM's specialized architecture.</span>
<span></span>
<span></span><span class="sd">    This internal function leverages the Segment Anything Model (SAM) for prompt-based, real-time segmentation.</span>
<span></span><span class="sd">    It processes various input prompts such as bounding boxes, points, and masks to generate segmentation masks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): Preprocessed input image tensor with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List | None): Bounding boxes in XYXY format with shape (N, 4).</span>
<span></span><span class="sd">        points (np.ndarray | List | None): Points indicating object locations with shape (N, 2) or (N, num_points, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List | None): Point prompt labels with shape (N) or (N, num_points). 1 for foreground, 0 for background.</span>
<span></span><span class="sd">        masks (np.ndarray | None): Low-res masks from previous predictions with shape (N, H, W). For SAM, H=W=256.</span>
<span></span><span class="sd">        multimask_output (bool): Flag to return multiple masks for ambiguous prompts.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If the number of points don't match the number of labels, in case labels were passed.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (np.ndarray): Output masks with shape (C, H, W), where C is the number of generated masks.</span>
<span></span><span class="sd">        (np.ndarray): Quality scores predicted by the model for each mask, with length C.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; im = torch.rand(1, 3, 1024, 1024)</span>
<span></span><span class="sd">        &gt;&gt;&gt; bboxes = [[100, 100, 200, 200]]</span>
<span></span><span class="sd">        &gt;&gt;&gt; masks, scores, logits = predictor.prompt_inference(im, bboxes=bboxes)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>
<span></span>
<span></span>    <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>    <span class="n">points</span> <span class="o">=</span> <span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<span></span>    <span class="c1"># Embed prompts</span>
<span></span>    <span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span> <span class="n">boxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Predict masks</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_decoder</span><span class="p">(</span>
<span></span>        <span class="n">image_embeddings</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
<span></span>        <span class="n">image_pe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="o">.</span><span class="n">get_dense_pe</span><span class="p">(),</span>
<span></span>        <span class="n">sparse_prompt_embeddings</span><span class="o">=</span><span class="n">sparse_embeddings</span><span class="p">,</span>
<span></span>        <span class="n">dense_prompt_embeddings</span><span class="o">=</span><span class="n">dense_embeddings</span><span class="p">,</span>
<span></span>        <span class="n">multimask_output</span><span class="o">=</span><span class="n">multimask_output</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># (N, d, H, W) --&gt; (N*d, H, W), (N, d) --&gt; (N*d, )</span>
<span></span>    <span class="c1"># `d` could be 1 or 3 depends on `multimask_output`.</span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">pred_scores</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.remove_small_regions">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">remove_small_regions</span>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">remove_small_regions</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Remove small disconnected regions and holes from segmentation masks.</p>
<p>This function performs post-processing on segmentation masks generated by the Segment Anything Model (SAM).
It removes small disconnected regions and holes from the input masks, and then performs Non-Maximum
Suppression (NMS) to eliminate any newly created duplicate boxes.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Segmentation masks to be processed, with shape (N, H, W) where N is the number of
masks, H is height, and W is width.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>min_area</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Minimum area threshold for removing disconnected regions and holes. Regions smaller than
this will be removed.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>nms_thresh</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>IoU threshold for the NMS algorithm to remove duplicate boxes.</p>
</div>
</td>
<td>
<code>0.7</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>new_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Processed masks with small regions removed, shape (N, H, W).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>keep</code></td> <td>
<code><span title="List">List</span>[<span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Indices of remaining masks after NMS, for filtering corresponding boxes.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span>  <span class="c1"># 5 random binary masks</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">new_masks</span><span class="p">,</span> <span class="n">keep</span> <span class="o">=</span> <span class="n">remove_small_regions</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original masks: </span><span class="si">{</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Processed masks: </span><span class="si">{</span><span class="n">new_masks</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Indices of kept masks: </span><span class="si">{</span><span class="n">keep</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>571</span>
<span>572</span>
<span>573</span>
<span>574</span>
<span>575</span>
<span>576</span>
<span>577</span>
<span>578</span>
<span>579</span>
<span>580</span>
<span>581</span>
<span>582</span>
<span>583</span>
<span>584</span>
<span>585</span>
<span>586</span>
<span>587</span>
<span>588</span>
<span>589</span>
<span>590</span>
<span>591</span>
<span>592</span>
<span>593</span>
<span>594</span>
<span>595</span>
<span>596</span>
<span>597</span>
<span>598</span>
<span>599</span>
<span>600</span>
<span>601</span>
<span>602</span>
<span>603</span>
<span>604</span>
<span>605</span>
<span>606</span>
<span>607</span>
<span>608</span>
<span>609</span>
<span>610</span>
<span>611</span>
<span>612</span>
<span>613</span>
<span>614</span>
<span>615</span>
<span>616</span>
<span>617</span>
<span>618</span>
<span>619</span>
<span>620</span>
<span>621</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@staticmethod</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">remove_small_regions</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Remove small disconnected regions and holes from segmentation masks.</span>
<span></span>
<span></span><span class="sd">    This function performs post-processing on segmentation masks generated by the Segment Anything Model (SAM).</span>
<span></span><span class="sd">    It removes small disconnected regions and holes from the input masks, and then performs Non-Maximum</span>
<span></span><span class="sd">    Suppression (NMS) to eliminate any newly created duplicate boxes.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        masks (torch.Tensor): Segmentation masks to be processed, with shape (N, H, W) where N is the number of</span>
<span></span><span class="sd">            masks, H is height, and W is width.</span>
<span></span><span class="sd">        min_area (int): Minimum area threshold for removing disconnected regions and holes. Regions smaller than</span>
<span></span><span class="sd">            this will be removed.</span>
<span></span><span class="sd">        nms_thresh (float): IoU threshold for the NMS algorithm to remove duplicate boxes.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        new_masks (torch.Tensor): Processed masks with small regions removed, shape (N, H, W).</span>
<span></span><span class="sd">        keep (List[int]): Indices of remaining masks after NMS, for filtering corresponding boxes.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; masks = torch.rand(5, 640, 640) &gt; 0.5  # 5 random binary masks</span>
<span></span><span class="sd">        &gt;&gt;&gt; new_masks, keep = remove_small_regions(masks, min_area=100, nms_thresh=0.7)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(f"Original masks: {masks.shape}, Processed masks: {new_masks.shape}")</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(f"Indices of kept masks: {keep}")</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>  <span class="c1"># scope for faster 'import ultralytics'</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">masks</span>
<span></span>
<span></span>    <span class="c1"># Filter small disconnected regions and holes</span>
<span></span>    <span class="n">new_masks</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">:</span>
<span></span>        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span></span>        <span class="n">mask</span><span class="p">,</span> <span class="n">changed</span> <span class="o">=</span> <span class="n">remove_small_regions</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">min_area</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"holes"</span><span class="p">)</span>
<span></span>        <span class="n">unchanged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">changed</span>
<span></span>        <span class="n">mask</span><span class="p">,</span> <span class="n">changed</span> <span class="o">=</span> <span class="n">remove_small_regions</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">min_area</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"islands"</span><span class="p">)</span>
<span></span>        <span class="n">unchanged</span> <span class="o">=</span> <span class="n">unchanged</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">changed</span>
<span></span>
<span></span>        <span class="n">new_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span></span>        <span class="c1"># Give score=0 to changed masks and 1 to unchanged masks so NMS prefers masks not needing postprocessing</span>
<span></span>        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">unchanged</span><span class="p">))</span>
<span></span>
<span></span>    <span class="c1"># Recalculate boxes and remove any new duplicates</span>
<span></span>    <span class="n">new_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">new_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="n">boxes</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">new_masks</span><span class="p">)</span>
<span></span>    <span class="n">keep</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">boxes</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">nms_thresh</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">new_masks</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">masks</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">masks</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">keep</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.reset_image">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">reset_image</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">reset_image</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Resets the current image and its features, clearing them for subsequent inference.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>566</span>
<span>567</span>
<span>568</span>
<span>569</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">reset_image</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Resets the current image and its features, clearing them for subsequent inference."""</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.set_image">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">set_image</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">set_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Preprocesses and sets a single image for inference.</p>
<p>This method prepares the model for inference on a single image by setting up the model if not already
initialized, configuring the data source, and preprocessing the image for feature extraction. It
ensures that only one image is set at a time and extracts image features for subsequent use.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image</code>
</td>
<td>
<code><span title="str">str</span> | <span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Path to the image file as a string, or a numpy array representing
an image read by cv2.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If more than one image is attempted to be set.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">))</span>
</code></pre></div>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>This method should be called before performing inference on a new image.</li>
<li>The extracted features are stored in the <code>self.features</code> attribute for later use.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>521</span>
<span>522</span>
<span>523</span>
<span>524</span>
<span>525</span>
<span>526</span>
<span>527</span>
<span>528</span>
<span>529</span>
<span>530</span>
<span>531</span>
<span>532</span>
<span>533</span>
<span>534</span>
<span>535</span>
<span>536</span>
<span>537</span>
<span>538</span>
<span>539</span>
<span>540</span>
<span>541</span>
<span>542</span>
<span>543</span>
<span>544</span>
<span>545</span>
<span>546</span>
<span>547</span>
<span>548</span>
<span>549</span>
<span>550</span>
<span>551</span>
<span>552</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Preprocesses and sets a single image for inference.</span>
<span></span>
<span></span><span class="sd">    This method prepares the model for inference on a single image by setting up the model if not already</span>
<span></span><span class="sd">    initialized, configuring the data source, and preprocessing the image for feature extraction. It</span>
<span></span><span class="sd">    ensures that only one image is set at a time and extracts image features for subsequent use.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        image (str | np.ndarray): Path to the image file as a string, or a numpy array representing</span>
<span></span><span class="sd">            an image read by cv2.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If more than one image is attempted to be set.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image("path/to/image.jpg")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image(cv2.imread("path/to/image.jpg"))</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - This method should be called before performing inference on a new image.</span>
<span></span><span class="sd">        - The extracted features are stored in the `self.features` attribute for later use.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"`set_image` only supports setting one image!"</span>
<span></span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="k">break</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.set_prompts">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">set_prompts</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">set_prompts</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Sets prompts for subsequent inference operations.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>562</span>
<span>563</span>
<span>564</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_prompts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompts</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Sets prompts for subsequent inference operations."""</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span> <span class="o">=</span> <span class="n">prompts</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.setup_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">setup_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Initializes the Segment Anything Model (SAM) for inference.</p>
<p>This method sets up the SAM model by allocating it to the appropriate device and initializing the necessary
parameters for image normalization and other Ultralytics compatibility settings.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>model</code>
</td>
<td>
<code><span title="torch.nn.Module">Module</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>A pretrained SAM model. If None, a new model is built based on config.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>verbose</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If True, prints selected device information.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">sam_model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>408</span>
<span>409</span>
<span>410</span>
<span>411</span>
<span>412</span>
<span>413</span>
<span>414</span>
<span>415</span>
<span>416</span>
<span>417</span>
<span>418</span>
<span>419</span>
<span>420</span>
<span>421</span>
<span>422</span>
<span>423</span>
<span>424</span>
<span>425</span>
<span>426</span>
<span>427</span>
<span>428</span>
<span>429</span>
<span>430</span>
<span>431</span>
<span>432</span>
<span>433</span>
<span>434</span>
<span>435</span>
<span>436</span>
<span>437</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initializes the Segment Anything Model (SAM) for inference.</span>
<span></span>
<span></span><span class="sd">    This method sets up the SAM model by allocating it to the appropriate device and initializing the necessary</span>
<span></span><span class="sd">    parameters for image normalization and other Ultralytics compatibility settings.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (torch.nn.Module | None): A pretrained SAM model. If None, a new model is built based on config.</span>
<span></span><span class="sd">        verbose (bool): If True, prints selected device information.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_model(model=sam_model, verbose=True)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">device</span> <span class="o">=</span> <span class="n">select_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
<span></span>    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">123.675</span><span class="p">,</span> <span class="mf">116.28</span><span class="p">,</span> <span class="mf">103.53</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">58.395</span><span class="p">,</span> <span class="mf">57.12</span><span class="p">,</span> <span class="mf">57.375</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Ultralytics compatibility settings</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pt</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">triton</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">32</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fp16</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">done_warmup</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.setup_source">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">setup_source</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">setup_source</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Sets up the data source for inference.</p>
<p>This method configures the data source from which images will be fetched for inference. It supports
various input types such as image files, directories, video files, and other compatible data sources.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>source</code>
</td>
<td>
<code><span title="str">str</span> | <span title="Path">Path</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The path or identifier for the image data source. Can be a file path,
directory path, URL, or other supported source types.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="s2">"path/to/images"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="s2">"video.mp4"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># Uses default source if available</span>
</code></pre></div>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>If source is None, the method may use a default source if configured.</li>
<li>The method adapts to different source types and prepares them for subsequent inference steps.</li>
<li>Supported source types may include local files, directories, URLs, and video streams.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>496</span>
<span>497</span>
<span>498</span>
<span>499</span>
<span>500</span>
<span>501</span>
<span>502</span>
<span>503</span>
<span>504</span>
<span>505</span>
<span>506</span>
<span>507</span>
<span>508</span>
<span>509</span>
<span>510</span>
<span>511</span>
<span>512</span>
<span>513</span>
<span>514</span>
<span>515</span>
<span>516</span>
<span>517</span>
<span>518</span>
<span>519</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">setup_source</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Sets up the data source for inference.</span>
<span></span>
<span></span><span class="sd">    This method configures the data source from which images will be fetched for inference. It supports</span>
<span></span><span class="sd">    various input types such as image files, directories, video files, and other compatible data sources.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        source (str | Path | None): The path or identifier for the image data source. Can be a file path,</span>
<span></span><span class="sd">            directory path, URL, or other supported source types.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_source("path/to/images")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_source("video.mp4")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_source(None)  # Uses default source if available</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - If source is None, the method may use a default source if configured.</span>
<span></span><span class="sd">        - The method adapts to different source types and prepares them for subsequent inference steps.</span>
<span></span><span class="sd">        - Supported source types may include local files, directories, URLs, and video streams.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">source</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.SAM2Predictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">SAM2Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.Predictor&lt;/span&gt;'>Predictor</a></code></p>
<p>SAM2Predictor class for advanced image segmentation using Segment Anything Model 2 architecture.</p>
<p>This class extends the base Predictor class to implement SAM2-specific functionality for image
segmentation tasks. It provides methods for model initialization, feature extraction, and
prompt-based inference.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor._bb_feat_sizes">_bb_feat_sizes</span></code></td>
<td>
<code><span title="List">List</span>[<span title="Tuple">Tuple</span>[<span title="int">int</span>, <span title="int">int</span>]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Feature sizes for different backbone levels.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.model">model</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The loaded SAM2 model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.device">device</span></code></td>
<td>
<code><span title="torch.device">device</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The device (CPU or GPU) on which the model is loaded.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.features">features</span></code></td>
<td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="torch.Tensor">Tensor</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Cached image features for efficient inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.segment_all">segment_all</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to indicate if all segments should be predicted.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.prompts">prompts</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary to store various types of prompts for inference.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.get_model&lt;/code&gt;)'>get_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Retrieves and initializes the SAM2 model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.prompt_inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;prompt_inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.prompt_inference&lt;/code&gt;)'>prompt_inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Performs image segmentation inference based on various prompts.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.set_image" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;set_image&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.set_image&lt;/code&gt;)'>set_image</a></code></td>
<td>
<div class="doc-md-description">
<p>Preprocesses and sets a single image for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.get_im_features" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_im_features&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.get_im_features&lt;/code&gt;)'>get_im_features</a></code></td>
<td>
<div class="doc-md-description">
<p>Extracts and processes image features using SAM2's image encoder.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predicted </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="p">)</span><span class="si">}</span><span class="s2"> masks with average score </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span> 79</span>
<span> 80</span>
<span> 81</span>
<span> 82</span>
<span> 83</span>
<span> 84</span>
<span> 85</span>
<span> 86</span>
<span> 87</span>
<span> 88</span>
<span> 89</span>
<span> 90</span>
<span> 91</span>
<span> 92</span>
<span> 93</span>
<span> 94</span>
<span> 95</span>
<span> 96</span>
<span> 97</span>
<span> 98</span>
<span> 99</span>
<span>100</span>
<span>101</span>
<span>102</span>
<span>103</span>
<span>104</span>
<span>105</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the Predictor with configuration, overrides, and callbacks.</span>
<span></span>
<span></span><span class="sd">    Sets up the Predictor object for SAM (Segment Anything Model) and applies any configuration overrides or</span>
<span></span><span class="sd">    callbacks provided. Initializes task-specific settings for SAM, such as retina_masks being set to True</span>
<span></span><span class="sd">    for optimal results.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (dict): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (Dict | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        _callbacks (Dict | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example = Predictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = Predictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = Predictor(_callbacks={"on_predict_start": custom_callback})</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">overrides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">overrides</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="n">overrides</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">"segment"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"predict"</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">retina_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Extracts image features from the SAM image encoder for subsequent processing.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>796</span>
<span>797</span>
<span>798</span>
<span>799</span>
<span>800</span>
<span>801</span>
<span>802</span>
<span>803</span>
<span>804</span>
<span>805</span>
<span>806</span>
<span>807</span>
<span>808</span>
<span>809</span>
<span>810</span>
<span>811</span>
<span>812</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Extracts image features from the SAM image encoder for subsequent processing."""</span>
<span></span>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span>
<span></span>        <span class="sa">f</span><span class="s2">"SAM 2 models only support square image size, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="si">}</span><span class="s2">."</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_imgsz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">_bb_feat_sizes</span> <span class="o">=</span> <span class="p">[[</span><span class="n">x</span> <span class="o">//</span> <span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span></span>
<span></span>    <span class="n">backbone_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward_image</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>    <span class="n">_</span><span class="p">,</span> <span class="n">vision_feats</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_prepare_backbone_features</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">directly_add_no_mem_embed</span><span class="p">:</span>
<span></span>        <span class="n">vision_feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">vision_feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">no_mem_embed</span>
<span></span>    <span class="n">feats</span> <span class="o">=</span> <span class="p">[</span>
<span></span>        <span class="n">feat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">feat_size</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vision_feats</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bb_feat_sizes</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span></span>    <span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span></span>    <span class="k">return</span> <span class="p">{</span><span class="s2">"image_embed"</span><span class="p">:</span> <span class="n">feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s2">"high_res_feats"</span><span class="p">:</span> <span class="n">feats</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]}</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.get_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_model</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Retrieves and initializes the Segment Anything Model 2 (SAM2) for image segmentation tasks.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>660</span>
<span>661</span>
<span>662</span>
<span>663</span>
<span>664</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Retrieves and initializes the Segment Anything Model 2 (SAM2) for image segmentation tasks."""</span>
<span></span>    <span class="kn">from</span><span class="w"> </span><span class="nn">.build</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_sam</span>  <span class="c1"># slow import</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">build_sam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.prompt_inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">prompt_inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">prompt_inference</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">img_idx</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Performs image segmentation inference based on various prompts using SAM2 architecture.</p>
<p>This method leverages the Segment Anything Model 2 (SAM2) to generate segmentation masks for input images
based on provided prompts such as bounding boxes, points, or existing masks. It supports both single and
multi-object prediction scenarios.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Preprocessed input image tensor with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span>[<span title="List">List</span>[<span title="float">float</span>]] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes in XYXY format with shape (N, 4).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span>[<span title="List">List</span>[<span title="float">float</span>]] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Object location points with shape (N, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span>[<span title="int">int</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Point prompt labels with shape (N,). 1 = foreground, 0 = background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Low-resolution masks from previous predictions with shape (N, H, W).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>multimask_output</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to return multiple masks for ambiguous prompts.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>img_idx</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Index of the image in the batch to process.</p>
</div>
</td>
<td>
<code>-1</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output masks with shape (C, H, W), where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Quality scores for each mask, with length C.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generated </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> masks with average score </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>The method supports batched inference for multiple objects when points or bboxes are provided.</li>
<li>Input prompts (bboxes, points) are automatically scaled to match the input image dimensions.</li>
<li>When both bboxes and points are provided, they are merged into a single 'points' input for the model.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>666</span>
<span>667</span>
<span>668</span>
<span>669</span>
<span>670</span>
<span>671</span>
<span>672</span>
<span>673</span>
<span>674</span>
<span>675</span>
<span>676</span>
<span>677</span>
<span>678</span>
<span>679</span>
<span>680</span>
<span>681</span>
<span>682</span>
<span>683</span>
<span>684</span>
<span>685</span>
<span>686</span>
<span>687</span>
<span>688</span>
<span>689</span>
<span>690</span>
<span>691</span>
<span>692</span>
<span>693</span>
<span>694</span>
<span>695</span>
<span>696</span>
<span>697</span>
<span>698</span>
<span>699</span>
<span>700</span>
<span>701</span>
<span>702</span>
<span>703</span>
<span>704</span>
<span>705</span>
<span>706</span>
<span>707</span>
<span>708</span>
<span>709</span>
<span>710</span>
<span>711</span>
<span>712</span>
<span>713</span>
<span>714</span>
<span>715</span>
<span>716</span>
<span>717</span>
<span>718</span>
<span>719</span>
<span>720</span>
<span>721</span>
<span>722</span>
<span>723</span>
<span>724</span>
<span>725</span>
<span>726</span>
<span>727</span>
<span>728</span>
<span>729</span>
<span>730</span>
<span>731</span>
<span>732</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prompt_inference</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">img_idx</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span></span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Performs image segmentation inference based on various prompts using SAM2 architecture.</span>
<span></span>
<span></span><span class="sd">    This method leverages the Segment Anything Model 2 (SAM2) to generate segmentation masks for input images</span>
<span></span><span class="sd">    based on provided prompts such as bounding boxes, points, or existing masks. It supports both single and</span>
<span></span><span class="sd">    multi-object prediction scenarios.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): Preprocessed input image tensor with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List[List[float]] | None): Bounding boxes in XYXY format with shape (N, 4).</span>
<span></span><span class="sd">        points (np.ndarray | List[List[float]] | None): Object location points with shape (N, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List[int] | None): Point prompt labels with shape (N,). 1 = foreground, 0 = background.</span>
<span></span><span class="sd">        masks (np.ndarray | None): Low-resolution masks from previous predictions with shape (N, H, W).</span>
<span></span><span class="sd">        multimask_output (bool): Flag to return multiple masks for ambiguous prompts.</span>
<span></span><span class="sd">        img_idx (int): Index of the image in the batch to process.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (np.ndarray): Output masks with shape (C, H, W), where C is the number of generated masks.</span>
<span></span><span class="sd">        (np.ndarray): Quality scores for each mask, with length C.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = SAM2Predictor(cfg)</span>
<span></span><span class="sd">        &gt;&gt;&gt; image = torch.rand(1, 3, 640, 640)</span>
<span></span><span class="sd">        &gt;&gt;&gt; bboxes = [[100, 100, 200, 200]]</span>
<span></span><span class="sd">        &gt;&gt;&gt; result = predictor(image, bboxes=bboxes)[0]</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(f"Generated {result.masks.shape[0]} masks with average score {result.boxes.conf.mean():.2f}")</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - The method supports batched inference for multiple objects when points or bboxes are provided.</span>
<span></span><span class="sd">        - Input prompts (bboxes, points) are automatically scaled to match the input image dimensions.</span>
<span></span><span class="sd">        - When both bboxes and points are provided, they are merged into a single 'points' input for the model.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>
<span></span>
<span></span>    <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>    <span class="n">points</span> <span class="o">=</span> <span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<span></span>
<span></span>    <span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sam_prompt_encoder</span><span class="p">(</span>
<span></span>        <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span>
<span></span>        <span class="n">boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>        <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="c1"># Predict masks</span>
<span></span>    <span class="n">batched_mode</span> <span class="o">=</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>  <span class="c1"># multi object prediction</span>
<span></span>    <span class="n">high_res_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feat_level</span><span class="p">[</span><span class="n">img_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">feat_level</span> <span class="ow">in</span> <span class="n">features</span><span class="p">[</span><span class="s2">"high_res_feats"</span><span class="p">]]</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sam_mask_decoder</span><span class="p">(</span>
<span></span>        <span class="n">image_embeddings</span><span class="o">=</span><span class="n">features</span><span class="p">[</span><span class="s2">"image_embed"</span><span class="p">][</span><span class="n">img_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span></span>        <span class="n">image_pe</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sam_prompt_encoder</span><span class="o">.</span><span class="n">get_dense_pe</span><span class="p">(),</span>
<span></span>        <span class="n">sparse_prompt_embeddings</span><span class="o">=</span><span class="n">sparse_embeddings</span><span class="p">,</span>
<span></span>        <span class="n">dense_prompt_embeddings</span><span class="o">=</span><span class="n">dense_embeddings</span><span class="p">,</span>
<span></span>        <span class="n">multimask_output</span><span class="o">=</span><span class="n">multimask_output</span><span class="p">,</span>
<span></span>        <span class="n">repeat_image</span><span class="o">=</span><span class="n">batched_mode</span><span class="p">,</span>
<span></span>        <span class="n">high_res_features</span><span class="o">=</span><span class="n">high_res_features</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="c1"># (N, d, H, W) --&gt; (N*d, H, W), (N, d) --&gt; (N*d, )</span>
<span></span>    <span class="c1"># `d` could be 1 or 3 depends on `multimask_output`.</span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">pred_scores</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.set_image">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">set_image</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">set_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Preprocesses and sets a single image for inference using the SAM2 model.</p>
<p>This method initializes the model if not already done, configures the data source to the specified image,
and preprocesses the image for feature extraction. It supports setting only one image at a time.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image</code>
</td>
<td>
<code><span title="str">str</span> | <span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Path to the image file as a string, or a numpy array representing the image.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If more than one image is attempted to be set.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">...</span><span class="p">]))</span>  <span class="c1"># Using a numpy array</span>
</code></pre></div>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>This method must be called before performing any inference on a new image.</li>
<li>The method caches the extracted features for efficient subsequent inferences on the same image.</li>
<li>Only one image can be set at a time. To process multiple images, call this method for each new image.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>764</span>
<span>765</span>
<span>766</span>
<span>767</span>
<span>768</span>
<span>769</span>
<span>770</span>
<span>771</span>
<span>772</span>
<span>773</span>
<span>774</span>
<span>775</span>
<span>776</span>
<span>777</span>
<span>778</span>
<span>779</span>
<span>780</span>
<span>781</span>
<span>782</span>
<span>783</span>
<span>784</span>
<span>785</span>
<span>786</span>
<span>787</span>
<span>788</span>
<span>789</span>
<span>790</span>
<span>791</span>
<span>792</span>
<span>793</span>
<span>794</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Preprocesses and sets a single image for inference using the SAM2 model.</span>
<span></span>
<span></span><span class="sd">    This method initializes the model if not already done, configures the data source to the specified image,</span>
<span></span><span class="sd">    and preprocesses the image for feature extraction. It supports setting only one image at a time.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        image (str | np.ndarray): Path to the image file as a string, or a numpy array representing the image.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If more than one image is attempted to be set.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = SAM2Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image("path/to/image.jpg")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image(np.array([...]))  # Using a numpy array</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - This method must be called before performing any inference on a new image.</span>
<span></span><span class="sd">        - The method caches the extracted features for efficient subsequent inferences on the same image.</span>
<span></span><span class="sd">        - Only one image can be set at a time. To process multiple images, call this method for each new image.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"`set_image` only supports setting one image!"</span>
<span></span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="k">break</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.SAM2VideoPredictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">SAM2VideoPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.SAM2Predictor&lt;/span&gt;'>SAM2Predictor</a></code></p>
<p>SAM2VideoPredictor to handle user interactions with videos and manage inference states.</p>
<p>This class extends the functionality of SAM2Predictor to support video processing and maintains
the state of inference operations. It includes configurations for managing non-overlapping masks,
clearing memory for non-conditional inputs, and setting up callbacks for prediction events.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.inference_state">inference_state</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A dictionary to store the current state of inference operations.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.non_overlap_masks">non_overlap_masks</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A flag indicating whether masks should be non-overlapping.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.clear_non_cond_mem_around_input">clear_non_cond_mem_around_input</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A flag to control clearing non-conditional memory around inputs.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.clear_non_cond_mem_for_multi_obj">clear_non_cond_mem_for_multi_obj</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A flag to control clearing non-conditional memory for multi-object scenarios.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.callbacks">callbacks</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A dictionary of callbacks for various prediction lifecycle events.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>cfg</code>
</td>
<td>
<code>(<span title="dict">dict</span>, <span title="Optional">Optional</span>)</code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration settings for the predictor. Defaults to DEFAULT_CFG.</p>
</div>
</td>
<td>
<code><span title="ultralytics.utils.DEFAULT_CFG">DEFAULT_CFG</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>overrides</code>
</td>
<td>
<code>(<span title="dict">dict</span>, <span title="Optional">Optional</span>)</code>
</td>
<td>
<div class="doc-md-description">
<p>Additional configuration overrides. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>_callbacks</code>
</td>
<td>
<code>(<span title="list">list</span>, <span title="Optional">Optional</span>)</code>
</td>
<td>
<div class="doc-md-description">
<p>Custom callbacks to be added. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<p>The <code>fill_hole_area</code> attribute is defined but not used in the current implementation.</p>
</details>
<p>This constructor initializes the SAM2VideoPredictor with a given configuration, applies any
specified overrides, and sets up the inference state along with certain flags
that control the behavior of the predictor.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>cfg</code>
</td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration dictionary containing default settings.</p>
</div>
</td>
<td>
<code><span title="ultralytics.utils.DEFAULT_CFG">DEFAULT_CFG</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>overrides</code>
</td>
<td>
<code><span title="Dict">Dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of values to override default configuration.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>_callbacks</code>
</td>
<td>
<code><span title="Dict">Dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of callback functions to customize behavior.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_imgsz</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">overrides</span><span class="o">=</span><span class="p">{</span><span class="s2">"imgsz"</span><span class="p">:</span> <span class="mi">640</span><span class="p">})</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_callback</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">_callbacks</span><span class="o">=</span><span class="p">{</span><span class="s2">"on_predict_start"</span><span class="p">:</span> <span class="n">custom_callback</span><span class="p">})</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>841</span>
<span>842</span>
<span>843</span>
<span>844</span>
<span>845</span>
<span>846</span>
<span>847</span>
<span>848</span>
<span>849</span>
<span>850</span>
<span>851</span>
<span>852</span>
<span>853</span>
<span>854</span>
<span>855</span>
<span>856</span>
<span>857</span>
<span>858</span>
<span>859</span>
<span>860</span>
<span>861</span>
<span>862</span>
<span>863</span>
<span>864</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the predictor with configuration and optional overrides.</span>
<span></span>
<span></span><span class="sd">    This constructor initializes the SAM2VideoPredictor with a given configuration, applies any</span>
<span></span><span class="sd">    specified overrides, and sets up the inference state along with certain flags</span>
<span></span><span class="sd">    that control the behavior of the predictor.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (dict): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (Dict | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        _callbacks (Dict | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = SAM2VideoPredictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = SAM2VideoPredictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = SAM2VideoPredictor(_callbacks={"on_predict_start": custom_callback})</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">non_overlap_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_around_input</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_for_multi_obj</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">[</span><span class="s2">"on_predict_start"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_state</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">add_new_prompts</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">add_new_prompts</span><span class="p">(</span><span class="n">obj_id</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">frame_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Adds new points or masks to a specific frame for a given object ID.</p>
<p>This method updates the inference state with new prompts (points or masks) for a specified
object and frame index. It ensures that the prompts are either points or masks, but not both,
and updates the internal state accordingly. It also handles the generation of new segmentations
based on the provided prompts and the existing state.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>obj_id</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The ID of the object to which the prompts are associated.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code>(<span title="torch.Tensor">Tensor</span>, <span title="Optional">Optional</span>)</code>
</td>
<td>
<div class="doc-md-description">
<p>The coordinates of the points of interest. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code>(<span title="torch.Tensor">Tensor</span>, <span title="Optional">Optional</span>)</code>
</td>
<td>
<div class="doc-md-description">
<p>The labels corresponding to the points. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Binary masks for the object. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>frame_idx</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The index of the frame to which the prompts are applied. Defaults to 0.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="tuple">tuple</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A tuple containing the flattened predicted masks and a tensor of ones indicating the number of objects.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If both <code>masks</code> and <code>points</code> are provided, or neither is provided.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<ul>
<li>Only one type of prompt (either points or masks) can be added per call.</li>
<li>If the frame is being tracked for the first time, it is treated as an initial conditioning frame.</li>
<li>The method handles the consolidation of outputs and resizing of masks to the original video resolution.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span> 975</span>
<span> 976</span>
<span> 977</span>
<span> 978</span>
<span> 979</span>
<span> 980</span>
<span> 981</span>
<span> 982</span>
<span> 983</span>
<span> 984</span>
<span> 985</span>
<span> 986</span>
<span> 987</span>
<span> 988</span>
<span> 989</span>
<span> 990</span>
<span> 991</span>
<span> 992</span>
<span> 993</span>
<span> 994</span>
<span> 995</span>
<span> 996</span>
<span> 997</span>
<span> 998</span>
<span> 999</span>
<span>1000</span>
<span>1001</span>
<span>1002</span>
<span>1003</span>
<span>1004</span>
<span>1005</span>
<span>1006</span>
<span>1007</span>
<span>1008</span>
<span>1009</span>
<span>1010</span>
<span>1011</span>
<span>1012</span>
<span>1013</span>
<span>1014</span>
<span>1015</span>
<span>1016</span>
<span>1017</span>
<span>1018</span>
<span>1019</span>
<span>1020</span>
<span>1021</span>
<span>1022</span>
<span>1023</span>
<span>1024</span>
<span>1025</span>
<span>1026</span>
<span>1027</span>
<span>1028</span>
<span>1029</span>
<span>1030</span>
<span>1031</span>
<span>1032</span>
<span>1033</span>
<span>1034</span>
<span>1035</span>
<span>1036</span>
<span>1037</span>
<span>1038</span>
<span>1039</span>
<span>1040</span>
<span>1041</span>
<span>1042</span>
<span>1043</span>
<span>1044</span>
<span>1045</span>
<span>1046</span>
<span>1047</span>
<span>1048</span>
<span>1049</span>
<span>1050</span>
<span>1051</span>
<span>1052</span>
<span>1053</span>
<span>1054</span>
<span>1055</span>
<span>1056</span>
<span>1057</span>
<span>1058</span>
<span>1059</span>
<span>1060</span>
<span>1061</span>
<span>1062</span>
<span>1063</span>
<span>1064</span>
<span>1065</span>
<span>1066</span>
<span>1067</span>
<span>1068</span>
<span>1069</span>
<span>1070</span>
<span>1071</span>
<span>1072</span>
<span>1073</span>
<span>1074</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">add_new_prompts</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">obj_id</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">frame_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Adds new points or masks to a specific frame for a given object ID.</span>
<span></span>
<span></span><span class="sd">    This method updates the inference state with new prompts (points or masks) for a specified</span>
<span></span><span class="sd">    object and frame index. It ensures that the prompts are either points or masks, but not both,</span>
<span></span><span class="sd">    and updates the internal state accordingly. It also handles the generation of new segmentations</span>
<span></span><span class="sd">    based on the provided prompts and the existing state.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        obj_id (int): The ID of the object to which the prompts are associated.</span>
<span></span><span class="sd">        points (torch.Tensor, Optional): The coordinates of the points of interest. Defaults to None.</span>
<span></span><span class="sd">        labels (torch.Tensor, Optional): The labels corresponding to the points. Defaults to None.</span>
<span></span><span class="sd">        masks (torch.Tensor, optional): Binary masks for the object. Defaults to None.</span>
<span></span><span class="sd">        frame_idx (int, optional): The index of the frame to which the prompts are applied. Defaults to 0.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (tuple): A tuple containing the flattened predicted masks and a tensor of ones indicating the number of objects.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If both `masks` and `points` are provided, or neither is provided.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        - Only one type of prompt (either points or masks) can be added per call.</span>
<span></span><span class="sd">        - If the frame is being tracked for the first time, it is treated as an initial conditioning frame.</span>
<span></span><span class="sd">        - The method handles the consolidation of outputs and resizing of masks to the original video resolution.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">assert</span> <span class="p">(</span><span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="o">^</span> <span class="p">(</span><span class="n">points</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">),</span> <span class="s2">"'masks' and 'points' prompts are not compatible with each other."</span>
<span></span>    <span class="n">obj_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obj_id_to_idx</span><span class="p">(</span><span class="n">obj_id</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">point_inputs</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="n">pop_key</span> <span class="o">=</span> <span class="s2">"point_inputs_per_obj"</span>
<span></span>    <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">point_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"point_coords"</span><span class="p">:</span> <span class="n">points</span><span class="p">,</span> <span class="s2">"point_labels"</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"point_inputs_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">point_inputs</span>
<span></span>        <span class="n">pop_key</span> <span class="o">=</span> <span class="s2">"mask_inputs_per_obj"</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"mask_inputs_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">masks</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="n">pop_key</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="c1"># If this frame hasn't been tracked before, we treat it as an initial conditioning</span>
<span></span>    <span class="c1"># frame, meaning that the inputs points are to generate segments on this frame without</span>
<span></span>    <span class="c1"># using any memory from other frames, like in SAM. Otherwise (if it has been tracked),</span>
<span></span>    <span class="c1"># the input points will be used to correct the already tracked masks.</span>
<span></span>    <span class="n">is_init_cond_frame</span> <span class="o">=</span> <span class="n">frame_idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"frames_already_tracked"</span><span class="p">]</span>
<span></span>    <span class="n">obj_output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">]</span>
<span></span>    <span class="n">obj_temp_output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"temp_output_dict_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">]</span>
<span></span>    <span class="c1"># Add a frame to conditioning output if it's an initial conditioning frame or</span>
<span></span>    <span class="c1"># if the model sees all frames receiving clicks/mask as conditioning frames.</span>
<span></span>    <span class="n">is_cond</span> <span class="o">=</span> <span class="n">is_init_cond_frame</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">add_all_frames_to_correct_as_cond</span>
<span></span>    <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"cond_frame_outputs"</span> <span class="k">if</span> <span class="n">is_cond</span> <span class="k">else</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>
<span></span>    <span class="c1"># Get any previously predicted mask logits on this object and feed it along with</span>
<span></span>    <span class="c1"># the new clicks into the SAM mask decoder.</span>
<span></span>    <span class="n">prev_sam_mask_logits</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="c1"># lookup temporary output dict first, which contains the most recent output</span>
<span></span>    <span class="c1"># (if not found, then lookup conditioning and non-conditioning frame output)</span>
<span></span>    <span class="k">if</span> <span class="n">point_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">prev_out</span> <span class="o">=</span> <span class="p">(</span>
<span></span>            <span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>            <span class="ow">or</span> <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>            <span class="ow">or</span> <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>        <span class="p">)</span>
<span></span>
<span></span>        <span class="k">if</span> <span class="n">prev_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prev_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"pred_masks"</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="n">prev_sam_mask_logits</span> <span class="o">=</span> <span class="n">prev_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span>            <span class="c1"># Clamp the scale of prev_sam_mask_logits to avoid rare numerical issues.</span>
<span></span>            <span class="n">prev_sam_mask_logits</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="mf">32.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">)</span>
<span></span>    <span class="n">current_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_single_frame_inference</span><span class="p">(</span>
<span></span>        <span class="n">output_dict</span><span class="o">=</span><span class="n">obj_output_dict</span><span class="p">,</span>  <span class="c1"># run on the slice of a single object</span>
<span></span>        <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame_idx</span><span class="p">,</span>
<span></span>        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># run on the slice of a single object</span>
<span></span>        <span class="n">is_init_cond_frame</span><span class="o">=</span><span class="n">is_init_cond_frame</span><span class="p">,</span>
<span></span>        <span class="n">point_inputs</span><span class="o">=</span><span class="n">point_inputs</span><span class="p">,</span>
<span></span>        <span class="n">mask_inputs</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
<span></span>        <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="c1"># Skip the memory encoder when adding clicks or mask. We execute the memory encoder</span>
<span></span>        <span class="c1"># at the beginning of `propagate_in_video` (after user finalize their clicks). This</span>
<span></span>        <span class="c1"># allows us to enforce non-overlapping constraints on all objects before encoding</span>
<span></span>        <span class="c1"># them into memory.</span>
<span></span>        <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="n">prev_sam_mask_logits</span><span class="o">=</span><span class="n">prev_sam_mask_logits</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="c1"># Add the output to the output dict (to be used as future memory)</span>
<span></span>    <span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_out</span>
<span></span>
<span></span>    <span class="c1"># Resize the output mask to the original video resolution</span>
<span></span>    <span class="n">consolidated_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_consolidate_temp_output_across_obj</span><span class="p">(</span>
<span></span>        <span class="n">frame_idx</span><span class="p">,</span>
<span></span>        <span class="n">is_cond</span><span class="o">=</span><span class="n">is_cond</span><span class="p">,</span>
<span></span>        <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Extracts and processes image features using SAM2's image encoder for subsequent segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The input image tensor.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>batch</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The batch size for expanding features if there are multiple prompts. Defaults to 1.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>vis_feats</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The visual features extracted from the image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>vis_pos_embed</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The positional embeddings for the visual features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>feat_sizes</code></td> <td>
<code><span title="List">List</span>(<span title="Tuple">Tuple</span>[<span title="int">int</span>])</code>
</td>
<td>
<div class="doc-md-description">
<p>A list containing the sizes of the extracted features.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<ul>
<li>If <code>batch</code> is greater than 1, the features are expanded to fit the batch size.</li>
<li>The method leverages the model's <code>_prepare_backbone_features</code> method to prepare the backbone features.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1195</span>
<span>1196</span>
<span>1197</span>
<span>1198</span>
<span>1199</span>
<span>1200</span>
<span>1201</span>
<span>1202</span>
<span>1203</span>
<span>1204</span>
<span>1205</span>
<span>1206</span>
<span>1207</span>
<span>1208</span>
<span>1209</span>
<span>1210</span>
<span>1211</span>
<span>1212</span>
<span>1213</span>
<span>1214</span>
<span>1215</span>
<span>1216</span>
<span>1217</span>
<span>1218</span>
<span>1219</span>
<span>1220</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Extracts and processes image features using SAM2's image encoder for subsequent segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): The input image tensor.</span>
<span></span><span class="sd">        batch (int, optional): The batch size for expanding features if there are multiple prompts. Defaults to 1.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        vis_feats (torch.Tensor): The visual features extracted from the image.</span>
<span></span><span class="sd">        vis_pos_embed (torch.Tensor): The positional embeddings for the visual features.</span>
<span></span><span class="sd">        feat_sizes (List(Tuple[int])): A list containing the sizes of the extracted features.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        - If `batch` is greater than 1, the features are expanded to fit the batch size.</span>
<span></span><span class="sd">        - The method leverages the model's `_prepare_backbone_features` method to prepare the backbone features.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">backbone_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward_image</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">batch</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># expand features if there's more than one prompt</span>
<span></span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">[</span><span class="s2">"backbone_fpn"</span><span class="p">]):</span>
<span></span>            <span class="n">backbone_out</span><span class="p">[</span><span class="s2">"backbone_fpn"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">[</span><span class="s2">"vision_pos_enc"</span><span class="p">]):</span>
<span></span>            <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>            <span class="n">backbone_out</span><span class="p">[</span><span class="s2">"vision_pos_enc"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos</span>
<span></span>    <span class="n">_</span><span class="p">,</span> <span class="n">vis_feats</span><span class="p">,</span> <span class="n">vis_pos_embed</span><span class="p">,</span> <span class="n">feat_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_prepare_backbone_features</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">vis_feats</span><span class="p">,</span> <span class="n">vis_pos_embed</span><span class="p">,</span> <span class="n">feat_sizes</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.get_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_model</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Retrieves and configures the model with binarization enabled.</p>
<details class="note" open="">
<summary>Note</summary>
<p>This method overrides the base class implementation to set the binarize flag to True.</p>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>866</span>
<span>867</span>
<span>868</span>
<span>869</span>
<span>870</span>
<span>871</span>
<span>872</span>
<span>873</span>
<span>874</span>
<span>875</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Retrieves and configures the model with binarization enabled.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        This method overrides the base class implementation to set the binarize flag to True.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">model</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
<span></span>    <span class="n">model</span><span class="o">.</span><span class="n">set_binarize</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">inference</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation inference based on the given input cues, using the currently loaded image. This
method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt encoder, and
mask decoder for real-time and promptable segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed input image in tensor format, with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes with shape (N, 4), in XYXY format.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Labels for point prompts, shape (N, ). 1 = foreground, 0 = background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Low-resolution masks from previous predictions shape (N,H,W). For SAM H=W=256.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output masks in shape CxHxW, where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>An array of length C containing quality scores predicted by the model for each mask.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>877</span>
<span>878</span>
<span>879</span>
<span>880</span>
<span>881</span>
<span>882</span>
<span>883</span>
<span>884</span>
<span>885</span>
<span>886</span>
<span>887</span>
<span>888</span>
<span>889</span>
<span>890</span>
<span>891</span>
<span>892</span>
<span>893</span>
<span>894</span>
<span>895</span>
<span>896</span>
<span>897</span>
<span>898</span>
<span>899</span>
<span>900</span>
<span>901</span>
<span>902</span>
<span>903</span>
<span>904</span>
<span>905</span>
<span>906</span>
<span>907</span>
<span>908</span>
<span>909</span>
<span>910</span>
<span>911</span>
<span>912</span>
<span>913</span>
<span>914</span>
<span>915</span>
<span>916</span>
<span>917</span>
<span>918</span>
<span>919</span>
<span>920</span>
<span>921</span>
<span>922</span>
<span>923</span>
<span>924</span>
<span>925</span>
<span>926</span>
<span>927</span>
<span>928</span>
<span>929</span>
<span>930</span>
<span>931</span>
<span>932</span>
<span>933</span>
<span>934</span>
<span>935</span>
<span>936</span>
<span>937</span>
<span>938</span>
<span>939</span>
<span>940</span>
<span>941</span>
<span>942</span>
<span>943</span>
<span>944</span>
<span>945</span>
<span>946</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation inference based on the given input cues, using the currently loaded image. This</span>
<span></span><span class="sd">    method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt encoder, and</span>
<span></span><span class="sd">    mask decoder for real-time and promptable segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): The preprocessed input image in tensor format, with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List, optional): Bounding boxes with shape (N, 4), in XYXY format.</span>
<span></span><span class="sd">        points (np.ndarray | List, optional): Points indicating object locations with shape (N, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List, optional): Labels for point prompts, shape (N, ). 1 = foreground, 0 = background.</span>
<span></span><span class="sd">        masks (np.ndarray, optional): Low-resolution masks from previous predictions shape (N,H,W). For SAM H=W=256.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (np.ndarray): The output masks in shape CxHxW, where C is the number of generated masks.</span>
<span></span><span class="sd">        (np.ndarray): An array of length C containing quality scores predicted by the model for each mask.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Override prompts if any stored in self.prompts</span>
<span></span>    <span class="n">bboxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"bboxes"</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">)</span>
<span></span>    <span class="n">points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"points"</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span></span>    <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"masks"</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">frame</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"im"</span><span class="p">]</span> <span class="o">=</span> <span class="n">im</span>
<span></span>    <span class="n">output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict"</span><span class="p">]</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># initialize prompts</span>
<span></span>        <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
<span></span>                <span class="bp">self</span><span class="o">.</span><span class="n">add_new_prompts</span><span class="p">(</span><span class="n">obj_id</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame</span><span class="p">)</span>
<span></span>        <span class="k">elif</span> <span class="n">masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)):</span>
<span></span>                <span class="bp">self</span><span class="o">.</span><span class="n">add_new_prompts</span><span class="p">(</span><span class="n">obj_id</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">propagate_in_video_preflight</span><span class="p">()</span>
<span></span>
<span></span>    <span class="n">consolidated_frame_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"consolidated_frame_inds"</span><span class="p">]</span>
<span></span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"obj_idx_to_id"</span><span class="p">])</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"No points are provided; please add points first"</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"cond_frame_outputs"</span>
<span></span>        <span class="n">current_out</span> <span class="o">=</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame</span><span class="p">]</span>
<span></span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_around_input</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_for_multi_obj</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
<span></span>            <span class="c1"># clear non-conditioning memory of the surrounding frames</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_non_cond_mem_around_input</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
<span></span>    <span class="k">elif</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>        <span class="n">current_out</span> <span class="o">=</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame</span><span class="p">]</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>        <span class="n">current_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_single_frame_inference</span><span class="p">(</span>
<span></span>            <span class="n">output_dict</span><span class="o">=</span><span class="n">output_dict</span><span class="p">,</span>
<span></span>            <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span>
<span></span>            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span></span>            <span class="n">is_init_cond_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>            <span class="n">point_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>            <span class="n">mask_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>            <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>            <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="p">)</span>
<span></span>        <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_out</span>
<span></span>    <span class="c1"># Create slices of per-object outputs for subsequent interaction with each</span>
<span></span>    <span class="c1"># individual object after tracking.</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">_add_output_per_object</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">current_out</span><span class="p">,</span> <span class="n">storage_key</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"frames_already_tracked"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">current_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">pred_masks</span><span class="p">[(</span><span class="n">pred_masks</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># filter blank masks</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.init_state">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">init_state</span>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">init_state</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Initialize an inference state for the predictor.</p>
<p>This function sets up the initial state required for performing inference on video data.
It includes initializing various dictionaries and ordered dictionaries that will store
inputs, outputs, and other metadata relevant to the tracking process.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>predictor</code>
</td>
<td>
<code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.SAM2VideoPredictor&lt;/span&gt;'>SAM2VideoPredictor</a></code>
</td>
<td>
<div class="doc-md-description">
<p>The predictor object for which to initialize the state.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1147</span>
<span>1148</span>
<span>1149</span>
<span>1150</span>
<span>1151</span>
<span>1152</span>
<span>1153</span>
<span>1154</span>
<span>1155</span>
<span>1156</span>
<span>1157</span>
<span>1158</span>
<span>1159</span>
<span>1160</span>
<span>1161</span>
<span>1162</span>
<span>1163</span>
<span>1164</span>
<span>1165</span>
<span>1166</span>
<span>1167</span>
<span>1168</span>
<span>1169</span>
<span>1170</span>
<span>1171</span>
<span>1172</span>
<span>1173</span>
<span>1174</span>
<span>1175</span>
<span>1176</span>
<span>1177</span>
<span>1178</span>
<span>1179</span>
<span>1180</span>
<span>1181</span>
<span>1182</span>
<span>1183</span>
<span>1184</span>
<span>1185</span>
<span>1186</span>
<span>1187</span>
<span>1188</span>
<span>1189</span>
<span>1190</span>
<span>1191</span>
<span>1192</span>
<span>1193</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@staticmethod</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_state</span><span class="p">(</span><span class="n">predictor</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize an inference state for the predictor.</span>
<span></span>
<span></span><span class="sd">    This function sets up the initial state required for performing inference on video data.</span>
<span></span><span class="sd">    It includes initializing various dictionaries and ordered dictionaries that will store</span>
<span></span><span class="sd">    inputs, outputs, and other metadata relevant to the tracking process.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        predictor (SAM2VideoPredictor): The predictor object for which to initialize the state.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">inference_state</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># means initialized</span>
<span></span>        <span class="k">return</span>
<span></span>    <span class="k">assert</span> <span class="n">predictor</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span></span>    <span class="k">assert</span> <span class="n">predictor</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">"video"</span>
<span></span>
<span></span>    <span class="n">inference_state</span> <span class="o">=</span> <span class="p">{</span>
<span></span>        <span class="s2">"num_frames"</span><span class="p">:</span> <span class="n">predictor</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">frames</span><span class="p">,</span>
<span></span>        <span class="s2">"point_inputs_per_obj"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># inputs points on each frame</span>
<span></span>        <span class="s2">"mask_inputs_per_obj"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># inputs mask on each frame</span>
<span></span>        <span class="s2">"constants"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># values that don't change across frames (so we only need to hold one copy of them)</span>
<span></span>        <span class="c1"># mapping between client-side object id and model-side object index</span>
<span></span>        <span class="s2">"obj_id_to_idx"</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">(),</span>
<span></span>        <span class="s2">"obj_idx_to_id"</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">(),</span>
<span></span>        <span class="s2">"obj_ids"</span><span class="p">:</span> <span class="p">[],</span>
<span></span>        <span class="c1"># A storage to hold the model's tracking results and states on each frame</span>
<span></span>        <span class="s2">"output_dict"</span><span class="p">:</span> <span class="p">{</span>
<span></span>            <span class="s2">"cond_frame_outputs"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># dict containing {frame_idx: &lt;out&gt;}</span>
<span></span>            <span class="s2">"non_cond_frame_outputs"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># dict containing {frame_idx: &lt;out&gt;}</span>
<span></span>        <span class="p">},</span>
<span></span>        <span class="c1"># Slice (view) of each object tracking results, sharing the same memory with "output_dict"</span>
<span></span>        <span class="s2">"output_dict_per_obj"</span><span class="p">:</span> <span class="p">{},</span>
<span></span>        <span class="c1"># A temporary storage to hold new outputs when user interact with a frame</span>
<span></span>        <span class="c1"># to add clicks or mask (it's merged into "output_dict" before propagation starts)</span>
<span></span>        <span class="s2">"temp_output_dict_per_obj"</span><span class="p">:</span> <span class="p">{},</span>
<span></span>        <span class="c1"># Frames that already holds consolidated outputs from click or mask inputs</span>
<span></span>        <span class="c1"># (we directly use their consolidated outputs during tracking)</span>
<span></span>        <span class="s2">"consolidated_frame_inds"</span><span class="p">:</span> <span class="p">{</span>
<span></span>            <span class="s2">"cond_frame_outputs"</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>  <span class="c1"># set containing frame indices</span>
<span></span>            <span class="s2">"non_cond_frame_outputs"</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>  <span class="c1"># set containing frame indices</span>
<span></span>        <span class="p">},</span>
<span></span>        <span class="c1"># metadata for each tracking frame (e.g. which direction it's tracked)</span>
<span></span>        <span class="s2">"tracking_has_started"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="s2">"frames_already_tracked"</span><span class="p">:</span> <span class="p">[],</span>
<span></span>    <span class="p">}</span>
<span></span>    <span class="n">predictor</span><span class="o">.</span><span class="n">inference_state</span> <span class="o">=</span> <span class="n">inference_state</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">postprocess</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Post-processes the predictions to apply non-overlapping constraints if required.</p>
<p>This method extends the post-processing functionality by applying non-overlapping constraints
to the predicted masks if the <code>non_overlap_masks</code> flag is set to True. This ensures that
the masks do not overlap, which can be useful for certain applications.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>preds</code>
</td>
<td>
<code><span title="Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The predictions from the model.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>img</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The processed image tensor.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>orig_imgs</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The original images before processing.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>results</code></td> <td>
<code><span title="list">list</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The post-processed predictions.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<p>If <code>non_overlap_masks</code> is True, the method applies constraints to ensure non-overlapping masks.</p>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>948</span>
<span>949</span>
<span>950</span>
<span>951</span>
<span>952</span>
<span>953</span>
<span>954</span>
<span>955</span>
<span>956</span>
<span>957</span>
<span>958</span>
<span>959</span>
<span>960</span>
<span>961</span>
<span>962</span>
<span>963</span>
<span>964</span>
<span>965</span>
<span>966</span>
<span>967</span>
<span>968</span>
<span>969</span>
<span>970</span>
<span>971</span>
<span>972</span>
<span>973</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Post-processes the predictions to apply non-overlapping constraints if required.</span>
<span></span>
<span></span><span class="sd">    This method extends the post-processing functionality by applying non-overlapping constraints</span>
<span></span><span class="sd">    to the predicted masks if the `non_overlap_masks` flag is set to True. This ensures that</span>
<span></span><span class="sd">    the masks do not overlap, which can be useful for certain applications.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        preds (Tuple[torch.Tensor]): The predictions from the model.</span>
<span></span><span class="sd">        img (torch.Tensor): The processed image tensor.</span>
<span></span><span class="sd">        orig_imgs (List[np.ndarray]): The original images before processing.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        results (list): The post-processed predictions.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        If `non_overlap_masks` is True, the method applies constraints to ensure non-overlapping masks.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_overlap_masks</span><span class="p">:</span>
<span></span>        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span></span>            <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>                <span class="k">continue</span>
<span></span>            <span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_apply_non_overlapping_constraints</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
<span></span>    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">propagate_in_video_preflight</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">propagate_in_video_preflight</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Prepare inference_state and consolidate temporary outputs before tracking.</p>
<p>This method marks the start of tracking, disallowing the addition of new objects until the session is reset.
It consolidates temporary outputs from <code>temp_output_dict_per_obj</code> and merges them into <code>output_dict</code>.
Additionally, it clears non-conditioning memory around input frames and ensures that the state is consistent
with the provided inputs.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1076</span>
<span>1077</span>
<span>1078</span>
<span>1079</span>
<span>1080</span>
<span>1081</span>
<span>1082</span>
<span>1083</span>
<span>1084</span>
<span>1085</span>
<span>1086</span>
<span>1087</span>
<span>1088</span>
<span>1089</span>
<span>1090</span>
<span>1091</span>
<span>1092</span>
<span>1093</span>
<span>1094</span>
<span>1095</span>
<span>1096</span>
<span>1097</span>
<span>1098</span>
<span>1099</span>
<span>1100</span>
<span>1101</span>
<span>1102</span>
<span>1103</span>
<span>1104</span>
<span>1105</span>
<span>1106</span>
<span>1107</span>
<span>1108</span>
<span>1109</span>
<span>1110</span>
<span>1111</span>
<span>1112</span>
<span>1113</span>
<span>1114</span>
<span>1115</span>
<span>1116</span>
<span>1117</span>
<span>1118</span>
<span>1119</span>
<span>1120</span>
<span>1121</span>
<span>1122</span>
<span>1123</span>
<span>1124</span>
<span>1125</span>
<span>1126</span>
<span>1127</span>
<span>1128</span>
<span>1129</span>
<span>1130</span>
<span>1131</span>
<span>1132</span>
<span>1133</span>
<span>1134</span>
<span>1135</span>
<span>1136</span>
<span>1137</span>
<span>1138</span>
<span>1139</span>
<span>1140</span>
<span>1141</span>
<span>1142</span>
<span>1143</span>
<span>1144</span>
<span>1145</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">propagate_in_video_preflight</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Prepare inference_state and consolidate temporary outputs before tracking.</span>
<span></span>
<span></span><span class="sd">    This method marks the start of tracking, disallowing the addition of new objects until the session is reset.</span>
<span></span><span class="sd">    It consolidates temporary outputs from `temp_output_dict_per_obj` and merges them into `output_dict`.</span>
<span></span><span class="sd">    Additionally, it clears non-conditioning memory around input frames and ensures that the state is consistent</span>
<span></span><span class="sd">    with the provided inputs.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Tracking has started and we don't allow adding new objects until session is reset.</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"tracking_has_started"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"obj_idx_to_id"</span><span class="p">])</span>
<span></span>
<span></span>    <span class="c1"># Consolidate per-object temporary outputs in "temp_output_dict_per_obj" and</span>
<span></span>    <span class="c1"># add them into "output_dict".</span>
<span></span>    <span class="n">temp_output_dict_per_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"temp_output_dict_per_obj"</span><span class="p">]</span>
<span></span>    <span class="n">output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict"</span><span class="p">]</span>
<span></span>    <span class="c1"># "consolidated_frame_inds" contains indices of those frames where consolidated</span>
<span></span>    <span class="c1"># temporary outputs have been added (either in this call or any previous calls</span>
<span></span>    <span class="c1"># to `propagate_in_video_preflight`).</span>
<span></span>    <span class="n">consolidated_frame_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"consolidated_frame_inds"</span><span class="p">]</span>
<span></span>    <span class="k">for</span> <span class="n">is_cond</span> <span class="ow">in</span> <span class="p">{</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">}:</span>
<span></span>        <span class="c1"># Separately consolidate conditioning and non-conditioning temp outputs</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"cond_frame_outputs"</span> <span class="k">if</span> <span class="n">is_cond</span> <span class="k">else</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>        <span class="c1"># Find all the frames that contain temporary outputs for any objects</span>
<span></span>        <span class="c1"># (these should be the frames that have just received clicks for mask inputs</span>
<span></span>        <span class="c1"># via `add_new_points` or `add_new_mask`)</span>
<span></span>        <span class="n">temp_frame_inds</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span></span>        <span class="k">for</span> <span class="n">obj_temp_output_dict</span> <span class="ow">in</span> <span class="n">temp_output_dict_per_obj</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>            <span class="n">temp_frame_inds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span></span>        <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">temp_frame_inds</span><span class="p">)</span>
<span></span>        <span class="c1"># consolidate the temporary output across all objects on this frame</span>
<span></span>        <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">temp_frame_inds</span><span class="p">:</span>
<span></span>            <span class="n">consolidated_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_consolidate_temp_output_across_obj</span><span class="p">(</span>
<span></span>                <span class="n">frame_idx</span><span class="p">,</span> <span class="n">is_cond</span><span class="o">=</span><span class="n">is_cond</span><span class="p">,</span> <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">True</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="c1"># merge them into "output_dict" and also create per-object slices</span>
<span></span>            <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">consolidated_out</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">_add_output_per_object</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="n">consolidated_out</span><span class="p">,</span> <span class="n">storage_key</span><span class="p">)</span>
<span></span>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_around_input</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_for_multi_obj</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
<span></span>                <span class="c1"># clear non-conditioning memory of the surrounding frames</span>
<span></span>                <span class="bp">self</span><span class="o">.</span><span class="n">_clear_non_cond_mem_around_input</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>
<span></span>        <span class="c1"># clear temporary outputs in `temp_output_dict_per_obj`</span>
<span></span>        <span class="k">for</span> <span class="n">obj_temp_output_dict</span> <span class="ow">in</span> <span class="n">temp_output_dict_per_obj</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>            <span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span></span>
<span></span>    <span class="c1"># edge case: if an output is added to "cond_frame_outputs", we remove any prior</span>
<span></span>    <span class="c1"># output on the same frame in "non_cond_frame_outputs"</span>
<span></span>    <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="n">output_dict</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="k">for</span> <span class="n">obj_output_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict_per_obj"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>            <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="k">assert</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]</span>
<span></span>        <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">discard</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Make sure that the frame indices in "consolidated_frame_inds" are exactly those frames</span>
<span></span>    <span class="c1"># with either points or mask inputs (which should be true under a correct workflow).</span>
<span></span>    <span class="n">all_consolidated_frame_inds</span> <span class="o">=</span> <span class="p">(</span>
<span></span>        <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]</span> <span class="o">|</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">input_frames_inds</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span></span>    <span class="k">for</span> <span class="n">point_inputs_per_frame</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"point_inputs_per_obj"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="n">input_frames_inds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">point_inputs_per_frame</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span></span>    <span class="k">for</span> <span class="n">mask_inputs_per_frame</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"mask_inputs_per_obj"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="n">input_frames_inds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mask_inputs_per_frame</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span></span>    <span class="k">assert</span> <span class="n">all_consolidated_frame_inds</span> <span class="o">==</span> <span class="n">input_frames_inds</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/></p>
<br/><br/>
<div class="git-info">
<div class="dates-container">
<span class="date-item" title="This page was first created on November 12, 2023">
<span class="hover-item">📅</span> Created 1 year ago
    </span>
<span class="date-item" title="This page was last updated on November 26, 2024">
<span class="hover-item">✏️</span> Updated 5 months ago
    </span>
</div>
<div class="authors-container">
<a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (2 changes)">
<img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)">
<img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (6 changes)">
<img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/Burhan-Q" title="Burhan-Q (1 change)">
<img alt="Burhan-Q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62214284?v=4&amp;s=96"/>
</a>
</div></div><div class="share-buttons">
<button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https://docs.ultralytics.com/reference/models/sam/predict', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-x-twitter"></i> Tweet
    </button>
<button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https://docs.ultralytics.com/reference/models/sam/predict', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-linkedin-in"></i> Share
    </button>
</div>
<br/>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: utils" class="md-footer__link md-footer__link--prev" href="../modules/utils/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                utils
              </div>
</div>
</a>
<a aria-label="Next: loss" class="md-footer__link md-footer__link--next" href="../../utils/loss/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                loss
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
<a href="https://www.ultralytics.com/" target="_blank">© 2025 Ultralytics Inc.</a> All rights reserved.
    </div>
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg>
</a>
<a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"></path></svg>
</a>
<a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"></path></svg>
</a>
<a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"></path></svg>
</a>
<a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"></path></svg>
</a>
<a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"></path></svg>
</a>
<a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5"></path></svg>
</a>
<a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../../../..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tooltips", "search.highlight", "search.share", "search.suggest", "toc.follow", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "navigation.indexes", "navigation.sections", "content.tabs.link"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
<script src="../../../../assets/javascripts/bundle.c8b220af.min.js"></script>
<script src="../../../../javascript/extra.js"></script>
<script src="../../../../javascript/giscus.js"></script>
<script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
<script src="../../../../javascript/tablesort.js"></script>
</body>
</html>