<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities." name="description"/>
<meta content="Ultralytics" name="author"/>
<link href="https://docs.ultralytics.com/reference/models/sam/predict/" rel="canonical"/>
<link href="../modules/utils/" rel="prev"/>
<link href="../../utils/loss/" rel="next"/>
<link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.18" name="generator"/>
<title>Reference for ultralytics/models/sam/predict.py</title>
<link href="../../../../assets/stylesheets/main.7e37652d.min.css" rel="stylesheet"/>
<link href="../../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="predict" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="Ultralytics, SAM, Segment Anything Model, SAM 2, Segment Anything Model 2, image segmentation, real-time, prediction, AI, machine learning, Python, torch, inference" name="keywords"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/reference/models/sam/predict" property="og:url"/><meta content="predict" property="og:title"/><meta content="Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities." property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/reference/models/sam/predict" property="twitter:url"/><meta content="predict" property="twitter:title"/><meta content="Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities." property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "headline": "predict", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2025-08-27 18:49:54 +0800", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "Explore Ultralytics SAM and SAM 2 Predictor for advanced, real-time image segmentation using the Segment Anything Model (SAM and SAM 2). Complete implementation details and auxiliary utilities."}</script></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#reference-for-ultralyticsmodelssampredictpy">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<a class="banner-wrapper" href="https://www.ultralytics.com/events/yolovision" target="_blank">
<div class="banner-content-wrapper">
<p>Register now for</p>
<img alt="Ultralytics YOLO Vision" height="40" loading="lazy" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/6895ca9b3ece7244d9981ab9_yv25-logo.avif"/>
</div>
</a>
</div>
</aside>
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Ultralytics YOLO Docs
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
              predict
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg>
</label>
<input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option">
<div class="md-select">
<button aria-label="Select language" class="md-header__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg>
</button>
<div class="md-select__inner">
<ul class="md-select__list">
<li class="md-select__item">
<a class="md-select__link" href="/" hreflang="en">
              ğŸ‡¬ğŸ‡§ English
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/zh/" hreflang="zh">
              ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ko/" hreflang="ko">
              ğŸ‡°ğŸ‡· í•œêµ­ì–´
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ja/" hreflang="ja">
              ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ru/" hreflang="ru">
              ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/de/" hreflang="de">
              ğŸ‡©ğŸ‡ª Deutsch
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/fr/" hreflang="fr">
              ğŸ‡«ğŸ‡· FranÃ§ais
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/es/" hreflang="es">
              ğŸ‡ªğŸ‡¸ EspaÃ±ol
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/pt/" hreflang="pt">
              ğŸ‡µğŸ‡¹ PortuguÃªs
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/it/" hreflang="it">
              ğŸ‡®ğŸ‡¹ Italiano
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/tr/" hreflang="tr">
              ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/vi/" hreflang="vi">
              ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ar/" hreflang="ar">
              ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            </a>
</li>
</ul>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../..">
  Home
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../quickstart/">
  Quickstart
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../modes/">
  Modes
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../tasks/">
  Tasks
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../models/">
  Models
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../datasets/">
  Datasets
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../solutions/">
  Solutions ğŸš€
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../guides/">
  Guides
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../integrations/">
  Integrations
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../hub/">
  HUB
        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../cfg/__init__/">
  Reference
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../help/">
  Help
        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
    Ultralytics YOLO Docs
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../..">
<span class="md-ellipsis">
    Home
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../quickstart/">
<span class="md-ellipsis">
    Quickstart
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../modes/">
<span class="md-ellipsis">
    Modes
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../tasks/">
<span class="md-ellipsis">
    Tasks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../models/">
<span class="md-ellipsis">
    Models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../datasets/">
<span class="md-ellipsis">
    Datasets
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../solutions/">
<span class="md-ellipsis">
    Solutions ğŸš€
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../guides/">
<span class="md-ellipsis">
    Guides
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../integrations/">
<span class="md-ellipsis">
    Integrations
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../hub/">
<span class="md-ellipsis">
    HUB
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_11">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_1" id="__nav_11_1_label" tabindex="">
<span class="md-ellipsis">
    cfg
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_1">
<span class="md-nav__icon md-icon"></span>
            cfg
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../cfg/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_2" id="__nav_11_2_label" tabindex="">
<span class="md-ellipsis">
    data
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_2">
<span class="md-nav__icon md-icon"></span>
            data
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/annotator/">
<span class="md-ellipsis">
    annotator
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/augment/">
<span class="md-ellipsis">
    augment
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/base/">
<span class="md-ellipsis">
    base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/converter/">
<span class="md-ellipsis">
    converter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/dataset/">
<span class="md-ellipsis">
    dataset
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/loaders/">
<span class="md-ellipsis">
    loaders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/split/">
<span class="md-ellipsis">
    split
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/split_dota/">
<span class="md-ellipsis">
    split_dota
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_3" id="__nav_11_3_label" tabindex="">
<span class="md-ellipsis">
    engine
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_3">
<span class="md-nav__icon md-icon"></span>
            engine
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/exporter/">
<span class="md-ellipsis">
    exporter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/predictor/">
<span class="md-ellipsis">
    predictor
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/results/">
<span class="md-ellipsis">
    results
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/trainer/">
<span class="md-ellipsis">
    trainer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../engine/validator/">
<span class="md-ellipsis">
    validator
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_4" id="__nav_11_4_label" tabindex="">
<span class="md-ellipsis">
    hub
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_4">
<span class="md-nav__icon md-icon"></span>
            hub
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/auth/">
<span class="md-ellipsis">
    auth
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../hub/google/__init__/">
<span class="md-ellipsis">
    google
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/session/">
<span class="md-ellipsis">
    session
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../hub/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5" id="__nav_11_5_label" tabindex="">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_5">
<span class="md-nav__icon md-icon"></span>
            models
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../fastsam/model/">
<span class="md-ellipsis">
    fastsam
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../nas/model/">
<span class="md-ellipsis">
    nas
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../rtdetr/model/">
<span class="md-ellipsis">
    rtdetr
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5_4" id="__nav_11_5_4_label" tabindex="0">
<span class="md-ellipsis">
    sam
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_4_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_11_5_4">
<span class="md-nav__icon md-icon"></span>
            sam
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../amg/">
<span class="md-ellipsis">
    amg
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../modules/blocks/">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    predict
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    predict
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â Predictor
    </span>
</a>
<nav aria-label="Â Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.generate">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â generate
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.inference_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.pre_transform">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â pre_transform
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.preprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â preprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.prompt_inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â prompt_inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.remove_small_regions">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â remove_small_regions
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.reset_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â reset_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â set_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â set_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â setup_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_source">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â setup_source
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2Predictor
    </span>
</a>
<nav aria-label="Â SAM2Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â set_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2VideoPredictor
    </span>
</a>
<nav aria-label="Â SAM2VideoPredictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â add_new_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.init_state">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â init_state
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â propagate_in_video_preflight
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2DynamicInteractivePredictor
    </span>
</a>
<nav aria-label="Â SAM2DynamicInteractivePredictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_maskmem_enc">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_maskmem_enc
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.track_step">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â track_step
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.update_memory">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â update_memory
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../utils/loss/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../yolo/classify/predict/">
<span class="md-ellipsis">
    yolo
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_6" id="__nav_11_6_label" tabindex="">
<span class="md-ellipsis">
    nn
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_6">
<span class="md-nav__icon md-icon"></span>
            nn
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nn/autobackend/">
<span class="md-ellipsis">
    autobackend
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../nn/modules/activation/">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nn/tasks/">
<span class="md-ellipsis">
    tasks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nn/text_model/">
<span class="md-ellipsis">
    text_model
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_7" id="__nav_11_7_label" tabindex="">
<span class="md-ellipsis">
    solutions
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_7">
<span class="md-nav__icon md-icon"></span>
            solutions
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/ai_gym/">
<span class="md-ellipsis">
    ai_gym
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/analytics/">
<span class="md-ellipsis">
    analytics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/config/">
<span class="md-ellipsis">
    config
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/distance_calculation/">
<span class="md-ellipsis">
    distance_calculation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/heatmap/">
<span class="md-ellipsis">
    heatmap
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/instance_segmentation/">
<span class="md-ellipsis">
    instance_segmentation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/object_blurrer/">
<span class="md-ellipsis">
    object_blurrer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/object_counter/">
<span class="md-ellipsis">
    object_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/object_cropper/">
<span class="md-ellipsis">
    object_cropper
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/parking_management/">
<span class="md-ellipsis">
    parking_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/queue_management/">
<span class="md-ellipsis">
    queue_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/region_counter/">
<span class="md-ellipsis">
    region_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/security_alarm/">
<span class="md-ellipsis">
    security_alarm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/similarity_search/">
<span class="md-ellipsis">
    similarity_search
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/solutions/">
<span class="md-ellipsis">
    solutions
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/speed_estimation/">
<span class="md-ellipsis">
    speed_estimation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/streamlit_inference/">
<span class="md-ellipsis">
    streamlit_inference
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/trackzone/">
<span class="md-ellipsis">
    trackzone
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../solutions/vision_eye/">
<span class="md-ellipsis">
    vision_eye
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_8" id="__nav_11_8_label" tabindex="">
<span class="md-ellipsis">
    trackers
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_8_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_8">
<span class="md-nav__icon md-icon"></span>
            trackers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/basetrack/">
<span class="md-ellipsis">
    basetrack
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/bot_sort/">
<span class="md-ellipsis">
    bot_sort
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/byte_tracker/">
<span class="md-ellipsis">
    byte_tracker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../trackers/track/">
<span class="md-ellipsis">
    track
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../trackers/utils/gmc/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_9" id="__nav_11_9_label" tabindex="">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_9_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_9">
<span class="md-nav__icon md-icon"></span>
            utils
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/autobatch/">
<span class="md-ellipsis">
    autobatch
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/autodevice/">
<span class="md-ellipsis">
    autodevice
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/benchmarks/">
<span class="md-ellipsis">
    benchmarks
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../utils/callbacks/base/">
<span class="md-ellipsis">
    callbacks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/checks/">
<span class="md-ellipsis">
    checks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/dist/">
<span class="md-ellipsis">
    dist
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/downloads/">
<span class="md-ellipsis">
    downloads
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/errors/">
<span class="md-ellipsis">
    errors
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/export/">
<span class="md-ellipsis">
    export
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/files/">
<span class="md-ellipsis">
    files
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/git/">
<span class="md-ellipsis">
    git
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/instance/">
<span class="md-ellipsis">
    instance
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/logger/">
<span class="md-ellipsis">
    logger
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/loss/">
<span class="md-ellipsis">
    loss
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/metrics/">
<span class="md-ellipsis">
    metrics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/nms/">
<span class="md-ellipsis">
    nms
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/ops/">
<span class="md-ellipsis">
    ops
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/patches/">
<span class="md-ellipsis">
    patches
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/plotting/">
<span class="md-ellipsis">
    plotting
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/tal/">
<span class="md-ellipsis">
    tal
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/torch_utils/">
<span class="md-ellipsis">
    torch_utils
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/tqdm/">
<span class="md-ellipsis">
    tqdm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/triton/">
<span class="md-ellipsis">
    triton
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../utils/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../help/">
<span class="md-ellipsis">
    Help
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â Predictor
    </span>
</a>
<nav aria-label="Â Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.generate">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â generate
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.inference_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.pre_transform">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â pre_transform
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.preprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â preprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.prompt_inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â prompt_inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.remove_small_regions">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â remove_small_regions
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.reset_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â reset_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â set_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.set_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â set_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â setup_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.Predictor.setup_source">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â setup_source
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2Predictor
    </span>
</a>
<nav aria-label="Â SAM2Predictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2Predictor.set_image">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â set_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2VideoPredictor
    </span>
</a>
<nav aria-label="Â SAM2VideoPredictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â add_new_prompts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_model">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.init_state">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â init_state
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â postprocess
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â propagate_in_video_preflight
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2DynamicInteractivePredictor
    </span>
</a>
<nav aria-label="Â SAM2DynamicInteractivePredictor" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_im_features">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_im_features
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_maskmem_enc">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â get_maskmem_enc
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.inference">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.track_step">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â track_step
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.update_memory">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â update_memory
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/reference/models/sam/predict.md" rel="edit" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a><a class="md-content__button md-icon" href="javascript:void(0)" onclick="copyMarkdownForLLM(this); return false;" title="Copy page in Markdown format"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></a>
<h1 id="reference-for-ultralyticsmodelssampredictpy">Reference for <code>ultralytics/models/sam/predict.py</code></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This file is available at <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/predict.py">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/predict.py</a>. If you spot a problem please help fix it by <a href="https://docs.ultralytics.com/help/contributing/">contributing</a> a <a href="https://github.com/ultralytics/ultralytics/edit/main/ultralytics/models/sam/predict.py">Pull Request</a> ğŸ› ï¸. Thank you ğŸ™!</p>
</div>
<p><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.Predictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="../../../engine/predictor/#ultralytics.engine.predictor.BasePredictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.engine.predictor.BasePredictor&lt;/span&gt;'>BasePredictor</a></code></p>
<p>Predictor class for SAM, enabling real-time image segmentation with promptable capabilities.</p>
<p>This class extends BasePredictor and implements the Segment Anything Model (SAM) for advanced image
segmentation tasks. It supports various input prompts like points, bounding boxes, and masks for
fine-grained control over segmentation results.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.args">args</span></code></td>
<td>
<code><span title="SimpleNamespace">SimpleNamespace</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration arguments for the predictor.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.model">model</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The loaded SAM model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.device">device</span></code></td>
<td>
<code><span title="torch.device">device</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The device (CPU or GPU) on which the model is loaded.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.im">im</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed input image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.features">features</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Extracted image features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.prompts">prompts</span></code></td>
<td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary to store various types of prompts (e.g., bboxes, points, masks).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.segment_all">segment_all</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to indicate if full image segmentation should be performed.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.mean">mean</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Mean values for image normalization.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.Predictor.std">std</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Standard deviation values for image normalization.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.preprocess" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;preprocess&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.preprocess&lt;/code&gt;)'>preprocess</a></code></td>
<td>
<div class="doc-md-description">
<p>Prepare input images for model inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.pre_transform" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;pre_transform&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.pre_transform&lt;/code&gt;)'>pre_transform</a></code></td>
<td>
<div class="doc-md-description">
<p>Perform initial transformations on the input image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.inference&lt;/code&gt;)'>inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Perform segmentation inference based on input prompts.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.prompt_inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;prompt_inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.prompt_inference&lt;/code&gt;)'>prompt_inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Internal function for prompt-based segmentation inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.generate" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;generate&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.generate&lt;/code&gt;)'>generate</a></code></td>
<td>
<div class="doc-md-description">
<p>Generate segmentation masks for an entire image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.setup_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;setup_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.setup_model&lt;/code&gt;)'>setup_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Initialize the SAM model for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.get_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.get_model&lt;/code&gt;)'>get_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Build and return a SAM model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.postprocess" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;postprocess&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.postprocess&lt;/code&gt;)'>postprocess</a></code></td>
<td>
<div class="doc-md-description">
<p>Post-process model outputs to generate final results.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.setup_source" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;setup_source&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.setup_source&lt;/code&gt;)'>setup_source</a></code></td>
<td>
<div class="doc-md-description">
<p>Set up the data source for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.set_image" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;set_image&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.set_image&lt;/code&gt;)'>set_image</a></code></td>
<td>
<div class="doc-md-description">
<p>Set and preprocess a single image for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.get_im_features" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_im_features&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.get_im_features&lt;/code&gt;)'>get_im_features</a></code></td>
<td>
<div class="doc-md-description">
<p>Extract image features using the SAM image encoder.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.set_prompts" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;set_prompts&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.set_prompts&lt;/code&gt;)'>set_prompts</a></code></td>
<td>
<div class="doc-md-description">
<p>Set prompts for subsequent inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.reset_image" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;reset_image&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.reset_image&lt;/code&gt;)'>reset_image</a></code></td>
<td>
<div class="doc-md-description">
<p>Reset the current image and its features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.remove_small_regions" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;remove_small_regions&lt;/span&gt;
  &lt;span class="doc doc-labels"&gt;
      &lt;small class="doc doc-label doc-label-staticmethod"&gt;&lt;code&gt;staticmethod&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.Predictor.remove_small_regions&lt;/code&gt;)'>remove_small_regions</a></code></td>
<td>
<div class="doc-md-description">
<p>Remove small disconnected regions and holes from masks.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"sam_model.pt"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)</span>
</code></pre></div>
<p>Sets up the Predictor object for SAM (Segment Anything Model) and applies any configuration overrides or
callbacks provided. Initializes task-specific settings for SAM, such as retina_masks being set to True
for optimal results.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>cfg</code>
</td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration dictionary containing default settings.</p>
</div>
</td>
<td>
<code><span title="ultralytics.utils.DEFAULT_CFG">DEFAULT_CFG</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>overrides</code>
</td>
<td>
<code><span title="dict">dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of values to override default configuration.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>_callbacks</code>
</td>
<td>
<code><span title="dict">dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of callback functions to customize behavior.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_imgsz</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">overrides</span><span class="o">=</span><span class="p">{</span><span class="s2">"imgsz"</span><span class="p">:</span> <span class="mi">640</span><span class="p">})</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_callback</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">_callbacks</span><span class="o">=</span><span class="p">{</span><span class="s2">"on_predict_start"</span><span class="p">:</span> <span class="n">custom_callback</span><span class="p">})</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span> 83</span>
<span> 84</span>
<span> 85</span>
<span> 86</span>
<span> 87</span>
<span> 88</span>
<span> 89</span>
<span> 90</span>
<span> 91</span>
<span> 92</span>
<span> 93</span>
<span> 94</span>
<span> 95</span>
<span> 96</span>
<span> 97</span>
<span> 98</span>
<span> 99</span>
<span>100</span>
<span>101</span>
<span>102</span>
<span>103</span>
<span>104</span>
<span>105</span>
<span>106</span>
<span>107</span>
<span>108</span>
<span>109</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the Predictor with configuration, overrides, and callbacks.</span>
<span></span>
<span></span><span class="sd">    Sets up the Predictor object for SAM (Segment Anything Model) and applies any configuration overrides or</span>
<span></span><span class="sd">    callbacks provided. Initializes task-specific settings for SAM, such as retina_masks being set to True</span>
<span></span><span class="sd">    for optimal results.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (dict): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (dict | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        _callbacks (dict | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example = Predictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = Predictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = Predictor(_callbacks={"on_predict_start": custom_callback})</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">overrides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">overrides</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="n">overrides</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">"segment"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"predict"</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">retina_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.generate">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">generate</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">generate</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">crop_n_layers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">crop_overlap_ratio</span><span class="o">=</span><span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span>
<span></span>    <span class="n">crop_downscale_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span></span>    <span class="n">point_grids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points_stride</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span></span>    <span class="n">points_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span></span>    <span class="n">conf_thres</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_offset</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">crop_nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation using the Segment Anything Model (SAM).</p>
<p>This method segments an entire image into constituent parts by leveraging SAM's advanced architecture
and real-time performance capabilities. It can optionally work on image crops for finer segmentation.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Input tensor representing the preprocessed image with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_n_layers</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of layers for additional mask predictions on image crops.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_overlap_ratio</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Overlap between crops, scaled down in subsequent layers.</p>
</div>
</td>
<td>
<code>512 / 1500</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_downscale_factor</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Scaling factor for sampled points-per-side in each layer.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>point_grids</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Custom grids for point sampling normalized to [0,1].</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points_stride</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of points to sample along each side of the image.</p>
</div>
</td>
<td>
<code>32</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points_batch_size</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Batch size for the number of points processed simultaneously.</p>
</div>
</td>
<td>
<code>64</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>conf_thres</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Confidence threshold [0,1] for filtering based on mask quality prediction.</p>
</div>
</td>
<td>
<code>0.88</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stability_score_thresh</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Stability threshold [0,1] for mask filtering based on stability.</p>
</div>
</td>
<td>
<code>0.95</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stability_score_offset</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Offset value for calculating stability score.</p>
</div>
</td>
<td>
<code>0.95</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>crop_nms_thresh</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>IoU cutoff for NMS to remove duplicate masks between crops.</p>
</div>
</td>
<td>
<code>0.7</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Segmented masks with shape (N, H, W).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_scores</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Confidence scores for each mask with shape (N,).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_bboxes</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes for each mask with shape (N, 4).</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>  <span class="c1"># Example input image</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">boxes</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>329</span>
<span>330</span>
<span>331</span>
<span>332</span>
<span>333</span>
<span>334</span>
<span>335</span>
<span>336</span>
<span>337</span>
<span>338</span>
<span>339</span>
<span>340</span>
<span>341</span>
<span>342</span>
<span>343</span>
<span>344</span>
<span>345</span>
<span>346</span>
<span>347</span>
<span>348</span>
<span>349</span>
<span>350</span>
<span>351</span>
<span>352</span>
<span>353</span>
<span>354</span>
<span>355</span>
<span>356</span>
<span>357</span>
<span>358</span>
<span>359</span>
<span>360</span>
<span>361</span>
<span>362</span>
<span>363</span>
<span>364</span>
<span>365</span>
<span>366</span>
<span>367</span>
<span>368</span>
<span>369</span>
<span>370</span>
<span>371</span>
<span>372</span>
<span>373</span>
<span>374</span>
<span>375</span>
<span>376</span>
<span>377</span>
<span>378</span>
<span>379</span>
<span>380</span>
<span>381</span>
<span>382</span>
<span>383</span>
<span>384</span>
<span>385</span>
<span>386</span>
<span>387</span>
<span>388</span>
<span>389</span>
<span>390</span>
<span>391</span>
<span>392</span>
<span>393</span>
<span>394</span>
<span>395</span>
<span>396</span>
<span>397</span>
<span>398</span>
<span>399</span>
<span>400</span>
<span>401</span>
<span>402</span>
<span>403</span>
<span>404</span>
<span>405</span>
<span>406</span>
<span>407</span>
<span>408</span>
<span>409</span>
<span>410</span>
<span>411</span>
<span>412</span>
<span>413</span>
<span>414</span>
<span>415</span>
<span>416</span>
<span>417</span>
<span>418</span>
<span>419</span>
<span>420</span>
<span>421</span>
<span>422</span>
<span>423</span>
<span>424</span>
<span>425</span>
<span>426</span>
<span>427</span>
<span>428</span>
<span>429</span>
<span>430</span>
<span>431</span>
<span>432</span>
<span>433</span>
<span>434</span>
<span>435</span>
<span>436</span>
<span>437</span>
<span>438</span>
<span>439</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">crop_n_layers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">crop_overlap_ratio</span><span class="o">=</span><span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span>
<span></span>    <span class="n">crop_downscale_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span></span>    <span class="n">point_grids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points_stride</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span></span>    <span class="n">points_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span></span>    <span class="n">conf_thres</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">stability_score_offset</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span></span>    <span class="n">crop_nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
<span></span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation using the Segment Anything Model (SAM).</span>
<span></span>
<span></span><span class="sd">    This method segments an entire image into constituent parts by leveraging SAM's advanced architecture</span>
<span></span><span class="sd">    and real-time performance capabilities. It can optionally work on image crops for finer segmentation.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): Input tensor representing the preprocessed image with shape (N, C, H, W).</span>
<span></span><span class="sd">        crop_n_layers (int): Number of layers for additional mask predictions on image crops.</span>
<span></span><span class="sd">        crop_overlap_ratio (float): Overlap between crops, scaled down in subsequent layers.</span>
<span></span><span class="sd">        crop_downscale_factor (int): Scaling factor for sampled points-per-side in each layer.</span>
<span></span><span class="sd">        point_grids (List[np.ndarray] | None): Custom grids for point sampling normalized to [0,1].</span>
<span></span><span class="sd">        points_stride (int): Number of points to sample along each side of the image.</span>
<span></span><span class="sd">        points_batch_size (int): Batch size for the number of points processed simultaneously.</span>
<span></span><span class="sd">        conf_thres (float): Confidence threshold [0,1] for filtering based on mask quality prediction.</span>
<span></span><span class="sd">        stability_score_thresh (float): Stability threshold [0,1] for mask filtering based on stability.</span>
<span></span><span class="sd">        stability_score_offset (float): Offset value for calculating stability score.</span>
<span></span><span class="sd">        crop_nms_thresh (float): IoU cutoff for NMS to remove duplicate masks between crops.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): Segmented masks with shape (N, H, W).</span>
<span></span><span class="sd">        pred_scores (torch.Tensor): Confidence scores for each mask with shape (N,).</span>
<span></span><span class="sd">        pred_bboxes (torch.Tensor): Bounding boxes for each mask with shape (N, 4).</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; im = torch.rand(1, 3, 1024, 1024)  # Example input image</span>
<span></span><span class="sd">        &gt;&gt;&gt; masks, scores, boxes = predictor.generate(im)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>  <span class="c1"># scope for faster 'import ultralytics'</span>
<span></span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
<span></span>    <span class="n">crop_regions</span><span class="p">,</span> <span class="n">layer_idxs</span> <span class="o">=</span> <span class="n">generate_crop_boxes</span><span class="p">((</span><span class="n">ih</span><span class="p">,</span> <span class="n">iw</span><span class="p">),</span> <span class="n">crop_n_layers</span><span class="p">,</span> <span class="n">crop_overlap_ratio</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">point_grids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">point_grids</span> <span class="o">=</span> <span class="n">build_all_layer_point_grids</span><span class="p">(</span><span class="n">points_stride</span><span class="p">,</span> <span class="n">crop_n_layers</span><span class="p">,</span> <span class="n">crop_downscale_factor</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">,</span> <span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">region_areas</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">crop_region</span><span class="p">,</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">crop_regions</span><span class="p">,</span> <span class="n">layer_idxs</span><span class="p">):</span>
<span></span>        <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">crop_region</span>
<span></span>        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">-</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y2</span> <span class="o">-</span> <span class="n">y1</span>
<span></span>        <span class="n">area</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">h</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">im</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="n">points_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">]])</span>  <span class="c1"># w, h</span>
<span></span>        <span class="c1"># Crop image and interpolate to input size</span>
<span></span>        <span class="n">crop_im</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">im</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">],</span> <span class="p">(</span><span class="n">ih</span><span class="p">,</span> <span class="n">iw</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>        <span class="c1"># (num_points, 2)</span>
<span></span>        <span class="n">points_for_image</span> <span class="o">=</span> <span class="n">point_grids</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">points_scale</span>
<span></span>        <span class="n">crop_masks</span><span class="p">,</span> <span class="n">crop_scores</span><span class="p">,</span> <span class="n">crop_bboxes</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span></span>        <span class="k">for</span> <span class="p">(</span><span class="n">points</span><span class="p">,)</span> <span class="ow">in</span> <span class="n">batch_iterator</span><span class="p">(</span><span class="n">points_batch_size</span><span class="p">,</span> <span class="n">points_for_image</span><span class="p">):</span>
<span></span>            <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_inference</span><span class="p">(</span><span class="n">crop_im</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span>            <span class="c1"># Interpolate predicted masks to input size</span>
<span></span>            <span class="n">pred_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">pred_score</span> <span class="o">&gt;</span> <span class="n">conf_thres</span>
<span></span>            <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="n">pred_mask</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">pred_score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span></span>
<span></span>            <span class="n">stability_score</span> <span class="o">=</span> <span class="n">calculate_stability_score</span><span class="p">(</span>
<span></span>                <span class="n">pred_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span><span class="p">,</span> <span class="n">stability_score_offset</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">stability_score</span> <span class="o">&gt;</span> <span class="n">stability_score_thresh</span>
<span></span>            <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="n">pred_mask</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">pred_score</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span></span>            <span class="c1"># Bool type is much more memory-efficient.</span>
<span></span>            <span class="n">pred_mask</span> <span class="o">=</span> <span class="n">pred_mask</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span>
<span></span>            <span class="c1"># (N, 4)</span>
<span></span>            <span class="n">pred_bbox</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span></span>            <span class="n">keep_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">is_box_near_crop_edge</span><span class="p">(</span><span class="n">pred_bbox</span><span class="p">,</span> <span class="n">crop_region</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">iw</span><span class="p">,</span> <span class="n">ih</span><span class="p">])</span>
<span></span>            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">keep_mask</span><span class="p">):</span>
<span></span>                <span class="n">pred_bbox</span><span class="p">,</span> <span class="n">pred_mask</span><span class="p">,</span> <span class="n">pred_score</span> <span class="o">=</span> <span class="n">pred_bbox</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">],</span> <span class="n">pred_mask</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">],</span> <span class="n">pred_score</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
<span></span>
<span></span>            <span class="n">crop_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">)</span>
<span></span>            <span class="n">crop_bboxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_bbox</span><span class="p">)</span>
<span></span>            <span class="n">crop_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_score</span><span class="p">)</span>
<span></span>
<span></span>        <span class="c1"># Do nms within this crop</span>
<span></span>        <span class="n">crop_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">)</span>
<span></span>        <span class="n">crop_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">)</span>
<span></span>        <span class="n">crop_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">crop_scores</span><span class="p">)</span>
<span></span>        <span class="n">keep</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">,</span> <span class="n">crop_scores</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">iou</span><span class="p">)</span>  <span class="c1"># NMS</span>
<span></span>        <span class="n">crop_bboxes</span> <span class="o">=</span> <span class="n">uncrop_boxes_xyxy</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">crop_region</span><span class="p">)</span>
<span></span>        <span class="n">crop_masks</span> <span class="o">=</span> <span class="n">uncrop_masks</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">crop_region</span><span class="p">,</span> <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span><span class="p">)</span>
<span></span>        <span class="n">crop_scores</span> <span class="o">=</span> <span class="n">crop_scores</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
<span></span>
<span></span>        <span class="n">pred_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">)</span>
<span></span>        <span class="n">pred_bboxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crop_bboxes</span><span class="p">)</span>
<span></span>        <span class="n">pred_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crop_scores</span><span class="p">)</span>
<span></span>        <span class="n">region_areas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">area</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">crop_masks</span><span class="p">)))</span>
<span></span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">)</span>
<span></span>    <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pred_bboxes</span><span class="p">)</span>
<span></span>    <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">)</span>
<span></span>    <span class="n">region_areas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">region_areas</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Remove duplicate masks between crops</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">crop_regions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span></span>        <span class="n">scores</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">region_areas</span>
<span></span>        <span class="n">keep</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">crop_nms_thresh</span><span class="p">)</span>
<span></span>        <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">pred_masks</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">pred_bboxes</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">pred_scores</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">,</span> <span class="n">pred_bboxes</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Extract image features using the SAM model's image encoder for subsequent mask prediction.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>591</span>
<span>592</span>
<span>593</span>
<span>594</span>
<span>595</span>
<span>596</span>
<span>597</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Extract image features using the SAM model's image encoder for subsequent mask prediction."""</span>
<span></span>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span>
<span></span>        <span class="sa">f</span><span class="s2">"SAM models only support square image size, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="si">}</span><span class="s2">."</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_imgsz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">image_encoder</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.get_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_model</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Retrieve or build the Segment Anything Model (SAM) for image segmentation tasks.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>474</span>
<span>475</span>
<span>476</span>
<span>477</span>
<span>478</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Retrieve or build the Segment Anything Model (SAM) for image segmentation tasks."""</span>
<span></span>    <span class="kn">from</span><span class="w"> </span><span class="nn">.build</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_sam</span>  <span class="c1"># slow import</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">build_sam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">inference</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
<span></span>    <span class="o">**</span><span class="n">kwargs</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation inference based on the given input cues, using the currently loaded image.</p>
<p>This method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt
encoder, and mask decoder for real-time and promptable segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed input image in tensor format, with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes with shape (N, 4), in XYXY format.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Labels for point prompts, shape (N,). 1 = foreground, 0 = background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Low-resolution masks from previous predictions, shape (N, H, W). For SAM H=W=256.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>multimask_output</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to return multiple masks. Helpful for ambiguous prompts.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>*args</code>
</td>
<td>
<code><span title="typing.Any">Any</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Additional positional arguments.</p>
</div>
</td>
<td>
<code>()</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>**kwargs</code>
</td>
<td>
<code><span title="typing.Any">Any</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Additional keyword arguments.</p>
</div>
</td>
<td>
<code>{}</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output masks in shape (C, H, W), where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_scores</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>An array of length C containing quality scores predicted by the model for each mask.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"sam_model.pt"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">]])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>171</span>
<span>172</span>
<span>173</span>
<span>174</span>
<span>175</span>
<span>176</span>
<span>177</span>
<span>178</span>
<span>179</span>
<span>180</span>
<span>181</span>
<span>182</span>
<span>183</span>
<span>184</span>
<span>185</span>
<span>186</span>
<span>187</span>
<span>188</span>
<span>189</span>
<span>190</span>
<span>191</span>
<span>192</span>
<span>193</span>
<span>194</span>
<span>195</span>
<span>196</span>
<span>197</span>
<span>198</span>
<span>199</span>
<span>200</span>
<span>201</span>
<span>202</span>
<span>203</span>
<span>204</span>
<span>205</span>
<span>206</span>
<span>207</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation inference based on the given input cues, using the currently loaded image.</span>
<span></span>
<span></span><span class="sd">    This method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt</span>
<span></span><span class="sd">    encoder, and mask decoder for real-time and promptable segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): The preprocessed input image in tensor format, with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List | None): Bounding boxes with shape (N, 4), in XYXY format.</span>
<span></span><span class="sd">        points (np.ndarray | List | None): Points indicating object locations with shape (N, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List | None): Labels for point prompts, shape (N,). 1 = foreground, 0 = background.</span>
<span></span><span class="sd">        masks (np.ndarray | None): Low-resolution masks from previous predictions, shape (N, H, W). For SAM H=W=256.</span>
<span></span><span class="sd">        multimask_output (bool): Flag to return multiple masks. Helpful for ambiguous prompts.</span>
<span></span><span class="sd">        *args (Any): Additional positional arguments.</span>
<span></span><span class="sd">        **kwargs (Any): Additional keyword arguments.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): The output masks in shape (C, H, W), where C is the number of generated masks.</span>
<span></span><span class="sd">        pred_scores (torch.Tensor): An array of length C containing quality scores predicted by the model for each mask.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_model(model_path="sam_model.pt")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image("image.jpg")</span>
<span></span><span class="sd">        &gt;&gt;&gt; results = predictor(bboxes=[[0, 0, 100, 100]])</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Override prompts if any stored in self.prompts</span>
<span></span>    <span class="n">bboxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"bboxes"</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">)</span>
<span></span>    <span class="n">points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"points"</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span></span>    <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"masks"</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>    <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"labels"</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">i</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">masks</span><span class="p">]):</span>
<span></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_inference</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">multimask_output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.inference_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">inference_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">inference_features</span><span class="p">(</span>
<span></span>    <span class="n">features</span><span class="p">,</span>
<span></span>    <span class="n">src_shape</span><span class="p">,</span>
<span></span>    <span class="n">dst_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform prompts preprocessing and inference on provided image features using the SAM model.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>features</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | <span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Extracted image features from the SAM/SAM2 model image encoder.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>src_shape</code>
</td>
<td>
<code><span title="Tuple">Tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The source shape (height, width) of the input image.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>dst_shape</code>
</td>
<td>
<code><span title="Tuple">Tuple</span>[<span title="int">int</span>, <span title="int">int</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The target shape (height, width) for the prompts. If None, defaults to (imgsz, imgsz).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span>[<span title="List">List</span>[<span title="float">float</span>]] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes in xyxy format with shape (N, 4).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span>[<span title="List">List</span>[<span title="float">float</span>]] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span>[<span title="int">int</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Point prompt labels with shape (N, ).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>] | <span title="numpy.ndarray">ndarray</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Masks for the objects, where each mask is a 2D array.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>multimask_output</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to return multiple masks for ambiguous prompts.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output masks in shape (C, H, W), where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_bboxes</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes for each mask with shape (N, 6), where N is the number of boxes.
Each box is in xyxy format with additional columns for score and class.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>The input features is a torch.Tensor of shape (B, C, H, W) if performing on SAM, or a Dict[str, Any] if performing on SAM2.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>660</span>
<span>661</span>
<span>662</span>
<span>663</span>
<span>664</span>
<span>665</span>
<span>666</span>
<span>667</span>
<span>668</span>
<span>669</span>
<span>670</span>
<span>671</span>
<span>672</span>
<span>673</span>
<span>674</span>
<span>675</span>
<span>676</span>
<span>677</span>
<span>678</span>
<span>679</span>
<span>680</span>
<span>681</span>
<span>682</span>
<span>683</span>
<span>684</span>
<span>685</span>
<span>686</span>
<span>687</span>
<span>688</span>
<span>689</span>
<span>690</span>
<span>691</span>
<span>692</span>
<span>693</span>
<span>694</span>
<span>695</span>
<span>696</span>
<span>697</span>
<span>698</span>
<span>699</span>
<span>700</span>
<span>701</span>
<span>702</span>
<span>703</span>
<span>704</span>
<span>705</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">inference_features</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">features</span><span class="p">,</span>
<span></span>    <span class="n">src_shape</span><span class="p">,</span>
<span></span>    <span class="n">dst_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform prompts preprocessing and inference on provided image features using the SAM model.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        features (torch.Tensor | Dict[str, Any]): Extracted image features from the SAM/SAM2 model image encoder.</span>
<span></span><span class="sd">        src_shape (Tuple[int, int]): The source shape (height, width) of the input image.</span>
<span></span><span class="sd">        dst_shape (Tuple[int, int] | None): The target shape (height, width) for the prompts. If None, defaults to (imgsz, imgsz).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List[List[float]] | None): Bounding boxes in xyxy format with shape (N, 4).</span>
<span></span><span class="sd">        points (np.ndarray | List[List[float]] | None): Points indicating object locations with shape (N, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List[int] | None): Point prompt labels with shape (N, ).</span>
<span></span><span class="sd">        masks (List[np.ndarray] | np.ndarray | None): Masks for the objects, where each mask is a 2D array.</span>
<span></span><span class="sd">        multimask_output (bool): Flag to return multiple masks for ambiguous prompts.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): The output masks in shape (C, H, W), where C is the number of generated masks.</span>
<span></span><span class="sd">        pred_bboxes (torch.Tensor): Bounding boxes for each mask with shape (N, 6), where N is the number of boxes.</span>
<span></span><span class="sd">            Each box is in xyxy format with additional columns for score and class.</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - The input features is a torch.Tensor of shape (B, C, H, W) if performing on SAM, or a Dict[str, Any] if performing on SAM2.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">dst_shape</span> <span class="o">=</span> <span class="n">dst_shape</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">imgsz</span><span class="p">)</span>
<span></span>    <span class="n">prompts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span><span class="n">dst_shape</span><span class="p">,</span> <span class="n">src_shape</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_features</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="o">*</span><span class="n">prompts</span><span class="p">,</span> <span class="n">multimask_output</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">scale_masks</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">src_shape</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span>        <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">pred_masks</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span>  <span class="c1"># to bool</span>
<span></span>        <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">)</span>
<span></span>        <span class="c1"># NOTE: SAM models do not return cls info. This `cls` here is just a placeholder for consistency.</span>
<span></span>        <span class="bp">cls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">cls</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_bboxes</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.postprocess">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">postprocess</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Post-process SAM's inference outputs to generate object detection masks and bounding boxes.</p>
<p>This method scales masks and boxes to the original image size and applies a threshold to the mask
predictions. It leverages SAM's advanced architecture for real-time, promptable segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>preds</code>
</td>
<td>
<code><span title="tuple">tuple</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output from SAM model inference, containing:
- pred_masks (torch.Tensor): Predicted masks with shape (N, 1, H, W).
- pred_scores (torch.Tensor): Confidence scores for each mask with shape (N, 1).
- pred_bboxes (torch.Tensor, optional): Predicted bounding boxes if segment_all is True.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>img</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The processed input image tensor with shape (C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>orig_imgs</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>] | <span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The original, unprocessed images.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="List">List</span>[<a class="autorefs autorefs-internal" href="../../../engine/results/#ultralytics.engine.results.Results" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.engine.results.Results&lt;/span&gt;'>Results</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of Results objects containing detection masks, bounding boxes, and other
metadata for each processed image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">preds</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>480</span>
<span>481</span>
<span>482</span>
<span>483</span>
<span>484</span>
<span>485</span>
<span>486</span>
<span>487</span>
<span>488</span>
<span>489</span>
<span>490</span>
<span>491</span>
<span>492</span>
<span>493</span>
<span>494</span>
<span>495</span>
<span>496</span>
<span>497</span>
<span>498</span>
<span>499</span>
<span>500</span>
<span>501</span>
<span>502</span>
<span>503</span>
<span>504</span>
<span>505</span>
<span>506</span>
<span>507</span>
<span>508</span>
<span>509</span>
<span>510</span>
<span>511</span>
<span>512</span>
<span>513</span>
<span>514</span>
<span>515</span>
<span>516</span>
<span>517</span>
<span>518</span>
<span>519</span>
<span>520</span>
<span>521</span>
<span>522</span>
<span>523</span>
<span>524</span>
<span>525</span>
<span>526</span>
<span>527</span>
<span>528</span>
<span>529</span>
<span>530</span>
<span>531</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Post-process SAM's inference outputs to generate object detection masks and bounding boxes.</span>
<span></span>
<span></span><span class="sd">    This method scales masks and boxes to the original image size and applies a threshold to the mask</span>
<span></span><span class="sd">    predictions. It leverages SAM's advanced architecture for real-time, promptable segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        preds (tuple): The output from SAM model inference, containing:</span>
<span></span><span class="sd">            - pred_masks (torch.Tensor): Predicted masks with shape (N, 1, H, W).</span>
<span></span><span class="sd">            - pred_scores (torch.Tensor): Confidence scores for each mask with shape (N, 1).</span>
<span></span><span class="sd">            - pred_bboxes (torch.Tensor, optional): Predicted bounding boxes if segment_all is True.</span>
<span></span><span class="sd">        img (torch.Tensor): The processed input image tensor with shape (C, H, W).</span>
<span></span><span class="sd">        orig_imgs (List[np.ndarray] | torch.Tensor): The original, unprocessed images.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (List[Results]): List of Results objects containing detection masks, bounding boxes, and other</span>
<span></span><span class="sd">            metadata for each processed image.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; preds = predictor.inference(img)</span>
<span></span><span class="sd">        &gt;&gt;&gt; results = predictor.postprocess(preds, img, orig_imgs)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># (N, 1, H, W), (N, 1)</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span></span>    <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="k">else</span> <span class="kc">None</span>
<span></span>    <span class="n">names</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">))))</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig_imgs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>  <span class="c1"># input images are a torch.Tensor, not a list</span>
<span></span>        <span class="n">orig_imgs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_torch2numpy_batch</span><span class="p">(</span><span class="n">orig_imgs</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">masks</span><span class="p">,</span> <span class="n">orig_img</span><span class="p">,</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">pred_masks</span><span class="p">],</span> <span class="n">orig_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
<span></span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>            <span class="n">masks</span><span class="p">,</span> <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="k">else</span><span class="p">:</span>
<span></span>            <span class="n">masks</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">scale_masks</span><span class="p">(</span><span class="n">masks</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">orig_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span>            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span>  <span class="c1"># to bool</span>
<span></span>            <span class="k">if</span> <span class="n">pred_bboxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>                <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">scale_boxes</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">pred_bboxes</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">orig_img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>            <span class="k">else</span><span class="p">:</span>
<span></span>                <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
<span></span>            <span class="c1"># NOTE: SAM models do not return cls info. This `cls` here is just a placeholder for consistency.</span>
<span></span>            <span class="bp">cls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">pred_scores</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">conf</span>
<span></span>            <span class="n">pred_bboxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">pred_bboxes</span><span class="p">,</span> <span class="n">pred_scores</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">cls</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span></span>            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span></span>        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Results</span><span class="p">(</span><span class="n">orig_img</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">img_path</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span> <span class="n">boxes</span><span class="o">=</span><span class="n">pred_bboxes</span><span class="p">))</span>
<span></span>    <span class="c1"># Reset segment-all mode.</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.pre_transform">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">pre_transform</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">pre_transform</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform initial transformations on the input image for preprocessing.</p>
<p>This method applies transformations such as resizing to prepare the image for further preprocessing.
Currently, batched inference is not supported; hence the list length should be 1.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List containing a single image in HWC numpy array format.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List containing the transformed image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If the input list contains more than one image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Single HWC image</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">transformed</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">pre_transform</span><span class="p">([</span><span class="n">image</span><span class="p">])</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformed</span><span class="p">))</span>
<span></span><span class="go">1</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>144</span>
<span>145</span>
<span>146</span>
<span>147</span>
<span>148</span>
<span>149</span>
<span>150</span>
<span>151</span>
<span>152</span>
<span>153</span>
<span>154</span>
<span>155</span>
<span>156</span>
<span>157</span>
<span>158</span>
<span>159</span>
<span>160</span>
<span>161</span>
<span>162</span>
<span>163</span>
<span>164</span>
<span>165</span>
<span>166</span>
<span>167</span>
<span>168</span>
<span>169</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">pre_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform initial transformations on the input image for preprocessing.</span>
<span></span>
<span></span><span class="sd">    This method applies transformations such as resizing to prepare the image for further preprocessing.</span>
<span></span><span class="sd">    Currently, batched inference is not supported; hence the list length should be 1.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (List[np.ndarray]): List containing a single image in HWC numpy array format.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (List[np.ndarray]): List containing the transformed image.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If the input list contains more than one image.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; image = np.random.rand(480, 640, 3)  # Single HWC image</span>
<span></span><span class="sd">        &gt;&gt;&gt; transformed = predictor.pre_transform([image])</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(len(transformed))</span>
<span></span><span class="sd">        1</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">im</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"SAM model does not currently support batched inference"</span>
<span></span>    <span class="n">letterbox</span> <span class="o">=</span> <span class="n">LetterBox</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="p">[</span><span class="n">letterbox</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">im</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.preprocess">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">preprocess</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">preprocess</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Preprocess the input image for model inference.</p>
<p>This method prepares the input image by applying transformations and normalization. It supports both
torch.Tensor and list of np.ndarray as input formats.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | <span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Input image(s) in BCHW tensor format or list of HWC numpy arrays.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed image tensor, normalized and converted to the appropriate dtype.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">preprocessed_image</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>111</span>
<span>112</span>
<span>113</span>
<span>114</span>
<span>115</span>
<span>116</span>
<span>117</span>
<span>118</span>
<span>119</span>
<span>120</span>
<span>121</span>
<span>122</span>
<span>123</span>
<span>124</span>
<span>125</span>
<span>126</span>
<span>127</span>
<span>128</span>
<span>129</span>
<span>130</span>
<span>131</span>
<span>132</span>
<span>133</span>
<span>134</span>
<span>135</span>
<span>136</span>
<span>137</span>
<span>138</span>
<span>139</span>
<span>140</span>
<span>141</span>
<span>142</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Preprocess the input image for model inference.</span>
<span></span>
<span></span><span class="sd">    This method prepares the input image by applying transformations and normalization. It supports both</span>
<span></span><span class="sd">    torch.Tensor and list of np.ndarray as input formats.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor | List[np.ndarray]): Input image(s) in BCHW tensor format or list of HWC numpy arrays.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (torch.Tensor): The preprocessed image tensor, normalized and converted to the appropriate dtype.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; image = torch.rand(1, 3, 640, 640)</span>
<span></span><span class="sd">        &gt;&gt;&gt; preprocessed_image = predictor.preprocess(image)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">im</span>
<span></span>    <span class="n">not_tensor</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">not_tensor</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_transform</span><span class="p">(</span><span class="n">im</span><span class="p">))</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">not_tensor</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="p">(</span><span class="n">im</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span>
<span></span>    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fp16</span> <span class="k">else</span> <span class="n">im</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span></span>    <span class="k">return</span> <span class="n">im</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.prompt_inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">prompt_inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">prompt_inference</span><span class="p">(</span>
<span></span>    <span class="n">im</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation inference based on input cues using SAM's specialized architecture.</p>
<p>This internal function leverages the Segment Anything Model (SAM) for prompt-based, real-time segmentation.
It processes various input prompts such as bounding boxes, points, and masks to generate segmentation masks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Preprocessed input image tensor with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes in XYXY format with shape (N, 4).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2) or (N, num_points, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Point prompt labels with shape (N) or (N, num_points). 1 for foreground, 0 for background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Low-res masks from previous predictions with shape (N, H, W). For SAM, H=W=256.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>multimask_output</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to return multiple masks for ambiguous prompts.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output masks with shape (C, H, W), where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_scores</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Quality scores predicted by the model for each mask, with length C.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">prompt_inference</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>209</span>
<span>210</span>
<span>211</span>
<span>212</span>
<span>213</span>
<span>214</span>
<span>215</span>
<span>216</span>
<span>217</span>
<span>218</span>
<span>219</span>
<span>220</span>
<span>221</span>
<span>222</span>
<span>223</span>
<span>224</span>
<span>225</span>
<span>226</span>
<span>227</span>
<span>228</span>
<span>229</span>
<span>230</span>
<span>231</span>
<span>232</span>
<span>233</span>
<span>234</span>
<span>235</span>
<span>236</span>
<span>237</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prompt_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation inference based on input cues using SAM's specialized architecture.</span>
<span></span>
<span></span><span class="sd">    This internal function leverages the Segment Anything Model (SAM) for prompt-based, real-time segmentation.</span>
<span></span><span class="sd">    It processes various input prompts such as bounding boxes, points, and masks to generate segmentation masks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): Preprocessed input image tensor with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List | None): Bounding boxes in XYXY format with shape (N, 4).</span>
<span></span><span class="sd">        points (np.ndarray | List | None): Points indicating object locations with shape (N, 2) or (N, num_points, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List | None): Point prompt labels with shape (N) or (N, num_points). 1 for foreground, 0 for background.</span>
<span></span><span class="sd">        masks (np.ndarray | None): Low-res masks from previous predictions with shape (N, H, W). For SAM, H=W=256.</span>
<span></span><span class="sd">        multimask_output (bool): Flag to return multiple masks for ambiguous prompts.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): Output masks with shape (C, H, W), where C is the number of generated masks.</span>
<span></span><span class="sd">        pred_scores (torch.Tensor): Quality scores predicted by the model for each mask, with length C.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; im = torch.rand(1, 3, 1024, 1024)</span>
<span></span><span class="sd">        &gt;&gt;&gt; bboxes = [[100, 100, 200, 200]]</span>
<span></span><span class="sd">        &gt;&gt;&gt; masks, scores, logits = predictor.prompt_inference(im, bboxes=bboxes)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span>
<span></span>
<span></span>    <span class="n">prompts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_features</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="o">*</span><span class="n">prompts</span><span class="p">,</span> <span class="n">multimask_output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.remove_small_regions">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">remove_small_regions</span>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">remove_small_regions</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Remove small disconnected regions and holes from segmentation masks.</p>
<p>This function performs post-processing on segmentation masks generated by the Segment Anything Model (SAM).
It removes small disconnected regions and holes from the input masks, and then performs Non-Maximum
Suppression (NMS) to eliminate any newly created duplicate boxes.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Segmentation masks to be processed, with shape (N, H, W) where N is the number of
masks, H is height, and W is width.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>min_area</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Minimum area threshold for removing disconnected regions and holes. Regions smaller than
this will be removed.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>nms_thresh</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>IoU threshold for the NMS algorithm to remove duplicate boxes.</p>
</div>
</td>
<td>
<code>0.7</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>new_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Processed masks with small regions removed, shape (N, H, W).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>keep</code></td> <td>
<code><span title="List">List</span>[<span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Indices of remaining masks after NMS, for filtering corresponding boxes.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span>  <span class="c1"># 5 random binary masks</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">new_masks</span><span class="p">,</span> <span class="n">keep</span> <span class="o">=</span> <span class="n">remove_small_regions</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original masks: </span><span class="si">{</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Processed masks: </span><span class="si">{</span><span class="n">new_masks</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Indices of kept masks: </span><span class="si">{</span><span class="n">keep</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>608</span>
<span>609</span>
<span>610</span>
<span>611</span>
<span>612</span>
<span>613</span>
<span>614</span>
<span>615</span>
<span>616</span>
<span>617</span>
<span>618</span>
<span>619</span>
<span>620</span>
<span>621</span>
<span>622</span>
<span>623</span>
<span>624</span>
<span>625</span>
<span>626</span>
<span>627</span>
<span>628</span>
<span>629</span>
<span>630</span>
<span>631</span>
<span>632</span>
<span>633</span>
<span>634</span>
<span>635</span>
<span>636</span>
<span>637</span>
<span>638</span>
<span>639</span>
<span>640</span>
<span>641</span>
<span>642</span>
<span>643</span>
<span>644</span>
<span>645</span>
<span>646</span>
<span>647</span>
<span>648</span>
<span>649</span>
<span>650</span>
<span>651</span>
<span>652</span>
<span>653</span>
<span>654</span>
<span>655</span>
<span>656</span>
<span>657</span>
<span>658</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@staticmethod</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">remove_small_regions</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nms_thresh</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Remove small disconnected regions and holes from segmentation masks.</span>
<span></span>
<span></span><span class="sd">    This function performs post-processing on segmentation masks generated by the Segment Anything Model (SAM).</span>
<span></span><span class="sd">    It removes small disconnected regions and holes from the input masks, and then performs Non-Maximum</span>
<span></span><span class="sd">    Suppression (NMS) to eliminate any newly created duplicate boxes.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        masks (torch.Tensor): Segmentation masks to be processed, with shape (N, H, W) where N is the number of</span>
<span></span><span class="sd">            masks, H is height, and W is width.</span>
<span></span><span class="sd">        min_area (int): Minimum area threshold for removing disconnected regions and holes. Regions smaller than</span>
<span></span><span class="sd">            this will be removed.</span>
<span></span><span class="sd">        nms_thresh (float): IoU threshold for the NMS algorithm to remove duplicate boxes.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        new_masks (torch.Tensor): Processed masks with small regions removed, shape (N, H, W).</span>
<span></span><span class="sd">        keep (List[int]): Indices of remaining masks after NMS, for filtering corresponding boxes.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; masks = torch.rand(5, 640, 640) &gt; 0.5  # 5 random binary masks</span>
<span></span><span class="sd">        &gt;&gt;&gt; new_masks, keep = remove_small_regions(masks, min_area=100, nms_thresh=0.7)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(f"Original masks: {masks.shape}, Processed masks: {new_masks.shape}")</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(f"Indices of kept masks: {keep}")</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>  <span class="c1"># scope for faster 'import ultralytics'</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">masks</span>
<span></span>
<span></span>    <span class="c1"># Filter small disconnected regions and holes</span>
<span></span>    <span class="n">new_masks</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">:</span>
<span></span>        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span></span>        <span class="n">mask</span><span class="p">,</span> <span class="n">changed</span> <span class="o">=</span> <span class="n">remove_small_regions</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">min_area</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"holes"</span><span class="p">)</span>
<span></span>        <span class="n">unchanged</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">changed</span>
<span></span>        <span class="n">mask</span><span class="p">,</span> <span class="n">changed</span> <span class="o">=</span> <span class="n">remove_small_regions</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">min_area</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"islands"</span><span class="p">)</span>
<span></span>        <span class="n">unchanged</span> <span class="o">=</span> <span class="n">unchanged</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">changed</span>
<span></span>
<span></span>        <span class="n">new_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span></span>        <span class="c1"># Give score=0 to changed masks and 1 to unchanged masks so NMS prefers masks not needing postprocessing</span>
<span></span>        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">unchanged</span><span class="p">))</span>
<span></span>
<span></span>    <span class="c1"># Recalculate boxes and remove any new duplicates</span>
<span></span>    <span class="n">new_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">new_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="n">boxes</span> <span class="o">=</span> <span class="n">batched_mask_to_box</span><span class="p">(</span><span class="n">new_masks</span><span class="p">)</span>
<span></span>    <span class="n">keep</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">boxes</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">nms_thresh</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">new_masks</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">masks</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">masks</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">keep</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.reset_image">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">reset_image</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">reset_image</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Reset the current image and its features, clearing them for subsequent inference.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>603</span>
<span>604</span>
<span>605</span>
<span>606</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">reset_image</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Reset the current image and its features, clearing them for subsequent inference."""</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.set_image">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">set_image</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">set_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Preprocess and set a single image for inference.</p>
<p>This method prepares the model for inference on a single image by setting up the model if not already
initialized, configuring the data source, and preprocessing the image for feature extraction. It
ensures that only one image is set at a time and extracts image features for subsequent use.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image</code>
</td>
<td>
<code><span title="str">str</span> | <span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Path to the image file as a string, or a numpy array representing
an image read by cv2.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">))</span>
</code></pre></div>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If more than one image is attempted to be set.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>This method should be called before performing inference on a new image.</li>
<li>The extracted features are stored in the <code>self.features</code> attribute for later use.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>558</span>
<span>559</span>
<span>560</span>
<span>561</span>
<span>562</span>
<span>563</span>
<span>564</span>
<span>565</span>
<span>566</span>
<span>567</span>
<span>568</span>
<span>569</span>
<span>570</span>
<span>571</span>
<span>572</span>
<span>573</span>
<span>574</span>
<span>575</span>
<span>576</span>
<span>577</span>
<span>578</span>
<span>579</span>
<span>580</span>
<span>581</span>
<span>582</span>
<span>583</span>
<span>584</span>
<span>585</span>
<span>586</span>
<span>587</span>
<span>588</span>
<span>589</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Preprocess and set a single image for inference.</span>
<span></span>
<span></span><span class="sd">    This method prepares the model for inference on a single image by setting up the model if not already</span>
<span></span><span class="sd">    initialized, configuring the data source, and preprocessing the image for feature extraction. It</span>
<span></span><span class="sd">    ensures that only one image is set at a time and extracts image features for subsequent use.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        image (str | np.ndarray): Path to the image file as a string, or a numpy array representing</span>
<span></span><span class="sd">            an image read by cv2.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image("path/to/image.jpg")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image(cv2.imread("path/to/image.jpg"))</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If more than one image is attempted to be set.</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - This method should be called before performing inference on a new image.</span>
<span></span><span class="sd">        - The extracted features are stored in the `self.features` attribute for later use.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"`set_image` only supports setting one image!"</span>
<span></span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="k">break</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.set_prompts">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">set_prompts</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">set_prompts</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Set prompts for subsequent inference operations.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>599</span>
<span>600</span>
<span>601</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_prompts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompts</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Set prompts for subsequent inference operations."""</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span> <span class="o">=</span> <span class="n">prompts</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.setup_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">setup_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Initialize the Segment Anything Model (SAM) for inference.</p>
<p>This method sets up the SAM model by allocating it to the appropriate device and initializing the necessary
parameters for image normalization and other Ultralytics compatibility settings.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>model</code>
</td>
<td>
<code><span title="torch.nn.Module">Module</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>A pretrained SAM model. If None, a new model is built based on config.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>verbose</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If True, prints selected device information.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">sam_model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>441</span>
<span>442</span>
<span>443</span>
<span>444</span>
<span>445</span>
<span>446</span>
<span>447</span>
<span>448</span>
<span>449</span>
<span>450</span>
<span>451</span>
<span>452</span>
<span>453</span>
<span>454</span>
<span>455</span>
<span>456</span>
<span>457</span>
<span>458</span>
<span>459</span>
<span>460</span>
<span>461</span>
<span>462</span>
<span>463</span>
<span>464</span>
<span>465</span>
<span>466</span>
<span>467</span>
<span>468</span>
<span>469</span>
<span>470</span>
<span>471</span>
<span>472</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the Segment Anything Model (SAM) for inference.</span>
<span></span>
<span></span><span class="sd">    This method sets up the SAM model by allocating it to the appropriate device and initializing the necessary</span>
<span></span><span class="sd">    parameters for image normalization and other Ultralytics compatibility settings.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (torch.nn.Module | None): A pretrained SAM model. If None, a new model is built based on config.</span>
<span></span><span class="sd">        verbose (bool): If True, prints selected device information.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_model(model=sam_model, verbose=True)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">device</span> <span class="o">=</span> <span class="n">select_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
<span></span>    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span></span>    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">half</span> <span class="k">else</span> <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">123.675</span><span class="p">,</span> <span class="mf">116.28</span><span class="p">,</span> <span class="mf">103.53</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">58.395</span><span class="p">,</span> <span class="mf">57.12</span><span class="p">,</span> <span class="mf">57.375</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Ultralytics compatibility settings</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pt</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">triton</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">32</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fp16</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">half</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">done_warmup</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fp16</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.Predictor.setup_source">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">setup_source</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">setup_source</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Set up the data source for inference.</p>
<p>This method configures the data source from which images will be fetched for inference. It supports
various input types such as image files, directories, video files, and other compatible data sources.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>source</code>
</td>
<td>
<code><span title="str">str</span> | <span title="Path">Path</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The path or identifier for the image data source. Can be a file path,
directory path, URL, or other supported source types.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="s2">"path/to/images"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="s2">"video.mp4"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># Uses default source if available</span>
</code></pre></div>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>If source is None, the method may use a default source if configured.</li>
<li>The method adapts to different source types and prepares them for subsequent inference steps.</li>
<li>Supported source types may include local files, directories, URLs, and video streams.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>533</span>
<span>534</span>
<span>535</span>
<span>536</span>
<span>537</span>
<span>538</span>
<span>539</span>
<span>540</span>
<span>541</span>
<span>542</span>
<span>543</span>
<span>544</span>
<span>545</span>
<span>546</span>
<span>547</span>
<span>548</span>
<span>549</span>
<span>550</span>
<span>551</span>
<span>552</span>
<span>553</span>
<span>554</span>
<span>555</span>
<span>556</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">setup_source</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Set up the data source for inference.</span>
<span></span>
<span></span><span class="sd">    This method configures the data source from which images will be fetched for inference. It supports</span>
<span></span><span class="sd">    various input types such as image files, directories, video files, and other compatible data sources.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        source (str | Path | None): The path or identifier for the image data source. Can be a file path,</span>
<span></span><span class="sd">            directory path, URL, or other supported source types.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_source("path/to/images")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_source("video.mp4")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.setup_source(None)  # Uses default source if available</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - If source is None, the method may use a default source if configured.</span>
<span></span><span class="sd">        - The method adapts to different source types and prepares them for subsequent inference steps.</span>
<span></span><span class="sd">        - Supported source types may include local files, directories, URLs, and video streams.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">source</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.SAM2Predictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">SAM2Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.Predictor&lt;/span&gt;'>Predictor</a></code></p>
<p>SAM2Predictor class for advanced image segmentation using Segment Anything Model 2 architecture.</p>
<p>This class extends the base Predictor class to implement SAM2-specific functionality for image
segmentation tasks. It provides methods for model initialization, feature extraction, and
prompt-based inference.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor._bb_feat_sizes">_bb_feat_sizes</span></code></td>
<td>
<code><span title="List">List</span>[<span title="tuple">tuple</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Feature sizes for different backbone levels.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.model">model</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The loaded SAM2 model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.device">device</span></code></td>
<td>
<code><span title="torch.device">device</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The device (CPU or GPU) on which the model is loaded.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.features">features</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Cached image features for efficient inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.segment_all">segment_all</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to indicate if all segments should be predicted.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2Predictor.prompts">prompts</span></code></td>
<td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary to store various types of prompts for inference.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.get_model&lt;/code&gt;)'>get_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Retrieve and initialize the SAM2 model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.prompt_inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;prompt_inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.prompt_inference&lt;/code&gt;)'>prompt_inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Perform image segmentation inference based on various prompts.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.set_image" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;set_image&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.set_image&lt;/code&gt;)'>set_image</a></code></td>
<td>
<div class="doc-md-description">
<p>Preprocess and set a single image for inference.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.get_im_features" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_im_features&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2Predictor.get_im_features&lt;/code&gt;)'>get_im_features</a></code></td>
<td>
<div class="doc-md-description">
<p>Extract and process image features using SAM2's image encoder.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2Predictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predicted </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="p">)</span><span class="si">}</span><span class="s2"> masks with average score </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span> 83</span>
<span> 84</span>
<span> 85</span>
<span> 86</span>
<span> 87</span>
<span> 88</span>
<span> 89</span>
<span> 90</span>
<span> 91</span>
<span> 92</span>
<span> 93</span>
<span> 94</span>
<span> 95</span>
<span> 96</span>
<span> 97</span>
<span> 98</span>
<span> 99</span>
<span>100</span>
<span>101</span>
<span>102</span>
<span>103</span>
<span>104</span>
<span>105</span>
<span>106</span>
<span>107</span>
<span>108</span>
<span>109</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the Predictor with configuration, overrides, and callbacks.</span>
<span></span>
<span></span><span class="sd">    Sets up the Predictor object for SAM (Segment Anything Model) and applies any configuration overrides or</span>
<span></span><span class="sd">    callbacks provided. Initializes task-specific settings for SAM, such as retina_masks being set to True</span>
<span></span><span class="sd">    for optimal results.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (dict): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (dict | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        _callbacks (dict | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example = Predictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = Predictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = Predictor(_callbacks={"on_predict_start": custom_callback})</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">overrides</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">overrides</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="n">overrides</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">"segment"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"predict"</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">retina_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">segment_all</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Extract image features from the SAM image encoder for subsequent processing.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>815</span>
<span>816</span>
<span>817</span>
<span>818</span>
<span>819</span>
<span>820</span>
<span>821</span>
<span>822</span>
<span>823</span>
<span>824</span>
<span>825</span>
<span>826</span>
<span>827</span>
<span>828</span>
<span>829</span>
<span>830</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Extract image features from the SAM image encoder for subsequent processing."""</span>
<span></span>    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span>
<span></span>        <span class="sa">f</span><span class="s2">"SAM 2 models only support square image size, but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="si">}</span><span class="s2">."</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_imgsz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">_bb_feat_sizes</span> <span class="o">=</span> <span class="p">[[</span><span class="n">x</span> <span class="o">//</span> <span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span></span>
<span></span>    <span class="n">backbone_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward_image</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>    <span class="n">_</span><span class="p">,</span> <span class="n">vision_feats</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_prepare_backbone_features</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">directly_add_no_mem_embed</span><span class="p">:</span>
<span></span>        <span class="n">vision_feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">vision_feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">no_mem_embed</span>
<span></span>    <span class="n">feats</span> <span class="o">=</span> <span class="p">[</span>
<span></span>        <span class="n">feat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">feat_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vision_feats</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bb_feat_sizes</span><span class="p">)</span>
<span></span>    <span class="p">]</span>
<span></span>    <span class="k">return</span> <span class="p">{</span><span class="s2">"image_embed"</span><span class="p">:</span> <span class="n">feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s2">"high_res_feats"</span><span class="p">:</span> <span class="n">feats</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]}</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.get_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_model</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Retrieve and initialize the Segment Anything Model 2 (SAM2) for image segmentation tasks.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>744</span>
<span>745</span>
<span>746</span>
<span>747</span>
<span>748</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Retrieve and initialize the Segment Anything Model 2 (SAM2) for image segmentation tasks."""</span>
<span></span>    <span class="kn">from</span><span class="w"> </span><span class="nn">.build</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_sam</span>  <span class="c1"># slow import</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">build_sam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2Predictor.set_image">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">set_image</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">set_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Preprocess and set a single image for inference using the SAM2 model.</p>
<p>This method initializes the model if not already done, configures the data source to the specified image,
and preprocesses the image for feature extraction. It supports setting only one image at a time.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image</code>
</td>
<td>
<code><span title="str">str</span> | <span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Path to the image file as a string, or a numpy array representing the image.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2Predictor</span><span class="p">()</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/image.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">...</span><span class="p">]))</span>  <span class="c1"># Using a numpy array</span>
</code></pre></div>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If more than one image is attempted to be set.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="notes" open="">
<summary>Notes</summary>
<ul>
<li>This method must be called before performing any inference on a new image.</li>
<li>The method caches the extracted features for efficient subsequent inferences on the same image.</li>
<li>Only one image can be set at a time. To process multiple images, call this method for each new image.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>783</span>
<span>784</span>
<span>785</span>
<span>786</span>
<span>787</span>
<span>788</span>
<span>789</span>
<span>790</span>
<span>791</span>
<span>792</span>
<span>793</span>
<span>794</span>
<span>795</span>
<span>796</span>
<span>797</span>
<span>798</span>
<span>799</span>
<span>800</span>
<span>801</span>
<span>802</span>
<span>803</span>
<span>804</span>
<span>805</span>
<span>806</span>
<span>807</span>
<span>808</span>
<span>809</span>
<span>810</span>
<span>811</span>
<span>812</span>
<span>813</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Preprocess and set a single image for inference using the SAM2 model.</span>
<span></span>
<span></span><span class="sd">    This method initializes the model if not already done, configures the data source to the specified image,</span>
<span></span><span class="sd">    and preprocesses the image for feature extraction. It supports setting only one image at a time.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        image (str | np.ndarray): Path to the image file as a string, or a numpy array representing the image.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = SAM2Predictor()</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image("path/to/image.jpg")</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor.set_image(np.array([...]))  # Using a numpy array</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If more than one image is attempted to be set.</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - This method must be called before performing any inference on a new image.</span>
<span></span><span class="sd">        - The method caches the extracted features for efficient subsequent inferences on the same image.</span>
<span></span><span class="sd">        - Only one image can be set at a time. To process multiple images, call this method for each new image.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">setup_source</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"`set_image` only supports setting one image!"</span>
<span></span>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="k">break</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.SAM2VideoPredictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">SAM2VideoPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.SAM2Predictor&lt;/span&gt;'>SAM2Predictor</a></code></p>
<p>SAM2VideoPredictor to handle user interactions with videos and manage inference states.</p>
<p>This class extends the functionality of SAM2Predictor to support video processing and maintains
the state of inference operations. It includes configurations for managing non-overlapping masks,
clearing memory for non-conditional inputs, and setting up callbacks for prediction events.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.inference_state">inference_state</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A dictionary to store the current state of inference operations.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.non_overlap_masks">non_overlap_masks</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A flag indicating whether masks should be non-overlapping.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.clear_non_cond_mem_around_input">clear_non_cond_mem_around_input</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A flag to control clearing non-conditional memory around inputs.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.clear_non_cond_mem_for_multi_obj">clear_non_cond_mem_for_multi_obj</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A flag to control clearing non-conditional memory for multi-object scenarios.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2VideoPredictor.callbacks">callbacks</span></code></td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A dictionary of callbacks for various prediction lifecycle events.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.get_model&lt;/code&gt;)'>get_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Retrieve and configure the model with binarization enabled.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.inference&lt;/code&gt;)'>inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Perform image segmentation inference based on the given input cues.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;postprocess&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess&lt;/code&gt;)'>postprocess</a></code></td>
<td>
<div class="doc-md-description">
<p>Post-process the predictions to apply non-overlapping constraints if required.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;add_new_prompts&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts&lt;/code&gt;)'>add_new_prompts</a></code></td>
<td>
<div class="doc-md-description">
<p>Add new points or masks to a specific frame for a given object ID.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;propagate_in_video_preflight&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight&lt;/code&gt;)'>propagate_in_video_preflight</a></code></td>
<td>
<div class="doc-md-description">
<p>Prepare inference_state and consolidate temporary outputs before tracking.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.init_state" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;init_state&lt;/span&gt;
  &lt;span class="doc doc-labels"&gt;
      &lt;small class="doc doc-label doc-label-staticmethod"&gt;&lt;code&gt;staticmethod&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.init_state&lt;/code&gt;)'>init_state</a></code></td>
<td>
<div class="doc-md-description">
<p>Initialize an inference state for the predictor.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_im_features&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features&lt;/code&gt;)'>get_im_features</a></code></td>
<td>
<div class="doc-md-description">
<p>Extract and process image features using SAM2's image encoder for subsequent segmentation tasks.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="o">.</span><span class="n">set_image</span><span class="p">(</span><span class="s2">"path/to/video_frame.jpg"</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bboxes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">]]</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">)</span>
</code></pre></div>
<details class="note" open="">
<summary>Note</summary>
<p>The <code>fill_hole_area</code> attribute is defined but not used in the current implementation.</p>
</details>
<p>This constructor initializes the SAM2VideoPredictor with a given configuration, applies any
specified overrides, and sets up the inference state along with certain flags
that control the behavior of the predictor.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>cfg</code>
</td>
<td>
<code><span title="dict">dict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration dictionary containing default settings.</p>
</div>
</td>
<td>
<code><span title="ultralytics.utils.DEFAULT_CFG">DEFAULT_CFG</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>overrides</code>
</td>
<td>
<code><span title="dict">dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of values to override default configuration.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>_callbacks</code>
</td>
<td>
<code><span title="dict">dict</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of callback functions to customize behavior.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_imgsz</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">overrides</span><span class="o">=</span><span class="p">{</span><span class="s2">"imgsz"</span><span class="p">:</span> <span class="mi">640</span><span class="p">})</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_callback</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="p">(</span><span class="n">_callbacks</span><span class="o">=</span><span class="p">{</span><span class="s2">"on_predict_start"</span><span class="p">:</span> <span class="n">custom_callback</span><span class="p">})</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>921</span>
<span>922</span>
<span>923</span>
<span>924</span>
<span>925</span>
<span>926</span>
<span>927</span>
<span>928</span>
<span>929</span>
<span>930</span>
<span>931</span>
<span>932</span>
<span>933</span>
<span>934</span>
<span>935</span>
<span>936</span>
<span>937</span>
<span>938</span>
<span>939</span>
<span>940</span>
<span>941</span>
<span>942</span>
<span>943</span>
<span>944</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">,</span> <span class="n">overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the predictor with configuration and optional overrides.</span>
<span></span>
<span></span><span class="sd">    This constructor initializes the SAM2VideoPredictor with a given configuration, applies any</span>
<span></span><span class="sd">    specified overrides, and sets up the inference state along with certain flags</span>
<span></span><span class="sd">    that control the behavior of the predictor.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (dict): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (dict | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        _callbacks (dict | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = SAM2VideoPredictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = SAM2VideoPredictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = SAM2VideoPredictor(_callbacks={"on_predict_start": custom_callback})</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span> <span class="o">=</span> <span class="p">{}</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">non_overlap_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_around_input</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_for_multi_obj</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">[</span><span class="s2">"on_predict_start"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_state</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.add_new_prompts">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">add_new_prompts</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">add_new_prompts</span><span class="p">(</span><span class="n">obj_id</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">frame_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Add new points or masks to a specific frame for a given object ID.</p>
<p>This method updates the inference state with new prompts (points or masks) for a specified
object and frame index. It ensures that the prompts are either points or masks, but not both,
and updates the internal state accordingly. It also handles the generation of new segmentations
based on the provided prompts and the existing state.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>obj_id</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The ID of the object to which the prompts are associated.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The coordinates of the points of interest.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The labels corresponding to the points.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Binary masks for the object.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>frame_idx</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The index of the frame to which the prompts are applied.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The flattened predicted masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_scores</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A tensor of ones indicating the number of objects.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If both <code>masks</code> and <code>points</code> are provided, or neither is provided.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<ul>
<li>Only one type of prompt (either points or masks) can be added per call.</li>
<li>If the frame is being tracked for the first time, it is treated as an initial conditioning frame.</li>
<li>The method handles the consolidation of outputs and resizing of masks to the original video resolution.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1057</span>
<span>1058</span>
<span>1059</span>
<span>1060</span>
<span>1061</span>
<span>1062</span>
<span>1063</span>
<span>1064</span>
<span>1065</span>
<span>1066</span>
<span>1067</span>
<span>1068</span>
<span>1069</span>
<span>1070</span>
<span>1071</span>
<span>1072</span>
<span>1073</span>
<span>1074</span>
<span>1075</span>
<span>1076</span>
<span>1077</span>
<span>1078</span>
<span>1079</span>
<span>1080</span>
<span>1081</span>
<span>1082</span>
<span>1083</span>
<span>1084</span>
<span>1085</span>
<span>1086</span>
<span>1087</span>
<span>1088</span>
<span>1089</span>
<span>1090</span>
<span>1091</span>
<span>1092</span>
<span>1093</span>
<span>1094</span>
<span>1095</span>
<span>1096</span>
<span>1097</span>
<span>1098</span>
<span>1099</span>
<span>1100</span>
<span>1101</span>
<span>1102</span>
<span>1103</span>
<span>1104</span>
<span>1105</span>
<span>1106</span>
<span>1107</span>
<span>1108</span>
<span>1109</span>
<span>1110</span>
<span>1111</span>
<span>1112</span>
<span>1113</span>
<span>1114</span>
<span>1115</span>
<span>1116</span>
<span>1117</span>
<span>1118</span>
<span>1119</span>
<span>1120</span>
<span>1121</span>
<span>1122</span>
<span>1123</span>
<span>1124</span>
<span>1125</span>
<span>1126</span>
<span>1127</span>
<span>1128</span>
<span>1129</span>
<span>1130</span>
<span>1131</span>
<span>1132</span>
<span>1133</span>
<span>1134</span>
<span>1135</span>
<span>1136</span>
<span>1137</span>
<span>1138</span>
<span>1139</span>
<span>1140</span>
<span>1141</span>
<span>1142</span>
<span>1143</span>
<span>1144</span>
<span>1145</span>
<span>1146</span>
<span>1147</span>
<span>1148</span>
<span>1149</span>
<span>1150</span>
<span>1151</span>
<span>1152</span>
<span>1153</span>
<span>1154</span>
<span>1155</span>
<span>1156</span>
<span>1157</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">add_new_prompts</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">obj_id</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">frame_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Add new points or masks to a specific frame for a given object ID.</span>
<span></span>
<span></span><span class="sd">    This method updates the inference state with new prompts (points or masks) for a specified</span>
<span></span><span class="sd">    object and frame index. It ensures that the prompts are either points or masks, but not both,</span>
<span></span><span class="sd">    and updates the internal state accordingly. It also handles the generation of new segmentations</span>
<span></span><span class="sd">    based on the provided prompts and the existing state.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        obj_id (int): The ID of the object to which the prompts are associated.</span>
<span></span><span class="sd">        points (torch.Tensor, optional): The coordinates of the points of interest.</span>
<span></span><span class="sd">        labels (torch.Tensor, optional): The labels corresponding to the points.</span>
<span></span><span class="sd">        masks (torch.Tensor, optional): Binary masks for the object.</span>
<span></span><span class="sd">        frame_idx (int, optional): The index of the frame to which the prompts are applied.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): The flattened predicted masks.</span>
<span></span><span class="sd">        pred_scores (torch.Tensor): A tensor of ones indicating the number of objects.</span>
<span></span>
<span></span><span class="sd">    Raises:</span>
<span></span><span class="sd">        AssertionError: If both `masks` and `points` are provided, or neither is provided.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        - Only one type of prompt (either points or masks) can be added per call.</span>
<span></span><span class="sd">        - If the frame is being tracked for the first time, it is treated as an initial conditioning frame.</span>
<span></span><span class="sd">        - The method handles the consolidation of outputs and resizing of masks to the original video resolution.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">assert</span> <span class="p">(</span><span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="o">^</span> <span class="p">(</span><span class="n">points</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">),</span> <span class="s2">"'masks' and 'points' prompts are not compatible with each other."</span>
<span></span>    <span class="n">obj_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obj_id_to_idx</span><span class="p">(</span><span class="n">obj_id</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">point_inputs</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="n">pop_key</span> <span class="o">=</span> <span class="s2">"point_inputs_per_obj"</span>
<span></span>    <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">point_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"point_coords"</span><span class="p">:</span> <span class="n">points</span><span class="p">,</span> <span class="s2">"point_labels"</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"point_inputs_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">point_inputs</span>
<span></span>        <span class="n">pop_key</span> <span class="o">=</span> <span class="s2">"mask_inputs_per_obj"</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"mask_inputs_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">masks</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="n">pop_key</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="c1"># If this frame hasn't been tracked before, we treat it as an initial conditioning</span>
<span></span>    <span class="c1"># frame, meaning that the inputs points are to generate segments on this frame without</span>
<span></span>    <span class="c1"># using any memory from other frames, like in SAM. Otherwise (if it has been tracked),</span>
<span></span>    <span class="c1"># the input points will be used to correct the already tracked masks.</span>
<span></span>    <span class="n">is_init_cond_frame</span> <span class="o">=</span> <span class="n">frame_idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"frames_already_tracked"</span><span class="p">]</span>
<span></span>    <span class="n">obj_output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">]</span>
<span></span>    <span class="n">obj_temp_output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"temp_output_dict_per_obj"</span><span class="p">][</span><span class="n">obj_idx</span><span class="p">]</span>
<span></span>    <span class="c1"># Add a frame to conditioning output if it's an initial conditioning frame or</span>
<span></span>    <span class="c1"># if the model sees all frames receiving clicks/mask as conditioning frames.</span>
<span></span>    <span class="n">is_cond</span> <span class="o">=</span> <span class="n">is_init_cond_frame</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">add_all_frames_to_correct_as_cond</span>
<span></span>    <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"cond_frame_outputs"</span> <span class="k">if</span> <span class="n">is_cond</span> <span class="k">else</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>
<span></span>    <span class="c1"># Get any previously predicted mask logits on this object and feed it along with</span>
<span></span>    <span class="c1"># the new clicks into the SAM mask decoder.</span>
<span></span>    <span class="n">prev_sam_mask_logits</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="c1"># lookup temporary output dict first, which contains the most recent output</span>
<span></span>    <span class="c1"># (if not found, then lookup conditioning and non-conditioning frame output)</span>
<span></span>    <span class="k">if</span> <span class="n">point_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">prev_out</span> <span class="o">=</span> <span class="p">(</span>
<span></span>            <span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>            <span class="ow">or</span> <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>            <span class="ow">or</span> <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>        <span class="p">)</span>
<span></span>
<span></span>        <span class="k">if</span> <span class="n">prev_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prev_out</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"pred_masks"</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="n">prev_sam_mask_logits</span> <span class="o">=</span> <span class="n">prev_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span>            <span class="c1"># Clamp the scale of prev_sam_mask_logits to avoid rare numerical issues.</span>
<span></span>            <span class="n">prev_sam_mask_logits</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="mf">32.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">)</span>
<span></span>    <span class="n">current_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_single_frame_inference</span><span class="p">(</span>
<span></span>        <span class="n">output_dict</span><span class="o">=</span><span class="n">obj_output_dict</span><span class="p">,</span>  <span class="c1"># run on the slice of a single object</span>
<span></span>        <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame_idx</span><span class="p">,</span>
<span></span>        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># run on the slice of a single object</span>
<span></span>        <span class="n">is_init_cond_frame</span><span class="o">=</span><span class="n">is_init_cond_frame</span><span class="p">,</span>
<span></span>        <span class="n">point_inputs</span><span class="o">=</span><span class="n">point_inputs</span><span class="p">,</span>
<span></span>        <span class="n">mask_inputs</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
<span></span>        <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="c1"># Skip the memory encoder when adding clicks or mask. We execute the memory encoder</span>
<span></span>        <span class="c1"># at the beginning of `propagate_in_video` (after user finalize their clicks). This</span>
<span></span>        <span class="c1"># allows us to enforce non-overlapping constraints on all objects before encoding</span>
<span></span>        <span class="c1"># them into memory.</span>
<span></span>        <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="n">prev_sam_mask_logits</span><span class="o">=</span><span class="n">prev_sam_mask_logits</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="c1"># Add the output to the output dict (to be used as future memory)</span>
<span></span>    <span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_out</span>
<span></span>
<span></span>    <span class="c1"># Resize the output mask to the original video resolution</span>
<span></span>    <span class="n">consolidated_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_consolidate_temp_output_across_obj</span><span class="p">(</span>
<span></span>        <span class="n">frame_idx</span><span class="p">,</span>
<span></span>        <span class="n">is_cond</span><span class="o">=</span><span class="n">is_cond</span><span class="p">,</span>
<span></span>        <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Extract and process image features using SAM2's image encoder for subsequent segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The input image tensor.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>batch</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The batch size for expanding features if there are multiple prompts.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>vis_feats</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The visual features extracted from the image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>vis_pos_embed</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The positional embeddings for the visual features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>feat_sizes</code></td> <td>
<code><span title="List">List</span>[<span title="tuple">tuple</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>A list containing the sizes of the extracted features.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<ul>
<li>If <code>batch</code> is greater than 1, the features are expanded to fit the batch size.</li>
<li>The method leverages the model's <code>_prepare_backbone_features</code> method to prepare the backbone features.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1278</span>
<span>1279</span>
<span>1280</span>
<span>1281</span>
<span>1282</span>
<span>1283</span>
<span>1284</span>
<span>1285</span>
<span>1286</span>
<span>1287</span>
<span>1288</span>
<span>1289</span>
<span>1290</span>
<span>1291</span>
<span>1292</span>
<span>1293</span>
<span>1294</span>
<span>1295</span>
<span>1296</span>
<span>1297</span>
<span>1298</span>
<span>1299</span>
<span>1300</span>
<span>1301</span>
<span>1302</span>
<span>1303</span>
<span>1304</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Extract and process image features using SAM2's image encoder for subsequent segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): The input image tensor.</span>
<span></span><span class="sd">        batch (int, optional): The batch size for expanding features if there are multiple prompts.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        vis_feats (torch.Tensor): The visual features extracted from the image.</span>
<span></span><span class="sd">        vis_pos_embed (torch.Tensor): The positional embeddings for the visual features.</span>
<span></span><span class="sd">        feat_sizes (List[tuple]): A list containing the sizes of the extracted features.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        - If `batch` is greater than 1, the features are expanded to fit the batch size.</span>
<span></span><span class="sd">        - The method leverages the model's `_prepare_backbone_features` method to prepare the backbone features.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_imgsz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">)</span>
<span></span>    <span class="n">backbone_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward_image</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">batch</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># expand features if there's more than one prompt</span>
<span></span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">[</span><span class="s2">"backbone_fpn"</span><span class="p">]):</span>
<span></span>            <span class="n">backbone_out</span><span class="p">[</span><span class="s2">"backbone_fpn"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">[</span><span class="s2">"vision_pos_enc"</span><span class="p">]):</span>
<span></span>            <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>            <span class="n">backbone_out</span><span class="p">[</span><span class="s2">"vision_pos_enc"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos</span>
<span></span>    <span class="n">_</span><span class="p">,</span> <span class="n">vis_feats</span><span class="p">,</span> <span class="n">vis_pos_embed</span><span class="p">,</span> <span class="n">feat_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_prepare_backbone_features</span><span class="p">(</span><span class="n">backbone_out</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">vis_feats</span><span class="p">,</span> <span class="n">vis_pos_embed</span><span class="p">,</span> <span class="n">feat_sizes</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.get_model">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_model</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_model</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Retrieve and configure the model with binarization enabled.</p>
<details class="note" open="">
<summary>Note</summary>
<p>This method overrides the base class implementation to set the binarize flag to True.</p>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>946</span>
<span>947</span>
<span>948</span>
<span>949</span>
<span>950</span>
<span>951</span>
<span>952</span>
<span>953</span>
<span>954</span>
<span>955</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Retrieve and configure the model with binarization enabled.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        This method overrides the base class implementation to set the binarize flag to True.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">model</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
<span></span>    <span class="n">model</span><span class="o">.</span><span class="n">set_binarize</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">inference</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform image segmentation inference based on the given input cues, using the currently loaded image. This
method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt encoder, and
mask decoder for real-time and promptable segmentation tasks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>im</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The preprocessed input image in tensor format, with shape (N, C, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Bounding boxes with shape (N, 4), in XYXY format.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Points indicating object locations with shape (N, 2), in pixels.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span> | <span title="List">List</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Labels for point prompts, shape (N, ). 1 = foreground, 0 = background.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Low-resolution masks from previous predictions shape (N,H,W). For SAM H=W=256.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>pred_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output masks in shape CxHxW, where C is the number of generated masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>pred_scores</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>An array of length C containing quality scores predicted by the model for each mask.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span> 957</span>
<span> 958</span>
<span> 959</span>
<span> 960</span>
<span> 961</span>
<span> 962</span>
<span> 963</span>
<span> 964</span>
<span> 965</span>
<span> 966</span>
<span> 967</span>
<span> 968</span>
<span> 969</span>
<span> 970</span>
<span> 971</span>
<span> 972</span>
<span> 973</span>
<span> 974</span>
<span> 975</span>
<span> 976</span>
<span> 977</span>
<span> 978</span>
<span> 979</span>
<span> 980</span>
<span> 981</span>
<span> 982</span>
<span> 983</span>
<span> 984</span>
<span> 985</span>
<span> 986</span>
<span> 987</span>
<span> 988</span>
<span> 989</span>
<span> 990</span>
<span> 991</span>
<span> 992</span>
<span> 993</span>
<span> 994</span>
<span> 995</span>
<span> 996</span>
<span> 997</span>
<span> 998</span>
<span> 999</span>
<span>1000</span>
<span>1001</span>
<span>1002</span>
<span>1003</span>
<span>1004</span>
<span>1005</span>
<span>1006</span>
<span>1007</span>
<span>1008</span>
<span>1009</span>
<span>1010</span>
<span>1011</span>
<span>1012</span>
<span>1013</span>
<span>1014</span>
<span>1015</span>
<span>1016</span>
<span>1017</span>
<span>1018</span>
<span>1019</span>
<span>1020</span>
<span>1021</span>
<span>1022</span>
<span>1023</span>
<span>1024</span>
<span>1025</span>
<span>1026</span>
<span>1027</span>
<span>1028</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform image segmentation inference based on the given input cues, using the currently loaded image. This</span>
<span></span><span class="sd">    method leverages SAM's (Segment Anything Model) architecture consisting of image encoder, prompt encoder, and</span>
<span></span><span class="sd">    mask decoder for real-time and promptable segmentation tasks.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        im (torch.Tensor): The preprocessed input image in tensor format, with shape (N, C, H, W).</span>
<span></span><span class="sd">        bboxes (np.ndarray | List, optional): Bounding boxes with shape (N, 4), in XYXY format.</span>
<span></span><span class="sd">        points (np.ndarray | List, optional): Points indicating object locations with shape (N, 2), in pixels.</span>
<span></span><span class="sd">        labels (np.ndarray | List, optional): Labels for point prompts, shape (N, ). 1 = foreground, 0 = background.</span>
<span></span><span class="sd">        masks (np.ndarray, optional): Low-resolution masks from previous predictions shape (N,H,W). For SAM H=W=256.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        pred_masks (torch.Tensor): The output masks in shape CxHxW, where C is the number of generated masks.</span>
<span></span><span class="sd">        pred_scores (torch.Tensor): An array of length C containing quality scores predicted by the model for each mask.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Override prompts if any stored in self.prompts</span>
<span></span>    <span class="n">bboxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"bboxes"</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">)</span>
<span></span>    <span class="n">points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"points"</span><span class="p">,</span> <span class="n">points</span><span class="p">)</span>
<span></span>    <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"masks"</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">frame</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"im"</span><span class="p">]</span> <span class="o">=</span> <span class="n">im</span>
<span></span>    <span class="n">output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict"</span><span class="p">]</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># initialize prompts</span>
<span></span>        <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span>
<span></span>            <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span>
<span></span>        <span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
<span></span>                <span class="bp">self</span><span class="o">.</span><span class="n">add_new_prompts</span><span class="p">(</span><span class="n">obj_id</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame</span><span class="p">)</span>
<span></span>        <span class="k">elif</span> <span class="n">masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)):</span>
<span></span>                <span class="bp">self</span><span class="o">.</span><span class="n">add_new_prompts</span><span class="p">(</span><span class="n">obj_id</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">propagate_in_video_preflight</span><span class="p">()</span>
<span></span>
<span></span>    <span class="n">consolidated_frame_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"consolidated_frame_inds"</span><span class="p">]</span>
<span></span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"obj_idx_to_id"</span><span class="p">])</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"No points are provided; please add points first"</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"cond_frame_outputs"</span>
<span></span>        <span class="n">current_out</span> <span class="o">=</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame</span><span class="p">]</span>
<span></span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_around_input</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_for_multi_obj</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
<span></span>            <span class="c1"># clear non-conditioning memory of the surrounding frames</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_non_cond_mem_around_input</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
<span></span>    <span class="k">elif</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>        <span class="n">current_out</span> <span class="o">=</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame</span><span class="p">]</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>        <span class="n">current_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_single_frame_inference</span><span class="p">(</span>
<span></span>            <span class="n">output_dict</span><span class="o">=</span><span class="n">output_dict</span><span class="p">,</span>
<span></span>            <span class="n">frame_idx</span><span class="o">=</span><span class="n">frame</span><span class="p">,</span>
<span></span>            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span></span>            <span class="n">is_init_cond_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>            <span class="n">point_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>            <span class="n">mask_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span></span>            <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>            <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="p">)</span>
<span></span>        <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_out</span>
<span></span>    <span class="c1"># Create slices of per-object outputs for subsequent interaction with each</span>
<span></span>    <span class="c1"># individual object after tracking.</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">_add_output_per_object</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">current_out</span><span class="p">,</span> <span class="n">storage_key</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"frames_already_tracked"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">current_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">pred_masks</span> <span class="o">=</span> <span class="n">pred_masks</span><span class="p">[(</span><span class="n">pred_masks</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">mask_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># filter blank masks</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_masks</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">pred_masks</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.init_state">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">init_state</span>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">init_state</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Initialize an inference state for the predictor.</p>
<p>This function sets up the initial state required for performing inference on video data.
It includes initializing various dictionaries and ordered dictionaries that will store
inputs, outputs, and other metadata relevant to the tracking process.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>predictor</code>
</td>
<td>
<code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2VideoPredictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.SAM2VideoPredictor&lt;/span&gt;'>SAM2VideoPredictor</a></code>
</td>
<td>
<div class="doc-md-description">
<p>The predictor object for which to initialize the state.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1230</span>
<span>1231</span>
<span>1232</span>
<span>1233</span>
<span>1234</span>
<span>1235</span>
<span>1236</span>
<span>1237</span>
<span>1238</span>
<span>1239</span>
<span>1240</span>
<span>1241</span>
<span>1242</span>
<span>1243</span>
<span>1244</span>
<span>1245</span>
<span>1246</span>
<span>1247</span>
<span>1248</span>
<span>1249</span>
<span>1250</span>
<span>1251</span>
<span>1252</span>
<span>1253</span>
<span>1254</span>
<span>1255</span>
<span>1256</span>
<span>1257</span>
<span>1258</span>
<span>1259</span>
<span>1260</span>
<span>1261</span>
<span>1262</span>
<span>1263</span>
<span>1264</span>
<span>1265</span>
<span>1266</span>
<span>1267</span>
<span>1268</span>
<span>1269</span>
<span>1270</span>
<span>1271</span>
<span>1272</span>
<span>1273</span>
<span>1274</span>
<span>1275</span>
<span>1276</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@staticmethod</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_state</span><span class="p">(</span><span class="n">predictor</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize an inference state for the predictor.</span>
<span></span>
<span></span><span class="sd">    This function sets up the initial state required for performing inference on video data.</span>
<span></span><span class="sd">    It includes initializing various dictionaries and ordered dictionaries that will store</span>
<span></span><span class="sd">    inputs, outputs, and other metadata relevant to the tracking process.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        predictor (SAM2VideoPredictor): The predictor object for which to initialize the state.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">inference_state</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># means initialized</span>
<span></span>        <span class="k">return</span>
<span></span>    <span class="k">assert</span> <span class="n">predictor</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span></span>    <span class="k">assert</span> <span class="n">predictor</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">"video"</span>
<span></span>
<span></span>    <span class="n">inference_state</span> <span class="o">=</span> <span class="p">{</span>
<span></span>        <span class="s2">"num_frames"</span><span class="p">:</span> <span class="n">predictor</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">frames</span><span class="p">,</span>
<span></span>        <span class="s2">"point_inputs_per_obj"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># inputs points on each frame</span>
<span></span>        <span class="s2">"mask_inputs_per_obj"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># inputs mask on each frame</span>
<span></span>        <span class="s2">"constants"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># values that don't change across frames (so we only need to hold one copy of them)</span>
<span></span>        <span class="c1"># mapping between client-side object id and model-side object index</span>
<span></span>        <span class="s2">"obj_id_to_idx"</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">(),</span>
<span></span>        <span class="s2">"obj_idx_to_id"</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">(),</span>
<span></span>        <span class="s2">"obj_ids"</span><span class="p">:</span> <span class="p">[],</span>
<span></span>        <span class="c1"># A storage to hold the model's tracking results and states on each frame</span>
<span></span>        <span class="s2">"output_dict"</span><span class="p">:</span> <span class="p">{</span>
<span></span>            <span class="s2">"cond_frame_outputs"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># dict containing {frame_idx: &lt;out&gt;}</span>
<span></span>            <span class="s2">"non_cond_frame_outputs"</span><span class="p">:</span> <span class="p">{},</span>  <span class="c1"># dict containing {frame_idx: &lt;out&gt;}</span>
<span></span>        <span class="p">},</span>
<span></span>        <span class="c1"># Slice (view) of each object tracking results, sharing the same memory with "output_dict"</span>
<span></span>        <span class="s2">"output_dict_per_obj"</span><span class="p">:</span> <span class="p">{},</span>
<span></span>        <span class="c1"># A temporary storage to hold new outputs when user interact with a frame</span>
<span></span>        <span class="c1"># to add clicks or mask (it's merged into "output_dict" before propagation starts)</span>
<span></span>        <span class="s2">"temp_output_dict_per_obj"</span><span class="p">:</span> <span class="p">{},</span>
<span></span>        <span class="c1"># Frames that already holds consolidated outputs from click or mask inputs</span>
<span></span>        <span class="c1"># (we directly use their consolidated outputs during tracking)</span>
<span></span>        <span class="s2">"consolidated_frame_inds"</span><span class="p">:</span> <span class="p">{</span>
<span></span>            <span class="s2">"cond_frame_outputs"</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>  <span class="c1"># set containing frame indices</span>
<span></span>            <span class="s2">"non_cond_frame_outputs"</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>  <span class="c1"># set containing frame indices</span>
<span></span>        <span class="p">},</span>
<span></span>        <span class="c1"># metadata for each tracking frame (e.g. which direction it's tracked)</span>
<span></span>        <span class="s2">"tracking_has_started"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="s2">"frames_already_tracked"</span><span class="p">:</span> <span class="p">[],</span>
<span></span>    <span class="p">}</span>
<span></span>    <span class="n">predictor</span><span class="o">.</span><span class="n">inference_state</span> <span class="o">=</span> <span class="n">inference_state</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.postprocess">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">postprocess</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Post-process the predictions to apply non-overlapping constraints if required.</p>
<p>This method extends the post-processing functionality by applying non-overlapping constraints
to the predicted masks if the <code>non_overlap_masks</code> flag is set to True. This ensures that
the masks do not overlap, which can be useful for certain applications.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>preds</code>
</td>
<td>
<code><span title="Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The predicted masks and scores from the model.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>img</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The processed image tensor.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>orig_imgs</code>
</td>
<td>
<code><span title="List">List</span>[<span title="numpy.ndarray">ndarray</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The original images before processing.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="list">list</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The post-processed predictions.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="note" open="">
<summary>Note</summary>
<p>If <code>non_overlap_masks</code> is True, the method applies constraints to ensure non-overlapping masks.</p>
</details>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1030</span>
<span>1031</span>
<span>1032</span>
<span>1033</span>
<span>1034</span>
<span>1035</span>
<span>1036</span>
<span>1037</span>
<span>1038</span>
<span>1039</span>
<span>1040</span>
<span>1041</span>
<span>1042</span>
<span>1043</span>
<span>1044</span>
<span>1045</span>
<span>1046</span>
<span>1047</span>
<span>1048</span>
<span>1049</span>
<span>1050</span>
<span>1051</span>
<span>1052</span>
<span>1053</span>
<span>1054</span>
<span>1055</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Post-process the predictions to apply non-overlapping constraints if required.</span>
<span></span>
<span></span><span class="sd">    This method extends the post-processing functionality by applying non-overlapping constraints</span>
<span></span><span class="sd">    to the predicted masks if the `non_overlap_masks` flag is set to True. This ensures that</span>
<span></span><span class="sd">    the masks do not overlap, which can be useful for certain applications.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        preds (Tuple[torch.Tensor, torch.Tensor]): The predicted masks and scores from the model.</span>
<span></span><span class="sd">        img (torch.Tensor): The processed image tensor.</span>
<span></span><span class="sd">        orig_imgs (List[np.ndarray]): The original images before processing.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (list): The post-processed predictions.</span>
<span></span>
<span></span><span class="sd">    Note:</span>
<span></span><span class="sd">        If `non_overlap_masks` is True, the method applies constraints to ensure non-overlapping masks.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">orig_imgs</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_overlap_masks</span><span class="p">:</span>
<span></span>        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span></span>            <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>                <span class="k">continue</span>
<span></span>            <span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_apply_non_overlapping_constraints</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">masks</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
<span></span>    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2VideoPredictor.propagate_in_video_preflight">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">propagate_in_video_preflight</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">propagate_in_video_preflight</span><span class="p">()</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Prepare inference_state and consolidate temporary outputs before tracking.</p>
<p>This method marks the start of tracking, disallowing the addition of new objects until the session is reset.
It consolidates temporary outputs from <code>temp_output_dict_per_obj</code> and merges them into <code>output_dict</code>.
Additionally, it clears non-conditioning memory around input frames and ensures that the state is consistent
with the provided inputs.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1159</span>
<span>1160</span>
<span>1161</span>
<span>1162</span>
<span>1163</span>
<span>1164</span>
<span>1165</span>
<span>1166</span>
<span>1167</span>
<span>1168</span>
<span>1169</span>
<span>1170</span>
<span>1171</span>
<span>1172</span>
<span>1173</span>
<span>1174</span>
<span>1175</span>
<span>1176</span>
<span>1177</span>
<span>1178</span>
<span>1179</span>
<span>1180</span>
<span>1181</span>
<span>1182</span>
<span>1183</span>
<span>1184</span>
<span>1185</span>
<span>1186</span>
<span>1187</span>
<span>1188</span>
<span>1189</span>
<span>1190</span>
<span>1191</span>
<span>1192</span>
<span>1193</span>
<span>1194</span>
<span>1195</span>
<span>1196</span>
<span>1197</span>
<span>1198</span>
<span>1199</span>
<span>1200</span>
<span>1201</span>
<span>1202</span>
<span>1203</span>
<span>1204</span>
<span>1205</span>
<span>1206</span>
<span>1207</span>
<span>1208</span>
<span>1209</span>
<span>1210</span>
<span>1211</span>
<span>1212</span>
<span>1213</span>
<span>1214</span>
<span>1215</span>
<span>1216</span>
<span>1217</span>
<span>1218</span>
<span>1219</span>
<span>1220</span>
<span>1221</span>
<span>1222</span>
<span>1223</span>
<span>1224</span>
<span>1225</span>
<span>1226</span>
<span>1227</span>
<span>1228</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">propagate_in_video_preflight</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Prepare inference_state and consolidate temporary outputs before tracking.</span>
<span></span>
<span></span><span class="sd">    This method marks the start of tracking, disallowing the addition of new objects until the session is reset.</span>
<span></span><span class="sd">    It consolidates temporary outputs from `temp_output_dict_per_obj` and merges them into `output_dict`.</span>
<span></span><span class="sd">    Additionally, it clears non-conditioning memory around input frames and ensures that the state is consistent</span>
<span></span><span class="sd">    with the provided inputs.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Tracking has started and we don't allow adding new objects until session is reset.</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"tracking_has_started"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"obj_idx_to_id"</span><span class="p">])</span>
<span></span>
<span></span>    <span class="c1"># Consolidate per-object temporary outputs in "temp_output_dict_per_obj" and</span>
<span></span>    <span class="c1"># add them into "output_dict".</span>
<span></span>    <span class="n">temp_output_dict_per_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"temp_output_dict_per_obj"</span><span class="p">]</span>
<span></span>    <span class="n">output_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict"</span><span class="p">]</span>
<span></span>    <span class="c1"># "consolidated_frame_inds" contains indices of those frames where consolidated</span>
<span></span>    <span class="c1"># temporary outputs have been added (either in this call or any previous calls</span>
<span></span>    <span class="c1"># to `propagate_in_video_preflight`).</span>
<span></span>    <span class="n">consolidated_frame_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"consolidated_frame_inds"</span><span class="p">]</span>
<span></span>    <span class="k">for</span> <span class="n">is_cond</span> <span class="ow">in</span> <span class="p">{</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">}:</span>
<span></span>        <span class="c1"># Separately consolidate conditioning and non-conditioning temp outputs</span>
<span></span>        <span class="n">storage_key</span> <span class="o">=</span> <span class="s2">"cond_frame_outputs"</span> <span class="k">if</span> <span class="n">is_cond</span> <span class="k">else</span> <span class="s2">"non_cond_frame_outputs"</span>
<span></span>        <span class="c1"># Find all the frames that contain temporary outputs for any objects</span>
<span></span>        <span class="c1"># (these should be the frames that have just received clicks for mask inputs</span>
<span></span>        <span class="c1"># via `add_new_points` or `add_new_mask`)</span>
<span></span>        <span class="n">temp_frame_inds</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span></span>        <span class="k">for</span> <span class="n">obj_temp_output_dict</span> <span class="ow">in</span> <span class="n">temp_output_dict_per_obj</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>            <span class="n">temp_frame_inds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span></span>        <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">temp_frame_inds</span><span class="p">)</span>
<span></span>        <span class="c1"># consolidate the temporary output across all objects on this frame</span>
<span></span>        <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">temp_frame_inds</span><span class="p">:</span>
<span></span>            <span class="n">consolidated_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_consolidate_temp_output_across_obj</span><span class="p">(</span>
<span></span>                <span class="n">frame_idx</span><span class="p">,</span> <span class="n">is_cond</span><span class="o">=</span><span class="n">is_cond</span><span class="p">,</span> <span class="n">run_mem_encoder</span><span class="o">=</span><span class="kc">True</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="c1"># merge them into "output_dict" and also create per-object slices</span>
<span></span>            <span class="n">output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">][</span><span class="n">frame_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">consolidated_out</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">_add_output_per_object</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="n">consolidated_out</span><span class="p">,</span> <span class="n">storage_key</span><span class="p">)</span>
<span></span>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_around_input</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clear_non_cond_mem_for_multi_obj</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
<span></span>                <span class="c1"># clear non-conditioning memory of the surrounding frames</span>
<span></span>                <span class="bp">self</span><span class="o">.</span><span class="n">_clear_non_cond_mem_around_input</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>
<span></span>        <span class="c1"># clear temporary outputs in `temp_output_dict_per_obj`</span>
<span></span>        <span class="k">for</span> <span class="n">obj_temp_output_dict</span> <span class="ow">in</span> <span class="n">temp_output_dict_per_obj</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>            <span class="n">obj_temp_output_dict</span><span class="p">[</span><span class="n">storage_key</span><span class="p">]</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span></span>
<span></span>    <span class="c1"># edge case: if an output is added to "cond_frame_outputs", we remove any prior</span>
<span></span>    <span class="c1"># output on the same frame in "non_cond_frame_outputs"</span>
<span></span>    <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="n">output_dict</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="k">for</span> <span class="n">obj_output_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"output_dict_per_obj"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>            <span class="n">obj_output_dict</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]:</span>
<span></span>        <span class="k">assert</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]</span>
<span></span>        <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span><span class="o">.</span><span class="n">discard</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Make sure that the frame indices in "consolidated_frame_inds" are exactly those frames</span>
<span></span>    <span class="c1"># with either points or mask inputs (which should be true under a correct workflow).</span>
<span></span>    <span class="n">all_consolidated_frame_inds</span> <span class="o">=</span> <span class="p">(</span>
<span></span>        <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"cond_frame_outputs"</span><span class="p">]</span> <span class="o">|</span> <span class="n">consolidated_frame_inds</span><span class="p">[</span><span class="s2">"non_cond_frame_outputs"</span><span class="p">]</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">input_frames_inds</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span></span>    <span class="k">for</span> <span class="n">point_inputs_per_frame</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"point_inputs_per_obj"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="n">input_frames_inds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">point_inputs_per_frame</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span></span>    <span class="k">for</span> <span class="n">mask_inputs_per_frame</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_state</span><span class="p">[</span><span class="s2">"mask_inputs_per_obj"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="n">input_frames_inds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mask_inputs_per_frame</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span></span>    <span class="k">assert</span> <span class="n">all_consolidated_frame_inds</span> <span class="o">==</span> <span class="n">input_frames_inds</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">SAM2DynamicInteractivePredictor</span><span class="p">(</span>
<span></span>    <span class="n">cfg</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">DEFAULT_CFG</span><span class="p">,</span>
<span></span>    <span class="n">overrides</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">max_obj_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span></span>    <span class="n">_callbacks</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.predict.SAM2Predictor&lt;/span&gt;'>SAM2Predictor</a></code></p>
<p>SAM2DynamicInteractivePredictor extends SAM2Predictor to support dynamic interactions with video frames or a
sequence of images.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.memory_bank">memory_bank</span></code></td>
<td>
<code><span title="list">list</span></code>
</td>
<td>
<div class="doc-md-description">
<p>OrderedDict: Stores the states of each image with prompts.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.obj_idx_set">obj_idx_set</span></code></td>
<td>
<code><span title="set">set</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A set to keep track of the object indices that have been added.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.obj_id_to_idx">obj_id_to_idx</span></code></td>
<td>
<code><span title="collections.OrderedDict">OrderedDict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Maps object IDs to their corresponding indices.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.obj_idx_to_id">obj_idx_to_id</span></code></td>
<td>
<code><span title="collections.OrderedDict">OrderedDict</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Maps object indices to their corresponding IDs.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2Predictor.get_model" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_model&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_model&lt;/code&gt;)'>get_model</a></code></td>
<td>
<div class="doc-md-description">
<p>Retrieves and configures the model with binarization enabled.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.inference" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;inference&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.inference&lt;/code&gt;)'>inference</a></code></td>
<td>
<div class="doc-md-description">
<p>Performs inference on a single image with optional prompts and object IDs.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.Predictor.postprocess" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;postprocess&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.postprocess&lt;/code&gt;)'>postprocess</a></code></td>
<td>
<div class="doc-md-description">
<p>Post-processes the predictions to apply non-overlapping constraints if required.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.update_memory" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;update_memory&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.update_memory&lt;/code&gt;)'>update_memory</a></code></td>
<td>
<div class="doc-md-description">
<p>Append the imgState to the memory_bank and update the memory for the model.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.track_step" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;track_step&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.track_step&lt;/code&gt;)'>track_step</a></code></td>
<td>
<div class="doc-md-description">
<p>Tracking step for the current image state to predict masks.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_maskmem_enc" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;get_maskmem_enc&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_maskmem_enc&lt;/code&gt;)'>get_maskmem_enc</a></code></td>
<td>
<div class="doc-md-description">
<p>Get memory and positional encoding from the memory bank.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2DynamicInteractivePredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">support_img1</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes1</span><span class="p">,</span> <span class="n">obj_ids</span><span class="o">=</span><span class="n">labels1</span><span class="p">,</span> <span class="n">update_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results1</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">query_img1</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">support_img2</span><span class="p">,</span> <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes2</span><span class="p">,</span> <span class="n">obj_ids</span><span class="o">=</span><span class="n">labels2</span><span class="p">,</span> <span class="n">update_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results2</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">query_img2</span><span class="p">)</span>
</code></pre></div>
<p>This constructor initializes the SAM2DynamicInteractivePredictor with a given configuration, applies any
specified overrides</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>cfg</code>
</td>
<td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Configuration dictionary containing default settings.</p>
</div>
</td>
<td>
<code><span title="ultralytics.utils.DEFAULT_CFG">DEFAULT_CFG</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>overrides</code>
</td>
<td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of values to override default configuration.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_obj_num</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Maximum number of objects to track. Default is 3. this is set to keep fix feature size for the model.</p>
</div>
</td>
<td>
<code>3</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>_callbacks</code>
</td>
<td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary of callback functions to customize behavior.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor</span> <span class="o">=</span> <span class="n">SAM2DynamicInteractivePredictor</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">DEFAULT_CFG</span><span class="p">)</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_imgsz</span> <span class="o">=</span> <span class="n">SAM2DynamicInteractivePredictor</span><span class="p">(</span><span class="n">overrides</span><span class="o">=</span><span class="p">{</span><span class="s2">"imgsz"</span><span class="p">:</span> <span class="mi">640</span><span class="p">})</span>
<span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictor_example_with_callback</span> <span class="o">=</span> <span class="n">SAM2DynamicInteractivePredictor</span><span class="p">(</span>
<span></span><span class="gp">... </span>    <span class="n">_callbacks</span><span class="o">=</span><span class="p">{</span><span class="s2">"on_predict_start"</span><span class="p">:</span> <span class="n">custom_callback</span><span class="p">}</span>
<span></span><span class="gp">... </span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1719</span>
<span>1720</span>
<span>1721</span>
<span>1722</span>
<span>1723</span>
<span>1724</span>
<span>1725</span>
<span>1726</span>
<span>1727</span>
<span>1728</span>
<span>1729</span>
<span>1730</span>
<span>1731</span>
<span>1732</span>
<span>1733</span>
<span>1734</span>
<span>1735</span>
<span>1736</span>
<span>1737</span>
<span>1738</span>
<span>1739</span>
<span>1740</span>
<span>1741</span>
<span>1742</span>
<span>1743</span>
<span>1744</span>
<span>1745</span>
<span>1746</span>
<span>1747</span>
<span>1748</span>
<span>1749</span>
<span>1750</span>
<span>1751</span>
<span>1752</span>
<span>1753</span>
<span>1754</span>
<span>1755</span>
<span>1756</span>
<span>1757</span>
<span>1758</span>
<span>1759</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">cfg</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">DEFAULT_CFG</span><span class="p">,</span>
<span></span>    <span class="n">overrides</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">max_obj_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span></span>    <span class="n">_callbacks</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the predictor with configuration and optional overrides.</span>
<span></span>
<span></span><span class="sd">    This constructor initializes the SAM2DynamicInteractivePredictor with a given configuration, applies any</span>
<span></span><span class="sd">    specified overrides</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        cfg (Dict[str, Any]): Configuration dictionary containing default settings.</span>
<span></span><span class="sd">        overrides (Dict[str, Any] | None): Dictionary of values to override default configuration.</span>
<span></span><span class="sd">        max_obj_num (int): Maximum number of objects to track. Default is 3. this is set to keep fix feature size for the model.</span>
<span></span><span class="sd">        _callbacks (Dict[str, Any] | None): Dictionary of callback functions to customize behavior.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor = SAM2DynamicInteractivePredictor(cfg=DEFAULT_CFG)</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_imgsz = SAM2DynamicInteractivePredictor(overrides={"imgsz": 640})</span>
<span></span><span class="sd">        &gt;&gt;&gt; predictor_example_with_callback = SAM2DynamicInteractivePredictor(</span>
<span></span><span class="sd">        ...     _callbacks={"on_predict_start": custom_callback}</span>
<span></span><span class="sd">        ... )</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">overrides</span><span class="p">,</span> <span class="n">_callbacks</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">non_overlap_masks</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>
<span></span>    <span class="c1"># Initialize the memory bank to store image states</span>
<span></span>    <span class="c1"># NOTE: probably need to use dict for better query</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">memory_bank</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>
<span></span>    <span class="c1"># Initialize the object index set and mappings</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">obj_idx_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">obj_id_to_idx</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">obj_idx_to_id</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span> <span class="o">=</span> <span class="n">max_obj_num</span>
<span></span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span><span class="p">):</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">obj_id_to_idx</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">obj_idx_to_id</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_im_features">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_im_features</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_im_features</span><span class="p">(</span><span class="n">img</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Initialize the image state by processing the input image and extracting features.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>img</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | <span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The input image tensor or numpy array.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1829</span>
<span>1830</span>
<span>1831</span>
<span>1832</span>
<span>1833</span>
<span>1834</span>
<span>1835</span>
<span>1836</span>
<span>1837</span>
<span>1838</span>
<span>1839</span>
<span>1840</span>
<span>1841</span>
<span>1842</span>
<span>1843</span>
<span>1844</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Initialize the image state by processing the input image and extracting features.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        img (torch.Tensor | np.ndarray): The input image tensor or numpy array.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">vis_feats</span><span class="p">,</span> <span class="n">vis_pos_embed</span><span class="p">,</span> <span class="n">feat_sizes</span> <span class="o">=</span> <span class="n">SAM2VideoPredictor</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">high_res_features</span> <span class="o">=</span> <span class="p">[</span>
<span></span>        <span class="n">feat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="o">*</span><span class="n">feat_size</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vis_feats</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">feat_sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span></span>    <span class="p">]</span>
<span></span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">vision_feats</span> <span class="o">=</span> <span class="n">vis_feats</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">vision_pos_embeds</span> <span class="o">=</span> <span class="n">vis_pos_embed</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">feat_sizes</span> <span class="o">=</span> <span class="n">feat_sizes</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.get_maskmem_enc">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">get_maskmem_enc</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">get_maskmem_enc</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Get the memory and positional encoding from the memory, which is used to condition the current image
features.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1963</span>
<span>1964</span>
<span>1965</span>
<span>1966</span>
<span>1967</span>
<span>1968</span>
<span>1969</span>
<span>1970</span>
<span>1971</span>
<span>1972</span>
<span>1973</span>
<span>1974</span>
<span>1975</span>
<span>1976</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_maskmem_enc</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span></span><span class="w">    </span><span class="sd">"""Get the memory and positional encoding from the memory, which is used to condition the current image</span>
<span></span><span class="sd">    features.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">to_cat_memory</span><span class="p">,</span> <span class="n">to_cat_memory_pos_embed</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span></span>    <span class="k">for</span> <span class="n">consolidated_out</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_bank</span><span class="p">:</span>
<span></span>        <span class="n">to_cat_memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"maskmem_features"</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># (H*W, B, C)</span>
<span></span>        <span class="n">maskmem_enc</span> <span class="o">=</span> <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"maskmem_pos_enc"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>        <span class="n">maskmem_enc</span> <span class="o">=</span> <span class="n">maskmem_enc</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">maskmem_tpos_enc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_maskmem</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
<span></span>        <span class="n">to_cat_memory_pos_embed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">maskmem_enc</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">to_cat_memory</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="n">memory_pos_embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">to_cat_memory_pos_embed</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_pos_embed</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.inference">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">inference</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">inference</span><span class="p">(</span>
<span></span>    <span class="n">img</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="n">ndarray</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">obj_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">update_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Perform inference on a single image with optional bounding boxes, masks, points and object IDs.
It has two modes: one is to run inference on a single image without updating the memory,
and the other is to update the memory with the provided prompts and object IDs.
When update_memory is True, it will update the memory with the provided prompts and obj_ids.
When update_memory is False, it will only run inference on the provided image without updating the memory.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>img</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | <span title="numpy.ndarray">ndarray</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The input image tensor or numpy array.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bboxes</code>
</td>
<td>
<code><span title="List">List</span>[<span title="List">List</span>[<span title="float">float</span>]] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional list of bounding boxes to update the memory.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="List">List</span>[<span title="torch.Tensor">Tensor</span> | <span title="numpy.ndarray">ndarray</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional masks to update the memory.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="List">List</span>[<span title="List">List</span>[<span title="float">float</span>]] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional list of points to update the memory, each point is [x, y].</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="List">List</span>[<span title="int">int</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional list of object IDs corresponding to the points (&gt;0 for positive, 0 for negative).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>obj_ids</code>
</td>
<td>
<code><span title="List">List</span>[<span title="int">int</span>] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional list of object IDs corresponding to the prompts.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>update_memory</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to indicate whether to update the memory with new objects.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>res_masks</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The output masks in shape (C, H, W)</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>object_score_logits</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Quality scores for each mask</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1761</span>
<span>1762</span>
<span>1763</span>
<span>1764</span>
<span>1765</span>
<span>1766</span>
<span>1767</span>
<span>1768</span>
<span>1769</span>
<span>1770</span>
<span>1771</span>
<span>1772</span>
<span>1773</span>
<span>1774</span>
<span>1775</span>
<span>1776</span>
<span>1777</span>
<span>1778</span>
<span>1779</span>
<span>1780</span>
<span>1781</span>
<span>1782</span>
<span>1783</span>
<span>1784</span>
<span>1785</span>
<span>1786</span>
<span>1787</span>
<span>1788</span>
<span>1789</span>
<span>1790</span>
<span>1791</span>
<span>1792</span>
<span>1793</span>
<span>1794</span>
<span>1795</span>
<span>1796</span>
<span>1797</span>
<span>1798</span>
<span>1799</span>
<span>1800</span>
<span>1801</span>
<span>1802</span>
<span>1803</span>
<span>1804</span>
<span>1805</span>
<span>1806</span>
<span>1807</span>
<span>1808</span>
<span>1809</span>
<span>1810</span>
<span>1811</span>
<span>1812</span>
<span>1813</span>
<span>1814</span>
<span>1815</span>
<span>1816</span>
<span>1817</span>
<span>1818</span>
<span>1819</span>
<span>1820</span>
<span>1821</span>
<span>1822</span>
<span>1823</span>
<span>1824</span>
<span>1825</span>
<span>1826</span>
<span>1827</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">inference</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">img</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span></span>    <span class="n">bboxes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">obj_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">update_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Perform inference on a single image with optional bounding boxes, masks, points and object IDs.</span>
<span></span><span class="sd">    It has two modes: one is to run inference on a single image without updating the memory,</span>
<span></span><span class="sd">    and the other is to update the memory with the provided prompts and object IDs.</span>
<span></span><span class="sd">    When update_memory is True, it will update the memory with the provided prompts and obj_ids.</span>
<span></span><span class="sd">    When update_memory is False, it will only run inference on the provided image without updating the memory.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        img (torch.Tensor | np.ndarray): The input image tensor or numpy array.</span>
<span></span><span class="sd">        bboxes (List[List[float]] | None): Optional list of bounding boxes to update the memory.</span>
<span></span><span class="sd">        masks (List[torch.Tensor | np.ndarray] | None): Optional masks to update the memory.</span>
<span></span><span class="sd">        points (List[List[float]] | None): Optional list of points to update the memory, each point is [x, y].</span>
<span></span><span class="sd">        labels (List[int] | None): Optional list of object IDs corresponding to the points (&gt;0 for positive, 0 for negative).</span>
<span></span><span class="sd">        obj_ids (List[int] | None): Optional list of object IDs corresponding to the prompts.</span>
<span></span><span class="sd">        update_memory (bool): Flag to indicate whether to update the memory with new objects.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        res_masks (torch.Tensor): The output masks in shape (C, H, W)</span>
<span></span><span class="sd">        object_score_logits (torch.Tensor): Quality scores for each mask</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">get_im_features</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span></span>    <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_prompts</span><span class="p">(</span>
<span></span>        <span class="n">dst_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span>
<span></span>        <span class="n">src_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
<span></span>        <span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span>
<span></span>        <span class="n">bboxes</span><span class="o">=</span><span class="n">bboxes</span><span class="p">,</span>
<span></span>        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
<span></span>        <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">update_memory</span><span class="p">:</span>
<span></span>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
<span></span>            <span class="n">obj_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj_ids</span><span class="p">]</span>
<span></span>        <span class="k">assert</span> <span class="n">obj_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">"obj_ids must be provided when update_memory is True"</span>
<span></span>        <span class="k">assert</span> <span class="n">masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
<span></span>            <span class="s2">"bboxes, masks, or points must be provided when update_memory is True"</span>
<span></span>        <span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">points</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># placeholder</span>
<span></span>            <span class="n">points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">torch_dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">),</span> <span class="s2">"masks and obj_ids must have the same length."</span>
<span></span>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">),</span> <span class="s2">"points and obj_ids must have the same length."</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">update_memory</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">current_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_step</span><span class="p">()</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">current_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">],</span> <span class="n">current_out</span><span class="p">[</span><span class="s2">"object_score_logits"</span><span class="p">]</span>
<span></span>    <span class="c1"># filter the masks and logits based on the object indices</span>
<span></span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obj_idx_set</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"No objects have been added to the state. Please add objects before inference."</span><span class="p">)</span>
<span></span>    <span class="n">idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obj_idx_set</span><span class="p">)</span>  <span class="c1"># cls id</span>
<span></span>    <span class="n">pred_masks</span><span class="p">,</span> <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">pred_masks</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">pred_scores</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span></span>    <span class="c1"># the original score are in [-32,32], and a object score larger than 0 means the object is present, we map it to [-1,1] range,</span>
<span></span>    <span class="c1"># and use a activate function to make sure the object score logits are non-negative, so that we can use it as a mask</span>
<span></span>    <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="n">pred_scores</span> <span class="o">/</span> <span class="mi">32</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">pred_masks</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">pred_scores</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.track_step">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">track_step</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">track_step</span><span class="p">(</span>
<span></span>    <span class="n">obj_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">point</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">label</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Tracking step for the current image state to predict masks.</p>
<p>This method processes the image features and runs the SAM heads to predict masks. If obj_idx is provided, it
processes the features for a specific prompted object in the image. If obj_idx is None, it processes the
features for all objects in the image. The method supports both mask-based output without SAM and full
SAM processing with memory-conditioned features.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>obj_idx</code>
</td>
<td>
<code><span title="int">int</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The index of the object for which to predict masks. If None, it processes all objects.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>point</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The coordinates of the points of interest with shape (N, 2).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>label</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The labels corresponding to the points where 1 means positive clicks, 0 means negative clicks.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mask</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The mask input for the object with shape (H, W).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>current_out</code></td> <td>
<code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>A dictionary containing the current output with mask predictions and object pointers.
Keys include 'point_inputs', 'mask_inputs', 'pred_masks', 'pred_masks_high_res', 'obj_ptr', 'object_score_logits'.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1990</span>
<span>1991</span>
<span>1992</span>
<span>1993</span>
<span>1994</span>
<span>1995</span>
<span>1996</span>
<span>1997</span>
<span>1998</span>
<span>1999</span>
<span>2000</span>
<span>2001</span>
<span>2002</span>
<span>2003</span>
<span>2004</span>
<span>2005</span>
<span>2006</span>
<span>2007</span>
<span>2008</span>
<span>2009</span>
<span>2010</span>
<span>2011</span>
<span>2012</span>
<span>2013</span>
<span>2014</span>
<span>2015</span>
<span>2016</span>
<span>2017</span>
<span>2018</span>
<span>2019</span>
<span>2020</span>
<span>2021</span>
<span>2022</span>
<span>2023</span>
<span>2024</span>
<span>2025</span>
<span>2026</span>
<span>2027</span>
<span>2028</span>
<span>2029</span>
<span>2030</span>
<span>2031</span>
<span>2032</span>
<span>2033</span>
<span>2034</span>
<span>2035</span>
<span>2036</span>
<span>2037</span>
<span>2038</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">track_step</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">obj_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">point</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">label</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Tracking step for the current image state to predict masks.</span>
<span></span>
<span></span><span class="sd">    This method processes the image features and runs the SAM heads to predict masks. If obj_idx is provided, it</span>
<span></span><span class="sd">    processes the features for a specific prompted object in the image. If obj_idx is None, it processes the</span>
<span></span><span class="sd">    features for all objects in the image. The method supports both mask-based output without SAM and full</span>
<span></span><span class="sd">    SAM processing with memory-conditioned features.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        obj_idx (int | None): The index of the object for which to predict masks. If None, it processes all objects.</span>
<span></span><span class="sd">        point (torch.Tensor | None): The coordinates of the points of interest with shape (N, 2).</span>
<span></span><span class="sd">        label (torch.Tensor | None): The labels corresponding to the points where 1 means positive clicks, 0 means negative clicks.</span>
<span></span><span class="sd">        mask (torch.Tensor | None): The mask input for the object with shape (H, W).</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        current_out (Dict[str, Any]): A dictionary containing the current output with mask predictions and object pointers.</span>
<span></span><span class="sd">            Keys include 'point_inputs', 'mask_inputs', 'pred_masks', 'pred_masks_high_res', 'obj_ptr', 'object_score_logits'.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_mask_input_as_output_without_sam</span><span class="p">:</span>
<span></span>        <span class="c1"># When use_mask_input_as_output_without_sam=True, we directly output the mask input</span>
<span></span>        <span class="c1"># (see it as a GT mask) without using a SAM prompt encoder + mask decoder.</span>
<span></span>        <span class="n">pix_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_feats</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span></span>        <span class="n">pix_feat</span> <span class="o">=</span> <span class="n">pix_feat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">memory_attention</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span></span>        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">low_res_masks</span><span class="p">,</span> <span class="n">high_res_masks</span><span class="p">,</span> <span class="n">obj_ptr</span><span class="p">,</span> <span class="n">object_score_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_use_mask_as_output</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="c1"># fused the visual feature with previous memory features in the memory bank</span>
<span></span>        <span class="n">pix_feat_with_mem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_memory_conditioned_features</span><span class="p">(</span><span class="n">obj_idx</span><span class="p">)</span>
<span></span>        <span class="c1"># calculate the first feature if adding obj_idx exists(means adding prompts)</span>
<span></span>        <span class="n">pix_feat_with_mem</span> <span class="o">=</span> <span class="n">pix_feat_with_mem</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">obj_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pix_feat_with_mem</span>
<span></span>        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">low_res_masks</span><span class="p">,</span> <span class="n">high_res_masks</span><span class="p">,</span> <span class="n">obj_ptr</span><span class="p">,</span> <span class="n">object_score_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_forward_sam_heads</span><span class="p">(</span>
<span></span>            <span class="n">backbone_features</span><span class="o">=</span><span class="n">pix_feat_with_mem</span><span class="p">,</span>
<span></span>            <span class="n">point_inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">"point_coords"</span><span class="p">:</span> <span class="n">point</span><span class="p">,</span> <span class="s2">"point_labels"</span><span class="p">:</span> <span class="n">label</span><span class="p">}</span> <span class="k">if</span> <span class="n">obj_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<span></span>            <span class="n">mask_inputs</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
<span></span>            <span class="n">multimask_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>            <span class="n">high_res_features</span><span class="o">=</span><span class="p">[</span><span class="n">feat</span><span class="p">[:</span> <span class="n">pix_feat_with_mem</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">high_res_features</span><span class="p">],</span>
<span></span>        <span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="p">{</span>
<span></span>        <span class="s2">"pred_masks"</span><span class="p">:</span> <span class="n">low_res_masks</span><span class="p">,</span>
<span></span>        <span class="s2">"pred_masks_high_res"</span><span class="p">:</span> <span class="n">high_res_masks</span><span class="p">,</span>
<span></span>        <span class="s2">"obj_ptr"</span><span class="p">:</span> <span class="n">obj_ptr</span><span class="p">,</span>
<span></span>        <span class="s2">"object_score_logits"</span><span class="p">:</span> <span class="n">object_score_logits</span><span class="p">,</span>
<span></span>    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.predict.SAM2DynamicInteractivePredictor.update_memory">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">update_memory</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><span></span><span class="nf">update_memory</span><span class="p">(</span>
<span></span>    <span class="n">obj_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Append the imgState to the memory_bank and update the memory for the model.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>obj_ids</code>
</td>
<td>
<code><span title="List">List</span>[<span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of object IDs corresponding to the prompts.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>points</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Tensor of shape (B, N, 2) representing the input points for N objects.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>labels</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Tensor of shape (B, N) representing the labels for the input points.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>masks</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional tensor of shape (N, H, W) representing the input masks for N objects.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/predict.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span>1846</span>
<span>1847</span>
<span>1848</span>
<span>1849</span>
<span>1850</span>
<span>1851</span>
<span>1852</span>
<span>1853</span>
<span>1854</span>
<span>1855</span>
<span>1856</span>
<span>1857</span>
<span>1858</span>
<span>1859</span>
<span>1860</span>
<span>1861</span>
<span>1862</span>
<span>1863</span>
<span>1864</span>
<span>1865</span>
<span>1866</span>
<span>1867</span>
<span>1868</span>
<span>1869</span>
<span>1870</span>
<span>1871</span>
<span>1872</span>
<span>1873</span>
<span>1874</span>
<span>1875</span>
<span>1876</span>
<span>1877</span>
<span>1878</span>
<span>1879</span>
<span>1880</span>
<span>1881</span>
<span>1882</span>
<span>1883</span>
<span>1884</span>
<span>1885</span>
<span>1886</span>
<span>1887</span>
<span>1888</span>
<span>1889</span>
<span>1890</span>
<span>1891</span>
<span>1892</span>
<span>1893</span>
<span>1894</span>
<span>1895</span>
<span>1896</span>
<span>1897</span>
<span>1898</span>
<span>1899</span>
<span>1900</span>
<span>1901</span>
<span>1902</span>
<span>1903</span>
<span>1904</span>
<span>1905</span>
<span>1906</span>
<span>1907</span>
<span>1908</span>
<span>1909</span>
<span>1910</span>
<span>1911</span>
<span>1912</span>
<span>1913</span>
<span>1914</span>
<span>1915</span>
<span>1916</span>
<span>1917</span>
<span>1918</span>
<span>1919</span>
<span>1920</span>
<span>1921</span>
<span>1922</span>
<span>1923</span>
<span>1924</span>
<span>1925</span>
<span>1926</span></pre></div></td><td class="code"><div><pre><span></span><code><span></span><span class="nd">@smart_inference_mode</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">update_memory</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">obj_ids</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">points</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">masks</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""</span>
<span></span><span class="sd">    Append the imgState to the memory_bank and update the memory for the model.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        obj_ids (List[int]): List of object IDs corresponding to the prompts.</span>
<span></span><span class="sd">        points (torch.Tensor | None): Tensor of shape (B, N, 2) representing the input points for N objects.</span>
<span></span><span class="sd">        labels (torch.Tensor | None): Tensor of shape (B, N) representing the labels for the input points.</span>
<span></span><span class="sd">        masks (torch.Tensor | None): Optional tensor of shape (N, H, W) representing the input masks for N objects.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">consolidated_out</span> <span class="o">=</span> <span class="p">{</span>
<span></span>        <span class="s2">"maskmem_features"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span></span>        <span class="s2">"maskmem_pos_enc"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span></span>        <span class="s2">"pred_masks"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<span></span>            <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">),</span>
<span></span>            <span class="n">fill_value</span><span class="o">=-</span><span class="mf">1024.0</span><span class="p">,</span>
<span></span>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">torch_dtype</span><span class="p">,</span>
<span></span>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span></span>        <span class="p">),</span>
<span></span>        <span class="s2">"obj_ptr"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<span></span>            <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">),</span>
<span></span>            <span class="n">fill_value</span><span class="o">=-</span><span class="mf">1024.0</span><span class="p">,</span>
<span></span>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">torch_dtype</span><span class="p">,</span>
<span></span>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span></span>        <span class="p">),</span>
<span></span>        <span class="s2">"object_score_logits"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
<span></span>            <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span></span>            <span class="c1"># default to 10.0 for object_score_logits, i.e. assuming the object is</span>
<span></span>            <span class="c1"># present as sigmoid(10)=1, same as in `predict_masks` of `MaskDecoder`</span>
<span></span>            <span class="n">fill_value</span><span class="o">=-</span><span class="mi">32</span><span class="p">,</span>  <span class="c1"># 10.0,</span>
<span></span>            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">torch_dtype</span><span class="p">,</span>
<span></span>            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span></span>        <span class="p">),</span>
<span></span>    <span class="p">}</span>
<span></span>
<span></span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">obj_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">):</span>
<span></span>        <span class="k">assert</span> <span class="n">obj_id</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_obj_num</span>
<span></span>        <span class="n">obj_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obj_id_to_idx</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">obj_id</span><span class="p">))</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">obj_idx_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">obj_idx</span><span class="p">)</span>
<span></span>        <span class="n">point</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">points</span><span class="p">[[</span><span class="n">i</span><span class="p">]],</span> <span class="n">labels</span><span class="p">[[</span><span class="n">i</span><span class="p">]]</span>
<span></span>        <span class="n">mask</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="kc">None</span><span class="p">]</span> <span class="k">if</span> <span class="n">masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<span></span>        <span class="c1"># Currently, only bbox prompt or mask prompt is supported, so we assert that bbox is not None.</span>
<span></span>        <span class="k">assert</span> <span class="n">point</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">"Either bbox, points or mask is required"</span>
<span></span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_step</span><span class="p">(</span><span class="n">obj_idx</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="n">obj_mask</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span>
<span></span>            <span class="k">assert</span> <span class="n">obj_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span> <span class="o">==</span> <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="p">(</span>
<span></span>                <span class="sa">f</span><span class="s2">"Expected mask shape </span><span class="si">{</span><span class="n">consolidated_out</span><span class="p">[</span><span class="s1">'pred_masks'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">obj_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span><span class="si">}</span><span class="s2"> for object </span><span class="si">{</span><span class="n">obj_idx</span><span class="si">}</span><span class="s2">."</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">][</span><span class="n">obj_idx</span> <span class="p">:</span> <span class="n">obj_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj_mask</span>
<span></span>            <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"obj_ptr"</span><span class="p">][</span><span class="n">obj_idx</span> <span class="p">:</span> <span class="n">obj_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s2">"obj_ptr"</span><span class="p">]</span>
<span></span>
<span></span>            <span class="k">if</span> <span class="s2">"object_score_logits"</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
<span></span>                <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"object_score_logits"</span><span class="p">][</span><span class="n">obj_idx</span> <span class="p">:</span> <span class="n">obj_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s2">"object_score_logits"</span><span class="p">]</span>
<span></span>
<span></span>    <span class="n">high_res_masks</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
<span></span>        <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"pred_masks"</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span></span>        <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">imgsz</span><span class="p">,</span>
<span></span>        <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span>
<span></span>        <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">non_overlap_masks_for_mem_enc</span><span class="p">:</span>
<span></span>        <span class="n">high_res_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_apply_non_overlapping_constraints</span><span class="p">(</span><span class="n">high_res_masks</span><span class="p">)</span>
<span></span>    <span class="n">maskmem_features</span><span class="p">,</span> <span class="n">maskmem_pos_enc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_encode_new_memory</span><span class="p">(</span>
<span></span>        <span class="n">current_vision_feats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_feats</span><span class="p">,</span>
<span></span>        <span class="n">feat_sizes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_sizes</span><span class="p">,</span>
<span></span>        <span class="n">pred_masks_high_res</span><span class="o">=</span><span class="n">high_res_masks</span><span class="p">,</span>
<span></span>        <span class="n">object_score_logits</span><span class="o">=</span><span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"object_score_logits"</span><span class="p">],</span>
<span></span>        <span class="n">is_mask_from_pts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"maskmem_features"</span><span class="p">]</span> <span class="o">=</span> <span class="n">maskmem_features</span>
<span></span>    <span class="n">consolidated_out</span><span class="p">[</span><span class="s2">"maskmem_pos_enc"</span><span class="p">]</span> <span class="o">=</span> <span class="n">maskmem_pos_enc</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">memory_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">consolidated_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/></p>
<br/><br/>
<div class="git-info">
<div class="dates-container">
<span class="date-item" title="This page was first created on November 12, 2023">
<span class="hover-item">ğŸ“…</span> Created 1 year ago
    </span>
<span class="date-item" title="This page was last updated on August 27, 2025">
<span class="hover-item">âœï¸</span> Updated 8 days ago
    </span>
</div>
<div class="authors-container">
<a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (6 changes)">
<img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (2 changes)">
<img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/ShuaiLYU" title="ShuaiLYU (1 change)">
<img alt="ShuaiLYU" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/31230805?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)">
<img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/Burhan-Q" title="Burhan-Q (1 change)">
<img alt="Burhan-Q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62214284?v=4&amp;s=96"/>
</a>
</div></div><div class="share-buttons">
<button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https://docs.ultralytics.com/reference/models/sam/predict', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-x-twitter"></i> Tweet
    </button>
<button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https://docs.ultralytics.com/reference/models/sam/predict', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-linkedin-in"></i> Share
    </button>
</div>
<br/>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: utils" class="md-footer__link md-footer__link--prev" href="../modules/utils/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                utils
              </div>
</div>
</a>
<a aria-label="Next: loss" class="md-footer__link md-footer__link--next" href="../../utils/loss/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                loss
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
<a href="https://www.ultralytics.com/" target="_blank">Â© 2025 Ultralytics Inc.</a> All rights reserved.
    </div>
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../../../..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tooltips", "toc.follow", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "navigation.indexes", "navigation.sections", "content.tabs.link"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
<script src="../../../../assets/javascripts/bundle.92b07e13.min.js"></script>
<script src="../../../../javascript/extra.js"></script>
<script src="../../../../javascript/giscus.js"></script>
<script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
<script src="../../../../javascript/tablesort.js"></script>
<script>
                    async function copyMarkdownForLLM(button) {
                        const editBtn = document.querySelector('a[title="Edit this page"]');
                        if (!editBtn) return;
                        const originalHTML = button.innerHTML;
                        const checkIcon = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19L21 7l-1.41-1.41L9 16.17z"></path></svg>';
                        // Handle both /blob/ and /tree/ in GitHub URLs
                        let rawUrl = editBtn.href.replace('github.com', 'raw.githubusercontent.com');
                        // Remove /blob/ or /tree/ from the URL
                        rawUrl = rawUrl.replace('/blob/', '/').replace('/tree/', '/');
                        try {
                            const response = await fetch(rawUrl);
                            let markdown = await response.text();
                            // Remove YAML front matter if present
                            if (markdown.startsWith('---')) {
                                const frontMatterEnd = markdown.indexOf('\n---\n', 3);
                                if (frontMatterEnd !== -1) {
                                    markdown = markdown.substring(frontMatterEnd + 5).trim();
                                }
                            }
                            const title = document.querySelector('h1')?.textContent || document.title;
                            const content = `# ${title}\n\nSource: ${window.location.href}\n\n---\n\n${markdown}`;
                            await navigator.clipboard.writeText(content);
                            button.innerHTML = checkIcon + ' Copied!';
                            setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                        } catch (err) {
                            button.innerHTML = 'âŒ Failed';
                            setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                        }
                    }
                    </script></body>
</html>