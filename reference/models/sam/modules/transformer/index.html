<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Explore the TwoWayTransformer module in Ultralytics, designed for simultaneous attention to image and query points. Ideal for object detection and segmentation tasks." name="description"/>
<meta content="Ultralytics" name="author"/>
<link href="https://docs.ultralytics.com/reference/models/sam/modules/transformer/" rel="canonical"/>
<link href="../tiny_encoder/" rel="prev"/>
<link href="../utils/" rel="next"/>
<link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.11" name="generator"/>
<title>Reference for ultralytics/models/sam/modules/transformer.py</title>
<link href="../../../../../assets/stylesheets/main.4af4bdda.min.css" rel="stylesheet"/>
<link href="../../../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="transformer" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="Ultralytics, TwoWayTransformer, module, deep learning, transformer, object detection, image segmentation, attention mechanism, neural networks" name="keywords"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/reference/models/sam/modules/transformer" property="og:url"/><meta content="transformer" property="og:title"/><meta content="Explore the TwoWayTransformer module in Ultralytics, designed for simultaneous attention to image and query points. Ideal for object detection and segmentation tasks." property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/reference/models/sam/modules/transformer" property="twitter:url"/><meta content="transformer" property="twitter:title"/><meta content="Explore the TwoWayTransformer module in Ultralytics, designed for simultaneous attention to image and query points. Ideal for object detection and segmentation tasks." property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "headline": "transformer", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2024-09-11 18:30:13 +0200", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "Explore the TwoWayTransformer module in Ultralytics, designed for simultaneous attention to image and query points. Ideal for object detection and segmentation tasks."}</script></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#reference-for-ultralyticsmodelssammodulestransformerpy">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<div class="banner-wrapper">
<div class="banner-content-wrapper" onclick="window.open('https://docs.ultralytics.com/models/yolo11')">
<p>Introducing</p>
<img alt="Ultralytics YOLO11" height="40" loading="lazy" src="https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/67d044caa316aa50fba40a08_Ultralytics_YOLO11_Logotype_Reverse.svg"/>
</div>
</div>
</div>
</aside>
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Ultralytics YOLO Docs
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
              transformer
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg>
</label>
<input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../..">
  Home
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../quickstart/">
  Quickstart
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../modes/">
  Modes
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../tasks/">
  Tasks
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../models/">
  Models
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../datasets/">
  Datasets
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../solutions/">
  Solutions 🚀
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../guides/">
  Guides
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../integrations/">
  Integrations
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../hub/">
  HUB
        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../../cfg/__init__/">
  Reference
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../help/">
  Help
        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
    Ultralytics YOLO Docs
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../..">
<span class="md-ellipsis">
    Home
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../quickstart/">
<span class="md-ellipsis">
    Quickstart
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../modes/">
<span class="md-ellipsis">
    Modes
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../tasks/">
<span class="md-ellipsis">
    Tasks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../models/">
<span class="md-ellipsis">
    Models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../datasets/">
<span class="md-ellipsis">
    Datasets
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../solutions/">
<span class="md-ellipsis">
    Solutions 🚀
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../guides/">
<span class="md-ellipsis">
    Guides
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../integrations/">
<span class="md-ellipsis">
    Integrations
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../hub/">
<span class="md-ellipsis">
    HUB
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_11">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_1" id="__nav_11_1_label" tabindex="">
<span class="md-ellipsis">
    cfg
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_1">
<span class="md-nav__icon md-icon"></span>
            cfg
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../cfg/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_2" id="__nav_11_2_label" tabindex="">
<span class="md-ellipsis">
    data
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_2">
<span class="md-nav__icon md-icon"></span>
            data
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/annotator/">
<span class="md-ellipsis">
    annotator
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/augment/">
<span class="md-ellipsis">
    augment
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/base/">
<span class="md-ellipsis">
    base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/converter/">
<span class="md-ellipsis">
    converter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/dataset/">
<span class="md-ellipsis">
    dataset
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/loaders/">
<span class="md-ellipsis">
    loaders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/split_dota/">
<span class="md-ellipsis">
    split_dota
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_3" id="__nav_11_3_label" tabindex="">
<span class="md-ellipsis">
    engine
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_3">
<span class="md-nav__icon md-icon"></span>
            engine
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/exporter/">
<span class="md-ellipsis">
    exporter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/predictor/">
<span class="md-ellipsis">
    predictor
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/results/">
<span class="md-ellipsis">
    results
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/trainer/">
<span class="md-ellipsis">
    trainer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/validator/">
<span class="md-ellipsis">
    validator
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_4" id="__nav_11_4_label" tabindex="">
<span class="md-ellipsis">
    hub
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_4">
<span class="md-nav__icon md-icon"></span>
            hub
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/auth/">
<span class="md-ellipsis">
    auth
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../hub/google/__init__/">
<span class="md-ellipsis">
    google
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/session/">
<span class="md-ellipsis">
    session
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5" id="__nav_11_5_label" tabindex="">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_5">
<span class="md-nav__icon md-icon"></span>
            models
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../fastsam/model/">
<span class="md-ellipsis">
    fastsam
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../nas/model/">
<span class="md-ellipsis">
    nas
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../rtdetr/model/">
<span class="md-ellipsis">
    rtdetr
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5_4" id="__nav_11_5_4_label" tabindex="0">
<span class="md-ellipsis">
    sam
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_4_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_11_5_4">
<span class="md-nav__icon md-icon"></span>
            sam
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../amg/">
<span class="md-ellipsis">
    amg
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5_4_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5_4_4" id="__nav_11_5_4_4_label" tabindex="0">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_4_4_label" class="md-nav" data-md-level="4">
<label class="md-nav__title" for="__nav_11_5_4_4">
<span class="md-nav__icon md-icon"></span>
            modules
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../blocks/">
<span class="md-ellipsis">
    blocks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../decoders/">
<span class="md-ellipsis">
    decoders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../encoders/">
<span class="md-ellipsis">
    encoders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../memory_attention/">
<span class="md-ellipsis">
    memory_attention
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../sam/">
<span class="md-ellipsis">
    sam
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../tiny_encoder/">
<span class="md-ellipsis">
    tiny_encoder
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    transformer
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    transformer
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayTransformer">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> TwoWayTransformer
    </span>
</a>
<nav aria-label=" TwoWayTransformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayTransformer.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> TwoWayAttentionBlock
    </span>
</a>
<nav aria-label=" TwoWayAttentionBlock" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.Attention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Attention
    </span>
</a>
<nav aria-label=" Attention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.Attention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../predict/">
<span class="md-ellipsis">
    predict
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../utils/loss/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../yolo/classify/predict/">
<span class="md-ellipsis">
    yolo
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_6" id="__nav_11_6_label" tabindex="">
<span class="md-ellipsis">
    nn
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_6">
<span class="md-nav__icon md-icon"></span>
            nn
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../nn/autobackend/">
<span class="md-ellipsis">
    autobackend
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../nn/modules/activation/">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../nn/tasks/">
<span class="md-ellipsis">
    tasks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../nn/text_model/">
<span class="md-ellipsis">
    text_model
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_7" id="__nav_11_7_label" tabindex="">
<span class="md-ellipsis">
    solutions
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_7">
<span class="md-nav__icon md-icon"></span>
            solutions
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/ai_gym/">
<span class="md-ellipsis">
    ai_gym
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/analytics/">
<span class="md-ellipsis">
    analytics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/distance_calculation/">
<span class="md-ellipsis">
    distance_calculation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/heatmap/">
<span class="md-ellipsis">
    heatmap
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/instance_segmentation/">
<span class="md-ellipsis">
    instance_segmentation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/object_blurrer/">
<span class="md-ellipsis">
    object_blurrer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/object_counter/">
<span class="md-ellipsis">
    object_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/object_cropper/">
<span class="md-ellipsis">
    object_cropper
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/parking_management/">
<span class="md-ellipsis">
    parking_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/queue_management/">
<span class="md-ellipsis">
    queue_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/region_counter/">
<span class="md-ellipsis">
    region_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/security_alarm/">
<span class="md-ellipsis">
    security_alarm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/solutions/">
<span class="md-ellipsis">
    solutions
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/speed_estimation/">
<span class="md-ellipsis">
    speed_estimation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/streamlit_inference/">
<span class="md-ellipsis">
    streamlit_inference
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/trackzone/">
<span class="md-ellipsis">
    trackzone
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/vision_eye/">
<span class="md-ellipsis">
    vision_eye
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_8" id="__nav_11_8_label" tabindex="">
<span class="md-ellipsis">
    trackers
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_8_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_8">
<span class="md-nav__icon md-icon"></span>
            trackers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/basetrack/">
<span class="md-ellipsis">
    basetrack
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/bot_sort/">
<span class="md-ellipsis">
    bot_sort
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/byte_tracker/">
<span class="md-ellipsis">
    byte_tracker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/track/">
<span class="md-ellipsis">
    track
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../trackers/utils/gmc/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_9" id="__nav_11_9_label" tabindex="">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_9_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_9">
<span class="md-nav__icon md-icon"></span>
            utils
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/autobatch/">
<span class="md-ellipsis">
    autobatch
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/benchmarks/">
<span class="md-ellipsis">
    benchmarks
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../utils/callbacks/base/">
<span class="md-ellipsis">
    callbacks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/checks/">
<span class="md-ellipsis">
    checks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/dist/">
<span class="md-ellipsis">
    dist
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/downloads/">
<span class="md-ellipsis">
    downloads
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/errors/">
<span class="md-ellipsis">
    errors
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/files/">
<span class="md-ellipsis">
    files
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/instance/">
<span class="md-ellipsis">
    instance
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/loss/">
<span class="md-ellipsis">
    loss
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/metrics/">
<span class="md-ellipsis">
    metrics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/ops/">
<span class="md-ellipsis">
    ops
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/patches/">
<span class="md-ellipsis">
    patches
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/plotting/">
<span class="md-ellipsis">
    plotting
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/tal/">
<span class="md-ellipsis">
    tal
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/torch_utils/">
<span class="md-ellipsis">
    torch_utils
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/triton/">
<span class="md-ellipsis">
    triton
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../help/">
<span class="md-ellipsis">
    Help
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayTransformer">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> TwoWayTransformer
    </span>
</a>
<nav aria-label=" TwoWayTransformer" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayTransformer.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> TwoWayAttentionBlock
    </span>
</a>
<nav aria-label=" TwoWayAttentionBlock" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.Attention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Attention
    </span>
</a>
<nav aria-label=" Attention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.transformer.Attention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/reference/models/sam/modules/transformer.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<h1 id="reference-for-ultralyticsmodelssammodulestransformerpy">Reference for <code>ultralytics/models/sam/modules/transformer.py</code></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This file is available at <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/transformer.py">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/transformer.py</a>. If you spot a problem please help fix it by <a href="https://docs.ultralytics.com/help/contributing/">contributing</a> a <a href="https://github.com/ultralytics/ultralytics/edit/main/ultralytics/models/sam/modules/transformer.py">Pull Request</a> 🛠️. Thank you 🙏!</p>
</div>
<p><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.transformer.TwoWayTransformer">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.transformer.TwoWayTransformer</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">TwoWayTransformer</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>A Two-Way Transformer module for simultaneous attention to image and query points.</p>
<p>This class implements a specialized transformer decoder that attends to an input image using queries with
supplied positional embeddings. It's useful for tasks like object detection, image segmentation, and point
cloud processing.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.depth">depth</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of layers in the transformer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.embedding_dim">embedding_dim</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Channel dimension for input embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.num_heads">num_heads</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of heads for multihead attention.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.mlp_dim">mlp_dim</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Internal channel dimension for the MLP block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.layers">layers</span></code></td>
<td>
<code><span title="torch.nn.ModuleList">ModuleList</span></code>
</td>
<td>
<div class="doc-md-description">
<p>List of TwoWayAttentionBlock layers composing the transformer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.final_attn_token_to_image">final_attn_token_to_image</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.Attention" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.modules.transformer.Attention&lt;/span&gt;'>Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Final attention layer from queries to image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayTransformer.norm_final_attn">norm_final_attn</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization applied to final queries.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.TwoWayTransformer.forward" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;forward&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.modules.transformer.TwoWayTransformer.forward&lt;/code&gt;)'>forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Processes image and point embeddings through the transformer.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">TwoWayTransformer</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">image_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">image_pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">point_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output_queries</span><span class="p">,</span> <span class="n">output_image</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">image_embedding</span><span class="p">,</span> <span class="n">image_pe</span><span class="p">,</span> <span class="n">point_embedding</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output_queries</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">output_image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>depth</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of layers in the transformer.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>embedding_dim</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Channel dimension for input embeddings.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of heads for multihead attention. Must divide embedding_dim.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mlp_dim</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Internal channel dimension for the MLP block.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>activation</code>
</td>
<td>
<code><span title="typing.Type">Type</span>[<span title="torch.nn.Module">Module</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Activation function to use in the MLP block.</p>
</div>
</td>
<td>
<code><span title="torch.nn.ReLU">ReLU</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>attention_downsample_rate</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Downsampling rate for attention mechanism.</p>
</div>
</td>
<td>
<code>2</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/transformer.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    Initialize a Two-Way Transformer for simultaneous attention to image and query points.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        depth (int): Number of layers in the transformer.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        embedding_dim (int): Channel dimension for input embeddings.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        num_heads (int): Number of heads for multihead attention. Must divide embedding_dim.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        mlp_dim (int): Internal channel dimension for the MLP block.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        activation (Type[nn.Module]): Activation function to use in the MLP block.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        attention_downsample_rate (int): Downsampling rate for attention mechanism.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    """</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dim</span> <span class="o">=</span> <span class="n">mlp_dim</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>            <span class="n">TwoWayAttentionBlock</span><span class="p">(</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>                <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>                <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>                <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>                <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>                <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>                <span class="n">skip_first_layer_pe</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>            <span class="p">)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="p">)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">final_attn_token_to_image</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm_final_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.transformer.TwoWayTransformer.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">image_embedding</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">image_pe</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">point_embedding</span><span class="p">:</span> <span class="n">Tensor</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Process image and point embeddings through the Two-Way Transformer.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image_embedding</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Image to attend to, with shape (B, embedding_dim, H, W).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>image_pe</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Positional encoding to add to the image, with same shape as image_embedding.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>point_embedding</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Embedding to add to query points, with shape (B, N_points, embedding_dim).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>queries</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Processed point embeddings with shape (B, N_points, embedding_dim).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>keys</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Processed image embeddings with shape (B, H*W, embedding_dim).</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/transformer.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="n">image_embedding</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="n">image_pe</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="n">point_embedding</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    Process image and point embeddings through the Two-Way Transformer.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        image_embedding (Tensor): Image to attend to, with shape (B, embedding_dim, H, W).</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        image_pe (Tensor): Positional encoding to add to the image, with same shape as image_embedding.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        point_embedding (Tensor): Embedding to add to query points, with shape (B, N_points, embedding_dim).</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        queries (Tensor): Processed point embeddings with shape (B, N_points, embedding_dim).</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">        keys (Tensor): Processed image embeddings with shape (B, H*W, embedding_dim).</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">    """</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="c1"># BxCxHxW -&gt; BxHWxC == B x N_image_tokens x C</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="n">image_embedding</span> <span class="o">=</span> <span class="n">image_embedding</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">image_pe</span> <span class="o">=</span> <span class="n">image_pe</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="c1"># Prepare queries</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="n">point_embedding</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="n">keys</span> <span class="o">=</span> <span class="n">image_embedding</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="c1"># Apply transformer blocks and final layernorm</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="n">queries</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>            <span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>            <span class="n">query_pe</span><span class="o">=</span><span class="n">point_embedding</span><span class="p">,</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>            <span class="n">key_pe</span><span class="o">=</span><span class="n">image_pe</span><span class="p">,</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="p">)</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="c1"># Apply the final attention layer from the points to the image</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">point_embedding</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">image_pe</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_attn_token_to_image</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">attn_out</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_final_attn</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>    <span class="k">return</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">TwoWayAttentionBlock</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>A two-way attention block for simultaneous attention to image and query points.</p>
<p>This class implements a specialized transformer block with four main layers: self-attention on sparse inputs,
cross-attention of sparse inputs to dense inputs, MLP block on sparse inputs, and cross-attention of dense
inputs to sparse inputs.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.self_attn">self_attn</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.Attention" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.modules.transformer.Attention&lt;/span&gt;'>Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Self-attention layer for queries.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.norm1">norm1</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after self-attention.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.cross_attn_token_to_image">cross_attn_token_to_image</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.Attention" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.modules.transformer.Attention&lt;/span&gt;'>Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Cross-attention layer from queries to keys.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.norm2">norm2</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after token-to-image attention.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.mlp">mlp</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" href="../../../../nn/modules/transformer/#ultralytics.nn.modules.transformer.MLPBlock" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.nn.modules.transformer.MLPBlock&lt;/span&gt; (&lt;code&gt;ultralytics.nn.modules.MLPBlock&lt;/code&gt;)'>MLPBlock</a></code>
</td>
<td>
<div class="doc-md-description">
<p>MLP block for transforming query embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.norm3">norm3</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after MLP block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.norm4">norm4</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after image-to-token attention.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.cross_attn_image_to_token">cross_attn_image_to_token</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.Attention" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-class"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-class-name"&gt;ultralytics.models.sam.modules.transformer.Attention&lt;/span&gt;'>Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Cross-attention layer from keys to queries.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.skip_first_layer_pe">skip_first_layer_pe</span></code></td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to skip positional encoding in the first layer.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.forward" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;forward&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.forward&lt;/code&gt;)'>forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies self-attention and cross-attention to queries and keys.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">8</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">TwoWayAttentionBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">queries</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">keys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">query_pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">key_pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">processed_queries</span><span class="p">,</span> <span class="n">processed_keys</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">query_pe</span><span class="p">,</span> <span class="n">key_pe</span><span class="p">)</span>
</code></pre></div>
<p>This block implements a specialized transformer layer with four main components: self-attention on sparse
inputs, cross-attention of sparse inputs to dense inputs, MLP block on sparse inputs, and cross-attention
of dense inputs to sparse inputs.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>embedding_dim</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Channel dimension of the embeddings.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads in the attention layers.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mlp_dim</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Hidden dimension of the MLP block.</p>
</div>
</td>
<td>
<code>2048</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>activation</code>
</td>
<td>
<code><span title="typing.Type">Type</span>[<span title="torch.nn.Module">Module</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Activation function for the MLP block.</p>
</div>
</td>
<td>
<code><span title="torch.nn.ReLU">ReLU</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>attention_downsample_rate</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Downsampling rate for the attention mechanism.</p>
</div>
</td>
<td>
<code>2</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>skip_first_layer_pe</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to skip positional encoding in the first layer.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/transformer.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Initialize a TwoWayAttentionBlock for simultaneous attention to image and query points.</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    This block implements a specialized transformer layer with four main components: self-attention on sparse</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">    inputs, cross-attention of sparse inputs to dense inputs, MLP block on sparse inputs, and cross-attention</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">    of dense inputs to sparse inputs.</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">        embedding_dim (int): Channel dimension of the embeddings.</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        num_heads (int): Number of attention heads in the attention layers.</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        mlp_dim (int): Hidden dimension of the MLP block.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">        activation (Type[nn.Module]): Activation function for the MLP block.</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">        attention_downsample_rate (int): Downsampling rate for the attention mechanism.</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        skip_first_layer_pe (bool): Whether to skip positional encoding in the first layer.</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">    """</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_token_to_image</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_image_to_token</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">skip_first_layer_pe</span> <span class="o">=</span> <span class="n">skip_first_layer_pe</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">queries</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">keys</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">query_pe</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">key_pe</span><span class="p">:</span> <span class="n">Tensor</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Apply two-way attention to process query and key embeddings in a transformer block.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>queries</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Query embeddings with shape (B, N_queries, embedding_dim).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>keys</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Key embeddings with shape (B, N_keys, embedding_dim).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>query_pe</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Positional encodings for queries with same shape as queries.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>key_pe</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Positional encodings for keys with same shape as keys.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>queries</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Processed query embeddings with shape (B, N_queries, embedding_dim).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code>keys</code></td> <td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Processed key embeddings with shape (B, N_keys, embedding_dim).</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/transformer.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">keys</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">query_pe</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">key_pe</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">    Apply two-way attention to process query and key embeddings in a transformer block.</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a><span class="sd">        queries (Tensor): Query embeddings with shape (B, N_queries, embedding_dim).</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a><span class="sd">        keys (Tensor): Key embeddings with shape (B, N_keys, embedding_dim).</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a><span class="sd">        query_pe (Tensor): Positional encodings for queries with same shape as queries.</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a><span class="sd">        key_pe (Tensor): Positional encodings for keys with same shape as keys.</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a><span class="sd">        queries (Tensor): Processed query embeddings with shape (B, N_queries, embedding_dim).</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a><span class="sd">        keys (Tensor): Processed key embeddings with shape (B, N_keys, embedding_dim).</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a><span class="sd">    """</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>    <span class="c1"># Self attention block</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip_first_layer_pe</span><span class="p">:</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">query_pe</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>        <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">attn_out</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>    <span class="c1"># Cross attention block, tokens attending to image embedding</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">query_pe</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">key_pe</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>    <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_token_to_image</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">attn_out</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>    <span class="c1"># MLP block</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>    <span class="n">mlp_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">mlp_out</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>    <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>    <span class="c1"># Cross attention block, image embedding attending to tokens</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">query_pe</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">key_pe</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>    <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_image_to_token</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>    <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">attn_out</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>    <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm4</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="k">return</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.transformer.Attention">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.transformer.Attention</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">Attention</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">kv_in_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>An attention layer with downscaling capability for embedding size after projection.</p>
<p>This class implements a multi-head attention mechanism with the option to downsample the internal
dimension of queries, keys, and values.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.embedding_dim">embedding_dim</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Dimensionality of input embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.kv_in_dim">kv_in_dim</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Dimensionality of key and value inputs.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.internal_dim">internal_dim</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Internal dimension after downsampling.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.num_heads">num_heads</span></code></td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.q_proj">q_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for queries.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.k_proj">k_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for keys.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.v_proj">v_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for values.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention.out_proj">out_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for output.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention._separate_heads">_separate_heads</span></code></td>
<td>
<div class="doc-md-description">
<p>Separates input tensor into attention heads.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.transformer.Attention._recombine_heads">_recombine_heads</span></code></td>
<td>
<div class="doc-md-description">
<p>Recombines separated attention heads.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" href="#ultralytics.models.sam.modules.transformer.Attention.forward" title='&lt;code class="doc-symbol doc-symbol-heading doc-symbol-method"&gt;&lt;/code&gt;            &lt;span class="doc doc-object-name doc-function-name"&gt;forward&lt;/span&gt; (&lt;code&gt;ultralytics.models.sam.modules.transformer.Attention.forward&lt;/code&gt;)'>forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Computes attention output for given query, key, and value tensors.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="go">torch.Size([1, 100, 256])</span>
</code></pre></div>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>embedding_dim</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Dimensionality of input embeddings.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>downsample_rate</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Factor by which internal dimensions are downsampled.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>kv_in_dim</code>
</td>
<td>
<code><span title="int">int</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Dimensionality of key and value inputs. If None, uses embedding_dim.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="AssertionError">AssertionError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If num_heads does not evenly divide the internal dim (embedding_dim / downsample_rate).</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/transformer.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>    <span class="n">downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>    <span class="n">kv_in_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">    Initialize the Attention module with specified dimensions and settings.</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">        embedding_dim (int): Dimensionality of input embeddings.</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">        num_heads (int): Number of attention heads.</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">        downsample_rate (int): Factor by which internal dimensions are downsampled.</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">        kv_in_dim (int | None): Dimensionality of key and value inputs. If None, uses embedding_dim.</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">        AssertionError: If num_heads does not evenly divide the internal dim (embedding_dim / downsample_rate).</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">    """</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">kv_in_dim</span> <span class="o">=</span> <span class="n">kv_in_dim</span> <span class="k">if</span> <span class="n">kv_in_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">embedding_dim</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span> <span class="o">//</span> <span class="n">downsample_rate</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"num_heads must divide embedding_dim."</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">)</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">k_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kv_in_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">)</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">v_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kv_in_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">)</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.transformer.Attention.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Apply multi-head attention to query, key, and value tensors with optional downsampling.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>q</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Query tensor with shape (B, N_q, embedding_dim).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>k</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Key tensor with shape (B, N_k, embedding_dim).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>v</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Value tensor with shape (B, N_k, embedding_dim).</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output tensor after attention with shape (B, N_q, embedding_dim).</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/transformer.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">    Apply multi-head attention to query, key, and value tensors with optional downsampling.</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a><span class="sd">        q (Tensor): Query tensor with shape (B, N_q, embedding_dim).</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a><span class="sd">        k (Tensor): Key tensor with shape (B, N_k, embedding_dim).</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a><span class="sd">        v (Tensor): Value tensor with shape (B, N_k, embedding_dim).</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="sd">        (Tensor): Output tensor after attention with shape (B, N_q, embedding_dim).</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a><span class="sd">    """</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>    <span class="c1"># Input projections</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="c1"># Separate into heads</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>    <span class="c1"># Attention</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c_per_head</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">q</span> <span class="o">@</span> <span class="n">k</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># B x N_heads x N_tokens x N_tokens</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">c_per_head</span><span class="p">)</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>    <span class="c1"># Get output</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">@</span> <span class="n">v</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recombine_heads</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/></p>
<div class="git-info">
<div class="dates-container">
<span class="date-item" title="This page was first created on November 12, 2023">
<span class="hover-item">📅</span> Created 1 year ago
    </span>
<span class="date-item" title="This page was last updated on September 11, 2024">
<span class="hover-item">✏️</span> Updated 6 months ago
    </span>
</div>
<div class="authors-container">
<a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)">
<img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (6 changes)">
<img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/Burhan-Q" title="Burhan-Q (1 change)">
<img alt="Burhan-Q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62214284?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (1 change)">
<img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/>
</a>
</div></div><div class="share-buttons">
<button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https://docs.ultralytics.com/reference/models/sam/modules/transformer', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-x-twitter"></i> Tweet
    </button>
<button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https://docs.ultralytics.com/reference/models/sam/modules/transformer', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-linkedin-in"></i> Share
    </button>
</div>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: tiny_encoder" class="md-footer__link md-footer__link--prev" href="../tiny_encoder/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                tiny_encoder
              </div>
</div>
</a>
<a aria-label="Next: utils" class="md-footer__link md-footer__link--next" href="../utils/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                utils
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
<a href="https://www.ultralytics.com/" target="_blank">© 2025 Ultralytics Inc.</a> All rights reserved.
    </div>
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg>
</a>
<a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"></path></svg>
</a>
<a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"></path></svg>
</a>
<a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"></path></svg>
</a>
<a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"></path></svg>
</a>
<a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"></path></svg>
</a>
<a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5"></path></svg>
</a>
<a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tooltips", "search.highlight", "search.share", "search.suggest", "toc.follow", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "navigation.indexes", "navigation.sections", "content.tabs.link"], "search": "../../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
<script src="../../../../../assets/javascripts/bundle.c8b220af.min.js"></script>
<script src="../../../../../javascript/extra.js"></script>
<script src="../../../../../javascript/giscus.js"></script>
<script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
<script src="../../../../../javascript/tablesort.js"></script>
</body>
</html>