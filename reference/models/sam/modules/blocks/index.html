 <!DOCTYPE html><html class="no-js" lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="Explore detailed documentation of various SAM and SAM 2 modules such as MaskDownSampler, CXBlock, and more, available in Ultralytics' repository." name="description"/><meta content="Ultralytics" name="author"/><link href="https://docs.ultralytics.com/reference/models/sam/modules/blocks/" rel="canonical"/><link href="../../model/" rel="prev"/><link href="../decoders/" rel="next"/><link href="/" hreflang="en" rel="alternate"/><link href="/zh/" hreflang="zh" rel="alternate"/><link href="/ko/" hreflang="ko" rel="alternate"/><link href="/ja/" hreflang="ja" rel="alternate"/><link href="/ru/" hreflang="ru" rel="alternate"/><link href="/de/" hreflang="de" rel="alternate"/><link href="/fr/" hreflang="fr" rel="alternate"/><link href="/es/" hreflang="es" rel="alternate"/><link href="/pt/" hreflang="pt" rel="alternate"/><link href="/it/" hreflang="it" rel="alternate"/><link href="/tr/" hreflang="tr" rel="alternate"/><link href="/vi/" hreflang="vi" rel="alternate"/><link href="/ar/" hreflang="ar" rel="alternate"/><link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/><meta content="zensical-0.0.14" name="generator"/><title>Reference for ultralytics/models/sam/modules/blocks.py</title><link href="../../../../../assets/stylesheets/modern/main.f1b6466b.min.css" rel="stylesheet"/><link href="../../../../../assets/stylesheets/modern/palette.dfe2e883.min.css" rel="stylesheet"/><style>:root{}</style><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,500,500i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link href="../../../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<style data-doc-kind="true">.doc-kind{display:inline-flex;align-items:center;gap:0.25em;padding:0.21em 0.59em;border-radius:999px;font-weight:700;font-size:0.81em;letter-spacing:0.06em;text-transform:uppercase;line-height:1;color:var(--doc-kind-color,#f8fafc);background:var(--doc-kind-bg,rgba(255,255,255,0.12));}.doc-kind-class{--doc-kind-color:#039dfc;--doc-kind-bg:rgba(3,157,252,0.22);}.doc-kind-function{--doc-kind-color:#fc9803;--doc-kind-bg:rgba(252,152,3,0.22);}.doc-kind-method{--doc-kind-color:#ef5eff;--doc-kind-bg:rgba(239,94,255,0.22);}.doc-kind-property{--doc-kind-color:#02e835;--doc-kind-bg:rgba(2,232,53,0.22);}</style><meta content="Reference for ultralytics/models/sam/modules/blocks.py" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/reference/models/sam/modules/blocks/" property="og:url"/><meta content="Reference for ultralytics/models/sam/modules/blocks.py" property="og:title"/><meta content="" property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/reference/models/sam/modules/blocks/" property="twitter:url"/><meta content="Reference for ultralytics/models/sam/modules/blocks.py" property="twitter:title"/><meta content="" property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "headline": "Reference for ultralytics/models/sam/modules/blocks.py", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2024-08-05 08:53:45 +0800", "dateModified": "2025-11-23 19:53:50 +0100", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": ""}</script></head><body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" for="__drawer"></label><div data-md-component="skip"><a class="md-skip" href="#reference-for-ultralyticsmodelssammodulesblockspy"> Skip to content </a></div><div data-md-component="announce"><aside class="md-banner"><div class="md-banner__inner md-grid md-typeset"><a class="banner-wrapper" href="https://www.ultralytics.com/news/ultralytics-raises-30m-series-a" target="_blank"><div class="banner-content-wrapper"><img alt="Ultralytics raises $30M Series A" height="40" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/691dac336b5de2ae8b398bca_writting.svg"/><div class="vc-wrapper"><img alt="Elephant" height="28" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/691dac33c95408144846afc7_image%201.png"/><img alt="SquareOne" height="28" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/691dac3333068d9632cc6df8_image%202.png"/></div></div></a></div></aside></div><header class="md-header md-header--shadow md-header--lifted" data-md-component="header"><nav aria-label="Header" class="md-header__inner md-grid"><a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a><label class="md-header__button md-icon" for="__drawer"><svg class="lucide lucide-menu" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 5h16M4 12h16M4 19h16"></path></svg></label><div class="md-header__title" data-md-component="header-title"><div class="md-header__ellipsis"><div class="md-header__topic"><span class="md-ellipsis"> Ultralytics YOLO Docs </span></div><div class="md-header__topic" data-md-component="header-topic"><span class="md-ellipsis"> Reference for ultralytics/models/sam/modules/blocks.py </span></div></div></div><form class="md-header__option" data-md-component="palette"><input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option"><div class="md-select"><button aria-label="Select language" class="md-header__button md-icon"><svg class="lucide lucide-languages" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m5 8 6 6M4 14l6-6 2-3M2 5h12M7 2h1M22 22l-5-10-5 10M14 18h6"></path></svg></button><div class="md-select__inner"><ul class="md-select__list"><li class="md-select__item"><a class="md-select__link" href="/" hreflang="en"> ğŸ‡¬ğŸ‡§ English </a></li><li class="md-select__item"><a class="md-select__link" href="/zh/" hreflang="zh"> ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡ </a></li><li class="md-select__item"><a class="md-select__link" href="/ko/" hreflang="ko"> ğŸ‡°ğŸ‡· í•œêµ­ì–´ </a></li><li class="md-select__item"><a class="md-select__link" href="/ja/" hreflang="ja"> ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª </a></li><li class="md-select__item"><a class="md-select__link" href="/ru/" hreflang="ru"> ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ </a></li><li class="md-select__item"><a class="md-select__link" href="/de/" hreflang="de"> ğŸ‡©ğŸ‡ª Deutsch </a></li><li class="md-select__item"><a class="md-select__link" href="/fr/" hreflang="fr"> ğŸ‡«ğŸ‡· FranÃ§ais </a></li><li class="md-select__item"><a class="md-select__link" href="/es/" hreflang="es"> ğŸ‡ªğŸ‡¸ EspaÃ±ol </a></li><li class="md-select__item"><a class="md-select__link" href="/pt/" hreflang="pt"> ğŸ‡µğŸ‡¹ PortuguÃªs </a></li><li class="md-select__item"><a class="md-select__link" href="/it/" hreflang="it"> ğŸ‡®ğŸ‡¹ Italiano </a></li><li class="md-select__item"><a class="md-select__link" href="/tr/" hreflang="tr"> ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e </a></li><li class="md-select__item"><a class="md-select__link" href="/vi/" hreflang="vi"> ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t </a></li><li class="md-select__item"><a class="md-select__link" href="/ar/" hreflang="ar"> ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© </a></li></ul></div></div></div><div class="md-header__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div></nav><nav aria-label="Tabs" class="md-tabs" data-md-component="tabs"><div class="md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../.."> Home </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../quickstart/"> Quickstart </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../modes/"> Modes </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../tasks/"> Tasks </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../models/"> Models </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../datasets/"> Datasets </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../solutions/"> Solutions </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../guides/"> Guides </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../integrations/"> Integrations </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../hub/"> HUB </a></li><li class="md-tabs__item md-tabs__item--active"><a class="md-tabs__link" href="../../../../__init__/"> Reference </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../../../help/"> Help </a></li></ul></div></nav></header><div class="md-container" data-md-component="container"><main class="md-main" data-md-component="main"><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0"><label class="md-nav__title" for="__drawer"><a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a> Ultralytics YOLO Docs </label><div class="md-nav__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../.."><span class="md-ellipsis"> Home </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../quickstart/"><span class="md-ellipsis"> Quickstart </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../modes/"><span class="md-ellipsis"> Modes </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../tasks/"><span class="md-ellipsis"> Tasks </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../models/"><span class="md-ellipsis"> Models </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../datasets/"><span class="md-ellipsis"> Datasets </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../solutions/"><span class="md-ellipsis"> Solutions </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../guides/"><span class="md-ellipsis"> Guides </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../integrations/"><span class="md-ellipsis"> Integrations </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../hub/"><span class="md-ellipsis"> HUB </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/><label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex=""><span class="md-ellipsis"> Reference </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1"><label class="md-nav__title" for="__nav_11"><span class="md-nav__icon md-icon"></span> Reference </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../__init__/"><span class="md-ellipsis"> __init__ </span></a></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_2" type="checkbox"/><label class="md-nav__link" for="__nav_11_2" id="__nav_11_2_label" tabindex=""><span class="md-ellipsis"> cfg </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_2_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_2"><span class="md-nav__icon md-icon"></span> cfg </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../cfg/__init__/"><span class="md-ellipsis"> __init__ </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_3" type="checkbox"/><label class="md-nav__link" for="__nav_11_3" id="__nav_11_3_label" tabindex=""><span class="md-ellipsis"> data </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_3_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_3"><span class="md-nav__icon md-icon"></span> data </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/annotator/"><span class="md-ellipsis"> annotator </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/augment/"><span class="md-ellipsis"> augment </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/base/"><span class="md-ellipsis"> base </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/build/"><span class="md-ellipsis"> build </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/converter/"><span class="md-ellipsis"> converter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/dataset/"><span class="md-ellipsis"> dataset </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/loaders/"><span class="md-ellipsis"> loaders </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/split/"><span class="md-ellipsis"> split </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/split_dota/"><span class="md-ellipsis"> split_dota </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../data/utils/"><span class="md-ellipsis"> utils </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_4" type="checkbox"/><label class="md-nav__link" for="__nav_11_4" id="__nav_11_4_label" tabindex=""><span class="md-ellipsis"> engine </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_4_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_4"><span class="md-nav__icon md-icon"></span> engine </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/exporter/"><span class="md-ellipsis"> exporter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/model/"><span class="md-ellipsis"> model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/predictor/"><span class="md-ellipsis"> predictor </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/results/"><span class="md-ellipsis"> results </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/trainer/"><span class="md-ellipsis"> trainer </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/tuner/"><span class="md-ellipsis"> tuner </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../engine/validator/"><span class="md-ellipsis"> validator </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_5" type="checkbox"/><label class="md-nav__link" for="__nav_11_5" id="__nav_11_5_label" tabindex=""><span class="md-ellipsis"> hub </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_5_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_5"><span class="md-nav__icon md-icon"></span> hub </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../hub/__init__/"><span class="md-ellipsis"> __init__ </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../hub/auth/"><span class="md-ellipsis"> auth </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../hub/google/__init__/"><span class="md-ellipsis"> google </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../hub/session/"><span class="md-ellipsis"> session </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../hub/utils/"><span class="md-ellipsis"> utils </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_11_6" type="checkbox"/><label class="md-nav__link" for="__nav_11_6" id="__nav_11_6_label" tabindex=""><span class="md-ellipsis"> models </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_11_6_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_6"><span class="md-nav__icon md-icon"></span> models </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../fastsam/model/"><span class="md-ellipsis"> fastsam </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../nas/model/"><span class="md-ellipsis"> nas </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../rtdetr/model/"><span class="md-ellipsis"> rtdetr </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_11_6_4" type="checkbox"/><label class="md-nav__link" for="__nav_11_6_4" id="__nav_11_6_4_label" tabindex="0"><span class="md-ellipsis"> sam </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_11_6_4_label" class="md-nav" data-md-level="3"><label class="md-nav__title" for="__nav_11_6_4"><span class="md-nav__icon md-icon"></span> sam </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../amg/"><span class="md-ellipsis"> amg </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../build/"><span class="md-ellipsis"> build </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../build_sam3/"><span class="md-ellipsis"> build_sam3 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../model/"><span class="md-ellipsis"> model </span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_11_6_4_5" type="checkbox"/><label class="md-nav__link" for="__nav_11_6_4_5" id="__nav_11_6_4_5_label" tabindex="0"><span class="md-ellipsis"> modules </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_11_6_4_5_label" class="md-nav" data-md-level="4"><label class="md-nav__title" for="__nav_11_6_4_5"><span class="md-nav__icon md-icon"></span> modules </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/><label class="md-nav__link md-nav__link--active" for="__toc"><span class="md-ellipsis"> blocks </span><span class="md-nav__icon md-icon"></span></label><a class="md-nav__link md-nav__link--active" href="./"><span class="md-ellipsis"> blocks </span></a><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> DropPath</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.DropPath" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> MaskDownSampler</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.MaskDownSampler" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> CXBlock</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.CXBlock" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> Fuser</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.Fuser" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> SAM2TwoWayAttentionBlock</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> SAM2TwoWayTransformer</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> RoPEAttention</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.RoPEAttention" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> MultiScaleAttention</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.MultiScaleAttention" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> MultiScaleBlock</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.MultiScaleBlock" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> PositionEmbeddingSine</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.PositionEmbeddingSine" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> _encode_xy</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> encode_boxes</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> encode_points</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> PositionEmbeddingRandom</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> _pe_encoding</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward_with_coords</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> Block</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.Block" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> REAttention</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.REAttention" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> PatchEmbed</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.PatchEmbed" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.do_pool"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> do_pool</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../decoders/"><span class="md-ellipsis"> decoders </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../encoders/"><span class="md-ellipsis"> encoders </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../memory_attention/"><span class="md-ellipsis"> memory_attention </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../sam/"><span class="md-ellipsis"> sam </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../tiny_encoder/"><span class="md-ellipsis"> tiny_encoder </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../transformer/"><span class="md-ellipsis"> transformer </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../utils/"><span class="md-ellipsis"> utils </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../../predict/"><span class="md-ellipsis"> predict </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../sam3/decoder/"><span class="md-ellipsis"> sam3 </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../utils/loss/"><span class="md-ellipsis"> utils </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../yolo/classify/predict/"><span class="md-ellipsis"> yolo </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_7" type="checkbox"/><label class="md-nav__link" for="__nav_11_7" id="__nav_11_7_label" tabindex=""><span class="md-ellipsis"> nn </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_7_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_7"><span class="md-nav__icon md-icon"></span> nn </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../nn/autobackend/"><span class="md-ellipsis"> autobackend </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../nn/modules/activation/"><span class="md-ellipsis"> modules </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../nn/tasks/"><span class="md-ellipsis"> tasks </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../nn/text_model/"><span class="md-ellipsis"> text_model </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_8" type="checkbox"/><label class="md-nav__link" for="__nav_11_8" id="__nav_11_8_label" tabindex=""><span class="md-ellipsis"> solutions </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_8_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_8"><span class="md-nav__icon md-icon"></span> solutions </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/ai_gym/"><span class="md-ellipsis"> ai_gym </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/analytics/"><span class="md-ellipsis"> analytics </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/config/"><span class="md-ellipsis"> config </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/distance_calculation/"><span class="md-ellipsis"> distance_calculation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/heatmap/"><span class="md-ellipsis"> heatmap </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/instance_segmentation/"><span class="md-ellipsis"> instance_segmentation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/object_blurrer/"><span class="md-ellipsis"> object_blurrer </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/object_counter/"><span class="md-ellipsis"> object_counter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/object_cropper/"><span class="md-ellipsis"> object_cropper </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/parking_management/"><span class="md-ellipsis"> parking_management </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/queue_management/"><span class="md-ellipsis"> queue_management </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/region_counter/"><span class="md-ellipsis"> region_counter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/security_alarm/"><span class="md-ellipsis"> security_alarm </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/similarity_search/"><span class="md-ellipsis"> similarity_search </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/solutions/"><span class="md-ellipsis"> solutions </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/speed_estimation/"><span class="md-ellipsis"> speed_estimation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/streamlit_inference/"><span class="md-ellipsis"> streamlit_inference </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/trackzone/"><span class="md-ellipsis"> trackzone </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../solutions/vision_eye/"><span class="md-ellipsis"> vision_eye </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_9" type="checkbox"/><label class="md-nav__link" for="__nav_11_9" id="__nav_11_9_label" tabindex=""><span class="md-ellipsis"> trackers </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_9_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_9"><span class="md-nav__icon md-icon"></span> trackers </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../trackers/basetrack/"><span class="md-ellipsis"> basetrack </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../trackers/bot_sort/"><span class="md-ellipsis"> bot_sort </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../trackers/byte_tracker/"><span class="md-ellipsis"> byte_tracker </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../trackers/track/"><span class="md-ellipsis"> track </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../trackers/utils/gmc/"><span class="md-ellipsis"> utils </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_10" type="checkbox"/><label class="md-nav__link" for="__nav_11_10" id="__nav_11_10_label" tabindex=""><span class="md-ellipsis"> utils </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_10_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_10"><span class="md-nav__icon md-icon"></span> utils </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/__init__/"><span class="md-ellipsis"> __init__ </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/autobatch/"><span class="md-ellipsis"> autobatch </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/autodevice/"><span class="md-ellipsis"> autodevice </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/benchmarks/"><span class="md-ellipsis"> benchmarks </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../utils/callbacks/base/"><span class="md-ellipsis"> callbacks </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/checks/"><span class="md-ellipsis"> checks </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/cpu/"><span class="md-ellipsis"> cpu </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/dist/"><span class="md-ellipsis"> dist </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/downloads/"><span class="md-ellipsis"> downloads </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/errors/"><span class="md-ellipsis"> errors </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/events/"><span class="md-ellipsis"> events </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../utils/export/engine/"><span class="md-ellipsis"> export </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/files/"><span class="md-ellipsis"> files </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/git/"><span class="md-ellipsis"> git </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/instance/"><span class="md-ellipsis"> instance </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/logger/"><span class="md-ellipsis"> logger </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/loss/"><span class="md-ellipsis"> loss </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/metrics/"><span class="md-ellipsis"> metrics </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/nms/"><span class="md-ellipsis"> nms </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/ops/"><span class="md-ellipsis"> ops </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/patches/"><span class="md-ellipsis"> patches </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/plotting/"><span class="md-ellipsis"> plotting </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/tal/"><span class="md-ellipsis"> tal </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/torch_utils/"><span class="md-ellipsis"> torch_utils </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/tqdm/"><span class="md-ellipsis"> tqdm </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/triton/"><span class="md-ellipsis"> triton </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../../utils/tuner/"><span class="md-ellipsis"> tuner </span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../../../help/"><span class="md-ellipsis"> Help </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> DropPath</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.DropPath" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> MaskDownSampler</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.MaskDownSampler" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> CXBlock</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.CXBlock" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> Fuser</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.Fuser" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> SAM2TwoWayAttentionBlock</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> SAM2TwoWayTransformer</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> RoPEAttention</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.RoPEAttention" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> MultiScaleAttention</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.MultiScaleAttention" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> MultiScaleBlock</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.MultiScaleBlock" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> PositionEmbeddingSine</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.PositionEmbeddingSine" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> _encode_xy</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> encode_boxes</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> encode_points</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> PositionEmbeddingRandom</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> _pe_encoding</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward_with_coords</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> Block</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.Block" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> REAttention</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.REAttention" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> PatchEmbed</span></a><nav aria-label="Class ultralytics.models.sam.modules.blocks.PatchEmbed" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> forward</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.do_pool"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> do_pool</span></a></li></ul></nav></div></div></div><div class="md-content" data-md-component="content"><article class="md-content__inner md-typeset"><a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/reference/models/sam/modules/blocks.md" rel="edit" title="Edit this page"><svg class="lucide lucide-file-pen" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"></path><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"></path></svg></a><h1 id="reference-for-ultralyticsmodelssammodulesblockspy">Reference for <code>ultralytics/models/sam/modules/blocks.py</code></h1><div class="admonition success"><p class="admonition-title">Improvements</p><p>This page is sourced from <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py</a>. Have an improvement or example to add? Open a <a href="https://docs.ultralytics.com/help/contributing/">Pull Request</a> â€” thank you! ğŸ™</p></div><p><br/></p><div class="admonition abstract"><p class="admonition-title">Summary</p><div class="tabbed-set tabbed-alternate" data-tabs="1:3"><input checked="checked" id="classes" name="__tabbed_1" type="radio"/><input id="methods" name="__tabbed_1" type="radio"/><input id="functions" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="classes"><span class="doc-kind doc-kind-class">Classes</span></label><label for="methods"><span class="doc-kind doc-kind-method">Methods</span></label><label for="functions"><span class="doc-kind doc-kind-function">Functions</span></label></div><div class="tabbed-content"><div class="tabbed-block"><ul><li><a href="#ultralytics.models.sam.modules.blocks.DropPath"><code>DropPath</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.MaskDownSampler"><code>MaskDownSampler</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.CXBlock"><code>CXBlock</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.Fuser"><code>Fuser</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock"><code>SAM2TwoWayAttentionBlock</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer"><code>SAM2TwoWayTransformer</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.RoPEAttention"><code>RoPEAttention</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention"><code>MultiScaleAttention</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock"><code>MultiScaleBlock</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine"><code>PositionEmbeddingSine</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom"><code>PositionEmbeddingRandom</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.Block"><code>Block</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.REAttention"><code>REAttention</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PatchEmbed"><code>PatchEmbed</code></a></li></ul></div><div class="tabbed-block"><ul><li><a href="#ultralytics.models.sam.modules.blocks.DropPath.forward"><code>DropPath.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward"><code>MaskDownSampler.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.CXBlock.forward"><code>CXBlock.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.Fuser.forward"><code>Fuser.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward"><code>RoPEAttention.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward"><code>MultiScaleAttention.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward"><code>MultiScaleBlock.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy"><code>PositionEmbeddingSine._encode_xy</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes"><code>PositionEmbeddingSine.encode_boxes</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points"><code>PositionEmbeddingSine.encode_points</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward"><code>PositionEmbeddingSine.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding"><code>PositionEmbeddingRandom._pe_encoding</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward"><code>PositionEmbeddingRandom.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords"><code>PositionEmbeddingRandom.forward_with_coords</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.Block.forward"><code>Block.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.REAttention.forward"><code>REAttention.forward</code></a></li><li><a href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward"><code>PatchEmbed.forward</code></a></li></ul></div><div class="tabbed-block"><ul><li><a href="#ultralytics.models.sam.modules.blocks.do_pool"><code>do_pool</code></a></li></ul></div></div></div></div><h2 id="ultralytics.models.sam.modules.blocks.DropPath"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.DropPath</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="n">DropPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">scale_by_keep</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>Implements stochastic depth regularization for neural networks during training.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>drop_prob</code></td><td><code>float</code></td><td></td><td><code>0.0</code></td></tr><tr><td><code>scale_by_keep</code></td><td><code>bool</code></td><td></td><td><code>True</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>drop_prob</code></td><td><code>float</code></td><td>Probability of dropping a path during training.</td></tr><tr><td><code>scale_by_keep</code></td><td><code>bool</code></td><td>Whether to scale the output by the keep probability.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.DropPath.forward"><code>forward</code></a></td><td>Apply stochastic depth to input tensor during training, with optional scaling.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">scale_by_keep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L19-L50"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DropPath</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Implements stochastic depth regularization for neural networks during training.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        drop_prob (float): Probability of dropping a path during training.</span>
<span></span><span class="sd">        scale_by_keep (bool): Whether to scale the output by the keep probability.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Applies stochastic depth to input tensor during training, with optional scaling.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; drop_path = DropPath(drop_prob=0.2, scale_by_keep=True)</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(32, 64, 224, 224)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = drop_path(x)</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">scale_by_keep</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize DropPath module for stochastic depth regularization during training."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span> <span class="o">=</span> <span class="n">drop_prob</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">scale_by_keep</span> <span class="o">=</span> <span class="n">scale_by_keep</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.DropPath.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.DropPath.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div><p>Apply stochastic depth to input tensor during training, with optional scaling.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L41-L50"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply stochastic depth to input tensor during training, with optional scaling."""</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">x</span>
<span></span>    <span class="n">keep_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span>
<span></span>    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">random_tensor</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">bernoulli_</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">keep_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_by_keep</span><span class="p">:</span>
<span></span>        <span class="n">random_tensor</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">random_tensor</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.MaskDownSampler"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.MaskDownSampler</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
<span></span>    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span></span>    <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span></span>    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">total_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
<span></span>    <span class="n">activation</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<span></span>    <span class="n">interpol_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>A mask downsampling and embedding module for efficient processing of input masks.</p><p>This class implements a mask downsampler that progressively reduces the spatial dimensions of input masks while expanding their channel dimensions using convolutional layers, layer normalization, and activation functions.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>embed_dim</code></td><td><code>int</code></td><td></td><td><code>256</code></td></tr><tr><td><code>kernel_size</code></td><td><code>int</code></td><td></td><td><code>4</code></td></tr><tr><td><code>stride</code></td><td><code>int</code></td><td></td><td><code>4</code></td></tr><tr><td><code>padding</code></td><td><code>int</code></td><td></td><td><code>0</code></td></tr><tr><td><code>total_stride</code></td><td><code>int</code></td><td></td><td><code>16</code></td></tr><tr><td><code>activation</code></td><td><code>type[nn.Module]</code></td><td></td><td><code>nn.GELU</code></td></tr><tr><td><code>interpol_size</code></td><td><code>tuple[int, int] | None</code></td><td></td><td><code>None</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>encoder</code></td><td><code>nn.Sequential</code></td><td>A sequential container of convolutional layers, layer normalization, and activation<br/> functions for downsampling and embedding masks.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward"><code>forward</code></a></td><td>Downsample and encode input mask to embed_dim channels using convolutional layers and LayerNorm2d.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">mask_downsampler</span> <span class="o">=</span> <span class="n">MaskDownSampler</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_stride</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">mask_downsampler</span><span class="p">(</span><span class="n">input_mask</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L53-L124"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MaskDownSampler</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""A mask downsampling and embedding module for efficient processing of input masks.</span>
<span></span>
<span></span><span class="sd">    This class implements a mask downsampler that progressively reduces the spatial dimensions of input masks while</span>
<span></span><span class="sd">    expanding their channel dimensions using convolutional layers, layer normalization, and activation functions.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        encoder (nn.Sequential): A sequential container of convolutional layers, layer normalization, and activation</span>
<span></span><span class="sd">            functions for downsampling and embedding masks.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Downsamples and encodes input mask to embed_dim channels.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; mask_downsampler = MaskDownSampler(embed_dim=256, kernel_size=4, stride=4, padding=0, total_stride=16)</span>
<span></span><span class="sd">        &gt;&gt;&gt; input_mask = torch.randn(1, 1, 256, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = mask_downsampler(input_mask)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 256, 16, 16])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
<span></span>        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span></span>        <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span></span>        <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span></span>        <span class="n">total_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
<span></span>        <span class="n">activation</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<span></span>        <span class="n">interpol_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a mask downsampler module for progressive downsampling and channel expansion."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">total_stride</span><span class="p">)</span> <span class="o">//</span> <span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">stride</span><span class="p">))</span>
<span></span>        <span class="k">assert</span> <span class="n">stride</span><span class="o">**</span><span class="n">num_layers</span> <span class="o">==</span> <span class="n">total_stride</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span></span>        <span class="n">mask_in_chans</span><span class="p">,</span> <span class="n">mask_out_chans</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<span></span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
<span></span>            <span class="n">mask_out_chans</span> <span class="o">=</span> <span class="n">mask_in_chans</span> <span class="o">*</span> <span class="p">(</span><span class="n">stride</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<span></span>                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
<span></span>                    <span class="n">mask_in_chans</span><span class="p">,</span>
<span></span>                    <span class="n">mask_out_chans</span><span class="p">,</span>
<span></span>                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
<span></span>                    <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
<span></span>                    <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
<span></span>                <span class="p">)</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">LayerNorm2d</span><span class="p">(</span><span class="n">mask_out_chans</span><span class="p">))</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<span></span>            <span class="n">mask_in_chans</span> <span class="o">=</span> <span class="n">mask_out_chans</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">mask_out_chans</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span> <span class="o">=</span> <span class="n">interpol_size</span>
<span></span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)),</span> <span class="p">(</span>
<span></span>                <span class="sa">f</span><span class="s2">"Unsupported type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span><span class="p">)</span><span class="si">}</span><span class="s2">. Should be a list or tuple."</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">interpol_size</span><span class="p">)</span>
<span></span>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.MaskDownSampler.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.MaskDownSampler.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div><p>Downsample and encode input mask to embed_dim channels using convolutional layers and LayerNorm2d.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L114-L124"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Downsample and encode input mask to embed_dim channels using convolutional layers and LayerNorm2d."""</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]):</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
<span></span>            <span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
<span></span>            <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">interpol_size</span><span class="p">,</span>
<span></span>            <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span></span>            <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span>
<span></span>            <span class="n">antialias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.CXBlock"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.CXBlock</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span>
<span></span>    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span></span>    <span class="n">drop_path</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span></span>    <span class="n">layer_scale_init_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
<span></span>    <span class="n">use_dwconv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>ConvNeXt Block for efficient feature extraction in convolutional neural networks.</p><p>This block implements a modified version of the ConvNeXt architecture, offering improved performance and flexibility in feature extraction.</p><p>This block implements a modified version of the ConvNeXt architecture, offering improved performance and flexibility in feature extraction.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td>Number of input channels.</td><td><em>required</em></td></tr><tr><td><code>kernel_size</code></td><td><code>int</code></td><td>Size of the convolutional kernel.</td><td><code>7</code></td></tr><tr><td><code>padding</code></td><td><code>int</code></td><td>Padding size for the convolution.</td><td><code>3</code></td></tr><tr><td><code>drop_path</code></td><td><code>float</code></td><td>Stochastic depth rate.</td><td><code>0.0</code></td></tr><tr><td><code>layer_scale_init_value</code></td><td><code>float</code></td><td>Initial value for Layer Scale.</td><td><code>1e-6</code></td></tr><tr><td><code>use_dwconv</code></td><td><code>bool</code></td><td>Whether to use depthwise convolution.</td><td><code>True</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dwconv</code></td><td><code>nn.Conv2d</code></td><td>Depthwise or standard 2D convolution layer.</td></tr><tr><td><code>norm</code></td><td><code>LayerNorm2d</code></td><td>Layer normalization applied to channels.</td></tr><tr><td><code>pwconv1</code></td><td><code>nn.Linear</code></td><td>First pointwise convolution implemented as a linear layer.</td></tr><tr><td><code>act</code></td><td><code>nn.GELU</code></td><td>GELU activation function.</td></tr><tr><td><code>pwconv2</code></td><td><code>nn.Linear</code></td><td>Second pointwise convolution implemented as a linear layer.</td></tr><tr><td><code>gamma</code></td><td><code>nn.Parameter | None</code></td><td>Learnable scale parameter for layer scaling.</td></tr><tr><td><code>drop_path</code></td><td><code>nn.Module</code></td><td>DropPath layer for stochastic depth regularization.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.CXBlock.forward"><code>forward</code></a></td><td>Apply ConvNeXt block operations to input tensor, including convolutions and residual connection.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">block</span> <span class="o">=</span> <span class="n">CXBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L127-L209"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CXBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""ConvNeXt Block for efficient feature extraction in convolutional neural networks.</span>
<span></span>
<span></span><span class="sd">    This block implements a modified version of the ConvNeXt architecture, offering improved performance and flexibility</span>
<span></span><span class="sd">    in feature extraction.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        dwconv (nn.Conv2d): Depthwise or standard 2D convolution layer.</span>
<span></span><span class="sd">        norm (LayerNorm2d): Layer normalization applied to channels.</span>
<span></span><span class="sd">        pwconv1 (nn.Linear): First pointwise convolution implemented as a linear layer.</span>
<span></span><span class="sd">        act (nn.GELU): GELU activation function.</span>
<span></span><span class="sd">        pwconv2 (nn.Linear): Second pointwise convolution implemented as a linear layer.</span>
<span></span><span class="sd">        gamma (nn.Parameter | None): Learnable scale parameter for layer scaling.</span>
<span></span><span class="sd">        drop_path (nn.Module): DropPath layer for stochastic depth regularization.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Processes the input tensor through the ConvNeXt block.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; import torch</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 64, 56, 56)</span>
<span></span><span class="sd">        &gt;&gt;&gt; block = CXBlock(dim=64, kernel_size=7, padding=3)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = block(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 64, 56, 56])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span>
<span></span>        <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span></span>        <span class="n">drop_path</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span></span>        <span class="n">layer_scale_init_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
<span></span>        <span class="n">use_dwconv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a ConvNeXt Block for efficient feature extraction in convolutional neural networks.</span>
<span></span>
<span></span><span class="sd">        This block implements a modified version of the ConvNeXt architecture, offering improved performance and</span>
<span></span><span class="sd">        flexibility in feature extraction.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            dim (int): Number of input channels.</span>
<span></span><span class="sd">            kernel_size (int): Size of the convolutional kernel.</span>
<span></span><span class="sd">            padding (int): Padding size for the convolution.</span>
<span></span><span class="sd">            drop_path (float): Stochastic depth rate.</span>
<span></span><span class="sd">            layer_scale_init_value (float): Initial value for Layer Scale.</span>
<span></span><span class="sd">            use_dwconv (bool): Whether to use depthwise convolution.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
<span></span>            <span class="n">dim</span><span class="p">,</span>
<span></span>            <span class="n">dim</span><span class="p">,</span>
<span></span>            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
<span></span>            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
<span></span>            <span class="n">groups</span><span class="o">=</span><span class="n">dim</span> <span class="k">if</span> <span class="n">use_dwconv</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>
<span></span>        <span class="p">)</span>  <span class="c1"># depthwise conv</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># pointwise/1x1 convs, implemented with linear layers</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
<span></span>            <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">layer_scale_init_value</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span>            <span class="k">if</span> <span class="n">layer_scale_init_value</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span></span>            <span class="k">else</span> <span class="kc">None</span>
<span></span>        <span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">drop_path</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.CXBlock.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.CXBlock.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div><p>Apply ConvNeXt block operations to input tensor, including convolutions and residual connection.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L195-L209"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply ConvNeXt block operations to input tensor, including convolutions and residual connection."""</span>
<span></span>    <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, C, H, W) -&gt; (N, H, W, C)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (N, H, W, C) -&gt; (N, C, H, W)</span>
<span></span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.Fuser"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.Fuser</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="n">Fuser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">input_projection</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>A module for fusing features through multiple layers of a neural network.</p><p>This class applies a series of identical layers to an input tensor, optionally projecting the input first.</p><p>This module creates a sequence of identical layers and optionally applies an input projection.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>layer</code></td><td><code>nn.Module</code></td><td>The layer to be replicated in the fuser.</td><td><em>required</em></td></tr><tr><td><code>num_layers</code></td><td><code>int</code></td><td>The number of times to replicate the layer.</td><td><em>required</em></td></tr><tr><td><code>dim</code></td><td><code>int | None</code></td><td>The dimension for input projection, if used.</td><td><code>None</code></td></tr><tr><td><code>input_projection</code></td><td><code>bool</code></td><td>Whether to use input projection.</td><td><code>False</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>proj</code></td><td><code>nn.Module</code></td><td>An optional input projection layer. Identity if no projection is needed.</td></tr><tr><td><code>layers</code></td><td><code>nn.ModuleList</code></td><td>A list of identical layers to be applied sequentially.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.Fuser.forward"><code>forward</code></a></td><td>Apply a series of layers to the input tensor, optionally projecting it first.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span> <span class="o">=</span> <span class="n">CXBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">fuser</span> <span class="o">=</span> <span class="n">Fuser</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_projection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">fuser</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L212-L257"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Fuser</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""A module for fusing features through multiple layers of a neural network.</span>
<span></span>
<span></span><span class="sd">    This class applies a series of identical layers to an input tensor, optionally projecting the input first.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        proj (nn.Module): An optional input projection layer. Identity if no projection is needed.</span>
<span></span><span class="sd">        layers (nn.ModuleList): A list of identical layers to be applied sequentially.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Applies the fuser to an input tensor.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; layer = CXBlock(dim=256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; fuser = Fuser(layer, num_layers=3, dim=256, input_projection=True)</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 256, 32, 32)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = fuser(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 256, 32, 32])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">input_projection</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize the Fuser module for feature fusion through multiple layers.</span>
<span></span>
<span></span><span class="sd">        This module creates a sequence of identical layers and optionally applies an input projection.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            layer (nn.Module): The layer to be replicated in the fuser.</span>
<span></span><span class="sd">            num_layers (int): The number of times to replicate the layer.</span>
<span></span><span class="sd">            dim (int | None): The dimension for input projection, if used.</span>
<span></span><span class="sd">            input_projection (bool): Whether to use input projection.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
<span></span>
<span></span>        <span class="k">if</span> <span class="n">input_projection</span><span class="p">:</span>
<span></span>            <span class="k">assert</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.Fuser.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.Fuser.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div><p>Apply a series of layers to the input tensor, optionally projecting it first.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L252-L257"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply a series of layers to the input tensor, optionally projecting it first."""</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<span></span>    <span class="n">activation</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<span></span>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span></span>    <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div><p><strong>Bases:</strong> <code>TwoWayAttentionBlock</code></p><p>A two-way attention block for performing self-attention and cross-attention in both directions.</p><p>This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on sparse inputs, cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and cross-attention from dense to sparse inputs.</p><p>This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on sparse inputs, cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and cross-attention from dense to sparse inputs.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>embedding_dim</code></td><td><code>int</code></td><td>The channel dimension of the embeddings.</td><td><em>required</em></td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td>The number of heads in the attention layers.</td><td><em>required</em></td></tr><tr><td><code>mlp_dim</code></td><td><code>int</code></td><td>The hidden dimension of the MLP block.</td><td><code>2048</code></td></tr><tr><td><code>activation</code></td><td><code>Type[nn.Module]</code></td><td>The activation function of the MLP block.</td><td><code>nn.ReLU</code></td></tr><tr><td><code>attention_downsample_rate</code></td><td><code>int</code></td><td>The downsample rate for attention computations.</td><td><code>2</code></td></tr><tr><td><code>skip_first_layer_pe</code></td><td><code>bool</code></td><td>Whether to skip the positional encoding in the first layer.</td><td><code>False</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>self_attn</code></td><td><code>Attention</code></td><td>Self-attention layer for queries.</td></tr><tr><td><code>norm1</code></td><td><code>nn.LayerNorm</code></td><td>Layer normalization after the first attention block.</td></tr><tr><td><code>cross_attn_token_to_image</code></td><td><code>Attention</code></td><td>Cross-attention layer from queries to keys.</td></tr><tr><td><code>norm2</code></td><td><code>nn.LayerNorm</code></td><td>Layer normalization after the second attention block.</td></tr><tr><td><code>mlp</code></td><td><code>MLP</code></td><td>MLP block for transforming query embeddings.</td></tr><tr><td><code>norm3</code></td><td><code>nn.LayerNorm</code></td><td>Layer normalization after the MLP block.</td></tr><tr><td><code>norm4</code></td><td><code>nn.LayerNorm</code></td><td>Layer normalization after the third attention block.</td></tr><tr><td><code>cross_attn_image_to_token</code></td><td><code>Attention</code></td><td>Cross-attention layer from keys to queries.</td></tr><tr><td><code>skip_first_layer_pe</code></td><td><code>bool</code></td><td>Flag to skip positional encoding in the first layer.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">block</span> <span class="o">=</span> <span class="n">SAM2TwoWayAttentionBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">sparse_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">dense_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">sparse_output</span><span class="p">,</span> <span class="n">dense_output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">sparse_input</span><span class="p">,</span> <span class="n">dense_input</span><span class="p">)</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L260-L312"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SAM2TwoWayAttentionBlock</span><span class="p">(</span><span class="n">TwoWayAttentionBlock</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""A two-way attention block for performing self-attention and cross-attention in both directions.</span>
<span></span>
<span></span><span class="sd">    This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on sparse inputs,</span>
<span></span><span class="sd">    cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and cross-attention from dense to sparse</span>
<span></span><span class="sd">    inputs.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        self_attn (Attention): Self-attention layer for queries.</span>
<span></span><span class="sd">        norm1 (nn.LayerNorm): Layer normalization after the first attention block.</span>
<span></span><span class="sd">        cross_attn_token_to_image (Attention): Cross-attention layer from queries to keys.</span>
<span></span><span class="sd">        norm2 (nn.LayerNorm): Layer normalization after the second attention block.</span>
<span></span><span class="sd">        mlp (MLP): MLP block for transforming query embeddings.</span>
<span></span><span class="sd">        norm3 (nn.LayerNorm): Layer normalization after the MLP block.</span>
<span></span><span class="sd">        norm4 (nn.LayerNorm): Layer normalization after the third attention block.</span>
<span></span><span class="sd">        cross_attn_image_to_token (Attention): Cross-attention layer from keys to queries.</span>
<span></span><span class="sd">        skip_first_layer_pe (bool): Flag to skip positional encoding in the first layer.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Processes input through the attention blocks and MLP.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; block = SAM2TwoWayAttentionBlock(embedding_dim=256, num_heads=8)</span>
<span></span><span class="sd">        &gt;&gt;&gt; sparse_input = torch.randn(1, 100, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; dense_input = torch.randn(1, 256, 16, 16)</span>
<span></span><span class="sd">        &gt;&gt;&gt; sparse_output, dense_output = block(sparse_input, dense_input)</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<span></span>        <span class="n">activation</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<span></span>        <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span></span>        <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a SAM2TwoWayAttentionBlock for performing self-attention and cross-attention in two directions.</span>
<span></span>
<span></span><span class="sd">        This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on sparse</span>
<span></span><span class="sd">        inputs, cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and cross-attention from</span>
<span></span><span class="sd">        dense to sparse inputs.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            embedding_dim (int): The channel dimension of the embeddings.</span>
<span></span><span class="sd">            num_heads (int): The number of heads in the attention layers.</span>
<span></span><span class="sd">            mlp_dim (int): The hidden dimension of the MLP block.</span>
<span></span><span class="sd">            activation (Type[nn.Module]): The activation function of the MLP block.</span>
<span></span><span class="sd">            attention_downsample_rate (int): The downsample rate for attention computations.</span>
<span></span><span class="sd">            skip_first_layer_pe (bool): Whether to skip the positional encoding in the first layer.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="p">,</span> <span class="n">skip_first_layer_pe</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">activation</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<span></span>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div><p><strong>Bases:</strong> <code>TwoWayTransformer</code></p><p>A Two-Way Transformer module for simultaneous attention to image and query points.</p><p>This class extends the TwoWayTransformer, implementing a specialized transformer decoder that attends to an input image using queries with supplied positional embeddings. It is particularly useful for tasks like object detection, image segmentation, and point cloud processing.</p><p>This transformer decoder attends to an input image using queries with supplied positional embeddings. It is designed for tasks like object detection, image segmentation, and point cloud processing.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>depth</code></td><td><code>int</code></td><td>Number of layers in the transformer.</td><td><em>required</em></td></tr><tr><td><code>embedding_dim</code></td><td><code>int</code></td><td>Channel dimension for the input embeddings.</td><td><em>required</em></td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td>Number of heads for multihead attention. Must divide embedding_dim.</td><td><em>required</em></td></tr><tr><td><code>mlp_dim</code></td><td><code>int</code></td><td>Channel dimension internal to the MLP block.</td><td><em>required</em></td></tr><tr><td><code>activation</code></td><td><code>Type[nn.Module]</code></td><td>Activation function to use in the MLP block.</td><td><code>nn.ReLU</code></td></tr><tr><td><code>attention_downsample_rate</code></td><td><code>int</code></td><td>Downsampling rate for attention computations.</td><td><code>2</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>depth</code></td><td><code>int</code></td><td>Number of layers in the transformer.</td></tr><tr><td><code>embedding_dim</code></td><td><code>int</code></td><td>Channel dimension for input embeddings.</td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td>Number of heads for multihead attention.</td></tr><tr><td><code>mlp_dim</code></td><td><code>int</code></td><td>Internal channel dimension for the MLP block.</td></tr><tr><td><code>layers</code></td><td><code>nn.ModuleList</code></td><td>List of SAM2TwoWayAttentionBlock layers comprising the transformer.</td></tr><tr><td><code>final_attn_token_to_image</code></td><td><code>Attention</code></td><td>Final attention layer from queries to image.</td></tr><tr><td><code>norm_final_attn</code></td><td><code>nn.LayerNorm</code></td><td>Layer normalization applied to final queries.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">SAM2TwoWayTransformer</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">image_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">query_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">image_embedding</span><span class="p">,</span> <span class="n">query_embedding</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L315-L377"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SAM2TwoWayTransformer</span><span class="p">(</span><span class="n">TwoWayTransformer</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""A Two-Way Transformer module for simultaneous attention to image and query points.</span>
<span></span>
<span></span><span class="sd">    This class extends the TwoWayTransformer, implementing a specialized transformer decoder that attends to an input</span>
<span></span><span class="sd">    image using queries with supplied positional embeddings. It is particularly useful for tasks like object detection,</span>
<span></span><span class="sd">    image segmentation, and point cloud processing.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        depth (int): Number of layers in the transformer.</span>
<span></span><span class="sd">        embedding_dim (int): Channel dimension for input embeddings.</span>
<span></span><span class="sd">        num_heads (int): Number of heads for multihead attention.</span>
<span></span><span class="sd">        mlp_dim (int): Internal channel dimension for the MLP block.</span>
<span></span><span class="sd">        layers (nn.ModuleList): List of SAM2TwoWayAttentionBlock layers comprising the transformer.</span>
<span></span><span class="sd">        final_attn_token_to_image (Attention): Final attention layer from queries to image.</span>
<span></span><span class="sd">        norm_final_attn (nn.LayerNorm): Layer normalization applied to final queries.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Processes input image embeddings and query embeddings through the transformer.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; transformer = SAM2TwoWayTransformer(depth=5, embedding_dim=256, num_heads=8, mlp_dim=2048)</span>
<span></span><span class="sd">        &gt;&gt;&gt; image_embedding = torch.randn(1, 256, 64, 64)</span>
<span></span><span class="sd">        &gt;&gt;&gt; query_embedding = torch.randn(1, 100, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = transformer(image_embedding, query_embedding)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output[0].shape, output[1].shape)</span>
<span></span><span class="sd">        torch.Size([1, 100, 256]) torch.Size([1, 256, 64, 64])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">activation</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<span></span>        <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span></span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a SAM2TwoWayTransformer instance.</span>
<span></span>
<span></span><span class="sd">        This transformer decoder attends to an input image using queries with supplied positional embeddings. It is</span>
<span></span><span class="sd">        designed for tasks like object detection, image segmentation, and point cloud processing.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            depth (int): Number of layers in the transformer.</span>
<span></span><span class="sd">            embedding_dim (int): Channel dimension for the input embeddings.</span>
<span></span><span class="sd">            num_heads (int): Number of heads for multihead attention. Must divide embedding_dim.</span>
<span></span><span class="sd">            mlp_dim (int): Channel dimension internal to the MLP block.</span>
<span></span><span class="sd">            activation (Type[nn.Module]): Activation function to use in the MLP block.</span>
<span></span><span class="sd">            attention_downsample_rate (int): Downsampling rate for attention computations.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
<span></span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<span></span>                <span class="n">SAM2TwoWayAttentionBlock</span><span class="p">(</span>
<span></span>                    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
<span></span>                    <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<span></span>                    <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
<span></span>                    <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
<span></span>                    <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">,</span>
<span></span>                    <span class="n">skip_first_layer_pe</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span>
<span></span>                <span class="p">)</span>
<span></span>            <span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.RoPEAttention"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.RoPEAttention</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
<span></span>    <span class="n">rope_theta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10000.0</span><span class="p">,</span>
<span></span>    <span class="n">rope_k_repeat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">feat_sizes</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>  <span class="c1"># [w, h] for stride 16 feats at 512 resolution</span>
<span></span>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>Attention</code></p><p>Implements rotary position encoding for attention mechanisms in transformer architectures.</p><p>This class extends the base Attention class by incorporating Rotary Position Encoding (RoPE) to enhance the positional awareness of the attention mechanism.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>*args</code></td><td></td><td></td><td><em>required</em></td></tr><tr><td><code>rope_theta</code></td><td><code>float</code></td><td></td><td><code>10000.0</code></td></tr><tr><td><code>rope_k_repeat</code></td><td><code>bool</code></td><td></td><td><code>False</code></td></tr><tr><td><code>feat_sizes</code></td><td><code>tuple[int, int]</code></td><td></td><td><code>(32, 32)</code></td></tr><tr><td><code>**kwargs</code></td><td></td><td></td><td><em>required</em></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>compute_cis</code></td><td><code>Callable</code></td><td>Function to compute axial complex numbers for rotary encoding.</td></tr><tr><td><code>freqs_cis</code></td><td><code>torch.Tensor</code></td><td>Precomputed frequency tensor for rotary encoding.</td></tr><tr><td><code>rope_k_repeat</code></td><td><code>bool</code></td><td>Flag to repeat query RoPE to match key length for cross-attention to memories.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward"><code>forward</code></a></td><td>Apply rotary position encoding and compute attention between query, key, and value tensors.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">rope_attn</span> <span class="o">=</span> <span class="n">RoPEAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">rope_theta</span><span class="o">=</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">feat_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">rope_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L380-L453"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RoPEAttention</span><span class="p">(</span><span class="n">Attention</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Implements rotary position encoding for attention mechanisms in transformer architectures.</span>
<span></span>
<span></span><span class="sd">    This class extends the base Attention class by incorporating Rotary Position Encoding (RoPE) to enhance the</span>
<span></span><span class="sd">    positional awareness of the attention mechanism.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        compute_cis (Callable): Function to compute axial complex numbers for rotary encoding.</span>
<span></span><span class="sd">        freqs_cis (torch.Tensor): Precomputed frequency tensor for rotary encoding.</span>
<span></span><span class="sd">        rope_k_repeat (bool): Flag to repeat query RoPE to match key length for cross-attention to memories.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Applies rotary position encoding and computes attention between query, key, and value tensors.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; rope_attn = RoPEAttention(embedding_dim=256, num_heads=8, rope_theta=10000.0, feat_sizes=(32, 32))</span>
<span></span><span class="sd">        &gt;&gt;&gt; q = torch.randn(1, 1024, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; k = torch.randn(1, 1024, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; v = torch.randn(1, 1024, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = rope_attn(q, k, v)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 1024, 256])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
<span></span>        <span class="n">rope_theta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10000.0</span><span class="p">,</span>
<span></span>        <span class="n">rope_k_repeat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="n">feat_sizes</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>  <span class="c1"># [w, h] for stride 16 feats at 512 resolution</span>
<span></span>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span></span>    <span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize RoPEAttention with rotary position encoding for enhanced positional awareness."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">compute_cis</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">compute_axial_cis</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">rope_theta</span><span class="p">)</span>
<span></span>        <span class="n">freqs_cis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cis</span><span class="p">(</span><span class="n">end_x</span><span class="o">=</span><span class="n">feat_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end_y</span><span class="o">=</span><span class="n">feat_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span> <span class="o">=</span> <span class="n">freqs_cis</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">rope_k_repeat</span> <span class="o">=</span> <span class="n">rope_k_repeat</span>  <span class="c1"># repeat q rope to match k length, needed for cross-attention to memories</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.RoPEAttention.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.RoPEAttention.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">num_k_exclude_rope</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Apply rotary position encoding and compute attention between query, key, and value tensors.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>q</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>k</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>v</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>num_k_exclude_rope</code></td><td><code>int</code></td><td></td><td><code>0</code></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L420-L453"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">num_k_exclude_rope</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply rotary position encoding and compute attention between query, key, and value tensors."""</span>
<span></span>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<span></span>    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span></span>    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Separate into heads</span>
<span></span>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span></span>    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span></span>    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Apply rotary position encoding</span>
<span></span>    <span class="n">w</span> <span class="o">=</span> <span class="n">h</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cis</span><span class="p">(</span><span class="n">end_x</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">end_y</span><span class="o">=</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
<span></span>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">rope_k_repeat</span>
<span></span>
<span></span>    <span class="n">num_k_rope</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_k_exclude_rope</span>
<span></span>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">num_k_rope</span><span class="p">]</span> <span class="o">=</span> <span class="n">apply_rotary_enc</span><span class="p">(</span>
<span></span>        <span class="n">q</span><span class="p">,</span>
<span></span>        <span class="n">k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">num_k_rope</span><span class="p">],</span>
<span></span>        <span class="n">freqs_cis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span><span class="p">,</span>
<span></span>        <span class="n">repeat_freqs_k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rope_k_repeat</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Attention</span>
<span></span>    <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recombine_heads</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span></span>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">out</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.MultiScaleAttention"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.MultiScaleAttention</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="n">MultiScaleAttention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">q_pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>Implements multiscale self-attention with optional query pooling for efficient feature extraction.</p><p>This class provides a flexible implementation of multiscale attention, allowing for optional downsampling of query features through pooling. It's designed to enhance the model's ability to capture multiscale information in visual tasks.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>dim_out</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>q_pool</code></td><td><code>nn.Module</code></td><td></td><td><code>None</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td>Input dimension of the feature map.</td></tr><tr><td><code>dim_out</code></td><td><code>int</code></td><td>Output dimension of the attention module.</td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td>Number of attention heads.</td></tr><tr><td><code>scale</code></td><td><code>float</code></td><td>Scaling factor for dot-product attention.</td></tr><tr><td><code>q_pool</code></td><td><code>nn.Module | None</code></td><td>Optional pooling module for query features.</td></tr><tr><td><code>qkv</code></td><td><code>nn.Linear</code></td><td>Linear projection for query, key, and value.</td></tr><tr><td><code>proj</code></td><td><code>nn.Linear</code></td><td>Output projection.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward"><code>forward</code></a></td><td>Apply multiscale attention with optional query pooling to extract multiscale features.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">msa</span> <span class="o">=</span> <span class="n">MultiScaleAttention</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">msa</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L471-L547"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiScaleAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Implements multiscale self-attention with optional query pooling for efficient feature extraction.</span>
<span></span>
<span></span><span class="sd">    This class provides a flexible implementation of multiscale attention, allowing for optional downsampling of query</span>
<span></span><span class="sd">    features through pooling. It's designed to enhance the model's ability to capture multiscale information in visual</span>
<span></span><span class="sd">    tasks.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        dim (int): Input dimension of the feature map.</span>
<span></span><span class="sd">        dim_out (int): Output dimension of the attention module.</span>
<span></span><span class="sd">        num_heads (int): Number of attention heads.</span>
<span></span><span class="sd">        scale (float): Scaling factor for dot-product attention.</span>
<span></span><span class="sd">        q_pool (nn.Module | None): Optional pooling module for query features.</span>
<span></span><span class="sd">        qkv (nn.Linear): Linear projection for query, key, and value.</span>
<span></span><span class="sd">        proj (nn.Linear): Output projection.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Applies multiscale attention to the input tensor.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; import torch</span>
<span></span><span class="sd">        &gt;&gt;&gt; from torch import nn</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 64, 64, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; msa = MultiScaleAttention(dim=256, dim_out=256, num_heads=8)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = msa(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 64, 64, 256])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">q_pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize multiscale attention with optional query pooling for efficient feature extraction."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<span></span>        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim_out</span> <span class="o">//</span> <span class="n">num_heads</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span><span class="o">**-</span><span class="mf">0.5</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">q_pool</span> <span class="o">=</span> <span class="n">q_pool</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Apply multiscale attention with optional query pooling to extract multiscale features.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L521-L547"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply multiscale attention with optional query pooling to extract multiscale features."""</span>
<span></span>    <span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<span></span>    <span class="c1"># qkv with shape (B, H * W, 3, nHead, C)</span>
<span></span>    <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="c1"># q, k, v with shape (B, H * W, nheads, C)</span>
<span></span>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Q pooling (for downsample at stage changes)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_pool</span><span class="p">:</span>
<span></span>        <span class="n">q</span> <span class="o">=</span> <span class="n">do_pool</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_pool</span><span class="p">)</span>
<span></span>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>  <span class="c1"># downsampled shape</span>
<span></span>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Torch's SDPA expects [B, nheads, H*W, C] so we transpose</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span>
<span></span>        <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span></span>        <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span></span>        <span class="n">v</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="c1"># Transpose back</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.MultiScaleBlock"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.MultiScaleBlock</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<span></span>    <span class="n">drop_path</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span></span>    <span class="n">norm_layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"LayerNorm"</span><span class="p">,</span>
<span></span>    <span class="n">q_stride</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="n">act_layer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<span></span>    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>A multiscale attention block with window partitioning and query pooling for efficient vision transformers.</p><p>This class implements a multiscale attention mechanism with optional window partitioning and downsampling, designed for use in vision transformer architectures.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>dim_out</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>mlp_ratio</code></td><td><code>float</code></td><td></td><td><code>4.0</code></td></tr><tr><td><code>drop_path</code></td><td><code>float</code></td><td></td><td><code>0.0</code></td></tr><tr><td><code>norm_layer</code></td><td><code>nn.Module | str</code></td><td></td><td><code>"LayerNorm"</code></td></tr><tr><td><code>q_stride</code></td><td><code>tuple[int, int] | None</code></td><td></td><td><code>None</code></td></tr><tr><td><code>act_layer</code></td><td><code>type[nn.Module]</code></td><td></td><td><code>nn.GELU</code></td></tr><tr><td><code>window_size</code></td><td><code>int</code></td><td></td><td><code>0</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td>Input dimension of the block.</td></tr><tr><td><code>dim_out</code></td><td><code>int</code></td><td>Output dimension of the block.</td></tr><tr><td><code>norm1</code></td><td><code>nn.Module</code></td><td>First normalization layer.</td></tr><tr><td><code>window_size</code></td><td><code>int</code></td><td>Size of the window for partitioning.</td></tr><tr><td><code>pool</code></td><td><code>nn.Module | None</code></td><td>Pooling layer for query downsampling.</td></tr><tr><td><code>q_stride</code></td><td><code>tuple[int, int] | None</code></td><td>Stride for query pooling.</td></tr><tr><td><code>attn</code></td><td><code>MultiScaleAttention</code></td><td>Multi-scale attention module.</td></tr><tr><td><code>drop_path</code></td><td><code>nn.Module</code></td><td>Drop path layer for regularization.</td></tr><tr><td><code>norm2</code></td><td><code>nn.Module</code></td><td>Second normalization layer.</td></tr><tr><td><code>mlp</code></td><td><code>MLP</code></td><td>Multi-layer perceptron module.</td></tr><tr><td><code>proj</code></td><td><code>nn.Linear | None</code></td><td>Projection layer for dimension mismatch.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward"><code>forward</code></a></td><td>Process input through multiscale attention and MLP, with optional windowing and downsampling.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">block</span> <span class="o">=</span> <span class="n">MultiScaleBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L550-L661"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiScaleBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""A multiscale attention block with window partitioning and query pooling for efficient vision transformers.</span>
<span></span>
<span></span><span class="sd">    This class implements a multiscale attention mechanism with optional window partitioning and downsampling, designed</span>
<span></span><span class="sd">    for use in vision transformer architectures.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        dim (int): Input dimension of the block.</span>
<span></span><span class="sd">        dim_out (int): Output dimension of the block.</span>
<span></span><span class="sd">        norm1 (nn.Module): First normalization layer.</span>
<span></span><span class="sd">        window_size (int): Size of the window for partitioning.</span>
<span></span><span class="sd">        pool (nn.Module | None): Pooling layer for query downsampling.</span>
<span></span><span class="sd">        q_stride (tuple[int, int] | None): Stride for query pooling.</span>
<span></span><span class="sd">        attn (MultiScaleAttention): Multi-scale attention module.</span>
<span></span><span class="sd">        drop_path (nn.Module): Drop path layer for regularization.</span>
<span></span><span class="sd">        norm2 (nn.Module): Second normalization layer.</span>
<span></span><span class="sd">        mlp (MLP): Multi-layer perceptron module.</span>
<span></span><span class="sd">        proj (nn.Linear | None): Projection layer for dimension mismatch.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Processes input tensor through the multiscale block.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; block = MultiScaleBlock(dim=256, dim_out=512, num_heads=8, window_size=7)</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 56, 56, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = block(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 28, 28, 512])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<span></span>        <span class="n">drop_path</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span></span>        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"LayerNorm"</span><span class="p">,</span>
<span></span>        <span class="n">q_stride</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>        <span class="n">act_layer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<span></span>        <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a multiscale attention block with window partitioning and optional query pooling."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>
<span></span>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">norm_layer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<span></span>            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">norm_layer</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">q_stride</span>
<span></span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span><span class="p">:</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">q_stride</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">q_stride</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiScaleAttention</span><span class="p">(</span>
<span></span>            <span class="n">dim</span><span class="p">,</span>
<span></span>            <span class="n">dim_out</span><span class="p">,</span>
<span></span>            <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<span></span>            <span class="n">q_pool</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">,</span>
<span></span>        <span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">drop_path</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim_out</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span>
<span></span>            <span class="n">dim_out</span><span class="p">,</span>
<span></span>            <span class="nb">int</span><span class="p">(</span><span class="n">dim_out</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">),</span>
<span></span>            <span class="n">dim_out</span><span class="p">,</span>
<span></span>            <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span></span>            <span class="n">act</span><span class="o">=</span><span class="n">act_layer</span><span class="p">,</span>
<span></span>        <span class="p">)</span>
<span></span>
<span></span>        <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="n">dim_out</span><span class="p">:</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Process input through multiscale attention and MLP, with optional windowing and downsampling.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L628-L661"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Process input through multiscale attention and MLP, with optional windowing and downsampling."""</span>
<span></span>    <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>  <span class="c1"># B, H, W, C</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Skip connection</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_out</span><span class="p">:</span>
<span></span>        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">do_pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Window partition</span>
<span></span>    <span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span>
<span></span>    <span class="k">if</span> <span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span></span>        <span class="n">x</span><span class="p">,</span> <span class="n">pad_hw</span> <span class="o">=</span> <span class="n">window_partition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Window Attention + Q Pooling (if stage change)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span><span class="p">:</span>
<span></span>        <span class="c1"># Shapes have changed due to Q pooling</span>
<span></span>        <span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span></span>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">shortcut</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span></span>
<span></span>        <span class="n">pad_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">H</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
<span></span>        <span class="n">pad_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">W</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
<span></span>        <span class="n">pad_hw</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">+</span> <span class="n">pad_h</span><span class="p">,</span> <span class="n">W</span> <span class="o">+</span> <span class="n">pad_w</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Reverse window partition</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">window_unpartition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">pad_hw</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<span></span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">shortcut</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="c1"># MLP</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span></span>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingSine</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">num_pos_feats</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
<span></span>    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>A module for generating sinusoidal positional embeddings for 2D inputs like images.</p><p>This class implements sinusoidal position encoding for 2D spatial positions, which can be used in transformer-based models for computer vision tasks.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>num_pos_feats</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr><tr><td><code>temperature</code></td><td><code>int</code></td><td></td><td><code>10000</code></td></tr><tr><td><code>normalize</code></td><td><code>bool</code></td><td></td><td><code>True</code></td></tr><tr><td><code>scale</code></td><td><code>float | None</code></td><td></td><td><code>None</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>num_pos_feats</code></td><td><code>int</code></td><td>Number of positional features (half of the embedding dimension).</td></tr><tr><td><code>temperature</code></td><td><code>int</code></td><td>Temperature parameter for the sinusoidal functions.</td></tr><tr><td><code>normalize</code></td><td><code>bool</code></td><td>Whether to normalize the positional embeddings.</td></tr><tr><td><code>scale</code></td><td><code>float</code></td><td>Scaling factor for the embeddings when normalize is True.</td></tr><tr><td><code>cache</code></td><td><code>dict</code></td><td>Cache for storing precomputed embeddings.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy"><code>_encode_xy</code></a></td><td>Encode 2D positions using sine/cosine functions for transformer positional embeddings.</td></tr><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes"><code>encode_boxes</code></a></td><td>Encode box coordinates and dimensions into positional embeddings for detection.</td></tr><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points"><code>encode_points</code></a></td><td>Encode 2D points with sinusoidal embeddings and append labels.</td></tr><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward"><code>forward</code></a></td><td>Generate sinusoidal position embeddings for 2D inputs like images.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">pos_emb</span> <span class="o">=</span> <span class="n">PositionEmbeddingSine</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">embeddings</span> <span class="o">=</span> <span class="n">pos_emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L664-L775"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PositionEmbeddingSine</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""A module for generating sinusoidal positional embeddings for 2D inputs like images.</span>
<span></span>
<span></span><span class="sd">    This class implements sinusoidal position encoding for 2D spatial positions, which can be used in transformer-based</span>
<span></span><span class="sd">    models for computer vision tasks.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        num_pos_feats (int): Number of positional features (half of the embedding dimension).</span>
<span></span><span class="sd">        temperature (int): Temperature parameter for the sinusoidal functions.</span>
<span></span><span class="sd">        normalize (bool): Whether to normalize the positional embeddings.</span>
<span></span><span class="sd">        scale (float): Scaling factor for the embeddings when normalize is True.</span>
<span></span><span class="sd">        cache (dict): Cache for storing precomputed embeddings.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        _encode_xy: Encodes 2D positions using sine and cosine functions.</span>
<span></span><span class="sd">        encode_boxes: Encodes box coordinates and dimensions into positional embeddings.</span>
<span></span><span class="sd">        encode_points: Encodes 2D point coordinates with sinusoidal positional embeddings.</span>
<span></span><span class="sd">        forward: Generates sinusoidal position embeddings for 2D inputs.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; pos_emb = PositionEmbeddingSine(num_pos_feats=128)</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 3, 224, 224)</span>
<span></span><span class="sd">        &gt;&gt;&gt; embeddings = pos_emb(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(embeddings.shape)</span>
<span></span><span class="sd">        torch.Size([1, 256, 224, 224])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">num_pos_feats</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">temperature</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
<span></span>        <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize sinusoidal position embeddings for 2D image inputs."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="k">assert</span> <span class="n">num_pos_feats</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"Expecting even model width"</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span> <span class="o">=</span> <span class="n">num_pos_feats</span> <span class="o">//</span> <span class="mi">2</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
<span></span>        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">normalize</span><span class="p">:</span>
<span></span>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"normalize should be True if scale is passed"</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>            <span class="n">scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_encode_xy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
</code></pre></div><p>Encode 2D positions using sine/cosine functions for transformer positional embeddings.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>y</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L712-L725"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_encode_xy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span></span><span class="w">    </span><span class="sd">"""Encode 2D positions using sine/cosine functions for transformer positional embeddings."""</span>
<span></span>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
<span></span>    <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<span></span>    <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<span></span>
<span></span>    <span class="n">dim_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="n">dim_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_t</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">pos_x</span> <span class="o">=</span> <span class="n">x_embed</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
<span></span>    <span class="n">pos_y</span> <span class="o">=</span> <span class="n">y_embed</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
<span></span>    <span class="n">pos_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">pos_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos_y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos_y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_boxes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Encode box coordinates and dimensions into positional embeddings for detection.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>y</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>w</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>h</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L728-L731"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_boxes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Encode box coordinates and dimensions into positional embeddings for detection."""</span>
<span></span>    <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_xy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">,</span> <span class="n">h</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">w</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Encode 2D points with sinusoidal embeddings and append labels.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>y</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>labels</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L736-L742"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">encode_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Encode 2D points with sinusoidal embeddings and append labels."""</span>
<span></span>    <span class="p">(</span><span class="n">bx</span><span class="p">,</span> <span class="n">nx</span><span class="p">),</span> <span class="p">(</span><span class="n">by</span><span class="p">,</span> <span class="n">ny</span><span class="p">),</span> <span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">nl</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span>
<span></span>    <span class="k">assert</span> <span class="n">bx</span> <span class="o">==</span> <span class="n">by</span> <span class="ow">and</span> <span class="n">nx</span> <span class="o">==</span> <span class="n">ny</span> <span class="ow">and</span> <span class="n">bx</span> <span class="o">==</span> <span class="n">bl</span> <span class="ow">and</span> <span class="n">nx</span> <span class="o">==</span> <span class="n">nl</span>
<span></span>    <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_xy</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span></span>    <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="n">pos_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bx</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">pos_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">by</span><span class="p">,</span> <span class="n">ny</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">,</span> <span class="n">labels</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div><p>Generate sinusoidal position embeddings for 2D inputs like images.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L745-L775"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Generate sinusoidal position embeddings for 2D inputs like images."""</span>
<span></span>    <span class="n">cache_key</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span></span>    <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">][</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">y_embed</span> <span class="o">=</span> <span class="p">(</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>        <span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">x_embed</span> <span class="o">=</span> <span class="p">(</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>        <span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
<span></span>        <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span></span>        <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y_embed</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_embed</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<span></span>        <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x_embed</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<span></span>
<span></span>    <span class="n">dim_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="n">dim_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_t</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">pos_x</span> <span class="o">=</span> <span class="n">x_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
<span></span>    <span class="n">pos_y</span> <span class="o">=</span> <span class="n">y_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
<span></span>    <span class="n">pos_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos_x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos_x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span></span>    <span class="n">pos_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos_y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos_y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span></span>    <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span></span>    <span class="k">return</span> <span class="n">pos</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="n">PositionEmbeddingRandom</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>Positional encoding using random spatial frequencies.</p><p>This class generates positional embeddings for input coordinates using random spatial frequencies. It is particularly useful for transformer-based models that require position information.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>num_pos_feats</code></td><td><code>int</code></td><td></td><td><code>64</code></td></tr><tr><td><code>scale</code></td><td><code>float | None</code></td><td></td><td><code>None</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>positional_encoding_gaussian_matrix</code></td><td><code>torch.Tensor</code></td><td>A buffer containing random values for encoding.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding"><code>_pe_encoding</code></a></td><td>Encode normalized [0,1] coordinates using random spatial frequencies.</td></tr><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward"><code>forward</code></a></td><td>Generate positional encoding for a grid using random spatial frequencies.</td></tr><tr><td><a href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords"><code>forward_with_coords</code></a></td><td>Positionally encode input coordinates, normalizing them to [0,1] based on the given image size.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">pe</span> <span class="o">=</span> <span class="n">PositionEmbeddingRandom</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">encoding</span> <span class="o">=</span> <span class="n">pe</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L778-L841"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PositionEmbeddingRandom</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Positional encoding using random spatial frequencies.</span>
<span></span>
<span></span><span class="sd">    This class generates positional embeddings for input coordinates using random spatial frequencies. It is</span>
<span></span><span class="sd">    particularly useful for transformer-based models that require position information.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        positional_encoding_gaussian_matrix (torch.Tensor): A buffer containing random values for encoding.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        _pe_encoding: Positionally encodes points that are normalized to [0,1].</span>
<span></span><span class="sd">        forward: Generates positional encoding for a grid of the specified size.</span>
<span></span><span class="sd">        forward_with_coords: Positionally encodes points that are not normalized to [0,1].</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; pe = PositionEmbeddingRandom(num_pos_feats=64)</span>
<span></span><span class="sd">        &gt;&gt;&gt; size = (32, 32)</span>
<span></span><span class="sd">        &gt;&gt;&gt; encoding = pe(size)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(encoding.shape)</span>
<span></span><span class="sd">        torch.Size([128, 32, 32])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize random spatial frequency position embedding for transformers."""</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">scale</span> <span class="o">&lt;=</span> <span class="mf">0.0</span><span class="p">:</span>
<span></span>            <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"positional_encoding_gaussian_matrix"</span><span class="p">,</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">)))</span>
<span></span>
<span></span>        <span class="c1"># Set non-deterministic for forward() error 'cumsum_cuda_kernel does not have a deterministic implementation'</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_pe_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Encode normalized [0,1] coordinates using random spatial frequencies.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>coords</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L811-L818"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_pe_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Encode normalized [0,1] coordinates using random spatial frequencies."""</span>
<span></span>    <span class="c1"># Assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape</span>
<span></span>    <span class="n">coords</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">coords</span> <span class="o">-</span> <span class="mi">1</span>
<span></span>    <span class="n">coords</span> <span class="o">=</span> <span class="n">coords</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding_gaussian_matrix</span>
<span></span>    <span class="n">coords</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">coords</span>
<span></span>    <span class="c1"># Outputs d_1 x ... x d_n x C shape</span>
<span></span>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">coords</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">coords</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Generate positional encoding for a grid using random spatial frequencies.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>size</code></td><td><code>tuple[int, int]</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L820-L834"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Generate positional encoding for a grid using random spatial frequencies."""</span>
<span></span>    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">size</span>
<span></span>    <span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
<span></span>        <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span>
<span></span>        <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding_gaussian_matrix</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span></span>        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding_gaussian_matrix</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">y_embed</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<span></span>    <span class="n">x_embed</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<span></span>    <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y_embed</span> <span class="o">/</span> <span class="n">h</span>
<span></span>    <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x_embed</span> <span class="o">/</span> <span class="n">w</span>
<span></span>
<span></span>    <span class="n">pe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pe_encoding</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x_embed</span><span class="p">,</span> <span class="n">y_embed</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<span></span>    <span class="k">return</span> <span class="n">pe</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># C x H x W</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward_with_coords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords_input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">image_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Positionally encode input coordinates, normalizing them to [0,1] based on the given image size.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>coords_input</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>image_size</code></td><td><code>tuple[int, int]</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L836-L841"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward_with_coords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords_input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">image_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Positionally encode input coordinates, normalizing them to [0,1] based on the given image size."""</span>
<span></span>    <span class="n">coords</span> <span class="o">=</span> <span class="n">coords_input</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span></span>    <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span></span>    <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pe_encoding</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span>  <span class="c1"># B x N x C</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.Block"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.Block</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<span></span>    <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="n">norm_layer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
<span></span>    <span class="n">act_layer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<span></span>    <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">input_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>Transformer block with support for window attention and residual propagation.</p><p>This class implements a transformer block that can use either global or windowed self-attention, followed by a feed-forward network. It supports relative positional embeddings and is designed for use in vision transformer architectures.</p><p>This constructor sets up a transformer block that can use either global or windowed self-attention, followed by a feed-forward network. It supports relative positional embeddings and is designed for use in vision transformer architectures.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td>Number of input channels.</td><td><em>required</em></td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td>Number of attention heads in the self-attention layer.</td><td><em>required</em></td></tr><tr><td><code>mlp_ratio</code></td><td><code>float</code></td><td>Ratio of mlp hidden dimension to embedding dimension.</td><td><code>4.0</code></td></tr><tr><td><code>qkv_bias</code></td><td><code>bool</code></td><td>If True, adds a learnable bias to query, key, value projections.</td><td><code>True</code></td></tr><tr><td><code>norm_layer</code></td><td><code>Type[nn.Module]</code></td><td>Type of normalization layer to use.</td><td><code>nn.LayerNorm</code></td></tr><tr><td><code>act_layer</code></td><td><code>Type[nn.Module]</code></td><td>Type of activation function to use in the MLP block.</td><td><code>nn.GELU</code></td></tr><tr><td><code>use_rel_pos</code></td><td><code>bool</code></td><td>If True, uses relative positional embeddings in attention.</td><td><code>False</code></td></tr><tr><td><code>rel_pos_zero_init</code></td><td><code>bool</code></td><td>If True, initializes relative positional parameters to zero.</td><td><code>True</code></td></tr><tr><td><code>window_size</code></td><td><code>int</code></td><td>Size of attention window. If 0, uses global attention.</td><td><code>0</code></td></tr><tr><td><code>input_size</code></td><td><code>tuple[int, int] | None</code></td><td>Input resolution for calculating relative positional parameter size.</td><td><code>None</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>norm1</code></td><td><code>nn.Module</code></td><td>First normalization layer.</td></tr><tr><td><code>attn</code></td><td><code>REAttention</code></td><td>Self-attention layer with optional relative positional encoding.</td></tr><tr><td><code>norm2</code></td><td><code>nn.Module</code></td><td>Second normalization layer.</td></tr><tr><td><code>mlp</code></td><td><code>MLPBlock</code></td><td>Multi-layer perceptron block.</td></tr><tr><td><code>window_size</code></td><td><code>int</code></td><td>Size of attention window. If 0, global attention is used.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.Block.forward"><code>forward</code></a></td><td>Process input through transformer block with optional windowed self-attention and residual connection.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">block</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L844-L932"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Transformer block with support for window attention and residual propagation.</span>
<span></span>
<span></span><span class="sd">    This class implements a transformer block that can use either global or windowed self-attention, followed by a</span>
<span></span><span class="sd">    feed-forward network. It supports relative positional embeddings and is designed for use in vision transformer</span>
<span></span><span class="sd">    architectures.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        norm1 (nn.Module): First normalization layer.</span>
<span></span><span class="sd">        attn (REAttention): Self-attention layer with optional relative positional encoding.</span>
<span></span><span class="sd">        norm2 (nn.Module): Second normalization layer.</span>
<span></span><span class="sd">        mlp (MLPBlock): Multi-layer perceptron block.</span>
<span></span><span class="sd">        window_size (int): Size of attention window. If 0, global attention is used.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Processes input through the transformer block.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; import torch</span>
<span></span><span class="sd">        &gt;&gt;&gt; block = Block(dim=256, num_heads=8, window_size=7)</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 56, 56, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = block(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 56, 56, 256])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<span></span>        <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="n">norm_layer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
<span></span>        <span class="n">act_layer</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<span></span>        <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span></span>        <span class="n">input_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a transformer block with optional window attention and relative positional embeddings.</span>
<span></span>
<span></span><span class="sd">        This constructor sets up a transformer block that can use either global or windowed self-attention, followed by</span>
<span></span><span class="sd">        a feed-forward network. It supports relative positional embeddings and is designed for use in vision transformer</span>
<span></span><span class="sd">        architectures.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            dim (int): Number of input channels.</span>
<span></span><span class="sd">            num_heads (int): Number of attention heads in the self-attention layer.</span>
<span></span><span class="sd">            mlp_ratio (float): Ratio of mlp hidden dimension to embedding dimension.</span>
<span></span><span class="sd">            qkv_bias (bool): If True, adds a learnable bias to query, key, value projections.</span>
<span></span><span class="sd">            norm_layer (Type[nn.Module]): Type of normalization layer to use.</span>
<span></span><span class="sd">            act_layer (Type[nn.Module]): Type of activation function to use in the MLP block.</span>
<span></span><span class="sd">            use_rel_pos (bool): If True, uses relative positional embeddings in attention.</span>
<span></span><span class="sd">            rel_pos_zero_init (bool): If True, initializes relative positional parameters to zero.</span>
<span></span><span class="sd">            window_size (int): Size of attention window. If 0, uses global attention.</span>
<span></span><span class="sd">            input_size (tuple[int, int] | None): Input resolution for calculating relative positional parameter size.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">REAttention</span><span class="p">(</span>
<span></span>            <span class="n">dim</span><span class="p">,</span>
<span></span>            <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<span></span>            <span class="n">qkv_bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">,</span>
<span></span>            <span class="n">use_rel_pos</span><span class="o">=</span><span class="n">use_rel_pos</span><span class="p">,</span>
<span></span>            <span class="n">rel_pos_zero_init</span><span class="o">=</span><span class="n">rel_pos_zero_init</span><span class="p">,</span>
<span></span>            <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span> <span class="k">if</span> <span class="n">window_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">),</span>
<span></span>        <span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">),</span> <span class="n">act</span><span class="o">=</span><span class="n">act_layer</span><span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.Block.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.Block.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Process input through transformer block with optional windowed self-attention and residual connection.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L917-L932"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Process input through transformer block with optional windowed self-attention and residual connection."""</span>
<span></span>    <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="c1"># Window partition</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span></span>        <span class="n">x</span><span class="p">,</span> <span class="n">pad_hw</span> <span class="o">=</span> <span class="n">window_partition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="c1"># Reverse window partition</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">window_unpartition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">,</span> <span class="n">pad_hw</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<span></span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">shortcut</span> <span class="o">+</span> <span class="n">x</span>
<span></span>    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.REAttention"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.REAttention</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
<span></span>    <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="n">input_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>Relative Position Attention module for efficient self-attention in transformer architectures.</p><p>This class implements a multi-head attention mechanism with relative positional embeddings, designed for use in vision transformer models. It supports optional query pooling and window partitioning for efficient processing of large inputs.</p><p>This module implements multi-head attention with optional relative positional encodings, designed specifically for vision tasks in transformer models.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>dim</code></td><td><code>int</code></td><td>Number of input channels.</td><td><em>required</em></td></tr><tr><td><code>num_heads</code></td><td><code>int</code></td><td>Number of attention heads.</td><td><code>8</code></td></tr><tr><td><code>qkv_bias</code></td><td><code>bool</code></td><td>If True, adds a learnable bias to query, key, value projections.</td><td><code>True</code></td></tr><tr><td><code>use_rel_pos</code></td><td><code>bool</code></td><td>If True, uses relative positional encodings.</td><td><code>False</code></td></tr><tr><td><code>rel_pos_zero_init</code></td><td><code>bool</code></td><td>If True, initializes relative positional parameters to zero.</td><td><code>True</code></td></tr><tr><td><code>input_size</code></td><td><code>tuple[int, int] | None</code></td><td>Input resolution for calculating relative positional parameter size.<br/> Required if use_rel_pos is True.</td><td><code>None</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>num_heads</code></td><td><code>int</code></td><td>Number of attention heads.</td></tr><tr><td><code>scale</code></td><td><code>float</code></td><td>Scaling factor for attention computation.</td></tr><tr><td><code>qkv</code></td><td><code>nn.Linear</code></td><td>Linear projection for query, key, and value.</td></tr><tr><td><code>proj</code></td><td><code>nn.Linear</code></td><td>Output projection layer.</td></tr><tr><td><code>use_rel_pos</code></td><td><code>bool</code></td><td>Whether to use relative positional embeddings.</td></tr><tr><td><code>rel_pos_h</code></td><td><code>nn.Parameter</code></td><td>Relative positional embeddings for height dimension.</td></tr><tr><td><code>rel_pos_w</code></td><td><code>nn.Parameter</code></td><td>Relative positional embeddings for width dimension.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.REAttention.forward"><code>forward</code></a></td><td>Apply multi-head attention with optional relative positional encoding to input tensor.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">attention</span> <span class="o">=</span> <span class="n">REAttention</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L935-L1015"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">REAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Relative Position Attention module for efficient self-attention in transformer architectures.</span>
<span></span>
<span></span><span class="sd">    This class implements a multi-head attention mechanism with relative positional embeddings, designed for use in</span>
<span></span><span class="sd">    vision transformer models. It supports optional query pooling and window partitioning for efficient processing of</span>
<span></span><span class="sd">    large inputs.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        num_heads (int): Number of attention heads.</span>
<span></span><span class="sd">        scale (float): Scaling factor for attention computation.</span>
<span></span><span class="sd">        qkv (nn.Linear): Linear projection for query, key, and value.</span>
<span></span><span class="sd">        proj (nn.Linear): Output projection layer.</span>
<span></span><span class="sd">        use_rel_pos (bool): Whether to use relative positional embeddings.</span>
<span></span><span class="sd">        rel_pos_h (nn.Parameter): Relative positional embeddings for height dimension.</span>
<span></span><span class="sd">        rel_pos_w (nn.Parameter): Relative positional embeddings for width dimension.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Applies multi-head attention with optional relative positional encoding to input tensor.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; attention = REAttention(dim=256, num_heads=8, input_size=(32, 32))</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 32, 32, 256)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = attention(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 32, 32, 256])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span></span>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
<span></span>        <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>        <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>        <span class="n">input_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span></span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize a Relative Position Attention module for transformer-based architectures.</span>
<span></span>
<span></span><span class="sd">        This module implements multi-head attention with optional relative positional encodings, designed specifically</span>
<span></span><span class="sd">        for vision tasks in transformer models.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            dim (int): Number of input channels.</span>
<span></span><span class="sd">            num_heads (int): Number of attention heads.</span>
<span></span><span class="sd">            qkv_bias (bool): If True, adds a learnable bias to query, key, value projections.</span>
<span></span><span class="sd">            use_rel_pos (bool): If True, uses relative positional encodings.</span>
<span></span><span class="sd">            rel_pos_zero_init (bool): If True, initializes relative positional parameters to zero.</span>
<span></span><span class="sd">            input_size (tuple[int, int] | None): Input resolution for calculating relative positional parameter size.</span>
<span></span><span class="sd">                Required if use_rel_pos is True.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<span></span>        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_heads</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span><span class="o">**-</span><span class="mf">0.5</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span> <span class="o">=</span> <span class="n">use_rel_pos</span>
<span></span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span><span class="p">:</span>
<span></span>            <span class="k">assert</span> <span class="n">input_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">"Input size must be provided if using relative positional encoding."</span>
<span></span>            <span class="c1"># Initialize relative positional embeddings</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">))</span>
<span></span>            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">))</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.REAttention.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.REAttention.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Apply multi-head attention with optional relative positional encoding to input tensor.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L1000-L1015"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply multi-head attention with optional relative positional encoding to input tensor."""</span>
<span></span>    <span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<span></span>    <span class="c1"># qkv with shape (3, B, nHead, H * W, C)</span>
<span></span>    <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span></span>    <span class="c1"># q, k, v with shape (B * nHead, H * W, C)</span>
<span></span>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">B</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">attn</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">@</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span><span class="p">:</span>
<span></span>        <span class="n">attn</span> <span class="o">=</span> <span class="n">add_decomposed_rel_pos</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_w</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<span></span>
<span></span>    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn</span> <span class="o">@</span> <span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.PatchEmbed"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.models.sam.modules.blocks.PatchEmbed</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>    <span class="bp">self</span><span class="p">,</span>
<span></span>    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<span></span>    <span class="n">stride</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<span></span>    <span class="n">padding</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
<span></span>    <span class="n">in_chans</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span></span>    <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
<span></span>    <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div><p><strong>Bases:</strong> <code>nn.Module</code></p><p>Image to Patch Embedding module for vision transformer architectures.</p><p>This module converts an input image into a sequence of patch embeddings using a convolutional layer. It is commonly used as the first layer in vision transformer architectures to transform image data into a suitable format for subsequent transformer blocks.</p><p>This module is typically used as the first layer in vision transformer architectures to transform image data into a suitable format for subsequent transformer blocks.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>kernel_size</code></td><td><code>tuple[int, int]</code></td><td>Size of the convolutional kernel for patch extraction.</td><td><code>(16, 16)</code></td></tr><tr><td><code>stride</code></td><td><code>tuple[int, int]</code></td><td>Stride of the convolutional operation.</td><td><code>(16, 16)</code></td></tr><tr><td><code>padding</code></td><td><code>tuple[int, int]</code></td><td>Padding applied to the input before convolution.</td><td><code>(0, 0)</code></td></tr><tr><td><code>in_chans</code></td><td><code>int</code></td><td>Number of input image channels.</td><td><code>3</code></td></tr><tr><td><code>embed_dim</code></td><td><code>int</code></td><td>Dimensionality of the output patch embeddings.</td><td><code>768</code></td></tr><tr><td><code>bias</code></td><td><code>bool</code></td><td>Whether to include a bias term in the convolutional layer.</td><td><code>True</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>proj</code></td><td><code>nn.Conv2d</code></td><td>Convolutional layer for projecting image patches to embeddings.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward"><code>forward</code></a></td><td>Compute patch embedding by applying convolution and transposing resulting tensor.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">patch_embed</span> <span class="o">=</span> <span class="n">PatchEmbed</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">patch_embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">])</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L1018-L1067"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PatchEmbed</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Image to Patch Embedding module for vision transformer architectures.</span>
<span></span>
<span></span><span class="sd">    This module converts an input image into a sequence of patch embeddings using a convolutional layer. It is commonly</span>
<span></span><span class="sd">    used as the first layer in vision transformer architectures to transform image data into a suitable format for</span>
<span></span><span class="sd">    subsequent transformer blocks.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        proj (nn.Conv2d): Convolutional layer for projecting image patches to embeddings.</span>
<span></span>
<span></span><span class="sd">    Methods:</span>
<span></span><span class="sd">        forward: Applies patch embedding to the input tensor.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; patch_embed = PatchEmbed(kernel_size=(16, 16), stride=(16, 16), in_chans=3, embed_dim=768)</span>
<span></span><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 3, 224, 224)</span>
<span></span><span class="sd">        &gt;&gt;&gt; output = patch_embed(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span></span><span class="sd">        torch.Size([1, 768, 14, 14])</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
<span></span>        <span class="bp">self</span><span class="p">,</span>
<span></span>        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<span></span>        <span class="n">stride</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<span></span>        <span class="n">padding</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
<span></span>        <span class="n">in_chans</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span></span>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
<span></span>        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize the PatchEmbed module for converting image patches to embeddings.</span>
<span></span>
<span></span><span class="sd">        This module is typically used as the first layer in vision transformer architectures to transform image data</span>
<span></span><span class="sd">        into a suitable format for subsequent transformer blocks.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            kernel_size (tuple[int, int]): Size of the convolutional kernel for patch extraction.</span>
<span></span><span class="sd">            stride (tuple[int, int]): Stride of the convolutional operation.</span>
<span></span><span class="sd">            padding (tuple[int, int]): Padding applied to the input before convolution.</span>
<span></span><span class="sd">            in_chans (int): Number of input image channels.</span>
<span></span><span class="sd">            embed_dim (int): Dimensionality of the output patch embeddings.</span>
<span></span><span class="sd">            bias (bool): Whether to include a bias term in the convolutional layer.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span></span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.models.sam.modules.blocks.PatchEmbed.forward"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.models.sam.modules.blocks.PatchEmbed.forward</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Compute patch embedding by applying convolution and transposing resulting tensor.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L1065-L1067"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Compute patch embedding by applying convolution and transposing resulting tensor."""</span>
<span></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># B C H W -&gt; B H W C</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.models.sam.modules.blocks.do_pool"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.models.sam.modules.blocks.do_pool</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">do_pool</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div><p>Apply pooling and optional normalization to a tensor, handling spatial dimension permutations.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>x</code></td><td><code>torch.Tensor</code></td><td></td><td><em>required</em></td></tr><tr><td><code>pool</code></td><td><code>nn.Module</code></td><td></td><td><em>required</em></td></tr><tr><td><code>norm</code></td><td><code>nn.Module</code></td><td></td><td><code>None</code></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py#L456-L468"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">do_pool</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Apply pooling and optional normalization to a tensor, handling spatial dimension permutations."""</span>
<span></span>    <span class="k">if</span> <span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">x</span>
<span></span>    <span class="c1"># (B, H, W, C) -&gt; (B, C, H, W)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>    <span class="c1"># (B, C, H', W') -&gt; (B, H', W', C)</span>
<span></span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">norm</span><span class="p">:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></details><p><br/><br/></p><br/><br/><div class="git-info"><div class="dates-container"><span class="date-item" title="This page was first created on August 05, 2024"><span class="hover-item">ğŸ“…</span> Created 1 year ago </span><span class="date-item" title="This page was last updated on November 23, 2025"><span class="hover-item">âœï¸</span> Updated 29 days ago </span></div><div class="authors-container"><a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (1 change)"><img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)"><img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (1 change)"><img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/></a></div></div><div class="share-buttons"><button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https%3A%2F%2Fdocs.ultralytics.com%2Freference%2Fmodels%2Fsam%2Fmodules%2Fblocks%2F', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet </button><button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdocs.ultralytics.com%2Freference%2Fmodels%2Fsam%2Fmodules%2Fblocks%2F', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share </button></div><br/></article></div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div><button class="md-top md-icon" data-md-component="top" hidden="" type="button"><svg class="lucide lucide-circle-arrow-up" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><path d="m16 12-4-4-4 4M12 16V8"></path></svg> Back to top
</button></main><footer class="md-footer"><nav aria-label="Footer" class="md-footer__inner md-grid"><a aria-label="Previous: model" class="md-footer__link md-footer__link--prev" href="../../model/"><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-left" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12 19-7-7 7-7M19 12H5"></path></svg></div><div class="md-footer__title"><span class="md-footer__direction"> Previous </span><div class="md-ellipsis"> model </div></div></a><a aria-label="Next: decoders" class="md-footer__link md-footer__link--next" href="../decoders/"><div class="md-footer__title"><span class="md-footer__direction"> Next </span><div class="md-ellipsis"> decoders </div></div><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-right" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 12h14M12 5l7 7-7 7"></path></svg></div></a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-copyright"><div class="md-copyright__highlight"><a href="https://www.ultralytics.com/" target="_blank">Â© 2025 Ultralytics Inc.</a> All rights reserved. </div> Made with <a href="https://zensical.org/" rel="noopener" target="_blank"> Zensical </a></div><div class="md-social"><a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg></a></div></div></div></footer></div><div class="md-dialog" data-md-component="dialog"><div class="md-dialog__inner md-typeset"></div></div><div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"annotate":null,"base":"../../../../..","features":["content.action.edit","content.code.annotate","content.code.copy","content.tooltips","toc.follow","navigation.top","navigation.tabs","navigation.tabs.sticky","navigation.prune","navigation.footer","navigation.tracking","navigation.instant","navigation.instant.progress","navigation.indexes","navigation.sections","content.tabs.link"],"search":"../../../../../assets/javascripts/workers/search.1bfe1b73.min.js","tags":null,"translations":{"clipboard.copied":"Copied to clipboard","clipboard.copy":"Copy to clipboard","search.result.more.one":"1 more on this page","search.result.more.other":"# more on this page","search.result.none":"No matching documents","search.result.one":"1 matching document","search.result.other":"# matching documents","search.result.placeholder":"Type to start searching","search.result.term.missing":"Missing","select.version":"Select version"},"version":null}</script>
<script src="../../../../../assets/javascripts/bundle.6008f134.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ultralytics/llm@v0.1.8/js/chat.min.js"></script>
<script src="https://unpkg.com/tablesort@5.6.0/dist/tablesort.min.js"></script>
<script src="../../../../../javascript/extra.js"></script>
<script src="../../../../../javascript/giscus.js"></script>
<script src="../../../../../javascript/tablesort.js"></script>
</body></html>