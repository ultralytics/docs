<!--Ultralytics YOLO ðŸš€, AGPL-3.0 license-->
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Explore detailed documentation of various SAM and SAM 2 modules such as MaskDownSampler, CXBlock, and more, available in Ultralytics' repository." name="description"/>
<meta content="Ultralytics" name="author"/>
<link href="https://docs.ultralytics.com/reference/models/sam/modules/blocks/" rel="canonical"/>
<link href="../../model/" rel="prev"/>
<link href="../decoders/" rel="next"/>
<link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.5.49" name="generator"/>
<title>blocks - Ultralytics YOLO Docs</title>
<link href="../../../../../assets/stylesheets/main.6f8fc17f.min.css" rel="stylesheet"/>
<link href="../../../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="blocks" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="Ultralytics, SAM encoder, SAM 2 encoder, DropPath, MaskDownSampler, CXBlock, Fuser, TwoWayTransformer, TwoWayAttentionBlock, RoPEAttention, MultiScaleAttention, MultiScaleBlock. PositionEmbeddingSine, do_pool" name="keywords"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/reference/models/sam/modules/blocks" property="og:url"/><meta content="blocks" property="og:title"/><meta content="Explore detailed documentation of various SAM and SAM 2 modules such as MaskDownSampler, CXBlock, and more, available in Ultralytics' repository." property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/reference/models/sam/modules/blocks" property="twitter:url"/><meta content="blocks" property="twitter:title"/><meta content="Explore detailed documentation of various SAM and SAM 2 modules such as MaskDownSampler, CXBlock, and more, available in Ultralytics' repository." property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "headline": "blocks", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2024-08-05 08:53:45 +0800", "dateModified": "2024-09-11 18:30:13 +0200", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "Explore detailed documentation of various SAM and SAM 2 modules such as MaskDownSampler, CXBlock, and more, available in Ultralytics' repository."}</script></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#reference-for-ultralyticsmodelssammodulesblockspy">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<div class="banner-wrapper">
<div class="banner-content-wrapper">
<p>YOLO Vision 2024 is here!</p>
<div class="banner-info-wrapper">
<img alt="YOLO Vision 24" height="20" loading="lazy" src="https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/66e9a87cfc78245ffa51d6f0_w_yv24.svg" width="20"/>
<p>September 27, 2024</p>
</div>
<div class="banner-info-wrapper">
<img alt="YOLO Vision 24" height="20" loading="lazy" src="https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/66e9a87cdfbd25e409560ed8_l_yv24.svg" width="20"/>
<p>Free hybrid event</p>
</div>
</div>
<div class="banner-button-wrapper">
<div class="banner-button-wrapper large">
<button onclick="window.open('https://www.ultralytics.com/events/yolovision', '_blank')">
        Join now
      </button>
</div>
</div>
</div>
</div>
</aside>
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Ultralytics YOLO Docs
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              blocks
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg>
</label>
<input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../..">
          
  
    
  
  Home

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../quickstart/">
          
  
    
  
  Quickstart

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../modes/">
          
  
    
  
  Modes

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../tasks/">
          
  
    
  
  Tasks

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../models/">
          
  
    
  
  Models

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../datasets/">
          
  
    
  
  Datasets

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../solutions/">
          
  
    
  
  Solutions ðŸš€ NEW

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../guides/">
          
  
    
  
  Guides

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../integrations/">
          
  
    
  
  Integrations

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../hub/">
          
  
    
  
  HUB

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../../cfg/__init__/">
          
  
    
  
  Reference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../help/">
          
  
    
  
  Help

        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
    Ultralytics YOLO Docs
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../..">
<span class="md-ellipsis">
    Home
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../quickstart/">
<span class="md-ellipsis">
    Quickstart
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../modes/">
<span class="md-ellipsis">
    Modes
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../tasks/">
<span class="md-ellipsis">
    Tasks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../models/">
<span class="md-ellipsis">
    Models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../datasets/">
<span class="md-ellipsis">
    Datasets
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../solutions/">
<span class="md-ellipsis">
    Solutions ðŸš€ NEW
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../guides/">
<span class="md-ellipsis">
    Guides
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../integrations/">
<span class="md-ellipsis">
    Integrations
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../hub/">
<span class="md-ellipsis">
    HUB
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_11">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_1" id="__nav_11_1_label" tabindex="">
<span class="md-ellipsis">
    cfg
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_1">
<span class="md-nav__icon md-icon"></span>
            cfg
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../cfg/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_2" id="__nav_11_2_label" tabindex="">
<span class="md-ellipsis">
    data
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_2">
<span class="md-nav__icon md-icon"></span>
            data
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/annotator/">
<span class="md-ellipsis">
    annotator
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/augment/">
<span class="md-ellipsis">
    augment
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/base/">
<span class="md-ellipsis">
    base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/converter/">
<span class="md-ellipsis">
    converter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/dataset/">
<span class="md-ellipsis">
    dataset
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/loaders/">
<span class="md-ellipsis">
    loaders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/split_dota/">
<span class="md-ellipsis">
    split_dota
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../data/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_3" id="__nav_11_3_label" tabindex="">
<span class="md-ellipsis">
    engine
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_3">
<span class="md-nav__icon md-icon"></span>
            engine
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/exporter/">
<span class="md-ellipsis">
    exporter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/predictor/">
<span class="md-ellipsis">
    predictor
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/results/">
<span class="md-ellipsis">
    results
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/trainer/">
<span class="md-ellipsis">
    trainer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../engine/validator/">
<span class="md-ellipsis">
    validator
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_4" id="__nav_11_4_label" tabindex="">
<span class="md-ellipsis">
    hub
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_4">
<span class="md-nav__icon md-icon"></span>
            hub
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/auth/">
<span class="md-ellipsis">
    auth
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../hub/google/__init__/">
<span class="md-ellipsis">
    google
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/session/">
<span class="md-ellipsis">
    session
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../hub/utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5" id="__nav_11_5_label" tabindex="">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_5">
<span class="md-nav__icon md-icon"></span>
            models
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../fastsam/model/">
<span class="md-ellipsis">
    fastsam
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../nas/model/">
<span class="md-ellipsis">
    nas
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../rtdetr/model/">
<span class="md-ellipsis">
    rtdetr
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5_4" id="__nav_11_5_4_label" tabindex="0">
<span class="md-ellipsis">
    sam
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_4_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_11_5_4">
<span class="md-nav__icon md-icon"></span>
            sam
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../amg/">
<span class="md-ellipsis">
    amg
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../build/">
<span class="md-ellipsis">
    build
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model/">
<span class="md-ellipsis">
    model
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11_5_4_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_5_4_4" id="__nav_11_5_4_4_label" tabindex="0">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_11_5_4_4_label" class="md-nav" data-md-level="4">
<label class="md-nav__title" for="__nav_11_5_4_4">
<span class="md-nav__icon md-icon"></span>
            modules
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    blocks
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    blocks
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â DropPath
    </span>
</a>
<nav aria-label="Â DropPath" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â MaskDownSampler
    </span>
</a>
<nav aria-label="Â MaskDownSampler" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â CXBlock
    </span>
</a>
<nav aria-label="Â CXBlock" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â Fuser
    </span>
</a>
<nav aria-label="Â Fuser" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2TwoWayAttentionBlock
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2TwoWayTransformer
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â RoPEAttention
    </span>
</a>
<nav aria-label="Â RoPEAttention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â MultiScaleAttention
    </span>
</a>
<nav aria-label="Â MultiScaleAttention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â MultiScaleBlock
    </span>
</a>
<nav aria-label="Â MultiScaleBlock" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â PositionEmbeddingSine
    </span>
</a>
<nav aria-label="Â PositionEmbeddingSine" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â encode_boxes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â encode_points
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â PositionEmbeddingRandom
    </span>
</a>
<nav aria-label="Â PositionEmbeddingRandom" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward_with_coords
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â Block
    </span>
</a>
<nav aria-label="Â Block" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â REAttention
    </span>
</a>
<nav aria-label="Â REAttention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â PatchEmbed
    </span>
</a>
<nav aria-label="Â PatchEmbed" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.do_pool">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>Â do_pool
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../decoders/">
<span class="md-ellipsis">
    decoders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../encoders/">
<span class="md-ellipsis">
    encoders
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../memory_attention/">
<span class="md-ellipsis">
    memory_attention
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../sam/">
<span class="md-ellipsis">
    sam
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../tiny_encoder/">
<span class="md-ellipsis">
    tiny_encoder
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../transformer/">
<span class="md-ellipsis">
    transformer
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../predict/">
<span class="md-ellipsis">
    predict
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../utils/loss/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../yolo/classify/predict/">
<span class="md-ellipsis">
    yolo
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_6" id="__nav_11_6_label" tabindex="">
<span class="md-ellipsis">
    nn
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_6">
<span class="md-nav__icon md-icon"></span>
            nn
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../nn/autobackend/">
<span class="md-ellipsis">
    autobackend
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../nn/modules/activation/">
<span class="md-ellipsis">
    modules
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../nn/tasks/">
<span class="md-ellipsis">
    tasks
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_7" id="__nav_11_7_label" tabindex="">
<span class="md-ellipsis">
    solutions
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_7_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_7">
<span class="md-nav__icon md-icon"></span>
            solutions
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/ai_gym/">
<span class="md-ellipsis">
    ai_gym
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/analytics/">
<span class="md-ellipsis">
    analytics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/distance_calculation/">
<span class="md-ellipsis">
    distance_calculation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/heatmap/">
<span class="md-ellipsis">
    heatmap
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/object_counter/">
<span class="md-ellipsis">
    object_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/parking_management/">
<span class="md-ellipsis">
    parking_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/queue_management/">
<span class="md-ellipsis">
    queue_management
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/region_counter/">
<span class="md-ellipsis">
    region_counter
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/security_alarm/">
<span class="md-ellipsis">
    security_alarm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/solutions/">
<span class="md-ellipsis">
    solutions
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/speed_estimation/">
<span class="md-ellipsis">
    speed_estimation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/streamlit_inference/">
<span class="md-ellipsis">
    streamlit_inference
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../solutions/trackzone/">
<span class="md-ellipsis">
    trackzone
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_8" id="__nav_11_8_label" tabindex="">
<span class="md-ellipsis">
    trackers
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_8_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_8">
<span class="md-nav__icon md-icon"></span>
            trackers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/basetrack/">
<span class="md-ellipsis">
    basetrack
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/bot_sort/">
<span class="md-ellipsis">
    bot_sort
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/byte_tracker/">
<span class="md-ellipsis">
    byte_tracker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../trackers/track/">
<span class="md-ellipsis">
    track
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../trackers/utils/gmc/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_11_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_11_9" id="__nav_11_9_label" tabindex="">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_11_9_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_11_9">
<span class="md-nav__icon md-icon"></span>
            utils
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/__init__/">
<span class="md-ellipsis">
    __init__
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/autobatch/">
<span class="md-ellipsis">
    autobatch
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/benchmarks/">
<span class="md-ellipsis">
    benchmarks
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../utils/callbacks/base/">
<span class="md-ellipsis">
    callbacks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/checks/">
<span class="md-ellipsis">
    checks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/dist/">
<span class="md-ellipsis">
    dist
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/downloads/">
<span class="md-ellipsis">
    downloads
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/errors/">
<span class="md-ellipsis">
    errors
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/files/">
<span class="md-ellipsis">
    files
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/instance/">
<span class="md-ellipsis">
    instance
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/loss/">
<span class="md-ellipsis">
    loss
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/metrics/">
<span class="md-ellipsis">
    metrics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/ops/">
<span class="md-ellipsis">
    ops
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/patches/">
<span class="md-ellipsis">
    patches
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/plotting/">
<span class="md-ellipsis">
    plotting
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/tal/">
<span class="md-ellipsis">
    tal
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/torch_utils/">
<span class="md-ellipsis">
    torch_utils
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/triton/">
<span class="md-ellipsis">
    triton
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../utils/tuner/">
<span class="md-ellipsis">
    tuner
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../help/">
<span class="md-ellipsis">
    Help
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â DropPath
    </span>
</a>
<nav aria-label="Â DropPath" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.DropPath.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â MaskDownSampler
    </span>
</a>
<nav aria-label="Â MaskDownSampler" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â CXBlock
    </span>
</a>
<nav aria-label="Â CXBlock" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.CXBlock.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â Fuser
    </span>
</a>
<nav aria-label="Â Fuser" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Fuser.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2TwoWayAttentionBlock
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â SAM2TwoWayTransformer
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â RoPEAttention
    </span>
</a>
<nav aria-label="Â RoPEAttention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â MultiScaleAttention
    </span>
</a>
<nav aria-label="Â MultiScaleAttention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â MultiScaleBlock
    </span>
</a>
<nav aria-label="Â MultiScaleBlock" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â PositionEmbeddingSine
    </span>
</a>
<nav aria-label="Â PositionEmbeddingSine" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â encode_boxes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â encode_points
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â PositionEmbeddingRandom
    </span>
</a>
<nav aria-label="Â PositionEmbeddingRandom" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward_with_coords
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â Block
    </span>
</a>
<nav aria-label="Â Block" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.Block.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â REAttention
    </span>
</a>
<nav aria-label="Â REAttention" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.REAttention.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>Â PatchEmbed
    </span>
</a>
<nav aria-label="Â PatchEmbed" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>Â forward
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ultralytics.models.sam.modules.blocks.do_pool">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>Â do_pool
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/reference/models/sam/modules/blocks.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<h1 id="reference-for-ultralyticsmodelssammodulesblockspy">Reference for <code>ultralytics/models/sam/modules/blocks.py</code></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This file is available at <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/models/sam/modules/blocks.py</a>. If you spot a problem please help fix it by <a href="https://docs.ultralytics.com/help/contributing/">contributing</a> a <a href="https://github.com/ultralytics/ultralytics/edit/main/ultralytics/models/sam/modules/blocks.py">Pull Request</a> ðŸ› ï¸. Thank you ðŸ™!</p>
</div>
<p><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.DropPath">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.DropPath</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">DropPath</span><span class="p">(</span><span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale_by_keep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>Implements stochastic depth regularization for neural networks during training.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.DropPath.drop_prob">drop_prob</span></code></td>
<td>
<code>float</code>
</td>
<td>
<div class="doc-md-description">
<p>Probability of dropping a path during training.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.DropPath.scale_by_keep">scale_by_keep</span></code></td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to scale the output by the keep probability.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.DropPath.forward" href="#ultralytics.models.sam.modules.blocks.DropPath.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies stochastic depth to input tensor during training, with optional scaling.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">scale_by_keep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale_by_keep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="w">    </span><span class="sd">"""Initialize DropPath module for stochastic depth regularization during training."""</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span> <span class="o">=</span> <span class="n">drop_prob</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">scale_by_keep</span> <span class="o">=</span> <span class="n">scale_by_keep</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.DropPath.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Applies stochastic depth to input tensor during training, with optional scaling.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="w">    </span><span class="sd">"""Applies stochastic depth to input tensor during training, with optional scaling."""</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">keep_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_prob</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="n">random_tensor</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">bernoulli_</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="k">if</span> <span class="n">keep_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_by_keep</span><span class="p">:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="n">random_tensor</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">random_tensor</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.MaskDownSampler">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.MaskDownSampler</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">MaskDownSampler</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">embed_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">total_stride</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>A mask downsampling and embedding module for efficient processing of input masks.</p>
<p>This class implements a mask downsampler that progressively reduces the spatial dimensions of input masks
while expanding their channel dimensions using convolutional layers, layer normalization, and activation
functions.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MaskDownSampler.encoder">encoder</span></code></td>
<td>
<code><span title="torch.nn.Sequential">Sequential</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A sequential container of convolutional layers, layer normalization, and
activation functions for downsampling and embedding masks.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.MaskDownSampler.forward" href="#ultralytics.models.sam.modules.blocks.MaskDownSampler.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Downsamples and encodes input mask to embed_dim channels.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">mask_downsampler</span> <span class="o">=</span> <span class="n">MaskDownSampler</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_stride</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">mask_downsampler</span><span class="p">(</span><span class="n">input_mask</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 256, 16, 16])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="n">embed_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">total_stride</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="p">):</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="w">    </span><span class="sd">"""Initializes a mask downsampler module for progressive downsampling and channel expansion."""</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">total_stride</span><span class="p">)</span> <span class="o">//</span> <span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">stride</span><span class="p">))</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="k">assert</span> <span class="n">stride</span><span class="o">**</span><span class="n">num_layers</span> <span class="o">==</span> <span class="n">total_stride</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="n">mask_in_chans</span><span class="p">,</span> <span class="n">mask_out_chans</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="n">mask_out_chans</span> <span class="o">=</span> <span class="n">mask_in_chans</span> <span class="o">*</span> <span class="p">(</span><span class="n">stride</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>                <span class="n">mask_in_chans</span><span class="p">,</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>                <span class="n">mask_out_chans</span><span class="p">,</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>                <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>            <span class="p">)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">LayerNorm2d</span><span class="p">(</span><span class="n">mask_out_chans</span><span class="p">))</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">mask_in_chans</span> <span class="o">=</span> <span class="n">mask_out_chans</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">mask_out_chans</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.MaskDownSampler.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Downsamples and encodes input mask to embed_dim channels using convolutional layers and LayerNorm2d.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="w">    </span><span class="sd">"""Downsamples and encodes input mask to embed_dim channels using convolutional layers and LayerNorm2d."""</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.CXBlock">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.CXBlock</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">CXBlock</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">dim</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">drop_path</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">layer_scale_init_value</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">use_dwconv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>ConvNeXt Block for efficient feature extraction in convolutional neural networks.</p>
<p>This block implements a modified version of the ConvNeXt architecture, offering improved performance and
flexibility in feature extraction.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.dwconv">dwconv</span></code></td>
<td>
<code><span title="torch.nn.Conv2d">Conv2d</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Depthwise or standard 2D convolution layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.norm">norm</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.nn.modules.LayerNorm2d" href="../../../../nn/modules/transformer/#ultralytics.nn.modules.transformer.LayerNorm2d">LayerNorm2d</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization applied to channels.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.pwconv1">pwconv1</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>First pointwise convolution implemented as a linear layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.act">act</span></code></td>
<td>
<code><span title="torch.nn.GELU">GELU</span></code>
</td>
<td>
<div class="doc-md-description">
<p>GELU activation function.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.pwconv2">pwconv2</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Second pointwise convolution implemented as a linear layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.gamma">gamma</span></code></td>
<td>
<code><span title="torch.nn.Parameter">Parameter</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Learnable scale parameter for layer scaling.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.CXBlock.drop_path">drop_path</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>DropPath layer for stochastic depth regularization.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.CXBlock.forward" href="#ultralytics.models.sam.modules.blocks.CXBlock.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Processes the input tensor through the ConvNeXt block.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">CXBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="go">torch.Size([1, 64, 56, 56])</span>
</code></pre></div>
<p>This block implements a modified version of the ConvNeXt architecture, offering improved performance and
flexibility in feature extraction.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of input channels.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>kernel_size</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Size of the convolutional kernel.</p>
</div>
</td>
<td>
<code>7</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>padding</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Padding size for the convolution.</p>
</div>
</td>
<td>
<code>3</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>drop_path</code>
</td>
<td>
<code>float</code>
</td>
<td>
<div class="doc-md-description">
<p>Stochastic depth rate.</p>
</div>
</td>
<td>
<code>0.0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>layer_scale_init_value</code>
</td>
<td>
<code>float</code>
</td>
<td>
<div class="doc-md-description">
<p>Initial value for Layer Scale.</p>
</div>
</td>
<td>
<code>1e-06</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>use_dwconv</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to use depthwise convolution.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">CXBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 64, 32, 32])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>    <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="n">drop_path</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="n">layer_scale_init_value</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="n">use_dwconv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="p">):</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    Initialize a ConvNeXt Block for efficient feature extraction in convolutional neural networks.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">    This block implements a modified version of the ConvNeXt architecture, offering improved performance and</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    flexibility in feature extraction.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">        dim (int): Number of input channels.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">        kernel_size (int): Size of the convolutional kernel.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        padding (int): Padding size for the convolution.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">        drop_path (float): Stochastic depth rate.</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        layer_scale_init_value (float): Initial value for Layer Scale.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        use_dwconv (bool): Whether to use depthwise convolution.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        &gt;&gt;&gt; block = CXBlock(dim=64, kernel_size=7, padding=3)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 64, 32, 32)</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        &gt;&gt;&gt; output = block(x)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        torch.Size([1, 64, 32, 32])</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    """</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">groups</span><span class="o">=</span><span class="n">dim</span> <span class="k">if</span> <span class="n">use_dwconv</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="p">)</span>  <span class="c1"># depthwise conv</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># pointwise/1x1 convs, implemented with linear layers</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">layer_scale_init_value</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="k">if</span> <span class="n">layer_scale_init_value</span> <span class="o">&gt;</span> <span class="mi">0</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="p">)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">drop_path</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.CXBlock.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Applies ConvNeXt block operations to input tensor, including convolutions and residual connection.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="w">    </span><span class="sd">"""Applies ConvNeXt block operations to input tensor, including convolutions and residual connection."""</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, C, H, W) -&gt; (N, H, W, C)</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (N, H, W, C) -&gt; (N, C, H, W)</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.Fuser">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.Fuser</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">Fuser</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_projection</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>A module for fusing features through multiple layers of a neural network.</p>
<p>This class applies a series of identical layers to an input tensor, optionally projecting the input first.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Fuser.proj">proj</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>An optional input projection layer. Identity if no projection is needed.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Fuser.layers">layers</span></code></td>
<td>
<code><span title="torch.nn.ModuleList">ModuleList</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A list of identical layers to be applied sequentially.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.Fuser.forward" href="#ultralytics.models.sam.modules.blocks.Fuser.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies the fuser to an input tensor.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">CXBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">fuser</span> <span class="o">=</span> <span class="n">Fuser</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_projection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">fuser</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="go">torch.Size([1, 256, 32, 32])</span>
</code></pre></div>
<p>This module creates a sequence of identical layers and optionally applies an input projection.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>layer</code>
</td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The layer to be replicated in the fuser.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_layers</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>The number of times to replicate the layer.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>dim</code>
</td>
<td>
<code>int | None</code>
</td>
<td>
<div class="doc-md-description">
<p>The dimension for input projection, if used.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>input_projection</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to use input projection.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">fuser</span> <span class="o">=</span> <span class="n">Fuser</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">input_projection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">fuser</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_projection</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a><span class="sd">    Initializes the Fuser module for feature fusion through multiple layers.</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a><span class="sd">    This module creates a sequence of identical layers and optionally applies an input projection.</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a><span class="sd">        layer (nn.Module): The layer to be replicated in the fuser.</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a><span class="sd">        num_layers (int): The number of times to replicate the layer.</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="sd">        dim (int | None): The dimension for input projection, if used.</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="sd">        input_projection (bool): Whether to use input projection.</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">        &gt;&gt;&gt; layer = nn.Linear(64, 64)</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">        &gt;&gt;&gt; fuser = Fuser(layer, num_layers=3, dim=64, input_projection=True)</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">        &gt;&gt;&gt; input_tensor = torch.randn(1, 64)</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a><span class="sd">        &gt;&gt;&gt; output = fuser(input_tensor)</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">    """</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="k">if</span> <span class="n">input_projection</span><span class="p">:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>        <span class="k">assert</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.Fuser.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Applies a series of layers to the input tensor, optionally projecting it first.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-256" name="__codelineno-0-256"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a><span class="w">    </span><span class="sd">"""Applies a series of layers to the input tensor, optionally projecting it first."""</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">SAM2TwoWayAttentionBlock</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock" href="../transformer/#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock">TwoWayAttentionBlock</a></code></p>
<p>A two-way attention block for performing self-attention and cross-attention in both directions.</p>
<p>This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on
sparse inputs, cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and
cross-attention from dense to sparse inputs.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.self_attn">self_attn</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.Attention" href="../transformer/#ultralytics.models.sam.modules.transformer.Attention">Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Self-attention layer for queries.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.norm1">norm1</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after the first attention block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.cross_attn_token_to_image">cross_attn_token_to_image</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.Attention" href="../transformer/#ultralytics.models.sam.modules.transformer.Attention">Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Cross-attention layer from queries to keys.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.norm2">norm2</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after the second attention block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.mlp">mlp</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.nn.modules.MLP" href="../../../../nn/modules/transformer/#ultralytics.nn.modules.transformer.MLP">MLP</a></code>
</td>
<td>
<div class="doc-md-description">
<p>MLP block for transforming query embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.norm3">norm3</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after the MLP block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.norm4">norm4</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization after the third attention block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.cross_attn_image_to_token">cross_attn_image_to_token</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.Attention" href="../transformer/#ultralytics.models.sam.modules.transformer.Attention">Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Cross-attention layer from keys to queries.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.skip_first_layer_pe">skip_first_layer_pe</span></code></td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to skip positional encoding in the first layer.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.SAM2TwoWayAttentionBlock.forward" href="../transformer/#ultralytics.models.sam.modules.transformer.TwoWayAttentionBlock.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Processes input through the attention blocks and MLP.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">SAM2TwoWayAttentionBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">dense_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_output</span><span class="p">,</span> <span class="n">dense_output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">sparse_input</span><span class="p">,</span> <span class="n">dense_input</span><span class="p">)</span>
</code></pre></div>
<p>This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on sparse
inputs, cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and cross-attention
from dense to sparse inputs.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>embedding_dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>The channel dimension of the embeddings.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>The number of heads in the attention layers.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mlp_dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>The hidden dimension of the MLP block.</p>
</div>
</td>
<td>
<code>2048</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>activation</code>
</td>
<td>
<code><span title="typing.Type">Type</span>[<span title="torch.nn.Module">Module</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The activation function of the MLP block.</p>
</div>
</td>
<td>
<code><span title="torch.nn.ReLU">ReLU</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>attention_downsample_rate</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>The downsample rate for attention computations.</p>
</div>
</td>
<td>
<code>2</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>skip_first_layer_pe</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to skip the positional encoding in the first layer.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">SAM2TwoWayAttentionBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">dense_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">sparse_outputs</span><span class="p">,</span> <span class="n">dense_outputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">sparse_inputs</span><span class="p">,</span> <span class="n">dense_inputs</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>    <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">    Initializes a SAM2TwoWayAttentionBlock for performing self-attention and cross-attention in two directions.</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">    This block extends the TwoWayAttentionBlock and consists of four main components: self-attention on sparse</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">    inputs, cross-attention from sparse to dense inputs, an MLP block on sparse inputs, and cross-attention</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">    from dense to sparse inputs.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a><span class="sd">        embedding_dim (int): The channel dimension of the embeddings.</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a><span class="sd">        num_heads (int): The number of heads in the attention layers.</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a><span class="sd">        mlp_dim (int): The hidden dimension of the MLP block.</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a><span class="sd">        activation (Type[nn.Module]): The activation function of the MLP block.</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a><span class="sd">        attention_downsample_rate (int): The downsample rate for attention computations.</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a><span class="sd">        skip_first_layer_pe (bool): Whether to skip the positional encoding in the first layer.</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">        &gt;&gt;&gt; block = SAM2TwoWayAttentionBlock(embedding_dim=256, num_heads=8, mlp_dim=2048)</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="sd">        &gt;&gt;&gt; sparse_inputs = torch.randn(1, 100, 256)</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">        &gt;&gt;&gt; dense_inputs = torch.randn(1, 256, 32, 32)</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="sd">        &gt;&gt;&gt; sparse_outputs, dense_outputs = block(sparse_inputs, dense_inputs)</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a><span class="sd">    """</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="p">,</span> <span class="n">skip_first_layer_pe</span><span class="p">)</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">SAM2TwoWayTransformer</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.TwoWayTransformer" href="../transformer/#ultralytics.models.sam.modules.transformer.TwoWayTransformer">TwoWayTransformer</a></code></p>
<p>A Two-Way Transformer module for simultaneous attention to image and query points.</p>
<p>This class extends the TwoWayTransformer, implementing a specialized transformer decoder that attends to an
input image using queries with supplied positional embeddings. It is particularly useful for tasks like
object detection, image segmentation, and point cloud processing.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.depth">depth</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of layers in the transformer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.embedding_dim">embedding_dim</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Channel dimension for input embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.num_heads">num_heads</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of heads for multihead attention.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.mlp_dim">mlp_dim</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Internal channel dimension for the MLP block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.layers">layers</span></code></td>
<td>
<code><span title="torch.nn.ModuleList">ModuleList</span></code>
</td>
<td>
<div class="doc-md-description">
<p>List of SAM2TwoWayAttentionBlock layers comprising the transformer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.final_attn_token_to_image">final_attn_token_to_image</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.Attention" href="../transformer/#ultralytics.models.sam.modules.transformer.Attention">Attention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Final attention layer from queries to image.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.norm_final_attn">norm_final_attn</span></code></td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Layer normalization applied to final queries.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.SAM2TwoWayTransformer.forward" href="../transformer/#ultralytics.models.sam.modules.transformer.TwoWayTransformer.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Processes input image embeddings and query embeddings through the transformer.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">SAM2TwoWayTransformer</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">image_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">query_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">image_embedding</span><span class="p">,</span> <span class="n">query_embedding</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="go">torch.Size([1, 100, 256]) torch.Size([1, 256, 64, 64])</span>
</code></pre></div>
<p>This transformer decoder attends to an input image using queries with supplied positional embeddings.
It is designed for tasks like object detection, image segmentation, and point cloud processing.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>depth</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of layers in the transformer.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>embedding_dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Channel dimension for the input embeddings.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of heads for multihead attention. Must divide embedding_dim.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mlp_dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Channel dimension internal to the MLP block.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>activation</code>
</td>
<td>
<code><span title="typing.Type">Type</span>[<span title="torch.nn.Module">Module</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Activation function to use in the MLP block.</p>
</div>
</td>
<td>
<code><span title="torch.nn.ReLU">ReLU</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>attention_downsample_rate</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Downsampling rate for attention computations.</p>
</div>
</td>
<td>
<code>2</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">SAM2TwoWayTransformer</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="go">SAM2TwoWayTransformer(</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="go">  (layers): ModuleList(</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">    (0-4): 5 x SAM2TwoWayAttentionBlock(...)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="go">  )</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="go">  (final_attn_token_to_image): Attention(...)</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="go">  (norm_final_attn): LayerNorm(...)</span>
<a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="go">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-356" name="__codelineno-0-356"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>    <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a>    <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a>    <span class="n">activation</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a>    <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="sd">    Initializes a SAM2TwoWayTransformer instance.</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="sd">    This transformer decoder attends to an input image using queries with supplied positional embeddings.</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a><span class="sd">    It is designed for tasks like object detection, image segmentation, and point cloud processing.</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a><span class="sd">        depth (int): Number of layers in the transformer.</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">        embedding_dim (int): Channel dimension for the input embeddings.</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a><span class="sd">        num_heads (int): Number of heads for multihead attention. Must divide embedding_dim.</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="sd">        mlp_dim (int): Channel dimension internal to the MLP block.</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="sd">        activation (Type[nn.Module]): Activation function to use in the MLP block.</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a><span class="sd">        attention_downsample_rate (int): Downsampling rate for attention computations.</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">        &gt;&gt;&gt; transformer = SAM2TwoWayTransformer(depth=5, embedding_dim=256, num_heads=8, mlp_dim=2048)</span>
<a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">        &gt;&gt;&gt; transformer</span>
<a id="__codelineno-0-382" name="__codelineno-0-382"></a><span class="sd">        SAM2TwoWayTransformer(</span>
<a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">          (layers): ModuleList(</span>
<a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">            (0-4): 5 x SAM2TwoWayAttentionBlock(...)</span>
<a id="__codelineno-0-385" name="__codelineno-0-385"></a><span class="sd">          )</span>
<a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">          (final_attn_token_to_image): Attention(...)</span>
<a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">          (norm_final_attn): LayerNorm(...)</span>
<a id="__codelineno-0-388" name="__codelineno-0-388"></a><span class="sd">        )</span>
<a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">    """</span>
<a id="__codelineno-0-390" name="__codelineno-0-390"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="p">)</span>
<a id="__codelineno-0-391" name="__codelineno-0-391"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
<a id="__codelineno-0-392" name="__codelineno-0-392"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
<a id="__codelineno-0-393" name="__codelineno-0-393"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<a id="__codelineno-0-394" name="__codelineno-0-394"></a>            <span class="n">SAM2TwoWayAttentionBlock</span><span class="p">(</span>
<a id="__codelineno-0-395" name="__codelineno-0-395"></a>                <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
<a id="__codelineno-0-396" name="__codelineno-0-396"></a>                <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-397" name="__codelineno-0-397"></a>                <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
<a id="__codelineno-0-398" name="__codelineno-0-398"></a>                <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
<a id="__codelineno-0-399" name="__codelineno-0-399"></a>                <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">,</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>                <span class="n">skip_first_layer_pe</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>            <span class="p">)</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.RoPEAttention">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.RoPEAttention</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">RoPEAttention</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">rope_theta</span><span class="o">=</span><span class="mf">10000.0</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">rope_k_repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">feat_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="o">**</span><span class="n">kwargs</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.transformer.Attention" href="../transformer/#ultralytics.models.sam.modules.transformer.Attention">Attention</a></code></p>
<p>Implements rotary position encoding for attention mechanisms in transformer architectures.</p>
<p>This class extends the base Attention class by incorporating Rotary Position Encoding (RoPE) to enhance
the positional awareness of the attention mechanism.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.RoPEAttention.compute_cis">compute_cis</span></code></td>
<td>
<code>Callable</code>
</td>
<td>
<div class="doc-md-description">
<p>Function to compute axial complex numbers for rotary encoding.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.RoPEAttention.freqs_cis">freqs_cis</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Precomputed frequency tensor for rotary encoding.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.RoPEAttention.rope_k_repeat">rope_k_repeat</span></code></td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to repeat query RoPE to match key length for cross-attention to memories.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.RoPEAttention.forward" href="#ultralytics.models.sam.modules.blocks.RoPEAttention.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies rotary position encoding and computes attention between query, key, and value tensors.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">rope_attn</span> <span class="o">=</span> <span class="n">RoPEAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">rope_theta</span><span class="o">=</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">feat_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">rope_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="go">torch.Size([1, 1024, 256])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span>
<span class="normal"><a href="#__codelineno-0-437">437</a></span>
<span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span>
<span class="normal"><a href="#__codelineno-0-442">442</a></span>
<span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-430" name="__codelineno-0-430"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="n">rope_theta</span><span class="o">=</span><span class="mf">10000.0</span><span class="p">,</span>
<a id="__codelineno-0-434" name="__codelineno-0-434"></a>    <span class="n">rope_k_repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-435" name="__codelineno-0-435"></a>    <span class="n">feat_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>  <span class="c1"># [w, h] for stride 16 feats at 512 resolution</span>
<a id="__codelineno-0-436" name="__codelineno-0-436"></a>    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<a id="__codelineno-0-437" name="__codelineno-0-437"></a><span class="p">):</span>
<a id="__codelineno-0-438" name="__codelineno-0-438"></a><span class="w">    </span><span class="sd">"""Initializes RoPEAttention with rotary position encoding for enhanced positional awareness."""</span>
<a id="__codelineno-0-439" name="__codelineno-0-439"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-440" name="__codelineno-0-440"></a>
<a id="__codelineno-0-441" name="__codelineno-0-441"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">compute_cis</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">compute_axial_cis</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">rope_theta</span><span class="p">)</span>
<a id="__codelineno-0-442" name="__codelineno-0-442"></a>    <span class="n">freqs_cis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cis</span><span class="p">(</span><span class="n">end_x</span><span class="o">=</span><span class="n">feat_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end_y</span><span class="o">=</span><span class="n">feat_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-443" name="__codelineno-0-443"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span> <span class="o">=</span> <span class="n">freqs_cis</span>
<a id="__codelineno-0-444" name="__codelineno-0-444"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">rope_k_repeat</span> <span class="o">=</span> <span class="n">rope_k_repeat</span>  <span class="c1"># repeat q rope to match k length, needed for cross-attention to memories</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.RoPEAttention.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">num_k_exclude_rope</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Applies rotary position encoding and computes attention between query, key, and value tensors.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span>
<span class="normal"><a href="#__codelineno-0-457">457</a></span>
<span class="normal"><a href="#__codelineno-0-458">458</a></span>
<span class="normal"><a href="#__codelineno-0-459">459</a></span>
<span class="normal"><a href="#__codelineno-0-460">460</a></span>
<span class="normal"><a href="#__codelineno-0-461">461</a></span>
<span class="normal"><a href="#__codelineno-0-462">462</a></span>
<span class="normal"><a href="#__codelineno-0-463">463</a></span>
<span class="normal"><a href="#__codelineno-0-464">464</a></span>
<span class="normal"><a href="#__codelineno-0-465">465</a></span>
<span class="normal"><a href="#__codelineno-0-466">466</a></span>
<span class="normal"><a href="#__codelineno-0-467">467</a></span>
<span class="normal"><a href="#__codelineno-0-468">468</a></span>
<span class="normal"><a href="#__codelineno-0-469">469</a></span>
<span class="normal"><a href="#__codelineno-0-470">470</a></span>
<span class="normal"><a href="#__codelineno-0-471">471</a></span>
<span class="normal"><a href="#__codelineno-0-472">472</a></span>
<span class="normal"><a href="#__codelineno-0-473">473</a></span>
<span class="normal"><a href="#__codelineno-0-474">474</a></span>
<span class="normal"><a href="#__codelineno-0-475">475</a></span>
<span class="normal"><a href="#__codelineno-0-476">476</a></span>
<span class="normal"><a href="#__codelineno-0-477">477</a></span>
<span class="normal"><a href="#__codelineno-0-478">478</a></span>
<span class="normal"><a href="#__codelineno-0-479">479</a></span>
<span class="normal"><a href="#__codelineno-0-480">480</a></span>
<span class="normal"><a href="#__codelineno-0-481">481</a></span>
<span class="normal"><a href="#__codelineno-0-482">482</a></span>
<span class="normal"><a href="#__codelineno-0-483">483</a></span>
<span class="normal"><a href="#__codelineno-0-484">484</a></span>
<span class="normal"><a href="#__codelineno-0-485">485</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-446" name="__codelineno-0-446"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">num_k_exclude_rope</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-447" name="__codelineno-0-447"></a><span class="w">    </span><span class="sd">"""Applies rotary position encoding and computes attention between query, key, and value tensors."""</span>
<a id="__codelineno-0-448" name="__codelineno-0-448"></a>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<a id="__codelineno-0-449" name="__codelineno-0-449"></a>    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<a id="__codelineno-0-450" name="__codelineno-0-450"></a>    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-451" name="__codelineno-0-451"></a>
<a id="__codelineno-0-452" name="__codelineno-0-452"></a>    <span class="c1"># Separate into heads</span>
<a id="__codelineno-0-453" name="__codelineno-0-453"></a>    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-454" name="__codelineno-0-454"></a>    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-455" name="__codelineno-0-455"></a>    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-456" name="__codelineno-0-456"></a>
<a id="__codelineno-0-457" name="__codelineno-0-457"></a>    <span class="c1"># Apply rotary position encoding</span>
<a id="__codelineno-0-458" name="__codelineno-0-458"></a>    <span class="n">w</span> <span class="o">=</span> <span class="n">h</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-0-459" name="__codelineno-0-459"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-460" name="__codelineno-0-460"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-461" name="__codelineno-0-461"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cis</span><span class="p">(</span><span class="n">end_x</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">end_y</span><span class="o">=</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-462" name="__codelineno-0-462"></a>    <span class="k">if</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-463" name="__codelineno-0-463"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">rope_k_repeat</span>
<a id="__codelineno-0-464" name="__codelineno-0-464"></a>
<a id="__codelineno-0-465" name="__codelineno-0-465"></a>    <span class="n">num_k_rope</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_k_exclude_rope</span>
<a id="__codelineno-0-466" name="__codelineno-0-466"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">num_k_rope</span><span class="p">]</span> <span class="o">=</span> <span class="n">apply_rotary_enc</span><span class="p">(</span>
<a id="__codelineno-0-467" name="__codelineno-0-467"></a>        <span class="n">q</span><span class="p">,</span>
<a id="__codelineno-0-468" name="__codelineno-0-468"></a>        <span class="n">k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">num_k_rope</span><span class="p">],</span>
<a id="__codelineno-0-469" name="__codelineno-0-469"></a>        <span class="n">freqs_cis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">freqs_cis</span><span class="p">,</span>
<a id="__codelineno-0-470" name="__codelineno-0-470"></a>        <span class="n">repeat_freqs_k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rope_k_repeat</span><span class="p">,</span>
<a id="__codelineno-0-471" name="__codelineno-0-471"></a>    <span class="p">)</span>
<a id="__codelineno-0-472" name="__codelineno-0-472"></a>
<a id="__codelineno-0-473" name="__codelineno-0-473"></a>    <span class="c1"># Attention</span>
<a id="__codelineno-0-474" name="__codelineno-0-474"></a>    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c_per_head</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-475" name="__codelineno-0-475"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">q</span> <span class="o">@</span> <span class="n">k</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># B x N_heads x N_tokens x N_tokens</span>
<a id="__codelineno-0-476" name="__codelineno-0-476"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">c_per_head</span><span class="p">)</span>
<a id="__codelineno-0-477" name="__codelineno-0-477"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-478" name="__codelineno-0-478"></a>
<a id="__codelineno-0-479" name="__codelineno-0-479"></a>    <span class="c1"># Get output</span>
<a id="__codelineno-0-480" name="__codelineno-0-480"></a>    <span class="n">out</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">@</span> <span class="n">v</span>
<a id="__codelineno-0-481" name="__codelineno-0-481"></a>
<a id="__codelineno-0-482" name="__codelineno-0-482"></a>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recombine_heads</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<a id="__codelineno-0-483" name="__codelineno-0-483"></a>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<a id="__codelineno-0-484" name="__codelineno-0-484"></a>
<a id="__codelineno-0-485" name="__codelineno-0-485"></a>    <span class="k">return</span> <span class="n">out</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.MultiScaleAttention">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.MultiScaleAttention</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">MultiScaleAttention</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">q_pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>Implements multiscale self-attention with optional query pooling for efficient feature extraction.</p>
<p>This class provides a flexible implementation of multiscale attention, allowing for optional
downsampling of query features through pooling. It's designed to enhance the model's ability to
capture multiscale information in visual tasks.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.dim">dim</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Input dimension of the feature map.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.dim_out">dim_out</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Output dimension of the attention module.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.num_heads">num_heads</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.scale">scale</span></code></td>
<td>
<code>float</code>
</td>
<td>
<div class="doc-md-description">
<p>Scaling factor for dot-product attention.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.q_pool">q_pool</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional pooling module for query features.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.qkv">qkv</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for query, key, and value.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.proj">proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output projection.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies multiscale attention to the input tensor.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">msa</span> <span class="o">=</span> <span class="n">MultiScaleAttention</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">msa</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="go">torch.Size([1, 64, 64, 256])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-533">533</a></span>
<span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-533" name="__codelineno-0-533"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-534" name="__codelineno-0-534"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-535" name="__codelineno-0-535"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-536" name="__codelineno-0-536"></a>    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-537" name="__codelineno-0-537"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-538" name="__codelineno-0-538"></a>    <span class="n">q_pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-539" name="__codelineno-0-539"></a><span class="p">):</span>
<a id="__codelineno-0-540" name="__codelineno-0-540"></a><span class="w">    </span><span class="sd">"""Initializes multiscale attention with optional query pooling for efficient feature extraction."""</span>
<a id="__codelineno-0-541" name="__codelineno-0-541"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-542" name="__codelineno-0-542"></a>
<a id="__codelineno-0-543" name="__codelineno-0-543"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
<a id="__codelineno-0-544" name="__codelineno-0-544"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
<a id="__codelineno-0-545" name="__codelineno-0-545"></a>
<a id="__codelineno-0-546" name="__codelineno-0-546"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-547" name="__codelineno-0-547"></a>    <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim_out</span> <span class="o">//</span> <span class="n">num_heads</span>
<a id="__codelineno-0-548" name="__codelineno-0-548"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span><span class="o">**-</span><span class="mf">0.5</span>
<a id="__codelineno-0-549" name="__codelineno-0-549"></a>
<a id="__codelineno-0-550" name="__codelineno-0-550"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">q_pool</span> <span class="o">=</span> <span class="n">q_pool</span>
<a id="__codelineno-0-551" name="__codelineno-0-551"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-0-552" name="__codelineno-0-552"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.MultiScaleAttention.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Applies multiscale attention with optional query pooling to extract multiscale features.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span>
<span class="normal"><a href="#__codelineno-0-578">578</a></span>
<span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-554" name="__codelineno-0-554"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-555" name="__codelineno-0-555"></a><span class="w">    </span><span class="sd">"""Applies multiscale attention with optional query pooling to extract multiscale features."""</span>
<a id="__codelineno-0-556" name="__codelineno-0-556"></a>    <span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-557" name="__codelineno-0-557"></a>    <span class="c1"># qkv with shape (B, H * W, 3, nHead, C)</span>
<a id="__codelineno-0-558" name="__codelineno-0-558"></a>    <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-559" name="__codelineno-0-559"></a>    <span class="c1"># q, k, v with shape (B, H * W, nheads, C)</span>
<a id="__codelineno-0-560" name="__codelineno-0-560"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-561" name="__codelineno-0-561"></a>
<a id="__codelineno-0-562" name="__codelineno-0-562"></a>    <span class="c1"># Q pooling (for downsample at stage changes)</span>
<a id="__codelineno-0-563" name="__codelineno-0-563"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_pool</span><span class="p">:</span>
<a id="__codelineno-0-564" name="__codelineno-0-564"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">do_pool</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_pool</span><span class="p">)</span>
<a id="__codelineno-0-565" name="__codelineno-0-565"></a>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>  <span class="c1"># downsampled shape</span>
<a id="__codelineno-0-566" name="__codelineno-0-566"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-567" name="__codelineno-0-567"></a>
<a id="__codelineno-0-568" name="__codelineno-0-568"></a>    <span class="c1"># Torch's SDPA expects [B, nheads, H*W, C] so we transpose</span>
<a id="__codelineno-0-569" name="__codelineno-0-569"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span>
<a id="__codelineno-0-570" name="__codelineno-0-570"></a>        <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<a id="__codelineno-0-571" name="__codelineno-0-571"></a>        <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<a id="__codelineno-0-572" name="__codelineno-0-572"></a>        <span class="n">v</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<a id="__codelineno-0-573" name="__codelineno-0-573"></a>    <span class="p">)</span>
<a id="__codelineno-0-574" name="__codelineno-0-574"></a>    <span class="c1"># Transpose back</span>
<a id="__codelineno-0-575" name="__codelineno-0-575"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-576" name="__codelineno-0-576"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-577" name="__codelineno-0-577"></a>
<a id="__codelineno-0-578" name="__codelineno-0-578"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-579" name="__codelineno-0-579"></a>
<a id="__codelineno-0-580" name="__codelineno-0-580"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.MultiScaleBlock">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.MultiScaleBlock</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">MultiScaleBlock</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">drop_path</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"LayerNorm"</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">q_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">act_layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<a href="#__codelineno-0-10" id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<a href="#__codelineno-0-11" id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>A multiscale attention block with window partitioning and query pooling for efficient vision transformers.</p>
<p>This class implements a multiscale attention mechanism with optional window partitioning and downsampling,
designed for use in vision transformer architectures.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.dim">dim</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Input dimension of the block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.dim_out">dim_out</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Output dimension of the block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.norm1">norm1</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>First normalization layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.window_size">window_size</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Size of the window for partitioning.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.pool">pool</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Pooling layer for query downsampling.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.q_stride">q_stride</span></code></td>
<td>
<code><span title="typing.Tuple">Tuple</span>[int, int] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Stride for query pooling.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.attn">attn</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.MultiScaleAttention" href="#ultralytics.models.sam.modules.blocks.MultiScaleAttention">MultiScaleAttention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Multi-scale attention module.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.drop_path">drop_path</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Drop path layer for regularization.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.norm2">norm2</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Second normalization layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.mlp">mlp</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.nn.modules.MLP" href="../../../../nn/modules/transformer/#ultralytics.nn.modules.transformer.MLP">MLP</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Multi-layer perceptron module.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.proj">proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span> | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Projection layer for dimension mismatch.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward" href="#ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Processes input tensor through the multiscale block.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">MultiScaleBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 28, 28, 512])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-614" name="__codelineno-0-614"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a>    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a>    <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a>    <span class="n">drop_path</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>    <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"LayerNorm"</span><span class="p">,</span>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a>    <span class="n">q_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a>    <span class="n">act_layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a>    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="p">):</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a><span class="w">    </span><span class="sd">"""Initializes a multiscale attention block with window partitioning and optional query pooling."""</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">norm_layer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a>        <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">norm_layer</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">q_stride</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span><span class="p">:</span>
<a id="__codelineno-0-640" name="__codelineno-0-640"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">q_stride</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">q_stride</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-641" name="__codelineno-0-641"></a>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiScaleAttention</span><span class="p">(</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a>        <span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a>        <span class="n">dim_out</span><span class="p">,</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a>        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a>        <span class="n">q_pool</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">,</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a>    <span class="p">)</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">drop_path</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>
<a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim_out</span><span class="p">)</span>
<a id="__codelineno-0-651" name="__codelineno-0-651"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span>
<a id="__codelineno-0-652" name="__codelineno-0-652"></a>        <span class="n">dim_out</span><span class="p">,</span>
<a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="nb">int</span><span class="p">(</span><span class="n">dim_out</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">),</span>
<a id="__codelineno-0-654" name="__codelineno-0-654"></a>        <span class="n">dim_out</span><span class="p">,</span>
<a id="__codelineno-0-655" name="__codelineno-0-655"></a>        <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<a id="__codelineno-0-656" name="__codelineno-0-656"></a>        <span class="n">act</span><span class="o">=</span><span class="n">act_layer</span><span class="p">,</span>
<a id="__codelineno-0-657" name="__codelineno-0-657"></a>    <span class="p">)</span>
<a id="__codelineno-0-658" name="__codelineno-0-658"></a>
<a id="__codelineno-0-659" name="__codelineno-0-659"></a>    <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="n">dim_out</span><span class="p">:</span>
<a id="__codelineno-0-660" name="__codelineno-0-660"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.MultiScaleBlock.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Processes input through multiscale attention and MLP, with optional windowing and downsampling.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-662" name="__codelineno-0-662"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-663" name="__codelineno-0-663"></a><span class="w">    </span><span class="sd">"""Processes input through multiscale attention and MLP, with optional windowing and downsampling."""</span>
<a id="__codelineno-0-664" name="__codelineno-0-664"></a>    <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>  <span class="c1"># B, H, W, C</span>
<a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-666" name="__codelineno-0-666"></a>
<a id="__codelineno-0-667" name="__codelineno-0-667"></a>    <span class="c1"># Skip connection</span>
<a id="__codelineno-0-668" name="__codelineno-0-668"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_out</span><span class="p">:</span>
<a id="__codelineno-0-669" name="__codelineno-0-669"></a>        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">do_pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">)</span>
<a id="__codelineno-0-670" name="__codelineno-0-670"></a>
<a id="__codelineno-0-671" name="__codelineno-0-671"></a>    <span class="c1"># Window partition</span>
<a id="__codelineno-0-672" name="__codelineno-0-672"></a>    <span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span>
<a id="__codelineno-0-673" name="__codelineno-0-673"></a>    <span class="k">if</span> <span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-674" name="__codelineno-0-674"></a>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-675" name="__codelineno-0-675"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">pad_hw</span> <span class="o">=</span> <span class="n">window_partition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
<a id="__codelineno-0-676" name="__codelineno-0-676"></a>
<a id="__codelineno-0-677" name="__codelineno-0-677"></a>    <span class="c1"># Window Attention + Q Pooling (if stage change)</span>
<a id="__codelineno-0-678" name="__codelineno-0-678"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-679" name="__codelineno-0-679"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span><span class="p">:</span>
<a id="__codelineno-0-680" name="__codelineno-0-680"></a>        <span class="c1"># Shapes have changed due to Q pooling</span>
<a id="__codelineno-0-681" name="__codelineno-0-681"></a>        <span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-682" name="__codelineno-0-682"></a>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">shortcut</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<a id="__codelineno-0-683" name="__codelineno-0-683"></a>
<a id="__codelineno-0-684" name="__codelineno-0-684"></a>        <span class="n">pad_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">H</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
<a id="__codelineno-0-685" name="__codelineno-0-685"></a>        <span class="n">pad_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">W</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
<a id="__codelineno-0-686" name="__codelineno-0-686"></a>        <span class="n">pad_hw</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">+</span> <span class="n">pad_h</span><span class="p">,</span> <span class="n">W</span> <span class="o">+</span> <span class="n">pad_w</span><span class="p">)</span>
<a id="__codelineno-0-687" name="__codelineno-0-687"></a>
<a id="__codelineno-0-688" name="__codelineno-0-688"></a>    <span class="c1"># Reverse window partition</span>
<a id="__codelineno-0-689" name="__codelineno-0-689"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-690" name="__codelineno-0-690"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">window_unpartition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">pad_hw</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<a id="__codelineno-0-691" name="__codelineno-0-691"></a>
<a id="__codelineno-0-692" name="__codelineno-0-692"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">shortcut</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-693" name="__codelineno-0-693"></a>    <span class="c1"># MLP</span>
<a id="__codelineno-0-694" name="__codelineno-0-694"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<a id="__codelineno-0-695" name="__codelineno-0-695"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.PositionEmbeddingSine</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">PositionEmbeddingSine</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">num_pos_feats</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>A module for generating sinusoidal positional embeddings for 2D inputs like images.</p>
<p>This class implements sinusoidal position encoding for 2D spatial positions, which can be used in
transformer-based models for computer vision tasks.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.num_pos_feats">num_pos_feats</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of positional features (half of the embedding dimension).</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.temperature">temperature</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Temperature parameter for the sinusoidal functions.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.normalize">normalize</span></code></td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Whether to normalize the positional embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.scale">scale</span></code></td>
<td>
<code>float</code>
</td>
<td>
<div class="doc-md-description">
<p>Scaling factor for the embeddings when normalize is True.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.cache">cache</span></code></td>
<td>
<code>Dict</code>
</td>
<td>
<div class="doc-md-description">
<p>Cache for storing precomputed embeddings.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine._encode_xy">_encode_xy</span></code></td>
<td>
<div class="doc-md-description">
<p>Encodes 2D positions using sine and cosine functions.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes">encode_boxes</a></code></td>
<td>
<div class="doc-md-description">
<p>Encodes box coordinates and dimensions into positional embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points">encode_points</a></code></td>
<td>
<div class="doc-md-description">
<p>Encodes 2D point coordinates with sinusoidal positional embeddings.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Generates sinusoidal position embeddings for 2D inputs.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">PositionEmbeddingSine</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">pos_emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 256, 224, 224])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span>
<span class="normal"><a href="#__codelineno-0-729">729</a></span>
<span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span>
<span class="normal"><a href="#__codelineno-0-736">736</a></span>
<span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-726" name="__codelineno-0-726"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-727" name="__codelineno-0-727"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-728" name="__codelineno-0-728"></a>    <span class="n">num_pos_feats</span><span class="p">,</span>
<a id="__codelineno-0-729" name="__codelineno-0-729"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span>
<a id="__codelineno-0-730" name="__codelineno-0-730"></a>    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-731" name="__codelineno-0-731"></a>    <span class="n">scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-732" name="__codelineno-0-732"></a><span class="p">):</span>
<a id="__codelineno-0-733" name="__codelineno-0-733"></a><span class="w">    </span><span class="sd">"""Initializes sinusoidal position embeddings for 2D image inputs."""</span>
<a id="__codelineno-0-734" name="__codelineno-0-734"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="k">assert</span> <span class="n">num_pos_feats</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"Expecting even model width"</span>
<a id="__codelineno-0-736" name="__codelineno-0-736"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span> <span class="o">=</span> <span class="n">num_pos_feats</span> <span class="o">//</span> <span class="mi">2</span>
<a id="__codelineno-0-737" name="__codelineno-0-737"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
<a id="__codelineno-0-738" name="__codelineno-0-738"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
<a id="__codelineno-0-739" name="__codelineno-0-739"></a>    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">normalize</span><span class="p">:</span>
<a id="__codelineno-0-740" name="__codelineno-0-740"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"normalize should be True if scale is passed"</span><span class="p">)</span>
<a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-742" name="__codelineno-0-742"></a>        <span class="n">scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
<a id="__codelineno-0-743" name="__codelineno-0-743"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
<a id="__codelineno-0-744" name="__codelineno-0-744"></a>
<a id="__codelineno-0-745" name="__codelineno-0-745"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_boxes">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">encode_boxes</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">encode_boxes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Encodes box coordinates and dimensions into positional embeddings for detection.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-762" name="__codelineno-0-762"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="k">def</span> <span class="nf">encode_boxes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
<a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="w">    </span><span class="sd">"""Encodes box coordinates and dimensions into positional embeddings for detection."""</span>
<a id="__codelineno-0-765" name="__codelineno-0-765"></a>    <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_xy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<a id="__codelineno-0-766" name="__codelineno-0-766"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">,</span> <span class="n">h</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">w</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.encode_points">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">encode_points</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">encode_points</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Encodes 2D points with sinusoidal embeddings and appends labels.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-770" name="__codelineno-0-770"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-771" name="__codelineno-0-771"></a><span class="k">def</span> <span class="nf">encode_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<a id="__codelineno-0-772" name="__codelineno-0-772"></a><span class="w">    </span><span class="sd">"""Encodes 2D points with sinusoidal embeddings and appends labels."""</span>
<a id="__codelineno-0-773" name="__codelineno-0-773"></a>    <span class="p">(</span><span class="n">bx</span><span class="p">,</span> <span class="n">nx</span><span class="p">),</span> <span class="p">(</span><span class="n">by</span><span class="p">,</span> <span class="n">ny</span><span class="p">),</span> <span class="p">(</span><span class="n">bl</span><span class="p">,</span> <span class="n">nl</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-774" name="__codelineno-0-774"></a>    <span class="k">assert</span> <span class="n">bx</span> <span class="o">==</span> <span class="n">by</span> <span class="ow">and</span> <span class="n">nx</span> <span class="o">==</span> <span class="n">ny</span> <span class="ow">and</span> <span class="n">bx</span> <span class="o">==</span> <span class="n">bl</span> <span class="ow">and</span> <span class="n">nx</span> <span class="o">==</span> <span class="n">nl</span>
<a id="__codelineno-0-775" name="__codelineno-0-775"></a>    <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_xy</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<a id="__codelineno-0-776" name="__codelineno-0-776"></a>    <span class="n">pos_x</span><span class="p">,</span> <span class="n">pos_y</span> <span class="o">=</span> <span class="n">pos_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bx</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">pos_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">by</span><span class="p">,</span> <span class="n">ny</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-777" name="__codelineno-0-777"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">,</span> <span class="n">labels</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingSine.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Generates sinusoidal position embeddings for 2D inputs like images.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-779">779</a></span>
<span class="normal"><a href="#__codelineno-0-780">780</a></span>
<span class="normal"><a href="#__codelineno-0-781">781</a></span>
<span class="normal"><a href="#__codelineno-0-782">782</a></span>
<span class="normal"><a href="#__codelineno-0-783">783</a></span>
<span class="normal"><a href="#__codelineno-0-784">784</a></span>
<span class="normal"><a href="#__codelineno-0-785">785</a></span>
<span class="normal"><a href="#__codelineno-0-786">786</a></span>
<span class="normal"><a href="#__codelineno-0-787">787</a></span>
<span class="normal"><a href="#__codelineno-0-788">788</a></span>
<span class="normal"><a href="#__codelineno-0-789">789</a></span>
<span class="normal"><a href="#__codelineno-0-790">790</a></span>
<span class="normal"><a href="#__codelineno-0-791">791</a></span>
<span class="normal"><a href="#__codelineno-0-792">792</a></span>
<span class="normal"><a href="#__codelineno-0-793">793</a></span>
<span class="normal"><a href="#__codelineno-0-794">794</a></span>
<span class="normal"><a href="#__codelineno-0-795">795</a></span>
<span class="normal"><a href="#__codelineno-0-796">796</a></span>
<span class="normal"><a href="#__codelineno-0-797">797</a></span>
<span class="normal"><a href="#__codelineno-0-798">798</a></span>
<span class="normal"><a href="#__codelineno-0-799">799</a></span>
<span class="normal"><a href="#__codelineno-0-800">800</a></span>
<span class="normal"><a href="#__codelineno-0-801">801</a></span>
<span class="normal"><a href="#__codelineno-0-802">802</a></span>
<span class="normal"><a href="#__codelineno-0-803">803</a></span>
<span class="normal"><a href="#__codelineno-0-804">804</a></span>
<span class="normal"><a href="#__codelineno-0-805">805</a></span>
<span class="normal"><a href="#__codelineno-0-806">806</a></span>
<span class="normal"><a href="#__codelineno-0-807">807</a></span>
<span class="normal"><a href="#__codelineno-0-808">808</a></span>
<span class="normal"><a href="#__codelineno-0-809">809</a></span>
<span class="normal"><a href="#__codelineno-0-810">810</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-779" name="__codelineno-0-779"></a><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-780" name="__codelineno-0-780"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-781" name="__codelineno-0-781"></a><span class="w">    </span><span class="sd">"""Generates sinusoidal position embeddings for 2D inputs like images."""</span>
<a id="__codelineno-0-782" name="__codelineno-0-782"></a>    <span class="n">cache_key</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-783" name="__codelineno-0-783"></a>    <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
<a id="__codelineno-0-784" name="__codelineno-0-784"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">][</span><span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-785" name="__codelineno-0-785"></a>    <span class="n">y_embed</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-786" name="__codelineno-0-786"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-787" name="__codelineno-0-787"></a>        <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-788" name="__codelineno-0-788"></a>        <span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<a id="__codelineno-0-789" name="__codelineno-0-789"></a>    <span class="p">)</span>
<a id="__codelineno-0-790" name="__codelineno-0-790"></a>    <span class="n">x_embed</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-791" name="__codelineno-0-791"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-792" name="__codelineno-0-792"></a>        <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-793" name="__codelineno-0-793"></a>        <span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-794" name="__codelineno-0-794"></a>    <span class="p">)</span>
<a id="__codelineno-0-795" name="__codelineno-0-795"></a>
<a id="__codelineno-0-796" name="__codelineno-0-796"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
<a id="__codelineno-0-797" name="__codelineno-0-797"></a>        <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
<a id="__codelineno-0-798" name="__codelineno-0-798"></a>        <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y_embed</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_embed</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<a id="__codelineno-0-799" name="__codelineno-0-799"></a>        <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x_embed</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<a id="__codelineno-0-800" name="__codelineno-0-800"></a>
<a id="__codelineno-0-801" name="__codelineno-0-801"></a>    <span class="n">dim_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-802" name="__codelineno-0-802"></a>    <span class="n">dim_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_t</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">)</span>
<a id="__codelineno-0-803" name="__codelineno-0-803"></a>
<a id="__codelineno-0-804" name="__codelineno-0-804"></a>    <span class="n">pos_x</span> <span class="o">=</span> <span class="n">x_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
<a id="__codelineno-0-805" name="__codelineno-0-805"></a>    <span class="n">pos_y</span> <span class="o">=</span> <span class="n">y_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
<a id="__codelineno-0-806" name="__codelineno-0-806"></a>    <span class="n">pos_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos_x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos_x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-0-807" name="__codelineno-0-807"></a>    <span class="n">pos_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos_y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos_y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-0-808" name="__codelineno-0-808"></a>    <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-809" name="__codelineno-0-809"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-810" name="__codelineno-0-810"></a>    <span class="k">return</span> <span class="n">pos</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">PositionEmbeddingRandom</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>Positional encoding using random spatial frequencies.</p>
<p>This class generates positional embeddings for input coordinates using random spatial frequencies. It is
particularly useful for transformer-based models that require position information.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.positional_encoding_gaussian_matrix">positional_encoding_gaussian_matrix</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>A buffer containing random values for encoding.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom._pe_encoding">_pe_encoding</span></code></td>
<td>
<div class="doc-md-description">
<p>Positionally encodes points that are normalized to [0,1].</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Generates positional encoding for a grid of the specified size.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords" href="#ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords">forward_with_coords</a></code></td>
<td>
<div class="doc-md-description">
<p>Positionally encodes points that are not normalized to [0,1].</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">pe</span> <span class="o">=</span> <span class="n">PositionEmbeddingRandom</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">encoding</span> <span class="o">=</span> <span class="n">pe</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([128, 32, 32])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-836">836</a></span>
<span class="normal"><a href="#__codelineno-0-837">837</a></span>
<span class="normal"><a href="#__codelineno-0-838">838</a></span>
<span class="normal"><a href="#__codelineno-0-839">839</a></span>
<span class="normal"><a href="#__codelineno-0-840">840</a></span>
<span class="normal"><a href="#__codelineno-0-841">841</a></span>
<span class="normal"><a href="#__codelineno-0-842">842</a></span>
<span class="normal"><a href="#__codelineno-0-843">843</a></span>
<span class="normal"><a href="#__codelineno-0-844">844</a></span>
<span class="normal"><a href="#__codelineno-0-845">845</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-836" name="__codelineno-0-836"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-837" name="__codelineno-0-837"></a><span class="w">    </span><span class="sd">"""Initializes random spatial frequency position embedding for transformers."""</span>
<a id="__codelineno-0-838" name="__codelineno-0-838"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-839" name="__codelineno-0-839"></a>    <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">scale</span> <span class="o">&lt;=</span> <span class="mf">0.0</span><span class="p">:</span>
<a id="__codelineno-0-840" name="__codelineno-0-840"></a>        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
<a id="__codelineno-0-841" name="__codelineno-0-841"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"positional_encoding_gaussian_matrix"</span><span class="p">,</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">)))</span>
<a id="__codelineno-0-842" name="__codelineno-0-842"></a>
<a id="__codelineno-0-843" name="__codelineno-0-843"></a>    <span class="c1"># Set non-deterministic for forward() error 'cumsum_cuda_kernel does not have a deterministic implementation'</span>
<a id="__codelineno-0-844" name="__codelineno-0-844"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-845" name="__codelineno-0-845"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Generates positional encoding for a grid using random spatial frequencies.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-856">856</a></span>
<span class="normal"><a href="#__codelineno-0-857">857</a></span>
<span class="normal"><a href="#__codelineno-0-858">858</a></span>
<span class="normal"><a href="#__codelineno-0-859">859</a></span>
<span class="normal"><a href="#__codelineno-0-860">860</a></span>
<span class="normal"><a href="#__codelineno-0-861">861</a></span>
<span class="normal"><a href="#__codelineno-0-862">862</a></span>
<span class="normal"><a href="#__codelineno-0-863">863</a></span>
<span class="normal"><a href="#__codelineno-0-864">864</a></span>
<span class="normal"><a href="#__codelineno-0-865">865</a></span>
<span class="normal"><a href="#__codelineno-0-866">866</a></span>
<span class="normal"><a href="#__codelineno-0-867">867</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-856" name="__codelineno-0-856"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-857" name="__codelineno-0-857"></a><span class="w">    </span><span class="sd">"""Generates positional encoding for a grid using random spatial frequencies."""</span>
<a id="__codelineno-0-858" name="__codelineno-0-858"></a>    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">size</span>
<a id="__codelineno-0-859" name="__codelineno-0-859"></a>    <span class="n">device</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding_gaussian_matrix</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-860" name="__codelineno-0-860"></a>    <span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a id="__codelineno-0-861" name="__codelineno-0-861"></a>    <span class="n">y_embed</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<a id="__codelineno-0-862" name="__codelineno-0-862"></a>    <span class="n">x_embed</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<a id="__codelineno-0-863" name="__codelineno-0-863"></a>    <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y_embed</span> <span class="o">/</span> <span class="n">h</span>
<a id="__codelineno-0-864" name="__codelineno-0-864"></a>    <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x_embed</span> <span class="o">/</span> <span class="n">w</span>
<a id="__codelineno-0-865" name="__codelineno-0-865"></a>
<a id="__codelineno-0-866" name="__codelineno-0-866"></a>    <span class="n">pe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pe_encoding</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x_embed</span><span class="p">,</span> <span class="n">y_embed</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-867" name="__codelineno-0-867"></a>    <span class="k">return</span> <span class="n">pe</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># C x H x W</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PositionEmbeddingRandom.forward_with_coords">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward_with_coords</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward_with_coords</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">coords_input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">image_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Positionally encodes input coordinates, normalizing them to [0,1] based on the given image size.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-869">869</a></span>
<span class="normal"><a href="#__codelineno-0-870">870</a></span>
<span class="normal"><a href="#__codelineno-0-871">871</a></span>
<span class="normal"><a href="#__codelineno-0-872">872</a></span>
<span class="normal"><a href="#__codelineno-0-873">873</a></span>
<span class="normal"><a href="#__codelineno-0-874">874</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-869" name="__codelineno-0-869"></a><span class="k">def</span> <span class="nf">forward_with_coords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords_input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">image_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-870" name="__codelineno-0-870"></a><span class="w">    </span><span class="sd">"""Positionally encodes input coordinates, normalizing them to [0,1] based on the given image size."""</span>
<a id="__codelineno-0-871" name="__codelineno-0-871"></a>    <span class="n">coords</span> <span class="o">=</span> <span class="n">coords_input</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<a id="__codelineno-0-872" name="__codelineno-0-872"></a>    <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-873" name="__codelineno-0-873"></a>    <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">coords</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-874" name="__codelineno-0-874"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pe_encoding</span><span class="p">(</span><span class="n">coords</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span>  <span class="c1"># B x N x C</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.Block">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.Block</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">Block</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">act_layer</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a href="#__codelineno-0-10" id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<a href="#__codelineno-0-11" id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="n">input_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a href="#__codelineno-0-12" id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>Transformer block with support for window attention and residual propagation.</p>
<p>This class implements a transformer block that can use either global or windowed self-attention,
followed by a feed-forward network. It supports relative positional embeddings and is designed
for use in vision transformer architectures.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Block.norm1">norm1</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>First normalization layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Block.attn">attn</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.REAttention" href="#ultralytics.models.sam.modules.blocks.REAttention">REAttention</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Self-attention layer with optional relative positional encoding.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Block.norm2">norm2</span></code></td>
<td>
<code><span title="torch.nn.Module">Module</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Second normalization layer.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Block.mlp">mlp</span></code></td>
<td>
<code><a class="autorefs autorefs-internal" title="ultralytics.nn.modules.MLPBlock" href="../../../../nn/modules/transformer/#ultralytics.nn.modules.transformer.MLPBlock">MLPBlock</a></code>
</td>
<td>
<div class="doc-md-description">
<p>Multi-layer perceptron block.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.Block.window_size">window_size</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Size of attention window. If 0, global attention is used.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.Block.forward" href="#ultralytics.models.sam.modules.blocks.Block.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Processes input through the transformer block.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="go">torch.Size([1, 56, 56, 256])</span>
</code></pre></div>
<p>This constructor sets up a transformer block that can use either global or windowed self-attention,
followed by a feed-forward network. It supports relative positional embeddings and is designed
for use in vision transformer architectures.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of input channels.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads in the self-attention layer.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mlp_ratio</code>
</td>
<td>
<code>float</code>
</td>
<td>
<div class="doc-md-description">
<p>Ratio of mlp hidden dimension to embedding dimension.</p>
</div>
</td>
<td>
<code>4.0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>qkv_bias</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If True, adds a learnable bias to query, key, value projections.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>norm_layer</code>
</td>
<td>
<code><span title="typing.Type">Type</span>[<span title="torch.nn.Module">Module</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Type of normalization layer to use.</p>
</div>
</td>
<td>
<code><span title="torch.nn.LayerNorm">LayerNorm</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>act_layer</code>
</td>
<td>
<code><span title="typing.Type">Type</span>[<span title="torch.nn.Module">Module</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Type of activation function to use in the MLP block.</p>
</div>
</td>
<td>
<code><span title="torch.nn.GELU">GELU</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>use_rel_pos</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If True, uses relative positional embeddings in attention.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>rel_pos_zero_init</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If True, initializes relative positional parameters to zero.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>window_size</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Size of attention window. If 0, uses global attention.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>input_size</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Tuple">Tuple</span>[int, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Input resolution for calculating relative positional parameter size.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">block</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 56, 56, 256])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-904">904</a></span>
<span class="normal"><a href="#__codelineno-0-905">905</a></span>
<span class="normal"><a href="#__codelineno-0-906">906</a></span>
<span class="normal"><a href="#__codelineno-0-907">907</a></span>
<span class="normal"><a href="#__codelineno-0-908">908</a></span>
<span class="normal"><a href="#__codelineno-0-909">909</a></span>
<span class="normal"><a href="#__codelineno-0-910">910</a></span>
<span class="normal"><a href="#__codelineno-0-911">911</a></span>
<span class="normal"><a href="#__codelineno-0-912">912</a></span>
<span class="normal"><a href="#__codelineno-0-913">913</a></span>
<span class="normal"><a href="#__codelineno-0-914">914</a></span>
<span class="normal"><a href="#__codelineno-0-915">915</a></span>
<span class="normal"><a href="#__codelineno-0-916">916</a></span>
<span class="normal"><a href="#__codelineno-0-917">917</a></span>
<span class="normal"><a href="#__codelineno-0-918">918</a></span>
<span class="normal"><a href="#__codelineno-0-919">919</a></span>
<span class="normal"><a href="#__codelineno-0-920">920</a></span>
<span class="normal"><a href="#__codelineno-0-921">921</a></span>
<span class="normal"><a href="#__codelineno-0-922">922</a></span>
<span class="normal"><a href="#__codelineno-0-923">923</a></span>
<span class="normal"><a href="#__codelineno-0-924">924</a></span>
<span class="normal"><a href="#__codelineno-0-925">925</a></span>
<span class="normal"><a href="#__codelineno-0-926">926</a></span>
<span class="normal"><a href="#__codelineno-0-927">927</a></span>
<span class="normal"><a href="#__codelineno-0-928">928</a></span>
<span class="normal"><a href="#__codelineno-0-929">929</a></span>
<span class="normal"><a href="#__codelineno-0-930">930</a></span>
<span class="normal"><a href="#__codelineno-0-931">931</a></span>
<span class="normal"><a href="#__codelineno-0-932">932</a></span>
<span class="normal"><a href="#__codelineno-0-933">933</a></span>
<span class="normal"><a href="#__codelineno-0-934">934</a></span>
<span class="normal"><a href="#__codelineno-0-935">935</a></span>
<span class="normal"><a href="#__codelineno-0-936">936</a></span>
<span class="normal"><a href="#__codelineno-0-937">937</a></span>
<span class="normal"><a href="#__codelineno-0-938">938</a></span>
<span class="normal"><a href="#__codelineno-0-939">939</a></span>
<span class="normal"><a href="#__codelineno-0-940">940</a></span>
<span class="normal"><a href="#__codelineno-0-941">941</a></span>
<span class="normal"><a href="#__codelineno-0-942">942</a></span>
<span class="normal"><a href="#__codelineno-0-943">943</a></span>
<span class="normal"><a href="#__codelineno-0-944">944</a></span>
<span class="normal"><a href="#__codelineno-0-945">945</a></span>
<span class="normal"><a href="#__codelineno-0-946">946</a></span>
<span class="normal"><a href="#__codelineno-0-947">947</a></span>
<span class="normal"><a href="#__codelineno-0-948">948</a></span>
<span class="normal"><a href="#__codelineno-0-949">949</a></span>
<span class="normal"><a href="#__codelineno-0-950">950</a></span>
<span class="normal"><a href="#__codelineno-0-951">951</a></span>
<span class="normal"><a href="#__codelineno-0-952">952</a></span>
<span class="normal"><a href="#__codelineno-0-953">953</a></span>
<span class="normal"><a href="#__codelineno-0-954">954</a></span>
<span class="normal"><a href="#__codelineno-0-955">955</a></span>
<span class="normal"><a href="#__codelineno-0-956">956</a></span>
<span class="normal"><a href="#__codelineno-0-957">957</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-904" name="__codelineno-0-904"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-905" name="__codelineno-0-905"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-906" name="__codelineno-0-906"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-907" name="__codelineno-0-907"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-908" name="__codelineno-0-908"></a>    <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
<a id="__codelineno-0-909" name="__codelineno-0-909"></a>    <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-910" name="__codelineno-0-910"></a>    <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
<a id="__codelineno-0-911" name="__codelineno-0-911"></a>    <span class="n">act_layer</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
<a id="__codelineno-0-912" name="__codelineno-0-912"></a>    <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-913" name="__codelineno-0-913"></a>    <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-914" name="__codelineno-0-914"></a>    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-915" name="__codelineno-0-915"></a>    <span class="n">input_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-916" name="__codelineno-0-916"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-917" name="__codelineno-0-917"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-918" name="__codelineno-0-918"></a><span class="sd">    Initializes a transformer block with optional window attention and relative positional embeddings.</span>
<a id="__codelineno-0-919" name="__codelineno-0-919"></a>
<a id="__codelineno-0-920" name="__codelineno-0-920"></a><span class="sd">    This constructor sets up a transformer block that can use either global or windowed self-attention,</span>
<a id="__codelineno-0-921" name="__codelineno-0-921"></a><span class="sd">    followed by a feed-forward network. It supports relative positional embeddings and is designed</span>
<a id="__codelineno-0-922" name="__codelineno-0-922"></a><span class="sd">    for use in vision transformer architectures.</span>
<a id="__codelineno-0-923" name="__codelineno-0-923"></a>
<a id="__codelineno-0-924" name="__codelineno-0-924"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-925" name="__codelineno-0-925"></a><span class="sd">        dim (int): Number of input channels.</span>
<a id="__codelineno-0-926" name="__codelineno-0-926"></a><span class="sd">        num_heads (int): Number of attention heads in the self-attention layer.</span>
<a id="__codelineno-0-927" name="__codelineno-0-927"></a><span class="sd">        mlp_ratio (float): Ratio of mlp hidden dimension to embedding dimension.</span>
<a id="__codelineno-0-928" name="__codelineno-0-928"></a><span class="sd">        qkv_bias (bool): If True, adds a learnable bias to query, key, value projections.</span>
<a id="__codelineno-0-929" name="__codelineno-0-929"></a><span class="sd">        norm_layer (Type[nn.Module]): Type of normalization layer to use.</span>
<a id="__codelineno-0-930" name="__codelineno-0-930"></a><span class="sd">        act_layer (Type[nn.Module]): Type of activation function to use in the MLP block.</span>
<a id="__codelineno-0-931" name="__codelineno-0-931"></a><span class="sd">        use_rel_pos (bool): If True, uses relative positional embeddings in attention.</span>
<a id="__codelineno-0-932" name="__codelineno-0-932"></a><span class="sd">        rel_pos_zero_init (bool): If True, initializes relative positional parameters to zero.</span>
<a id="__codelineno-0-933" name="__codelineno-0-933"></a><span class="sd">        window_size (int): Size of attention window. If 0, uses global attention.</span>
<a id="__codelineno-0-934" name="__codelineno-0-934"></a><span class="sd">        input_size (Optional[Tuple[int, int]]): Input resolution for calculating relative positional parameter size.</span>
<a id="__codelineno-0-935" name="__codelineno-0-935"></a>
<a id="__codelineno-0-936" name="__codelineno-0-936"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-937" name="__codelineno-0-937"></a><span class="sd">        &gt;&gt;&gt; block = Block(dim=256, num_heads=8, window_size=7)</span>
<a id="__codelineno-0-938" name="__codelineno-0-938"></a><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 56, 56, 256)</span>
<a id="__codelineno-0-939" name="__codelineno-0-939"></a><span class="sd">        &gt;&gt;&gt; output = block(x)</span>
<a id="__codelineno-0-940" name="__codelineno-0-940"></a><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<a id="__codelineno-0-941" name="__codelineno-0-941"></a><span class="sd">        torch.Size([1, 56, 56, 256])</span>
<a id="__codelineno-0-942" name="__codelineno-0-942"></a><span class="sd">    """</span>
<a id="__codelineno-0-943" name="__codelineno-0-943"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-944" name="__codelineno-0-944"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-945" name="__codelineno-0-945"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">REAttention</span><span class="p">(</span>
<a id="__codelineno-0-946" name="__codelineno-0-946"></a>        <span class="n">dim</span><span class="p">,</span>
<a id="__codelineno-0-947" name="__codelineno-0-947"></a>        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-948" name="__codelineno-0-948"></a>        <span class="n">qkv_bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">,</span>
<a id="__codelineno-0-949" name="__codelineno-0-949"></a>        <span class="n">use_rel_pos</span><span class="o">=</span><span class="n">use_rel_pos</span><span class="p">,</span>
<a id="__codelineno-0-950" name="__codelineno-0-950"></a>        <span class="n">rel_pos_zero_init</span><span class="o">=</span><span class="n">rel_pos_zero_init</span><span class="p">,</span>
<a id="__codelineno-0-951" name="__codelineno-0-951"></a>        <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span> <span class="k">if</span> <span class="n">window_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">),</span>
<a id="__codelineno-0-952" name="__codelineno-0-952"></a>    <span class="p">)</span>
<a id="__codelineno-0-953" name="__codelineno-0-953"></a>
<a id="__codelineno-0-954" name="__codelineno-0-954"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-955" name="__codelineno-0-955"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPBlock</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">),</span> <span class="n">act</span><span class="o">=</span><span class="n">act_layer</span><span class="p">)</span>
<a id="__codelineno-0-956" name="__codelineno-0-956"></a>
<a id="__codelineno-0-957" name="__codelineno-0-957"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.Block.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Processes input through transformer block with optional windowed self-attention and residual connection.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-959">959</a></span>
<span class="normal"><a href="#__codelineno-0-960">960</a></span>
<span class="normal"><a href="#__codelineno-0-961">961</a></span>
<span class="normal"><a href="#__codelineno-0-962">962</a></span>
<span class="normal"><a href="#__codelineno-0-963">963</a></span>
<span class="normal"><a href="#__codelineno-0-964">964</a></span>
<span class="normal"><a href="#__codelineno-0-965">965</a></span>
<span class="normal"><a href="#__codelineno-0-966">966</a></span>
<span class="normal"><a href="#__codelineno-0-967">967</a></span>
<span class="normal"><a href="#__codelineno-0-968">968</a></span>
<span class="normal"><a href="#__codelineno-0-969">969</a></span>
<span class="normal"><a href="#__codelineno-0-970">970</a></span>
<span class="normal"><a href="#__codelineno-0-971">971</a></span>
<span class="normal"><a href="#__codelineno-0-972">972</a></span>
<span class="normal"><a href="#__codelineno-0-973">973</a></span>
<span class="normal"><a href="#__codelineno-0-974">974</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-959" name="__codelineno-0-959"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-960" name="__codelineno-0-960"></a><span class="w">    </span><span class="sd">"""Processes input through transformer block with optional windowed self-attention and residual connection."""</span>
<a id="__codelineno-0-961" name="__codelineno-0-961"></a>    <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
<a id="__codelineno-0-962" name="__codelineno-0-962"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-963" name="__codelineno-0-963"></a>    <span class="c1"># Window partition</span>
<a id="__codelineno-0-964" name="__codelineno-0-964"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-965" name="__codelineno-0-965"></a>        <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-966" name="__codelineno-0-966"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">pad_hw</span> <span class="o">=</span> <span class="n">window_partition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">)</span>
<a id="__codelineno-0-967" name="__codelineno-0-967"></a>
<a id="__codelineno-0-968" name="__codelineno-0-968"></a>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-969" name="__codelineno-0-969"></a>    <span class="c1"># Reverse window partition</span>
<a id="__codelineno-0-970" name="__codelineno-0-970"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-971" name="__codelineno-0-971"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">window_unpartition</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">,</span> <span class="n">pad_hw</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<a id="__codelineno-0-972" name="__codelineno-0-972"></a>
<a id="__codelineno-0-973" name="__codelineno-0-973"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">shortcut</span> <span class="o">+</span> <span class="n">x</span>
<a id="__codelineno-0-974" name="__codelineno-0-974"></a>    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.REAttention">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.REAttention</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">REAttention</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">input_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>Rotary Embedding Attention module for efficient self-attention in transformer architectures.</p>
<p>This class implements a multi-head attention mechanism with rotary positional embeddings, designed
for use in vision transformer models. It supports optional query pooling and window partitioning
for efficient processing of large inputs.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.compute_cis">compute_cis</span></code></td>
<td>
<code>Callable</code>
</td>
<td>
<div class="doc-md-description">
<p>Function to compute axial complex numbers for rotary encoding.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.freqs_cis">freqs_cis</span></code></td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Precomputed frequency tensor for rotary encoding.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.rope_k_repeat">rope_k_repeat</span></code></td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to repeat query RoPE to match key length for cross-attention to memories.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.q_proj">q_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for query.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.k_proj">k_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for key.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.v_proj">v_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Linear projection for value.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.out_proj">out_proj</span></code></td>
<td>
<code><span title="torch.nn.Linear">Linear</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output projection.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.num_heads">num_heads</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads.</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.REAttention.internal_dim">internal_dim</span></code></td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Internal dimension for attention computation.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.REAttention.forward" href="#ultralytics.models.sam.modules.blocks.REAttention.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies rotary position encoding and computes attention between query, key, and value tensors.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">rope_attn</span> <span class="o">=</span> <span class="n">REAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">rope_theta</span><span class="o">=</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">feat_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">rope_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="go">torch.Size([1, 1024, 256])</span>
</code></pre></div>
<p>This module implements multi-head attention with optional relative positional encodings, designed
specifically for vision tasks in transformer models.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of input channels.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>num_heads</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of attention heads. Default is 8.</p>
</div>
</td>
<td>
<code>8</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>qkv_bias</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If True, adds a learnable bias to query, key, value projections. Default is True.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>use_rel_pos</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If True, uses relative positional encodings. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>rel_pos_zero_init</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If True, initializes relative positional parameters to zero. Default is True.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>input_size</code>
</td>
<td>
<code><span title="typing.Tuple">Tuple</span>[int, int] | None</code>
</td>
<td>
<div class="doc-md-description">
<p>Input resolution for calculating relative positional parameter size.
Required if use_rel_pos is True. Default is None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">attention</span> <span class="o">=</span> <span class="n">REAttention</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 32, 32, 256])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span>
<span class="normal"><a href="#__codelineno-0-1017">1017</a></span>
<span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1009" name="__codelineno-0-1009"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1011" name="__codelineno-0-1011"></a>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-1012" name="__codelineno-0-1012"></a>    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
<a id="__codelineno-0-1013" name="__codelineno-0-1013"></a>    <span class="n">qkv_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-1014" name="__codelineno-0-1014"></a>    <span class="n">use_rel_pos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>    <span class="n">rel_pos_zero_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-1016" name="__codelineno-0-1016"></a>    <span class="n">input_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1017" name="__codelineno-0-1017"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1018" name="__codelineno-0-1018"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-1019" name="__codelineno-0-1019"></a><span class="sd">    Initializes a Relative Position Attention module for transformer-based architectures.</span>
<a id="__codelineno-0-1020" name="__codelineno-0-1020"></a>
<a id="__codelineno-0-1021" name="__codelineno-0-1021"></a><span class="sd">    This module implements multi-head attention with optional relative positional encodings, designed</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022"></a><span class="sd">    specifically for vision tasks in transformer models.</span>
<a id="__codelineno-0-1023" name="__codelineno-0-1023"></a>
<a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">        dim (int): Number of input channels.</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">        num_heads (int): Number of attention heads. Default is 8.</span>
<a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">        qkv_bias (bool): If True, adds a learnable bias to query, key, value projections. Default is True.</span>
<a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">        use_rel_pos (bool): If True, uses relative positional encodings. Default is False.</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029"></a><span class="sd">        rel_pos_zero_init (bool): If True, initializes relative positional parameters to zero. Default is True.</span>
<a id="__codelineno-0-1030" name="__codelineno-0-1030"></a><span class="sd">        input_size (Tuple[int, int] | None): Input resolution for calculating relative positional parameter size.</span>
<a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">            Required if use_rel_pos is True. Default is None.</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032"></a>
<a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">        &gt;&gt;&gt; attention = REAttention(dim=256, num_heads=8, input_size=(32, 32))</span>
<a id="__codelineno-0-1035" name="__codelineno-0-1035"></a><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 32, 32, 256)</span>
<a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">        &gt;&gt;&gt; output = attention(x)</span>
<a id="__codelineno-0-1037" name="__codelineno-0-1037"></a><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">        torch.Size([1, 32, 32, 256])</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">    """</span>
<a id="__codelineno-0-1040" name="__codelineno-0-1040"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-1042" name="__codelineno-0-1042"></a>    <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_heads</span>
<a id="__codelineno-0-1043" name="__codelineno-0-1043"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span><span class="o">**-</span><span class="mf">0.5</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044"></a>
<a id="__codelineno-0-1045" name="__codelineno-0-1045"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
<a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
<a id="__codelineno-0-1047" name="__codelineno-0-1047"></a>
<a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span> <span class="o">=</span> <span class="n">use_rel_pos</span>
<a id="__codelineno-0-1049" name="__codelineno-0-1049"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span><span class="p">:</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050"></a>        <span class="k">assert</span> <span class="n">input_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">"Input size must be provided if using relative positional encoding."</span>
<a id="__codelineno-0-1051" name="__codelineno-0-1051"></a>        <span class="c1"># Initialize relative positional embeddings</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">))</span>
<a id="__codelineno-0-1053" name="__codelineno-0-1053"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.REAttention.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Applies multi-head attention with optional relative positional encoding to input tensor.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056"></a><span class="w">    </span><span class="sd">"""Applies multi-head attention with optional relative positional encoding to input tensor."""</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>    <span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>    <span class="c1"># qkv with shape (3, B, nHead, H * W, C)</span>
<a id="__codelineno-0-1059" name="__codelineno-0-1059"></a>    <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060"></a>    <span class="c1"># q, k, v with shape (B * nHead, H * W, C)</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">B</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>
<a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">@</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1064" name="__codelineno-0-1064"></a>
<a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span><span class="p">:</span>
<a id="__codelineno-0-1066" name="__codelineno-0-1066"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">add_decomposed_rel_pos</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_w</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067"></a>
<a id="__codelineno-0-1068" name="__codelineno-0-1068"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1069" name="__codelineno-0-1069"></a>    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn</span> <span class="o">@</span> <span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PatchEmbed">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <span class="doc doc-object-name doc-class-name">ultralytics.models.sam.modules.blocks.PatchEmbed</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">PatchEmbed</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">padding</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">in_chans</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="p">)</span>
</code></pre></div>
<div class="doc doc-contents first">
<p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>
<p>Image to Patch Embedding module for vision transformer architectures.</p>
<p>This module converts an input image into a sequence of patch embeddings using a convolutional layer.
It is commonly used as the first layer in vision transformer architectures to transform image data
into a suitable format for subsequent transformer blocks.</p>
<p><span class="doc-section-title">Attributes:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><span title="ultralytics.models.sam.modules.blocks.PatchEmbed.proj">proj</span></code></td>
<td>
<code><span title="torch.nn.Conv2d">Conv2d</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Convolutional layer for projecting image patches to embeddings.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Methods:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code><a class="autorefs autorefs-internal" title="ultralytics.models.sam.modules.blocks.PatchEmbed.forward" href="#ultralytics.models.sam.modules.blocks.PatchEmbed.forward">forward</a></code></td>
<td>
<div class="doc-md-description">
<p>Applies patch embedding to the input tensor.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">patch_embed</span> <span class="o">=</span> <span class="n">PatchEmbed</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">patch_embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 768, 14, 14])</span>
</code></pre></div>
<p>This module is typically used as the first layer in vision transformer architectures to transform
image data into a suitable format for subsequent transformer blocks.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>kernel_size</code>
</td>
<td>
<code><span title="typing.Tuple">Tuple</span>[int, int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Size of the convolutional kernel for patch extraction.</p>
</div>
</td>
<td>
<code>(16, 16)</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stride</code>
</td>
<td>
<code><span title="typing.Tuple">Tuple</span>[int, int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Stride of the convolutional operation.</p>
</div>
</td>
<td>
<code>(16, 16)</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>padding</code>
</td>
<td>
<code><span title="typing.Tuple">Tuple</span>[int, int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Padding applied to the input before convolution.</p>
</div>
</td>
<td>
<code>(0, 0)</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>in_chans</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of input image channels.</p>
</div>
</td>
<td>
<code>3</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>embed_dim</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Dimensionality of the output patch embeddings.</p>
</div>
</td>
<td>
<code>768</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Examples:</span></p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">patch_embed</span> <span class="o">=</span> <span class="n">PatchEmbed</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">patch_embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="go">torch.Size([1, 768, 14, 14])</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1095" name="__codelineno-0-1095"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-1096" name="__codelineno-0-1096"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1097" name="__codelineno-0-1097"></a>    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098"></a>    <span class="n">stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
<a id="__codelineno-0-1099" name="__codelineno-0-1099"></a>    <span class="n">padding</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100"></a>    <span class="n">in_chans</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<a id="__codelineno-0-1101" name="__codelineno-0-1101"></a>    <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-1104" name="__codelineno-0-1104"></a><span class="sd">    Initializes the PatchEmbed module for converting image patches to embeddings.</span>
<a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>
<a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    This module is typically used as the first layer in vision transformer architectures to transform</span>
<a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">    image data into a suitable format for subsequent transformer blocks.</span>
<a id="__codelineno-0-1108" name="__codelineno-0-1108"></a>
<a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110"></a><span class="sd">        kernel_size (Tuple[int, int]): Size of the convolutional kernel for patch extraction.</span>
<a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">        stride (Tuple[int, int]): Stride of the convolutional operation.</span>
<a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">        padding (Tuple[int, int]): Padding applied to the input before convolution.</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="sd">        in_chans (int): Number of input image channels.</span>
<a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">        embed_dim (int): Dimensionality of the output patch embeddings.</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115"></a>
<a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">        &gt;&gt;&gt; patch_embed = PatchEmbed(kernel_size=(16, 16), stride=(16, 16), in_chans=3, embed_dim=768)</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">        &gt;&gt;&gt; x = torch.randn(1, 3, 224, 224)</span>
<a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">        &gt;&gt;&gt; output = patch_embed(x)</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121"></a><span class="sd">        torch.Size([1, 768, 14, 14])</span>
<a id="__codelineno-0-1122" name="__codelineno-0-1122"></a><span class="sd">    """</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>
<a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.PatchEmbed.forward">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <span class="doc doc-object-name doc-function-name">forward</span>
</h3>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents">
<p>Computes patch embedding by applying convolution and transposing resulting tensor.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1127" name="__codelineno-0-1127"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128"></a><span class="w">    </span><span class="sd">"""Computes patch embedding by applying convolution and transposing resulting tensor."""</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># B C H W -&gt; B H W C</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div><p><br/><br/><hr/><br/></p>
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="ultralytics.models.sam.modules.blocks.do_pool">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code> <span class="doc doc-object-name doc-function-name">ultralytics.models.sam.modules.blocks.do_pool</span>
</h2>
<div class="doc-signature highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nf">do_pool</span><span class="p">(</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</code></pre></div>
<div class="doc doc-contents first">
<p>Applies pooling and optional normalization to a tensor, handling spatial dimension permutations.</p>
<details class="quote">
<summary>Source code in <code>ultralytics/models/sam/modules/blocks.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-488">488</a></span>
<span class="normal"><a href="#__codelineno-0-489">489</a></span>
<span class="normal"><a href="#__codelineno-0-490">490</a></span>
<span class="normal"><a href="#__codelineno-0-491">491</a></span>
<span class="normal"><a href="#__codelineno-0-492">492</a></span>
<span class="normal"><a href="#__codelineno-0-493">493</a></span>
<span class="normal"><a href="#__codelineno-0-494">494</a></span>
<span class="normal"><a href="#__codelineno-0-495">495</a></span>
<span class="normal"><a href="#__codelineno-0-496">496</a></span>
<span class="normal"><a href="#__codelineno-0-497">497</a></span>
<span class="normal"><a href="#__codelineno-0-498">498</a></span>
<span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-488" name="__codelineno-0-488"></a><span class="k">def</span> <span class="nf">do_pool</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-489" name="__codelineno-0-489"></a><span class="w">    </span><span class="sd">"""Applies pooling and optional normalization to a tensor, handling spatial dimension permutations."""</span>
<a id="__codelineno-0-490" name="__codelineno-0-490"></a>    <span class="k">if</span> <span class="n">pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-491" name="__codelineno-0-491"></a>        <span class="k">return</span> <span class="n">x</span>
<a id="__codelineno-0-492" name="__codelineno-0-492"></a>    <span class="c1"># (B, H, W, C) -&gt; (B, C, H, W)</span>
<a id="__codelineno-0-493" name="__codelineno-0-493"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-494" name="__codelineno-0-494"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-495" name="__codelineno-0-495"></a>    <span class="c1"># (B, C, H', W') -&gt; (B, H', W', C)</span>
<a id="__codelineno-0-496" name="__codelineno-0-496"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-497" name="__codelineno-0-497"></a>    <span class="k">if</span> <span class="n">norm</span><span class="p">:</span>
<a id="__codelineno-0-498" name="__codelineno-0-498"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-499" name="__codelineno-0-499"></a>
<a id="__codelineno-0-500" name="__codelineno-0-500"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div><p><br/><br/></p>
<div class="git-info">
<div class="dates-container">
<span class="date-item" title="This page was first created on August 05, 2024">
<span class="hover-item">ðŸ“…</span> Created 5 months ago
    </span>
<span class="date-item" title="This page was last updated on September 11, 2024">
<span class="hover-item">âœï¸</span> Updated 3 months ago
    </span>
</div>
<div class="authors-container">
<a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)">
<img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (1 change)">
<img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/>
</a>
</div></div><div class="share-buttons">
<button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https://docs.ultralytics.com/reference/models/sam/modules/blocks', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-x-twitter"></i> Tweet
    </button>
<button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https://docs.ultralytics.com/reference/models/sam/modules/blocks', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-linkedin-in"></i> Share
    </button>
</div>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: model" class="md-footer__link md-footer__link--prev" href="../../model/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                model
              </div>
</div>
</a>
<a aria-label="Next: decoders" class="md-footer__link md-footer__link--next" href="../decoders/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                decoders
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
<a href="https://www.ultralytics.com/" target="_blank">Â© 2024 Ultralytics Inc.</a> All rights reserved.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg>
</a>
<a class="md-social__link" href="https://twitter.com/ultralytics" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"></path></svg>
</a>
<a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"></path></svg>
</a>
<a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"></path></svg>
</a>
<a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"></path></svg>
</a>
<a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"></path></svg>
</a>
<a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tooltips", "search.highlight", "search.share", "search.suggest", "toc.follow", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "navigation.indexes", "navigation.sections", "content.tabs.link"], "search": "../../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
<script src="../../../../../javascript/extra.js"></script>
<script src="../../../../../javascript/giscus.js"></script>
</body>
</html>