 <!DOCTYPE html><html class="no-js" lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="Explore valuable torch utilities from Ultralytics for optimized model performance, including device selection, model fusion, and inference optimization." name="description"/><meta content="Ultralytics" name="author"/><link href="https://docs.ultralytics.com/reference/utils/torch_utils/" rel="canonical"/><link href="../tal/" rel="prev"/><link href="../tqdm/" rel="next"/><link href="/" hreflang="en" rel="alternate"/><link href="/zh/" hreflang="zh" rel="alternate"/><link href="/ko/" hreflang="ko" rel="alternate"/><link href="/ja/" hreflang="ja" rel="alternate"/><link href="/ru/" hreflang="ru" rel="alternate"/><link href="/de/" hreflang="de" rel="alternate"/><link href="/fr/" hreflang="fr" rel="alternate"/><link href="/es/" hreflang="es" rel="alternate"/><link href="/pt/" hreflang="pt" rel="alternate"/><link href="/it/" hreflang="it" rel="alternate"/><link href="/tr/" hreflang="tr" rel="alternate"/><link href="/vi/" hreflang="vi" rel="alternate"/><link href="/ar/" hreflang="ar" rel="alternate"/><link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/><meta content="zensical-0.0.17" name="generator"/><title>Reference for ultralytics/utils/torch_utils.py - Ultralytics YOLO Docs</title><link href="../../../assets/stylesheets/modern/main.d4922b3c.min.css" rel="stylesheet"/><link href="../../../assets/stylesheets/modern/palette.dfe2e883.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,500,500i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link href="../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<style data-doc-kind="true">.doc-kind{display:inline-flex;align-items:center;gap:0.25em;padding:0.21em 0.59em;border-radius:999px;font-weight:700;font-size:0.81em;letter-spacing:0.06em;text-transform:uppercase;line-height:1;color:var(--doc-kind-color,#f8fafc);background:var(--doc-kind-bg,rgba(255,255,255,0.12));}.doc-kind-class{--doc-kind-color:#039dfc;--doc-kind-bg:rgba(3,157,252,0.22);}.doc-kind-function{--doc-kind-color:#fc9803;--doc-kind-bg:rgba(252,152,3,0.22);}.doc-kind-method{--doc-kind-color:#ef5eff;--doc-kind-bg:rgba(239,94,255,0.22);}.doc-kind-property{--doc-kind-color:#02e835;--doc-kind-bg:rgba(2,232,53,0.22);}</style><meta content="Reference for ultralytics/utils/torch_utils.py" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/reference/utils/torch_utils/" property="og:url"/><meta content="Reference for ultralytics/utils/torch_utils.py" property="og:title"/><meta content="" property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/reference/utils/torch_utils/" property="twitter:url"/><meta content="Reference for ultralytics/utils/torch_utils.py" property="twitter:title"/><meta content="" property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "headline": "Reference for ultralytics/utils/torch_utils.py", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2025-11-23 19:53:50 +0100", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": ""}</script></head><body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" for="__drawer"></label><div data-md-component="skip"><a class="md-skip" href="#reference-for-ultralyticsutilstorch_utilspy"> Skip to content </a></div><div data-md-component="announce"><aside class="md-banner"><div class="md-banner__inner md-grid md-typeset"><a class="banner-wrapper" href="https://docs.ultralytics.com/models/yolo26"><div class="banner-content-wrapper"><img alt="Ultralytics YOLO26" height="40" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/6967372a0d67914985d322e7_Ultralytics%20YOLO26%201.svg"/><p>Built End-to-End. Built for the Edge.</p></div></a></div></aside></div><header class="md-header md-header--shadow md-header--lifted" data-md-component="header"><nav aria-label="Header" class="md-header__inner md-grid"><a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a><label class="md-header__button md-icon" for="__drawer"><svg class="lucide lucide-menu" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 5h16M4 12h16M4 19h16"></path></svg></label><div class="md-header__title" data-md-component="header-title"><div class="md-header__ellipsis"><div class="md-header__topic"><span class="md-ellipsis"> Ultralytics YOLO Docs </span></div><div class="md-header__topic" data-md-component="header-topic"><span class="md-ellipsis"> Reference for ultralytics/utils/torch_utils.py </span></div></div></div><form class="md-header__option" data-md-component="palette"><input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option"><div class="md-select"><button aria-label="Select language" class="md-header__button md-icon"><svg class="lucide lucide-languages" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m5 8 6 6M4 14l6-6 2-3M2 5h12M7 2h1M22 22l-5-10-5 10M14 18h6"></path></svg></button><div class="md-select__inner"><ul class="md-select__list"><li class="md-select__item"><a class="md-select__link" href="/" hreflang="en"> ğŸ‡¬ğŸ‡§ English </a></li><li class="md-select__item"><a class="md-select__link" href="/zh/" hreflang="zh"> ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡ </a></li><li class="md-select__item"><a class="md-select__link" href="/ko/" hreflang="ko"> ğŸ‡°ğŸ‡· í•œêµ­ì–´ </a></li><li class="md-select__item"><a class="md-select__link" href="/ja/" hreflang="ja"> ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª </a></li><li class="md-select__item"><a class="md-select__link" href="/ru/" hreflang="ru"> ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ </a></li><li class="md-select__item"><a class="md-select__link" href="/de/" hreflang="de"> ğŸ‡©ğŸ‡ª Deutsch </a></li><li class="md-select__item"><a class="md-select__link" href="/fr/" hreflang="fr"> ğŸ‡«ğŸ‡· FranÃ§ais </a></li><li class="md-select__item"><a class="md-select__link" href="/es/" hreflang="es"> ğŸ‡ªğŸ‡¸ EspaÃ±ol </a></li><li class="md-select__item"><a class="md-select__link" href="/pt/" hreflang="pt"> ğŸ‡µğŸ‡¹ PortuguÃªs </a></li><li class="md-select__item"><a class="md-select__link" href="/it/" hreflang="it"> ğŸ‡®ğŸ‡¹ Italiano </a></li><li class="md-select__item"><a class="md-select__link" href="/tr/" hreflang="tr"> ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e </a></li><li class="md-select__item"><a class="md-select__link" href="/vi/" hreflang="vi"> ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t </a></li><li class="md-select__item"><a class="md-select__link" href="/ar/" hreflang="ar"> ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© </a></li></ul></div></div></div><div class="md-header__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div></nav><nav aria-label="Tabs" class="md-tabs" data-md-component="tabs"><div class="md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a class="md-tabs__link" href="../../.."> Home </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../quickstart/"> Quickstart </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../modes/"> Modes </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../tasks/"> Tasks </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../models/"> Models </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../datasets/"> Datasets </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../solutions/"> Solutions </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../guides/"> Guides </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../integrations/"> Integrations </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../platform/"> Platform </a></li><li class="md-tabs__item md-tabs__item--active"><a class="md-tabs__link" href="../../__init__/"> Reference </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../help/"> Help </a></li></ul></div></nav></header><div class="md-container" data-md-component="container"><main class="md-main" data-md-component="main"><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0"><label class="md-nav__title" for="__drawer"><a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a> Ultralytics YOLO Docs </label><div class="md-nav__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../.."><span class="md-ellipsis"> Home </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../quickstart/"><span class="md-ellipsis"> Quickstart </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../modes/"><span class="md-ellipsis"> Modes </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../tasks/"><span class="md-ellipsis"> Tasks </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../models/"><span class="md-ellipsis"> Models </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../datasets/"><span class="md-ellipsis"> Datasets </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../solutions/"><span class="md-ellipsis"> Solutions </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../guides/"><span class="md-ellipsis"> Guides </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../integrations/"><span class="md-ellipsis"> Integrations </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../platform/"><span class="md-ellipsis"> Platform </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/><label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex=""><span class="md-ellipsis"> Reference </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1"><label class="md-nav__title" for="__nav_11"><span class="md-nav__icon md-icon"></span> Reference </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../__init__/"><span class="md-ellipsis"> __init__ </span></a></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_2" type="checkbox"/><label class="md-nav__link" for="__nav_11_2" id="__nav_11_2_label" tabindex=""><span class="md-ellipsis"> cfg </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_2_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_2"><span class="md-nav__icon md-icon"></span> cfg </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../cfg/__init__/"><span class="md-ellipsis"> __init__ </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_3" type="checkbox"/><label class="md-nav__link" for="__nav_11_3" id="__nav_11_3_label" tabindex=""><span class="md-ellipsis"> data </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_3_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_3"><span class="md-nav__icon md-icon"></span> data </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../data/annotator/"><span class="md-ellipsis"> annotator </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/augment/"><span class="md-ellipsis"> augment </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/base/"><span class="md-ellipsis"> base </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/build/"><span class="md-ellipsis"> build </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/converter/"><span class="md-ellipsis"> converter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/dataset/"><span class="md-ellipsis"> dataset </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/loaders/"><span class="md-ellipsis"> loaders </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/split/"><span class="md-ellipsis"> split </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/split_dota/"><span class="md-ellipsis"> split_dota </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../data/utils/"><span class="md-ellipsis"> utils </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_4" type="checkbox"/><label class="md-nav__link" for="__nav_11_4" id="__nav_11_4_label" tabindex=""><span class="md-ellipsis"> engine </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_4_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_4"><span class="md-nav__icon md-icon"></span> engine </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../engine/exporter/"><span class="md-ellipsis"> exporter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../engine/model/"><span class="md-ellipsis"> model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../engine/predictor/"><span class="md-ellipsis"> predictor </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../engine/results/"><span class="md-ellipsis"> results </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../engine/trainer/"><span class="md-ellipsis"> trainer </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../engine/tuner/"><span class="md-ellipsis"> tuner </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../engine/validator/"><span class="md-ellipsis"> validator </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_5" type="checkbox"/><label class="md-nav__link" for="__nav_11_5" id="__nav_11_5_label" tabindex=""><span class="md-ellipsis"> hub </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_5_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_5"><span class="md-nav__icon md-icon"></span> hub </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../hub/__init__/"><span class="md-ellipsis"> __init__ </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../hub/auth/"><span class="md-ellipsis"> auth </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../hub/google/__init__/"><span class="md-ellipsis"> google </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../hub/session/"><span class="md-ellipsis"> session </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../hub/utils/"><span class="md-ellipsis"> utils </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_6" type="checkbox"/><label class="md-nav__link" for="__nav_11_6" id="__nav_11_6_label" tabindex=""><span class="md-ellipsis"> models </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_6_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_6"><span class="md-nav__icon md-icon"></span> models </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/fastsam/model/"><span class="md-ellipsis"> fastsam </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/nas/model/"><span class="md-ellipsis"> nas </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/rtdetr/model/"><span class="md-ellipsis"> rtdetr </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/sam/amg/"><span class="md-ellipsis"> sam </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/utils/loss/"><span class="md-ellipsis"> utils </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/yolo/classify/predict/"><span class="md-ellipsis"> yolo </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_7" type="checkbox"/><label class="md-nav__link" for="__nav_11_7" id="__nav_11_7_label" tabindex=""><span class="md-ellipsis"> nn </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_7_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_7"><span class="md-nav__icon md-icon"></span> nn </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../nn/autobackend/"><span class="md-ellipsis"> autobackend </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../nn/modules/activation/"><span class="md-ellipsis"> modules </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../nn/tasks/"><span class="md-ellipsis"> tasks </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../nn/text_model/"><span class="md-ellipsis"> text_model </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_8" type="checkbox"/><label class="md-nav__link" for="__nav_11_8" id="__nav_11_8_label" tabindex=""><span class="md-ellipsis"> optim </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_8_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_8"><span class="md-nav__icon md-icon"></span> optim </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../optim/muon/"><span class="md-ellipsis"> muon </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_9" type="checkbox"/><label class="md-nav__link" for="__nav_11_9" id="__nav_11_9_label" tabindex=""><span class="md-ellipsis"> solutions </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_9_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_9"><span class="md-nav__icon md-icon"></span> solutions </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/ai_gym/"><span class="md-ellipsis"> ai_gym </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/analytics/"><span class="md-ellipsis"> analytics </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/config/"><span class="md-ellipsis"> config </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/distance_calculation/"><span class="md-ellipsis"> distance_calculation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/heatmap/"><span class="md-ellipsis"> heatmap </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/instance_segmentation/"><span class="md-ellipsis"> instance_segmentation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/object_blurrer/"><span class="md-ellipsis"> object_blurrer </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/object_counter/"><span class="md-ellipsis"> object_counter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/object_cropper/"><span class="md-ellipsis"> object_cropper </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/parking_management/"><span class="md-ellipsis"> parking_management </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/queue_management/"><span class="md-ellipsis"> queue_management </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/region_counter/"><span class="md-ellipsis"> region_counter </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/security_alarm/"><span class="md-ellipsis"> security_alarm </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/similarity_search/"><span class="md-ellipsis"> similarity_search </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/solutions/"><span class="md-ellipsis"> solutions </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/speed_estimation/"><span class="md-ellipsis"> speed_estimation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/streamlit_inference/"><span class="md-ellipsis"> streamlit_inference </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/trackzone/"><span class="md-ellipsis"> trackzone </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../solutions/vision_eye/"><span class="md-ellipsis"> vision_eye </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_11_10" type="checkbox"/><label class="md-nav__link" for="__nav_11_10" id="__nav_11_10_label" tabindex=""><span class="md-ellipsis"> trackers </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="false" aria-labelledby="__nav_11_10_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_10"><span class="md-nav__icon md-icon"></span> trackers </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../trackers/basetrack/"><span class="md-ellipsis"> basetrack </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../trackers/bot_sort/"><span class="md-ellipsis"> bot_sort </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../trackers/byte_tracker/"><span class="md-ellipsis"> byte_tracker </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../trackers/track/"><span class="md-ellipsis"> track </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../trackers/utils/gmc/"><span class="md-ellipsis"> utils </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_11_11" type="checkbox"/><label class="md-nav__link" for="__nav_11_11" id="__nav_11_11_label" tabindex=""><span class="md-ellipsis"> utils </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_11_11_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_11_11"><span class="md-nav__icon md-icon"></span> utils </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../__init__/"><span class="md-ellipsis"> __init__ </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../autobatch/"><span class="md-ellipsis"> autobatch </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../autodevice/"><span class="md-ellipsis"> autodevice </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../benchmarks/"><span class="md-ellipsis"> benchmarks </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../callbacks/base/"><span class="md-ellipsis"> callbacks </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../checks/"><span class="md-ellipsis"> checks </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../cpu/"><span class="md-ellipsis"> cpu </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../dist/"><span class="md-ellipsis"> dist </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../downloads/"><span class="md-ellipsis"> downloads </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../errors/"><span class="md-ellipsis"> errors </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../events/"><span class="md-ellipsis"> events </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../export/engine/"><span class="md-ellipsis"> export </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../files/"><span class="md-ellipsis"> files </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../git/"><span class="md-ellipsis"> git </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../instance/"><span class="md-ellipsis"> instance </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../logger/"><span class="md-ellipsis"> logger </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../loss/"><span class="md-ellipsis"> loss </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../metrics/"><span class="md-ellipsis"> metrics </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../nms/"><span class="md-ellipsis"> nms </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../ops/"><span class="md-ellipsis"> ops </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../patches/"><span class="md-ellipsis"> patches </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../plotting/"><span class="md-ellipsis"> plotting </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../tal/"><span class="md-ellipsis"> tal </span></a></li><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/><label class="md-nav__link md-nav__link--active" for="__toc"><span class="md-ellipsis"> torch_utils </span><span class="md-nav__icon md-icon"></span></label><a class="md-nav__link md-nav__link--active" href="./"><span class="md-ellipsis"> torch_utils </span></a><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.ModelEMA"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> ModelEMA</span></a><nav aria-label="Class ultralytics.utils.torch_utils.ModelEMA" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.ModelEMA.update"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> update</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.ModelEMA.update_attr"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> update_attr</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.EarlyStopping"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> EarlyStopping</span></a><nav aria-label="Class ultralytics.utils.torch_utils.EarlyStopping" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.EarlyStopping.__call__"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> __call__</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.torch_distributed_zero_first"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> torch_distributed_zero_first</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.smart_inference_mode"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> smart_inference_mode</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.autocast"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> autocast</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_cpu_info"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_cpu_info</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_gpu_info"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_gpu_info</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.select_device"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> select_device</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.time_sync"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> time_sync</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.fuse_conv_and_bn"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> fuse_conv_and_bn</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.fuse_deconv_and_bn"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> fuse_deconv_and_bn</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.model_info"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> model_info</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_num_params"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_num_params</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_num_gradients"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_num_gradients</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.model_info_for_loggers"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> model_info_for_loggers</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_flops"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_flops</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_flops_with_torch_profiler"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_flops_with_torch_profiler</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.initialize_weights"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> initialize_weights</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.scale_img"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> scale_img</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.copy_attr"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> copy_attr</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.intersect_dicts"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> intersect_dicts</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.is_parallel"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> is_parallel</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.unwrap_model"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> unwrap_model</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.one_cycle"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> one_cycle</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.init_seeds"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> init_seeds</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.unset_deterministic"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> unset_deterministic</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.strip_optimizer"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> strip_optimizer</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.convert_optimizer_state_dict_to_fp16"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> convert_optimizer_state_dict_to_fp16</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.cuda_memory_usage"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> cuda_memory_usage</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.profile_ops"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> profile_ops</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.attempt_compile"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> attempt_compile</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../tqdm/"><span class="md-ellipsis"> tqdm </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../triton/"><span class="md-ellipsis"> triton </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../tuner/"><span class="md-ellipsis"> tuner </span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../help/"><span class="md-ellipsis"> Help </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.ModelEMA"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> ModelEMA</span></a><nav aria-label="Class ultralytics.utils.torch_utils.ModelEMA" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.ModelEMA.update"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> update</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.ModelEMA.update_attr"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> update_attr</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.EarlyStopping"><span class="md-ellipsis"><span class="doc-kind doc-kind-class">class</span> EarlyStopping</span></a><nav aria-label="Class ultralytics.utils.torch_utils.EarlyStopping" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.EarlyStopping.__call__"><span class="md-ellipsis"><span class="doc-kind doc-kind-method">method</span> __call__</span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.torch_distributed_zero_first"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> torch_distributed_zero_first</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.smart_inference_mode"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> smart_inference_mode</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.autocast"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> autocast</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_cpu_info"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_cpu_info</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_gpu_info"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_gpu_info</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.select_device"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> select_device</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.time_sync"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> time_sync</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.fuse_conv_and_bn"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> fuse_conv_and_bn</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.fuse_deconv_and_bn"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> fuse_deconv_and_bn</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.model_info"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> model_info</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_num_params"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_num_params</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_num_gradients"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_num_gradients</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.model_info_for_loggers"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> model_info_for_loggers</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_flops"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_flops</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.get_flops_with_torch_profiler"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> get_flops_with_torch_profiler</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.initialize_weights"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> initialize_weights</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.scale_img"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> scale_img</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.copy_attr"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> copy_attr</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.intersect_dicts"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> intersect_dicts</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.is_parallel"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> is_parallel</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.unwrap_model"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> unwrap_model</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.one_cycle"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> one_cycle</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.init_seeds"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> init_seeds</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.unset_deterministic"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> unset_deterministic</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.strip_optimizer"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> strip_optimizer</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.convert_optimizer_state_dict_to_fp16"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> convert_optimizer_state_dict_to_fp16</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.cuda_memory_usage"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> cuda_memory_usage</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.profile_ops"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> profile_ops</span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#ultralytics.utils.torch_utils.attempt_compile"><span class="md-ellipsis"><span class="doc-kind doc-kind-function">function</span> attempt_compile</span></a></li></ul></nav></div></div></div><div class="md-content" data-md-component="content"><article class="md-content__inner md-typeset"><a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/reference/utils/torch_utils.md" rel="edit" title="Edit this page"><svg class="lucide lucide-file-pen" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"></path><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"></path></svg></a><h1 id="reference-for-ultralyticsutilstorch_utilspy">Reference for <code>ultralytics/utils/torch_utils.py</code></h1><div class="admonition success"><p class="admonition-title">Improvements</p><p>This page is sourced from <a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py">https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py</a>. Have an improvement or example to add? Open a <a href="https://docs.ultralytics.com/help/contributing/">Pull Request</a> â€” thank you! ğŸ™</p></div><p><br/></p><div class="admonition abstract"><p class="admonition-title">Summary</p><div class="tabbed-set tabbed-alternate" data-tabs="1:3"><input checked="checked" id="classes" name="__tabbed_1" type="radio"/><input id="methods" name="__tabbed_1" type="radio"/><input id="functions" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="classes"><span class="doc-kind doc-kind-class">Classes</span></label><label for="methods"><span class="doc-kind doc-kind-method">Methods</span></label><label for="functions"><span class="doc-kind doc-kind-function">Functions</span></label></div><div class="tabbed-content"><div class="tabbed-block"><ul><li><a href="#ultralytics.utils.torch_utils.ModelEMA"><code>ModelEMA</code></a></li><li><a href="#ultralytics.utils.torch_utils.EarlyStopping"><code>EarlyStopping</code></a></li></ul></div><div class="tabbed-block"><ul><li><a href="#ultralytics.utils.torch_utils.ModelEMA.update"><code>ModelEMA.update</code></a></li><li><a href="#ultralytics.utils.torch_utils.ModelEMA.update_attr"><code>ModelEMA.update_attr</code></a></li><li><a href="#ultralytics.utils.torch_utils.EarlyStopping.__call__"><code>EarlyStopping.__call__</code></a></li></ul></div><div class="tabbed-block"><ul><li><a href="#ultralytics.utils.torch_utils.torch_distributed_zero_first"><code>torch_distributed_zero_first</code></a></li><li><a href="#ultralytics.utils.torch_utils.smart_inference_mode"><code>smart_inference_mode</code></a></li><li><a href="#ultralytics.utils.torch_utils.autocast"><code>autocast</code></a></li><li><a href="#ultralytics.utils.torch_utils.get_cpu_info"><code>get_cpu_info</code></a></li><li><a href="#ultralytics.utils.torch_utils.get_gpu_info"><code>get_gpu_info</code></a></li><li><a href="#ultralytics.utils.torch_utils.select_device"><code>select_device</code></a></li><li><a href="#ultralytics.utils.torch_utils.time_sync"><code>time_sync</code></a></li><li><a href="#ultralytics.utils.torch_utils.fuse_conv_and_bn"><code>fuse_conv_and_bn</code></a></li><li><a href="#ultralytics.utils.torch_utils.fuse_deconv_and_bn"><code>fuse_deconv_and_bn</code></a></li><li><a href="#ultralytics.utils.torch_utils.model_info"><code>model_info</code></a></li><li><a href="#ultralytics.utils.torch_utils.get_num_params"><code>get_num_params</code></a></li><li><a href="#ultralytics.utils.torch_utils.get_num_gradients"><code>get_num_gradients</code></a></li><li><a href="#ultralytics.utils.torch_utils.model_info_for_loggers"><code>model_info_for_loggers</code></a></li><li><a href="#ultralytics.utils.torch_utils.get_flops"><code>get_flops</code></a></li><li><a href="#ultralytics.utils.torch_utils.get_flops_with_torch_profiler"><code>get_flops_with_torch_profiler</code></a></li><li><a href="#ultralytics.utils.torch_utils.initialize_weights"><code>initialize_weights</code></a></li><li><a href="#ultralytics.utils.torch_utils.scale_img"><code>scale_img</code></a></li><li><a href="#ultralytics.utils.torch_utils.copy_attr"><code>copy_attr</code></a></li><li><a href="#ultralytics.utils.torch_utils.intersect_dicts"><code>intersect_dicts</code></a></li><li><a href="#ultralytics.utils.torch_utils.is_parallel"><code>is_parallel</code></a></li><li><a href="#ultralytics.utils.torch_utils.unwrap_model"><code>unwrap_model</code></a></li><li><a href="#ultralytics.utils.torch_utils.one_cycle"><code>one_cycle</code></a></li><li><a href="#ultralytics.utils.torch_utils.init_seeds"><code>init_seeds</code></a></li><li><a href="#ultralytics.utils.torch_utils.unset_deterministic"><code>unset_deterministic</code></a></li><li><a href="#ultralytics.utils.torch_utils.strip_optimizer"><code>strip_optimizer</code></a></li><li><a href="#ultralytics.utils.torch_utils.convert_optimizer_state_dict_to_fp16"><code>convert_optimizer_state_dict_to_fp16</code></a></li><li><a href="#ultralytics.utils.torch_utils.cuda_memory_usage"><code>cuda_memory_usage</code></a></li><li><a href="#ultralytics.utils.torch_utils.profile_ops"><code>profile_ops</code></a></li><li><a href="#ultralytics.utils.torch_utils.attempt_compile"><code>attempt_compile</code></a></li></ul></div></div></div></div><h2 id="ultralytics.utils.torch_utils.ModelEMA"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.utils.torch_utils.ModelEMA</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="n">ModelEMA</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">decay</span> <span class="o">=</span> <span class="mf">0.9999</span><span class="p">,</span> <span class="n">tau</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">updates</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div><p>Updated Exponential Moving Average (EMA) implementation.</p><p>Keeps a moving average of everything in the model state_dict (parameters and buffers). For EMA details see References.</p><p>To disable EMA set the <code>enabled</code> attribute to <code>False</code>.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>Model to create EMA for.</td><td><em>required</em></td></tr><tr><td><code>decay</code></td><td><code>float, optional</code></td><td>Maximum EMA decay rate.</td><td><code>0.9999</code></td></tr><tr><td><code>tau</code></td><td><code>int, optional</code></td><td>EMA decay time constant.</td><td><code>2000</code></td></tr><tr><td><code>updates</code></td><td><code>int, optional</code></td><td>Initial number of updates.</td><td><code>0</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>ema</code></td><td><code>nn.Module</code></td><td>Copy of the model in evaluation mode.</td></tr><tr><td><code>updates</code></td><td><code>int</code></td><td>Number of EMA updates.</td></tr><tr><td><code>decay</code></td><td><code>function</code></td><td>Decay function that determines the EMA weight.</td></tr><tr><td><code>enabled</code></td><td><code>bool</code></td><td>Whether EMA is enabled.</td></tr><tr><td><code>References</code></td><td></td><td></td></tr><tr><td><code>- https://github.com/rwightman/pytorch-image-models</code></td><td></td><td></td></tr><tr><td><code>- https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage</code></td><td></td><td></td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.utils.torch_utils.ModelEMA.update"><code>update</code></a></td><td>Update EMA parameters.</td></tr><tr><td><a href="#ultralytics.utils.torch_utils.ModelEMA.update_attr"><code>update_attr</code></a></td><td>Update attributes and save stripped model with optimizer removed.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L606-L667"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ModelEMA</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Updated Exponential Moving Average (EMA) implementation.</span>
<span></span>
<span></span><span class="sd">    Keeps a moving average of everything in the model state_dict (parameters and buffers). For EMA details see</span>
<span></span><span class="sd">    References.</span>
<span></span>
<span></span><span class="sd">    To disable EMA set the `enabled` attribute to `False`.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        ema (nn.Module): Copy of the model in evaluation mode.</span>
<span></span><span class="sd">        updates (int): Number of EMA updates.</span>
<span></span><span class="sd">        decay (function): Decay function that determines the EMA weight.</span>
<span></span><span class="sd">        enabled (bool): Whether EMA is enabled.</span>
<span></span>
<span></span><span class="sd">    References:</span>
<span></span><span class="sd">        - https://github.com/rwightman/pytorch-image-models</span>
<span></span><span class="sd">        - https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.9999</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize EMA for 'model' with given arguments.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            model (nn.Module): Model to create EMA for.</span>
<span></span><span class="sd">            decay (float, optional): Maximum EMA decay rate.</span>
<span></span><span class="sd">            tau (int, optional): EMA decay time constant.</span>
<span></span><span class="sd">            updates (int, optional): Initial number of updates.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">))</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># FP32 EMA</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">updates</span> <span class="o">=</span> <span class="n">updates</span>  <span class="c1"># number of EMA updates</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">decay</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">/</span> <span class="n">tau</span><span class="p">))</span>  <span class="c1"># decay exponential ramp (to help early epochs)</span>
<span></span>        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span></span>            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.utils.torch_utils.ModelEMA.update"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.utils.torch_utils.ModelEMA.update</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</code></pre></div><p>Update EMA parameters.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>Model to update EMA from.</td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L641-L655"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Update EMA parameters.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (nn.Module): Model to update EMA from.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>
<span></span>        <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">updates</span><span class="p">)</span>
<span></span>
<span></span>        <span class="n">msd</span> <span class="o">=</span> <span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>  <span class="c1"># model state_dict</span>
<span></span>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span></span>            <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span>  <span class="c1"># true for FP16 and FP32</span>
<span></span>                <span class="n">v</span> <span class="o">*=</span> <span class="n">d</span>
<span></span>                <span class="n">v</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="n">msd</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.utils.torch_utils.ModelEMA.update_attr"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.utils.torch_utils.ModelEMA.update_attr</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">include</span> <span class="o">=</span> <span class="p">(),</span> <span class="n">exclude</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"process_group"</span><span class="p">,</span> <span class="s2">"reducer"</span><span class="p">))</span>
</code></pre></div><p>Update attributes and save stripped model with optimizer removed.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>Model to update attributes from.</td><td><em>required</em></td></tr><tr><td><code>include</code></td><td><code>tuple, optional</code></td><td>Attributes to include.</td><td><code>()</code></td></tr><tr><td><code>exclude</code></td><td><code>tuple, optional</code></td><td>Attributes to exclude.</td><td><code>("process_group", "reducer")</code></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L658-L667"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">include</span><span class="o">=</span><span class="p">(),</span> <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">"process_group"</span><span class="p">,</span> <span class="s2">"reducer"</span><span class="p">)):</span>
<span></span><span class="w">    </span><span class="sd">"""Update attributes and save stripped model with optimizer removed.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (nn.Module): Model to update attributes from.</span>
<span></span><span class="sd">        include (tuple, optional): Attributes to include.</span>
<span></span><span class="sd">        exclude (tuple, optional): Attributes to exclude.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
<span></span>        <span class="n">copy_attr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">include</span><span class="p">,</span> <span class="n">exclude</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.EarlyStopping"><span class="doc-kind doc-kind-class">class</span> <code>ultralytics.utils.torch_utils.EarlyStopping</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="n">EarlyStopping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
</code></pre></div><p>Early stopping class that stops training when a specified number of epochs have passed without improvement.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>patience</code></td><td><code>int, optional</code></td><td>Number of epochs to wait after fitness stops improving before stopping.</td><td><code>50</code></td></tr></tbody></table><p><strong>Attributes</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>best_fitness</code></td><td><code>float</code></td><td>Best fitness value observed.</td></tr><tr><td><code>best_epoch</code></td><td><code>int</code></td><td>Epoch where best fitness was observed.</td></tr><tr><td><code>patience</code></td><td><code>int</code></td><td>Number of epochs to wait after fitness stops improving before stopping.</td></tr><tr><td><code>possible_stop</code></td><td><code>bool</code></td><td>Flag indicating if stopping may occur next epoch.</td></tr></tbody></table><p><strong>Methods</strong></p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="#ultralytics.utils.torch_utils.EarlyStopping.__call__"><code>__call__</code></a></td><td>Check whether to stop training.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L857-L905"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">class</span><span class="w"> </span><span class="nc">EarlyStopping</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Early stopping class that stops training when a specified number of epochs have passed without improvement.</span>
<span></span>
<span></span><span class="sd">    Attributes:</span>
<span></span><span class="sd">        best_fitness (float): Best fitness value observed.</span>
<span></span><span class="sd">        best_epoch (int): Epoch where best fitness was observed.</span>
<span></span><span class="sd">        patience (int): Number of epochs to wait after fitness stops improving before stopping.</span>
<span></span><span class="sd">        possible_stop (bool): Flag indicating if stopping may occur next epoch.</span>
<span></span><span class="sd">    """</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Initialize early stopping object.</span>
<span></span>
<span></span><span class="sd">        Args:</span>
<span></span><span class="sd">            patience (int, optional): Number of epochs to wait after fitness stops improving before stopping.</span>
<span></span><span class="sd">        """</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">best_fitness</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># i.e. mAP</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>  <span class="c1"># epochs to wait after fitness stops improving to stop</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">possible_stop</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># possible stop may occur next epoch</span>
</code></pre></div></details><p><br/></p><h3 id="ultralytics.utils.torch_utils.EarlyStopping.__call__"><span class="doc-kind doc-kind-method">method</span> <code>ultralytics.utils.torch_utils.EarlyStopping.__call__</code></h3><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">fitness</span><span class="p">)</span>
</code></pre></div><p>Check whether to stop training.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>epoch</code></td><td><code>int</code></td><td>Current epoch of training</td><td><em>required</em></td></tr><tr><td><code>fitness</code></td><td><code>float</code></td><td>Fitness value of current epoch</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>bool</code></td><td>True if training should stop, False otherwise</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L878-L905"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">fitness</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Check whether to stop training.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        epoch (int): Current epoch of training</span>
<span></span><span class="sd">        fitness (float): Fitness value of current epoch</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (bool): True if training should stop, False otherwise</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">fitness</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># check if fitness=None (happens when val=False)</span>
<span></span>        <span class="k">return</span> <span class="kc">False</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">fitness</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_fitness</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_fitness</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># allow for early zero-fitness stage of training</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
<span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">best_fitness</span> <span class="o">=</span> <span class="n">fitness</span>
<span></span>    <span class="n">delta</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span>  <span class="c1"># epochs without improvement</span>
<span></span>    <span class="bp">self</span><span class="o">.</span><span class="n">possible_stop</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># possible stop may occur next epoch</span>
<span></span>    <span class="n">stop</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span>  <span class="c1"># stop training if patience exceeded</span>
<span></span>    <span class="k">if</span> <span class="n">stop</span><span class="p">:</span>
<span></span>        <span class="n">prefix</span> <span class="o">=</span> <span class="n">colorstr</span><span class="p">(</span><span class="s2">"EarlyStopping: "</span><span class="p">)</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
<span></span>            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">Training stopped early as no improvement observed in last </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="si">}</span><span class="s2"> epochs. "</span>
<span></span>            <span class="sa">f</span><span class="s2">"Best results observed at epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">, best model saved as best.pt.</span><span class="se">\n</span><span class="s2">"</span>
<span></span>            <span class="sa">f</span><span class="s2">"To update EarlyStopping(patience=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="si">}</span><span class="s2">) pass a new patience value, "</span>
<span></span>            <span class="sa">f</span><span class="s2">"i.e. `patience=300` or use `patience=0` to disable EarlyStopping."</span>
<span></span>        <span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">stop</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.torch_distributed_zero_first"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.torch_distributed_zero_first</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">torch_distributed_zero_first</span><span class="p">(</span><span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span>
</code></pre></div><p>Ensure all processes in distributed training wait for the local master (rank 0) to complete a task first.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>local_rank</code></td><td><code>int</code></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L61-L70"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@contextmanager</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">torch_distributed_zero_first</span><span class="p">(</span><span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Ensure all processes in distributed training wait for the local master (rank 0) to complete a task first."""</span>
<span></span>    <span class="n">initialized</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span>
<span></span>    <span class="n">use_ids</span> <span class="o">=</span> <span class="n">initialized</span> <span class="ow">and</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_backend</span><span class="p">()</span> <span class="o">==</span> <span class="s2">"nccl"</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">initialized</span> <span class="ow">and</span> <span class="n">local_rank</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">}:</span>
<span></span>        <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">local_rank</span><span class="p">])</span> <span class="k">if</span> <span class="n">use_ids</span> <span class="k">else</span> <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
<span></span>    <span class="k">yield</span>
<span></span>    <span class="k">if</span> <span class="n">initialized</span> <span class="ow">and</span> <span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">local_rank</span><span class="p">])</span> <span class="k">if</span> <span class="n">use_ids</span> <span class="k">else</span> <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.smart_inference_mode"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.smart_inference_mode</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">smart_inference_mode</span><span class="p">()</span>
</code></pre></div><p>Apply torch.inference_mode() decorator if torch&gt;=1.9.0 else torch.no_grad() decorator.</p><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L73-L83"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">smart_inference_mode</span><span class="p">():</span>
<span></span><span class="w">    </span><span class="sd">"""Apply torch.inference_mode() decorator if torch&gt;=1.9.0 else torch.no_grad() decorator."""</span>
<span></span>
<span></span>    <span class="k">def</span><span class="w"> </span><span class="nf">decorate</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
<span></span><span class="w">        </span><span class="sd">"""Apply appropriate torch decorator for inference mode based on torch version."""</span>
<span></span>        <span class="k">if</span> <span class="n">TORCH_1_9</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_inference_mode_enabled</span><span class="p">():</span>
<span></span>            <span class="k">return</span> <span class="n">fn</span>  <span class="c1"># already in inference_mode, act as a pass-through</span>
<span></span>        <span class="k">else</span><span class="p">:</span>
<span></span>            <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span> <span class="k">if</span> <span class="n">TORCH_1_9</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">)()(</span><span class="n">fn</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">decorate</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.autocast"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.autocast</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"cuda"</span><span class="p">)</span>
</code></pre></div><p>Get the appropriate autocast context manager based on PyTorch version and AMP setting.</p><p>This function returns a context manager for automatic mixed precision (AMP) training that is compatible with both older and newer versions of PyTorch. It handles the differences in the autocast API between PyTorch versions.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>enabled</code></td><td><code>bool</code></td><td>Whether to enable automatic mixed precision.</td><td><em>required</em></td></tr><tr><td><code>device</code></td><td><code>str, optional</code></td><td>The device to use for autocast.</td><td><code>"cuda"</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>torch.amp.autocast</code></td><td>The appropriate autocast context manager.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span></span><span class="o">...</span>     <span class="c1"># Your mixed precision operations here</span>
<span></span><span class="o">...</span>     <span class="k">pass</span>
</code></pre></div><div class="admonition note"><p class="admonition-title">Notes</p><ul><li>For PyTorch versions 1.13 and newer, it uses <code>torch.amp.autocast</code>.</li><li>For older versions, it uses <code>torch.cuda.autocast</code>.</li></ul></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L86-L111"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"cuda"</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Get the appropriate autocast context manager based on PyTorch version and AMP setting.</span>
<span></span>
<span></span><span class="sd">    This function returns a context manager for automatic mixed precision (AMP) training that is compatible with both</span>
<span></span><span class="sd">    older and newer versions of PyTorch. It handles the differences in the autocast API between PyTorch versions.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        enabled (bool): Whether to enable automatic mixed precision.</span>
<span></span><span class="sd">        device (str, optional): The device to use for autocast.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (torch.amp.autocast): The appropriate autocast context manager.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; with autocast(enabled=True):</span>
<span></span><span class="sd">        ...     # Your mixed precision operations here</span>
<span></span><span class="sd">        ...     pass</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - For PyTorch versions 1.13 and newer, it uses `torch.amp.autocast`.</span>
<span></span><span class="sd">        - For older versions, it uses `torch.cuda.autocast`.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">TORCH_1_13</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="n">enabled</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.get_cpu_info"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.get_cpu_info</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_cpu_info</span><span class="p">()</span>
</code></pre></div><p>Return a string with system CPU information, i.e. 'Apple M2'.</p><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L115-L124"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_cpu_info</span><span class="p">():</span>
<span></span><span class="w">    </span><span class="sd">"""Return a string with system CPU information, i.e. 'Apple M2'."""</span>
<span></span>    <span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">PERSISTENT_CACHE</span>  <span class="c1"># avoid circular import error</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="s2">"cpu_info"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PERSISTENT_CACHE</span><span class="p">:</span>
<span></span>        <span class="k">try</span><span class="p">:</span>
<span></span>            <span class="n">PERSISTENT_CACHE</span><span class="p">[</span><span class="s2">"cpu_info"</span><span class="p">]</span> <span class="o">=</span> <span class="n">CPUInfo</span><span class="o">.</span><span class="n">name</span><span class="p">()</span>
<span></span>        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<span></span>            <span class="k">pass</span>
<span></span>    <span class="k">return</span> <span class="n">PERSISTENT_CACHE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"cpu_info"</span><span class="p">,</span> <span class="s2">"unknown"</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.get_gpu_info"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.get_gpu_info</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_gpu_info</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
</code></pre></div><p>Return a string with system GPU information, i.e. 'Tesla T4, 15102MiB'.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>index</code></td><td></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L128-L131"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_gpu_info</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Return a string with system GPU information, i.e. 'Tesla T4, 15102MiB'."""</span>
<span></span>    <span class="n">properties</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">properties</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">properties</span><span class="o">.</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">20</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">MiB"</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.select_device"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.select_device</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">select_device</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span> <span class="n">newline</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div><p>Select the appropriate PyTorch device based on the provided arguments.</p><p>The function takes a string specifying the device or a torch.device object and returns a torch.device object representing the selected device. The function also validates the number of available devices and raises an exception if the requested device(s) are not available.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>device</code></td><td><code>str | torch.device, optional</code></td><td>Device string or torch.device object. Options are 'None', 'cpu', or<br/> 'cuda', or '0' or '0,1,2,3'. Auto-selects the first available GPU, or CPU if no GPU is available.</td><td><code>""</code></td></tr><tr><td><code>newline</code></td><td><code>bool, optional</code></td><td>If True, adds a newline at the end of the log string.</td><td><code>False</code></td></tr><tr><td><code>verbose</code></td><td><code>bool, optional</code></td><td>If True, logs the device information.</td><td><code>True</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>torch.device</code></td><td>Selected device.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">select_device</span><span class="p">(</span><span class="s2">"cuda:0"</span><span class="p">)</span>
<span></span><span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">'cuda'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">select_device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span></span><span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">)</span>
</code></pre></div><div class="admonition note"><p class="admonition-title">Notes</p><p>Sets the 'CUDA_VISIBLE_DEVICES' environment variable for specifying which GPUs to use.</p></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L134-L227"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">select_device</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Select the appropriate PyTorch device based on the provided arguments.</span>
<span></span>
<span></span><span class="sd">    The function takes a string specifying the device or a torch.device object and returns a torch.device object</span>
<span></span><span class="sd">    representing the selected device. The function also validates the number of available devices and raises an</span>
<span></span><span class="sd">    exception if the requested device(s) are not available.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        device (str | torch.device, optional): Device string or torch.device object. Options are 'None', 'cpu', or</span>
<span></span><span class="sd">            'cuda', or '0' or '0,1,2,3'. Auto-selects the first available GPU, or CPU if no GPU is available.</span>
<span></span><span class="sd">        newline (bool, optional): If True, adds a newline at the end of the log string.</span>
<span></span><span class="sd">        verbose (bool, optional): If True, logs the device information.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (torch.device): Selected device.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; select_device("cuda:0")</span>
<span></span><span class="sd">        device(type='cuda', index=0)</span>
<span></span>
<span></span><span class="sd">        &gt;&gt;&gt; select_device("cpu")</span>
<span></span><span class="sd">        device(type='cpu')</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        Sets the 'CUDA_VISIBLE_DEVICES' environment variable for specifying which GPUs to use.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">"tpu"</span><span class="p">,</span> <span class="s2">"intel"</span><span class="p">,</span> <span class="s2">"vulkan"</span><span class="p">)):</span>
<span></span>        <span class="k">return</span> <span class="n">device</span>
<span></span>
<span></span>    <span class="n">s</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Ultralytics </span><span class="si">{</span><span class="n">__version__</span><span class="si">}</span><span class="s2"> ğŸš€ Python-</span><span class="si">{</span><span class="n">PYTHON_VERSION</span><span class="si">}</span><span class="s2"> torch-</span><span class="si">{</span><span class="n">TORCH_VERSION</span><span class="si">}</span><span class="s2"> "</span>
<span></span>    <span class="n">device</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span></span>    <span class="k">for</span> <span class="n">remove</span> <span class="ow">in</span> <span class="s2">"cuda:"</span><span class="p">,</span> <span class="s2">"none"</span><span class="p">,</span> <span class="s2">"("</span><span class="p">,</span> <span class="s2">")"</span><span class="p">,</span> <span class="s2">"["</span><span class="p">,</span> <span class="s2">"]"</span><span class="p">,</span> <span class="s2">"'"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">:</span>
<span></span>        <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">remove</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>  <span class="c1"># to string, 'cuda:0' -&gt; '0' and '(0, 1)' -&gt; '0,1'</span>
<span></span>
<span></span>    <span class="c1"># Auto-select GPUs</span>
<span></span>    <span class="k">if</span> <span class="s2">"-1"</span> <span class="ow">in</span> <span class="n">device</span><span class="p">:</span>
<span></span>        <span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics.utils.autodevice</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPUInfo</span>
<span></span>
<span></span>        <span class="c1"># Replace each -1 with a selected GPU or remove it</span>
<span></span>        <span class="n">parts</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)</span>
<span></span>        <span class="n">selected</span> <span class="o">=</span> <span class="n">GPUInfo</span><span class="p">()</span><span class="o">.</span><span class="n">select_idle_gpu</span><span class="p">(</span><span class="n">count</span><span class="o">=</span><span class="n">parts</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">"-1"</span><span class="p">),</span> <span class="n">min_memory_fraction</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)):</span>
<span></span>            <span class="k">if</span> <span class="n">parts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"-1"</span><span class="p">:</span>
<span></span>                <span class="n">parts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">selected</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="k">if</span> <span class="n">selected</span> <span class="k">else</span> <span class="s2">""</span>
<span></span>        <span class="n">device</span> <span class="o">=</span> <span class="s2">","</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parts</span> <span class="k">if</span> <span class="n">p</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">cpu</span> <span class="o">=</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">"cpu"</span>
<span></span>    <span class="n">mps</span> <span class="o">=</span> <span class="n">device</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">"mps"</span><span class="p">,</span> <span class="s2">"mps:0"</span><span class="p">}</span>  <span class="c1"># Apple Metal Performance Shaders (MPS)</span>
<span></span>    <span class="k">if</span> <span class="n">cpu</span> <span class="ow">or</span> <span class="n">mps</span><span class="p">:</span>
<span></span>        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">""</span>  <span class="c1"># force torch.cuda.is_available() = False</span>
<span></span>    <span class="k">elif</span> <span class="n">device</span><span class="p">:</span>  <span class="c1"># non-cpu device requested</span>
<span></span>        <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">"cuda"</span><span class="p">:</span>
<span></span>            <span class="n">device</span> <span class="o">=</span> <span class="s2">"0"</span>
<span></span>        <span class="k">if</span> <span class="s2">","</span> <span class="ow">in</span> <span class="n">device</span><span class="p">:</span>
<span></span>            <span class="n">device</span> <span class="o">=</span> <span class="s2">","</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">device</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span><span class="p">])</span>  <span class="c1"># remove sequential commas, i.e. "0,,1" -&gt; "0,1"</span>
<span></span>        <span class="n">visible</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">]</span> <span class="o">=</span> <span class="n">device</span>  <span class="c1"># set environment variable - must be before assert is_available()</span>
<span></span>        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">device</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">))):</span>
<span></span>            <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span></span>            <span class="n">install</span> <span class="o">=</span> <span class="p">(</span>
<span></span>                <span class="s2">"See https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no "</span>
<span></span>                <span class="s2">"CUDA devices are seen by torch.</span><span class="se">\n</span><span class="s2">"</span>
<span></span>                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
<span></span>                <span class="k">else</span> <span class="s2">""</span>
<span></span>            <span class="p">)</span>
<span></span>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span></span>                <span class="sa">f</span><span class="s2">"Invalid CUDA 'device=</span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">' requested."</span>
<span></span>                <span class="sa">f</span><span class="s2">" Use 'device=cpu' or pass valid CUDA device(s) if available,"</span>
<span></span>                <span class="sa">f</span><span class="s2">" i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.</span><span class="se">\n</span><span class="s2">"</span>
<span></span>                <span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">torch.cuda.is_available(): </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span>
<span></span>                <span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">torch.cuda.device_count(): </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span>
<span></span>                <span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">os.environ['CUDA_VISIBLE_DEVICES']: </span><span class="si">{</span><span class="n">visible</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>
<span></span>                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">install</span><span class="si">}</span><span class="s2">"</span>
<span></span>            <span class="p">)</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">cpu</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">mps</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>  <span class="c1"># prefer GPU if available</span>
<span></span>        <span class="n">devices</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)</span> <span class="k">if</span> <span class="n">device</span> <span class="k">else</span> <span class="s2">"0"</span>  <span class="c1"># i.e. "0,1" -&gt; ["0", "1"]</span>
<span></span>        <span class="n">space</span> <span class="o">=</span> <span class="s2">" "</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">devices</span><span class="p">):</span>
<span></span>            <span class="n">s</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">''</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">space</span><span class="si">}</span><span class="s2">CUDA:</span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">get_gpu_info</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">"</span>  <span class="c1"># bytes to MB</span>
<span></span>        <span class="n">arg</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
<span></span>    <span class="k">elif</span> <span class="n">mps</span> <span class="ow">and</span> <span class="n">TORCH_2_0</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<span></span>        <span class="c1"># Prefer MPS if available</span>
<span></span>        <span class="n">s</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"MPS (</span><span class="si">{</span><span class="n">get_cpu_info</span><span class="p">()</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">"</span>
<span></span>        <span class="n">arg</span> <span class="o">=</span> <span class="s2">"mps"</span>
<span></span>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># revert to CPU</span>
<span></span>        <span class="n">s</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"CPU (</span><span class="si">{</span><span class="n">get_cpu_info</span><span class="p">()</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">"</span>
<span></span>        <span class="n">arg</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">arg</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">"cpu"</span><span class="p">,</span> <span class="s2">"mps"</span><span class="p">}:</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">NUM_THREADS</span><span class="p">)</span>  <span class="c1"># reset OMP_NUM_THREADS for cpu training</span>
<span></span>    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">s</span> <span class="k">if</span> <span class="n">newline</span> <span class="k">else</span> <span class="n">s</span><span class="o">.</span><span class="n">rstrip</span><span class="p">())</span>
<span></span>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.time_sync"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.time_sync</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">time_sync</span><span class="p">()</span>
</code></pre></div><p>Return PyTorch-accurate time.</p><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L230-L234"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">time_sync</span><span class="p">():</span>
<span></span><span class="w">    </span><span class="sd">"""Return PyTorch-accurate time."""</span>
<span></span>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span></span>    <span class="k">return</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.fuse_conv_and_bn"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.fuse_conv_and_bn</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fuse_conv_and_bn</span><span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">bn</span><span class="p">)</span>
</code></pre></div><p>Fuse Conv2d and BatchNorm2d layers for inference optimization.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>conv</code></td><td><code>nn.Conv2d</code></td><td>Convolutional layer to fuse.</td><td><em>required</em></td></tr><tr><td><code>bn</code></td><td><code>nn.BatchNorm2d</code></td><td>Batch normalization layer to fuse.</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>nn.Conv2d</code></td><td>The fused convolutional layer with gradients disabled.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">fused_conv</span> <span class="o">=</span> <span class="n">fuse_conv_and_bn</span><span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">bn</span><span class="p">)</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L237-L267"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fuse_conv_and_bn</span><span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">bn</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Fuse Conv2d and BatchNorm2d layers for inference optimization.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        conv (nn.Conv2d): Convolutional layer to fuse.</span>
<span></span><span class="sd">        bn (nn.BatchNorm2d): Batch normalization layer to fuse.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (nn.Conv2d): The fused convolutional layer with gradients disabled.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; conv = nn.Conv2d(3, 16, 3)</span>
<span></span><span class="sd">        &gt;&gt;&gt; bn = nn.BatchNorm2d(16)</span>
<span></span><span class="sd">        &gt;&gt;&gt; fused_conv = fuse_conv_and_bn(conv, bn)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Compute fused weights</span>
<span></span>    <span class="n">w_conv</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">w_bn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">eps</span> <span class="o">+</span> <span class="n">bn</span><span class="o">.</span><span class="n">running_var</span><span class="p">)))</span>
<span></span>    <span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">w_bn</span><span class="p">,</span> <span class="n">w_conv</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Compute fused bias</span>
<span></span>    <span class="n">b_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">conv</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">conv</span><span class="o">.</span><span class="n">bias</span>
<span></span>    <span class="n">b_bn</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">bias</span> <span class="o">-</span> <span class="n">bn</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">running_var</span> <span class="o">+</span> <span class="n">bn</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span>
<span></span>    <span class="n">fused_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">w_bn</span><span class="p">,</span> <span class="n">b_conv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_bn</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">conv</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">conv</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">"bias"</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">fused_bias</span><span class="p">))</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">conv</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fused_bias</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">conv</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.fuse_deconv_and_bn"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.fuse_deconv_and_bn</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fuse_deconv_and_bn</span><span class="p">(</span><span class="n">deconv</span><span class="p">,</span> <span class="n">bn</span><span class="p">)</span>
</code></pre></div><p>Fuse ConvTranspose2d and BatchNorm2d layers for inference optimization.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>deconv</code></td><td><code>nn.ConvTranspose2d</code></td><td>Transposed convolutional layer to fuse.</td><td><em>required</em></td></tr><tr><td><code>bn</code></td><td><code>nn.BatchNorm2d</code></td><td>Batch normalization layer to fuse.</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>nn.ConvTranspose2d</code></td><td>The fused transposed convolutional layer with gradients disabled.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">deconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">fused_deconv</span> <span class="o">=</span> <span class="n">fuse_deconv_and_bn</span><span class="p">(</span><span class="n">deconv</span><span class="p">,</span> <span class="n">bn</span><span class="p">)</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L270-L300"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">fuse_deconv_and_bn</span><span class="p">(</span><span class="n">deconv</span><span class="p">,</span> <span class="n">bn</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Fuse ConvTranspose2d and BatchNorm2d layers for inference optimization.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        deconv (nn.ConvTranspose2d): Transposed convolutional layer to fuse.</span>
<span></span><span class="sd">        bn (nn.BatchNorm2d): Batch normalization layer to fuse.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (nn.ConvTranspose2d): The fused transposed convolutional layer with gradients disabled.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; deconv = nn.ConvTranspose2d(16, 3, 3)</span>
<span></span><span class="sd">        &gt;&gt;&gt; bn = nn.BatchNorm2d(3)</span>
<span></span><span class="sd">        &gt;&gt;&gt; fused_deconv = fuse_deconv_and_bn(deconv, bn)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="c1"># Compute fused weights</span>
<span></span>    <span class="n">w_deconv</span> <span class="o">=</span> <span class="n">deconv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">deconv</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span></span>    <span class="n">w_bn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">eps</span> <span class="o">+</span> <span class="n">bn</span><span class="o">.</span><span class="n">running_var</span><span class="p">)))</span>
<span></span>    <span class="n">deconv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">w_bn</span><span class="p">,</span> <span class="n">w_deconv</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">deconv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span></span>
<span></span>    <span class="c1"># Compute fused bias</span>
<span></span>    <span class="n">b_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">deconv</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">deconv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">deconv</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">deconv</span><span class="o">.</span><span class="n">bias</span>
<span></span>    <span class="n">b_bn</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">bias</span> <span class="o">-</span> <span class="n">bn</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">running_var</span> <span class="o">+</span> <span class="n">bn</span><span class="o">.</span><span class="n">eps</span><span class="p">))</span>
<span></span>    <span class="n">fused_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">w_bn</span><span class="p">,</span> <span class="n">b_conv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_bn</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">deconv</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span></span>        <span class="n">deconv</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">"bias"</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">fused_bias</span><span class="p">))</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">deconv</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fused_bias</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">deconv</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.model_info"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.model_info</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">model_info</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">detailed</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">imgsz</span> <span class="o">=</span> <span class="mi">640</span><span class="p">)</span>
</code></pre></div><p>Print and return detailed model information layer by layer.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>Model to analyze.</td><td><em>required</em></td></tr><tr><td><code>detailed</code></td><td><code>bool, optional</code></td><td>Whether to print detailed layer information.</td><td><code>False</code></td></tr><tr><td><code>verbose</code></td><td><code>bool, optional</code></td><td>Whether to print model information.</td><td><code>True</code></td></tr><tr><td><code>imgsz</code></td><td><code>int | list, optional</code></td><td>Input image size.</td><td><code>640</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>n_l (int)</code></td><td>Number of layers.</td></tr><tr><td><code>n_p (int)</code></td><td>Number of parameters.</td></tr><tr><td><code>n_g (int)</code></td><td>Number of gradients.</td></tr><tr><td><code>flops (float)</code></td><td>GFLOPs.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L303-L344"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">model_info</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">detailed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Print and return detailed model information layer by layer.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (nn.Module): Model to analyze.</span>
<span></span><span class="sd">        detailed (bool, optional): Whether to print detailed layer information.</span>
<span></span><span class="sd">        verbose (bool, optional): Whether to print model information.</span>
<span></span><span class="sd">        imgsz (int | list, optional): Input image size.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        n_l (int): Number of layers.</span>
<span></span><span class="sd">        n_p (int): Number of parameters.</span>
<span></span><span class="sd">        n_g (int): Number of gradients.</span>
<span></span><span class="sd">        flops (float): GFLOPs.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">verbose</span><span class="p">:</span>
<span></span>        <span class="k">return</span>
<span></span>    <span class="n">n_p</span> <span class="o">=</span> <span class="n">get_num_params</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c1"># number of parameters</span>
<span></span>    <span class="n">n_g</span> <span class="o">=</span> <span class="n">get_num_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c1"># number of gradients</span>
<span></span>    <span class="n">layers</span> <span class="o">=</span> <span class="nb">__import__</span><span class="p">(</span><span class="s2">"collections"</span><span class="p">)</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="n">n_l</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>  <span class="c1"># number of layers</span>
<span></span>    <span class="k">if</span> <span class="n">detailed</span><span class="p">:</span>
<span></span>        <span class="n">h</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'layer'</span><span class="si">:</span><span class="s2">&gt;5</span><span class="si">}{</span><span class="s1">'name'</span><span class="si">:</span><span class="s2">&gt;40</span><span class="si">}{</span><span class="s1">'type'</span><span class="si">:</span><span class="s2">&gt;20</span><span class="si">}{</span><span class="s1">'gradient'</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}{</span><span class="s1">'parameters'</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}{</span><span class="s1">'shape'</span><span class="si">:</span><span class="s2">&gt;20</span><span class="si">}{</span><span class="s1">'mu'</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}{</span><span class="s1">'sigma'</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">"</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span></span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">mn</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
<span></span>            <span class="n">mn</span> <span class="o">=</span> <span class="n">mn</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"module_list."</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
<span></span>            <span class="n">mt</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
<span></span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">_parameters</span><span class="p">):</span>
<span></span>                <span class="k">for</span> <span class="n">pn</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span></span>                    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
<span></span>                        <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">&gt;5g</span><span class="si">}{</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">mn</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">pn</span><span class="si">}</span><span class="s1">'</span><span class="si">:</span><span class="s2">&gt;40</span><span class="si">}{</span><span class="n">mt</span><span class="si">:</span><span class="s2">&gt;20</span><span class="si">}{</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="si">!r:</span><span class="s2">&gt;10</span><span class="si">}{</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;12g</span><span class="si">}{</span><span class="nb">list</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">!s:</span><span class="s2">&gt;20</span><span class="si">}{</span><span class="n">p</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;10.3g</span><span class="si">}{</span><span class="n">p</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;10.3g</span><span class="si">}{</span><span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'torch.'</span><span class="p">,</span><span class="w"> </span><span class="s1">''</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">"</span>
<span></span>                    <span class="p">)</span>
<span></span>            <span class="k">else</span><span class="p">:</span>  <span class="c1"># layers with no learnable params</span>
<span></span>                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">&gt;5g</span><span class="si">}{</span><span class="n">mn</span><span class="si">:</span><span class="s2">&gt;40</span><span class="si">}{</span><span class="n">mt</span><span class="si">:</span><span class="s2">&gt;20</span><span class="si">}{</span><span class="kc">False</span><span class="si">!r:</span><span class="s2">&gt;10</span><span class="si">}{</span><span class="mi">0</span><span class="si">:</span><span class="s2">&gt;12g</span><span class="si">}{</span><span class="p">[]</span><span class="si">!s:</span><span class="s2">&gt;20</span><span class="si">}{</span><span class="s1">'-'</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}{</span><span class="s1">'-'</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}{</span><span class="s1">'-'</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">flops</span> <span class="o">=</span> <span class="n">get_flops</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgsz</span><span class="p">)</span>  <span class="c1"># imgsz may be int or list, i.e. imgsz=640 or imgsz=[640, 320]</span>
<span></span>    <span class="n">fused</span> <span class="o">=</span> <span class="s2">" (fused)"</span> <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"is_fused"</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="kc">False</span><span class="p">)()</span> <span class="k">else</span> <span class="s2">""</span>
<span></span>    <span class="n">fs</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">", </span><span class="si">{</span><span class="n">flops</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GFLOPs"</span> <span class="k">if</span> <span class="n">flops</span> <span class="k">else</span> <span class="s2">""</span>
<span></span>    <span class="n">yaml_file</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"yaml_file"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"yaml"</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"yaml_file"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
<span></span>    <span class="n">model_name</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"yolo"</span><span class="p">,</span> <span class="s2">"YOLO"</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">"Model"</span>
<span></span>    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> summary</span><span class="si">{</span><span class="n">fused</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">n_l</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> layers, </span><span class="si">{</span><span class="n">n_p</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> parameters, </span><span class="si">{</span><span class="n">n_g</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> gradients</span><span class="si">{</span><span class="n">fs</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">n_l</span><span class="p">,</span> <span class="n">n_p</span><span class="p">,</span> <span class="n">n_g</span><span class="p">,</span> <span class="n">flops</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.get_num_params"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.get_num_params</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_num_params</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div><p>Return the total number of parameters in a YOLO model.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L347-L349"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_num_params</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Return the total number of parameters in a YOLO model."""</span>
<span></span>    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.get_num_gradients"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.get_num_gradients</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_num_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div><p>Return the total number of parameters with gradients in a YOLO model.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L352-L354"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_num_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Return the total number of parameters with gradients in a YOLO model."""</span>
<span></span>    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.model_info_for_loggers"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.model_info_for_loggers</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">model_info_for_loggers</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
</code></pre></div><p>Return model info dict with useful model information.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>trainer</code></td><td><code>ultralytics.engine.trainer.BaseTrainer</code></td><td>The trainer object containing model and validation data.</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dict</code></td><td>Dictionary containing model parameters, GFLOPs, and inference speeds.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="n">YOLOv8n</span> <span class="n">info</span> <span class="k">for</span> <span class="n">loggers</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
<span></span><span class="o">...</span>    <span class="s2">"model/parameters"</span><span class="p">:</span> <span class="mi">3151904</span><span class="p">,</span>
<span></span><span class="o">...</span>    <span class="s2">"model/GFLOPs"</span><span class="p">:</span> <span class="mf">8.746</span><span class="p">,</span>
<span></span><span class="o">...</span>    <span class="s2">"model/speed_ONNX(ms)"</span><span class="p">:</span> <span class="mf">41.244</span><span class="p">,</span>
<span></span><span class="o">...</span>    <span class="s2">"model/speed_TensorRT(ms)"</span><span class="p">:</span> <span class="mf">3.211</span><span class="p">,</span>
<span></span><span class="o">...</span>    <span class="s2">"model/speed_PyTorch(ms)"</span><span class="p">:</span> <span class="mf">18.755</span><span class="p">,</span>
<span></span><span class="o">...</span><span class="p">}</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L357-L387"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">model_info_for_loggers</span><span class="p">(</span><span class="n">trainer</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Return model info dict with useful model information.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        trainer (ultralytics.engine.trainer.BaseTrainer): The trainer object containing model and validation data.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (dict): Dictionary containing model parameters, GFLOPs, and inference speeds.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        YOLOv8n info for loggers</span>
<span></span><span class="sd">        &gt;&gt;&gt; results = {</span>
<span></span><span class="sd">        ...    "model/parameters": 3151904,</span>
<span></span><span class="sd">        ...    "model/GFLOPs": 8.746,</span>
<span></span><span class="sd">        ...    "model/speed_ONNX(ms)": 41.244,</span>
<span></span><span class="sd">        ...    "model/speed_TensorRT(ms)": 3.211,</span>
<span></span><span class="sd">        ...    "model/speed_PyTorch(ms)": 18.755,</span>
<span></span><span class="sd">        ...}</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">profile</span><span class="p">:</span>  <span class="c1"># profile ONNX and TensorRT times</span>
<span></span>        <span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics.utils.benchmarks</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProfileModels</span>
<span></span>
<span></span>        <span class="n">results</span> <span class="o">=</span> <span class="n">ProfileModels</span><span class="p">([</span><span class="n">trainer</span><span class="o">.</span><span class="n">last</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span></span>        <span class="n">results</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"model/name"</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># only return PyTorch times from most recent validation</span>
<span></span>        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
<span></span>            <span class="s2">"model/parameters"</span><span class="p">:</span> <span class="n">get_num_params</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">),</span>
<span></span>            <span class="s2">"model/GFLOPs"</span><span class="p">:</span> <span class="nb">round</span><span class="p">(</span><span class="n">get_flops</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">),</span> <span class="mi">3</span><span class="p">),</span>
<span></span>        <span class="p">}</span>
<span></span>    <span class="n">results</span><span class="p">[</span><span class="s2">"model/speed_PyTorch(ms)"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">validator</span><span class="o">.</span><span class="n">speed</span><span class="p">[</span><span class="s2">"inference"</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.get_flops"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.get_flops</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_flops</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgsz</span> <span class="o">=</span> <span class="mi">640</span><span class="p">)</span>
</code></pre></div><p>Calculate FLOPs (floating point operations) for a model in billions.</p><p>Attempts two calculation methods: first with a stride-based tensor for efficiency, then falls back to full image size if needed (e.g., for RTDETR models). Returns 0.0 if thop library is unavailable or calculation fails.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>The model to calculate FLOPs for.</td><td><em>required</em></td></tr><tr><td><code>imgsz</code></td><td><code>int | list, optional</code></td><td>Input image size.</td><td><code>640</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>float</code></td><td>The model FLOPs in billions.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L390-L427"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_flops</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Calculate FLOPs (floating point operations) for a model in billions.</span>
<span></span>
<span></span><span class="sd">    Attempts two calculation methods: first with a stride-based tensor for efficiency, then falls back to full image</span>
<span></span><span class="sd">    size if needed (e.g., for RTDETR models). Returns 0.0 if thop library is unavailable or calculation fails.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (nn.Module): The model to calculate FLOPs for.</span>
<span></span><span class="sd">        imgsz (int | list, optional): Input image size.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (float): The model FLOPs in billions.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="kn">import</span><span class="w"> </span><span class="nn">thop</span>
<span></span>    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
<span></span>        <span class="n">thop</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># conda support without 'ultralytics-thop' installed</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">thop</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># if not installed return 0.0 GFLOPs</span>
<span></span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="n">model</span> <span class="o">=</span> <span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span></span>        <span class="n">p</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span></span>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">imgsz</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
<span></span>            <span class="n">imgsz</span> <span class="o">=</span> <span class="p">[</span><span class="n">imgsz</span><span class="p">,</span> <span class="n">imgsz</span><span class="p">]</span>  <span class="c1"># expand if int/float</span>
<span></span>        <span class="k">try</span><span class="p">:</span>
<span></span>            <span class="c1"># Method 1: Use stride-based input tensor</span>
<span></span>            <span class="n">stride</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="mi">32</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"stride"</span><span class="p">)</span> <span class="k">else</span> <span class="mi">32</span>  <span class="c1"># max stride</span>
<span></span>            <span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># input image in BCHW format</span>
<span></span>            <span class="n">flops</span> <span class="o">=</span> <span class="n">thop</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">im</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># stride GFLOPs</span>
<span></span>            <span class="k">return</span> <span class="n">flops</span> <span class="o">*</span> <span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">stride</span> <span class="o">*</span> <span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">stride</span>  <span class="c1"># imgsz GFLOPs</span>
<span></span>        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<span></span>            <span class="c1"># Method 2: Use actual image size (required for RTDETR models)</span>
<span></span>            <span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">*</span><span class="n">imgsz</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># input image in BCHW format</span>
<span></span>            <span class="k">return</span> <span class="n">thop</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">im</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># imgsz GFLOPs</span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.get_flops_with_torch_profiler"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.get_flops_with_torch_profiler</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_flops_with_torch_profiler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgsz</span> <span class="o">=</span> <span class="mi">640</span><span class="p">)</span>
</code></pre></div><p>Compute model FLOPs using torch profiler (alternative to thop package, but 2-10x slower).</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>The model to calculate FLOPs for.</td><td><em>required</em></td></tr><tr><td><code>imgsz</code></td><td><code>int | list, optional</code></td><td>Input image size.</td><td><code>640</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>float</code></td><td>The model's FLOPs in billions.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L430-L460"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_flops_with_torch_profiler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Compute model FLOPs using torch profiler (alternative to thop package, but 2-10x slower).</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (nn.Module): The model to calculate FLOPs for.</span>
<span></span><span class="sd">        imgsz (int | list, optional): Input image size.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (float): The model's FLOPs in billions.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">TORCH_2_0</span><span class="p">:</span>  <span class="c1"># torch profiler implemented in torch&gt;=2.0</span>
<span></span>        <span class="k">return</span> <span class="mf">0.0</span>
<span></span>    <span class="n">model</span> <span class="o">=</span> <span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span></span>    <span class="n">p</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">imgsz</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
<span></span>        <span class="n">imgsz</span> <span class="o">=</span> <span class="p">[</span><span class="n">imgsz</span><span class="p">,</span> <span class="n">imgsz</span><span class="p">]</span>  <span class="c1"># expand if int/float</span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="c1"># Use stride size for input tensor</span>
<span></span>        <span class="n">stride</span> <span class="o">=</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="mi">32</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"stride"</span><span class="p">)</span> <span class="k">else</span> <span class="mi">32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># max stride</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># input image in BCHW format</span>
<span></span>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">with_flops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
<span></span>            <span class="n">model</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="n">flops</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flops</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">())</span> <span class="o">/</span> <span class="mf">1e9</span>
<span></span>        <span class="n">flops</span> <span class="o">=</span> <span class="n">flops</span> <span class="o">*</span> <span class="n">imgsz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">stride</span> <span class="o">*</span> <span class="n">imgsz</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">stride</span>  <span class="c1"># 640x640 GFLOPs</span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<span></span>        <span class="c1"># Use actual image size for input tensor (i.e. required for RTDETR models)</span>
<span></span>        <span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">*</span><span class="n">imgsz</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># input image in BCHW format</span>
<span></span>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">with_flops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
<span></span>            <span class="n">model</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span></span>        <span class="n">flops</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flops</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">())</span> <span class="o">/</span> <span class="mf">1e9</span>
<span></span>    <span class="k">return</span> <span class="n">flops</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.initialize_weights"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.initialize_weights</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div><p>Initialize model weights to random values.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td></td><td></td><td><em>required</em></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L463-L473"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Initialize model weights to random values."""</span>
<span></span>    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
<span></span>        <span class="n">t</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">:</span>
<span></span>            <span class="k">pass</span>  <span class="c1"># nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')</span>
<span></span>        <span class="k">elif</span> <span class="n">t</span> <span class="ow">is</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">:</span>
<span></span>            <span class="n">m</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span></span>            <span class="n">m</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.03</span>
<span></span>        <span class="k">elif</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">{</span><span class="n">nn</span><span class="o">.</span><span class="n">Hardswish</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">}:</span>
<span></span>            <span class="n">m</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.scale_img"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.scale_img</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">scale_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ratio</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">same_shape</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">gs</span> <span class="o">=</span> <span class="mi">32</span><span class="p">)</span>
</code></pre></div><p>Scale and pad an image tensor, optionally maintaining aspect ratio and padding to gs multiple.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>img</code></td><td><code>torch.Tensor</code></td><td>Input image tensor.</td><td><em>required</em></td></tr><tr><td><code>ratio</code></td><td><code>float, optional</code></td><td>Scaling ratio.</td><td><code>1.0</code></td></tr><tr><td><code>same_shape</code></td><td><code>bool, optional</code></td><td>Whether to maintain the same shape.</td><td><code>False</code></td></tr><tr><td><code>gs</code></td><td><code>int, optional</code></td><td>Grid size for padding.</td><td><code>32</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>torch.Tensor</code></td><td>Scaled and padded image tensor.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L476-L495"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">scale_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">same_shape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gs</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Scale and pad an image tensor, optionally maintaining aspect ratio and padding to gs multiple.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        img (torch.Tensor): Input image tensor.</span>
<span></span><span class="sd">        ratio (float, optional): Scaling ratio.</span>
<span></span><span class="sd">        same_shape (bool, optional): Whether to maintain the same shape.</span>
<span></span><span class="sd">        gs (int, optional): Grid size for padding.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (torch.Tensor): Scaled and padded image tensor.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="n">ratio</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">img</span>
<span></span>    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
<span></span>    <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">))</span>  <span class="c1"># new size</span>
<span></span>    <span class="n">img</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># resize</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">same_shape</span><span class="p">:</span>  <span class="c1"># pad/crop img</span>
<span></span>        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">/</span> <span class="n">gs</span><span class="p">)</span> <span class="o">*</span> <span class="n">gs</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
<span></span>    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">w</span> <span class="o">-</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="n">h</span> <span class="o">-</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.447</span><span class="p">)</span>  <span class="c1"># value = imagenet mean</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.copy_attr"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.copy_attr</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">copy_attr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">include</span> <span class="o">=</span> <span class="p">(),</span> <span class="n">exclude</span> <span class="o">=</span> <span class="p">())</span>
</code></pre></div><p>Copy attributes from object 'b' to object 'a', with options to include/exclude certain attributes.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>a</code></td><td><code>Any</code></td><td>Destination object to copy attributes to.</td><td><em>required</em></td></tr><tr><td><code>b</code></td><td><code>Any</code></td><td>Source object to copy attributes from.</td><td><em>required</em></td></tr><tr><td><code>include</code></td><td><code>tuple, optional</code></td><td>Attributes to include. If empty, all attributes are included.</td><td><code>()</code></td></tr><tr><td><code>exclude</code></td><td><code>tuple, optional</code></td><td>Attributes to exclude.</td><td><code>()</code></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L498-L511"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">copy_attr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">include</span><span class="o">=</span><span class="p">(),</span> <span class="n">exclude</span><span class="o">=</span><span class="p">()):</span>
<span></span><span class="w">    </span><span class="sd">"""Copy attributes from object 'b' to object 'a', with options to include/exclude certain attributes.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        a (Any): Destination object to copy attributes to.</span>
<span></span><span class="sd">        b (Any): Source object to copy attributes from.</span>
<span></span><span class="sd">        include (tuple, optional): Attributes to include. If empty, all attributes are included.</span>
<span></span><span class="sd">        exclude (tuple, optional): Attributes to exclude.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">b</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span></span>        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">include</span><span class="p">)</span> <span class="ow">and</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">include</span><span class="p">)</span> <span class="ow">or</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"_"</span><span class="p">)</span> <span class="ow">or</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">exclude</span><span class="p">:</span>
<span></span>            <span class="k">continue</span>
<span></span>        <span class="k">else</span><span class="p">:</span>
<span></span>            <span class="nb">setattr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.intersect_dicts"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.intersect_dicts</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">intersect_dicts</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">exclude</span> <span class="o">=</span> <span class="p">())</span>
</code></pre></div><p>Return a dictionary of intersecting keys with matching shapes, excluding 'exclude' keys, using da values.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>da</code></td><td><code>dict</code></td><td>First dictionary.</td><td><em>required</em></td></tr><tr><td><code>db</code></td><td><code>dict</code></td><td>Second dictionary.</td><td><em>required</em></td></tr><tr><td><code>exclude</code></td><td><code>tuple, optional</code></td><td>Keys to exclude.</td><td><code>()</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dict</code></td><td>Dictionary of intersecting keys with matching shapes.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L514-L525"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">intersect_dicts</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="p">()):</span>
<span></span><span class="w">    </span><span class="sd">"""Return a dictionary of intersecting keys with matching shapes, excluding 'exclude' keys, using da values.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        da (dict): First dictionary.</span>
<span></span><span class="sd">        db (dict): Second dictionary.</span>
<span></span><span class="sd">        exclude (tuple, optional): Keys to exclude.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (dict): Dictionary of intersecting keys with matching shapes.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">da</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">db</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">exclude</span><span class="p">)</span> <span class="ow">and</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">}</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.is_parallel"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.is_parallel</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">is_parallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div><p>Return True if model is of type DP or DDP.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>nn.Module</code></td><td>Model to check.</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>bool</code></td><td>True if model is DataParallel or DistributedDataParallel.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L528-L537"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">is_parallel</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Return True if model is of type DP or DDP.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (nn.Module): Model to check.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (bool): True if model is DataParallel or DistributedDataParallel.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">))</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.unwrap_model"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.unwrap_model</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unwrap_model</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
</code></pre></div><p>Unwrap compiled and parallel models to get the base model.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>m</code></td><td><code>nn.Module</code></td><td>A model that may be wrapped by torch.compile (._orig_mod) or parallel wrappers such as<br/> DataParallel/DistributedDataParallel (.module).</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>m (nn.Module)</code></td><td>The unwrapped base model without compile or parallel wrappers.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L540-L556"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unwrap_model</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Unwrap compiled and parallel models to get the base model.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        m (nn.Module): A model that may be wrapped by torch.compile (._orig_mod) or parallel wrappers such as</span>
<span></span><span class="sd">            DataParallel/DistributedDataParallel (.module).</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        m (nn.Module): The unwrapped base model without compile or parallel wrappers.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span></span>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">"_orig_mod"</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">_orig_mod</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span>            <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">_orig_mod</span>
<span></span>        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">"module"</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span></span>            <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">module</span>
<span></span>        <span class="k">else</span><span class="p">:</span>
<span></span>            <span class="k">return</span> <span class="n">m</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.one_cycle"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.one_cycle</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">one_cycle</span><span class="p">(</span><span class="n">y1</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">steps</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</code></pre></div><p>Return a lambda function for sinusoidal ramp from y1 to y2 <a href="https://arxiv.org/pdf/1812.01187.pdf">https://arxiv.org/pdf/1812.01187.pdf</a>.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>y1</code></td><td><code>float, optional</code></td><td>Initial value.</td><td><code>0.0</code></td></tr><tr><td><code>y2</code></td><td><code>float, optional</code></td><td>Final value.</td><td><code>1.0</code></td></tr><tr><td><code>steps</code></td><td><code>int, optional</code></td><td>Number of steps.</td><td><code>100</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>function</code></td><td>Lambda function for computing the sinusoidal ramp.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L559-L570"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">one_cycle</span><span class="p">(</span><span class="n">y1</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">y2</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Return a lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        y1 (float, optional): Initial value.</span>
<span></span><span class="sd">        y2 (float, optional): Final value.</span>
<span></span><span class="sd">        steps (int, optional): Number of steps.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (function): Lambda function for computing the sinusoidal ramp.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">max</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="n">steps</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y2</span> <span class="o">-</span> <span class="n">y1</span><span class="p">)</span> <span class="o">+</span> <span class="n">y1</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.init_seeds"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.init_seeds</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_seeds</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</code></pre></div><p>Initialize random number generator (RNG) seeds <a href="https://pytorch.org/docs/stable/notes/randomness.html">https://pytorch.org/docs/stable/notes/randomness.html</a>.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>seed</code></td><td><code>int, optional</code></td><td>Random seed.</td><td><code>0</code></td></tr><tr><td><code>deterministic</code></td><td><code>bool, optional</code></td><td>Whether to set deterministic algorithms.</td><td><code>False</code></td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L573-L595"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_seeds</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        seed (int, optional): Random seed.</span>
<span></span><span class="sd">        deterministic (bool, optional): Whether to set deterministic algorithms.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span></span>    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># for Multi-GPU, exception safe</span>
<span></span>    <span class="c1"># torch.backends.cudnn.benchmark = True  # AutoBatch problem https://github.com/ultralytics/yolov5/issues/9287</span>
<span></span>    <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
<span></span>        <span class="k">if</span> <span class="n">TORCH_2_0</span><span class="p">:</span>
<span></span>            <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">warn_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># warn if deterministic is not possible</span>
<span></span>            <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUBLAS_WORKSPACE_CONFIG"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">":4096:8"</span>
<span></span>            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"PYTHONHASHSEED"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span></span>        <span class="k">else</span><span class="p">:</span>
<span></span>            <span class="n">LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Upgrade to torch&gt;=2.0.0 for deterministic training."</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">unset_deterministic</span><span class="p">()</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.unset_deterministic"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.unset_deterministic</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unset_deterministic</span><span class="p">()</span>
</code></pre></div><p>Unset all the configurations applied for deterministic training.</p><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L598-L603"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unset_deterministic</span><span class="p">():</span>
<span></span><span class="w">    </span><span class="sd">"""Unset all the configurations applied for deterministic training."""</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"CUBLAS_WORKSPACE_CONFIG"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span></span>    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"PYTHONHASHSEED"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.strip_optimizer"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.strip_optimizer</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">strip_optimizer</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span> <span class="o">=</span> <span class="s2">"best.pt"</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span> <span class="n">updates</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
</code></pre></div><p>Strip optimizer from 'f' to finalize training, optionally save as 's'.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>f</code></td><td><code>str | Path</code></td><td>File path to model to strip the optimizer from.</td><td><code>"best.pt"</code></td></tr><tr><td><code>s</code></td><td><code>str, optional</code></td><td>File path to save the model with stripped optimizer to. If not provided, 'f' will be<br/> overwritten.</td><td><code>""</code></td></tr><tr><td><code>updates</code></td><td><code>dict, optional</code></td><td>A dictionary of updates to overlay onto the checkpoint before saving.</td><td><code>None</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dict</code></td><td>The combined checkpoint dictionary.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics.utils.torch_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">strip_optimizer</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"path/to/model/checkpoints"</span><span class="p">)</span><span class="o">.</span><span class="n">rglob</span><span class="p">(</span><span class="s2">"*.pt"</span><span class="p">):</span>
<span></span><span class="o">&gt;&gt;&gt;</span>    <span class="n">strip_optimizer</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L670-L727"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">strip_optimizer</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span> <span class="o">=</span> <span class="s2">"best.pt"</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span> <span class="n">updates</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span></span><span class="w">    </span><span class="sd">"""Strip optimizer from 'f' to finalize training, optionally save as 's'.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        f (str | Path): File path to model to strip the optimizer from.</span>
<span></span><span class="sd">        s (str, optional): File path to save the model with stripped optimizer to. If not provided, 'f' will be</span>
<span></span><span class="sd">            overwritten.</span>
<span></span><span class="sd">        updates (dict, optional): A dictionary of updates to overlay onto the checkpoint before saving.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (dict): The combined checkpoint dictionary.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; from pathlib import Path</span>
<span></span><span class="sd">        &gt;&gt;&gt; from ultralytics.utils.torch_utils import strip_optimizer</span>
<span></span><span class="sd">        &gt;&gt;&gt; for f in Path("path/to/model/checkpoints").rglob("*.pt"):</span>
<span></span><span class="sd">        &gt;&gt;&gt;    strip_optimizer(f)</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch_load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">))</span>
<span></span>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="s2">"checkpoint is not a Python dictionary"</span>
<span></span>        <span class="k">assert</span> <span class="s2">"model"</span> <span class="ow">in</span> <span class="n">x</span><span class="p">,</span> <span class="s2">"'model' missing from checkpoint"</span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Skipping </span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s2">, not a valid Ultralytics model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>        <span class="k">return</span> <span class="p">{}</span>
<span></span>
<span></span>    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
<span></span>        <span class="s2">"date"</span><span class="p">:</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">isoformat</span><span class="p">(),</span>
<span></span>        <span class="s2">"version"</span><span class="p">:</span> <span class="n">__version__</span><span class="p">,</span>
<span></span>        <span class="s2">"license"</span><span class="p">:</span> <span class="s2">"AGPL-3.0 License (https://ultralytics.com/license)"</span><span class="p">,</span>
<span></span>        <span class="s2">"docs"</span><span class="p">:</span> <span class="s2">"https://docs.ultralytics.com"</span><span class="p">,</span>
<span></span>    <span class="p">}</span>
<span></span>
<span></span>    <span class="c1"># Update model</span>
<span></span>    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"ema"</span><span class="p">):</span>
<span></span>        <span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="s2">"ema"</span><span class="p">]</span>  <span class="c1"># replace model with EMA</span>
<span></span>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">],</span> <span class="s2">"args"</span><span class="p">):</span>
<span></span>        <span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># convert from IterableSimpleNamespace to dict</span>
<span></span>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">],</span> <span class="s2">"criterion"</span><span class="p">):</span>
<span></span>        <span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># strip loss criterion</span>
<span></span>    <span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>  <span class="c1"># to FP16</span>
<span></span>    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span></span>        <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>
<span></span>    <span class="c1"># Update other keys</span>
<span></span>    <span class="n">args</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">DEFAULT_CFG_DICT</span><span class="p">,</span> <span class="o">**</span><span class="n">x</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"train_args"</span><span class="p">,</span> <span class="p">{})}</span>  <span class="c1"># combine args</span>
<span></span>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="s2">"optimizer"</span><span class="p">,</span> <span class="s2">"best_fitness"</span><span class="p">,</span> <span class="s2">"ema"</span><span class="p">,</span> <span class="s2">"updates"</span><span class="p">,</span> <span class="s2">"scaler"</span><span class="p">:</span>  <span class="c1"># keys</span>
<span></span>        <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>    <span class="n">x</span><span class="p">[</span><span class="s2">"epoch"</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span></span>    <span class="n">x</span><span class="p">[</span><span class="s2">"train_args"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">DEFAULT_CFG_KEYS</span><span class="p">}</span>  <span class="c1"># strip non-default keys</span>
<span></span>    <span class="c1"># x['model'].args = x['train_args']</span>
<span></span>
<span></span>    <span class="c1"># Save</span>
<span></span>    <span class="n">combined</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">metadata</span><span class="p">,</span> <span class="o">**</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="n">updates</span> <span class="ow">or</span> <span class="p">{})}</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">combined</span><span class="p">,</span> <span class="n">s</span> <span class="ow">or</span> <span class="n">f</span><span class="p">)</span>  <span class="c1"># combine dicts (prefer to the right)</span>
<span></span>    <span class="n">mb</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">s</span> <span class="ow">or</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e6</span>  <span class="c1"># file size</span>
<span></span>    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Optimizer stripped from </span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="sa">f</span><span class="s1">' saved as </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s1">,'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">''</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">mb</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">MB"</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">combined</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.convert_optimizer_state_dict_to_fp16"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.convert_optimizer_state_dict_to_fp16</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">convert_optimizer_state_dict_to_fp16</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</code></pre></div><p>Convert the state_dict of a given optimizer to FP16, focusing on the 'state' key for tensor conversions.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>state_dict</code></td><td><code>dict</code></td><td>Optimizer state dictionary.</td><td><em>required</em></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dict</code></td><td>Converted optimizer state dictionary with FP16 tensors.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L730-L744"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">convert_optimizer_state_dict_to_fp16</span><span class="p">(</span><span class="n">state_dict</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Convert the state_dict of a given optimizer to FP16, focusing on the 'state' key for tensor conversions.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        state_dict (dict): Optimizer state dictionary.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (dict): Converted optimizer state dictionary with FP16 tensors.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">"state"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<span></span>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span></span>            <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">"step"</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">v</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
<span></span>                <span class="n">state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
<span></span>
<span></span>    <span class="k">return</span> <span class="n">state_dict</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.cuda_memory_usage"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.cuda_memory_usage</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">cuda_memory_usage</span><span class="p">(</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div><p>Monitor and manage CUDA memory usage.</p><p>This function checks if CUDA is available and, if so, empties the CUDA cache to free up unused memory. It then yields a dictionary containing memory usage information, which can be updated by the caller. Finally, it updates the dictionary with the amount of memory reserved by CUDA on the specified device.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>device</code></td><td><code>torch.device, optional</code></td><td>The CUDA device to query memory usage for.</td><td><code>None</code></td></tr></tbody></table><p><strong>Yields</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>dict</code></td><td>A dictionary with a key 'memory' initialized to 0, which will be updated with the reserved memory.</td></tr></tbody></table><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L748-L769"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="nd">@contextmanager</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">cuda_memory_usage</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Monitor and manage CUDA memory usage.</span>
<span></span>
<span></span><span class="sd">    This function checks if CUDA is available and, if so, empties the CUDA cache to free up unused memory. It then</span>
<span></span><span class="sd">    yields a dictionary containing memory usage information, which can be updated by the caller. Finally, it updates the</span>
<span></span><span class="sd">    dictionary with the amount of memory reserved by CUDA on the specified device.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        device (torch.device, optional): The CUDA device to query memory usage for.</span>
<span></span>
<span></span><span class="sd">    Yields:</span>
<span></span><span class="sd">        (dict): A dictionary with a key 'memory' initialized to 0, which will be updated with the reserved memory.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="n">cuda_info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">memory</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
<span></span>        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span></span>        <span class="k">try</span><span class="p">:</span>
<span></span>            <span class="k">yield</span> <span class="n">cuda_info</span>
<span></span>        <span class="k">finally</span><span class="p">:</span>
<span></span>            <span class="n">cuda_info</span><span class="p">[</span><span class="s2">"memory"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="k">yield</span> <span class="n">cuda_info</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.profile_ops"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.profile_ops</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">profile_ops</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_num_obj</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div><p>Ultralytics speed, memory and FLOPs profiler.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>input</code></td><td><code>torch.Tensor | list</code></td><td>Input tensor(s) to profile.</td><td><em>required</em></td></tr><tr><td><code>ops</code></td><td><code>nn.Module | list</code></td><td>Model or list of operations to profile.</td><td><em>required</em></td></tr><tr><td><code>n</code></td><td><code>int, optional</code></td><td>Number of iterations to average.</td><td><code>10</code></td></tr><tr><td><code>device</code></td><td><code>str | torch.device, optional</code></td><td>Device to profile on.</td><td><code>None</code></td></tr><tr><td><code>max_num_obj</code></td><td><code>int, optional</code></td><td>Maximum number of objects for simulation.</td><td><code>0</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>list</code></td><td>Profile results for each operation.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics.utils.torch_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">profile_ops</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">m1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">()</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">profile_ops</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># profile over 100 iterations</span>
</code></pre></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L772-L854"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">profile_ops</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_num_obj</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Ultralytics speed, memory and FLOPs profiler.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        input (torch.Tensor | list): Input tensor(s) to profile.</span>
<span></span><span class="sd">        ops (nn.Module | list): Model or list of operations to profile.</span>
<span></span><span class="sd">        n (int, optional): Number of iterations to average.</span>
<span></span><span class="sd">        device (str | torch.device, optional): Device to profile on.</span>
<span></span><span class="sd">        max_num_obj (int, optional): Maximum number of objects for simulation.</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        (list): Profile results for each operation.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; from ultralytics.utils.torch_utils import profile_ops</span>
<span></span><span class="sd">        &gt;&gt;&gt; input = torch.randn(16, 3, 640, 640)</span>
<span></span><span class="sd">        &gt;&gt;&gt; m1 = lambda x: x * torch.sigmoid(x)</span>
<span></span><span class="sd">        &gt;&gt;&gt; m2 = nn.SiLU()</span>
<span></span><span class="sd">        &gt;&gt;&gt; profile_ops(input, [m1, m2], n=100)  # profile over 100 iterations</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="kn">import</span><span class="w"> </span><span class="nn">thop</span>
<span></span>    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
<span></span>        <span class="n">thop</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># conda support without 'ultralytics-thop' installed</span>
<span></span>
<span></span>    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
<span></span>        <span class="n">device</span> <span class="o">=</span> <span class="n">select_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
<span></span>        <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'Params'</span><span class="si">:</span><span class="s2">&gt;12s</span><span class="si">}{</span><span class="s1">'GFLOPs'</span><span class="si">:</span><span class="s2">&gt;12s</span><span class="si">}{</span><span class="s1">'GPU_mem (GB)'</span><span class="si">:</span><span class="s2">&gt;14s</span><span class="si">}{</span><span class="s1">'forward (ms)'</span><span class="si">:</span><span class="s2">&gt;14s</span><span class="si">}{</span><span class="s1">'backward (ms)'</span><span class="si">:</span><span class="s2">&gt;14s</span><span class="si">}</span><span class="s2">"</span>
<span></span>        <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'input'</span><span class="si">:</span><span class="s2">&gt;24s</span><span class="si">}{</span><span class="s1">'output'</span><span class="si">:</span><span class="s2">&gt;24s</span><span class="si">}</span><span class="s2">"</span>
<span></span>    <span class="p">)</span>
<span></span>    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="c1"># attempt to free unused memory</span>
<span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span></span>    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">input</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="nb">input</span><span class="p">]:</span>
<span></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">ops</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">ops</span><span class="p">]:</span>
<span></span>            <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">"to"</span><span class="p">)</span> <span class="k">else</span> <span class="n">m</span>  <span class="c1"># device</span>
<span></span>            <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">"half"</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span> <span class="k">else</span> <span class="n">m</span>
<span></span>            <span class="n">tf</span><span class="p">,</span> <span class="n">tb</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># dt forward, backward</span>
<span></span>            <span class="k">try</span><span class="p">:</span>
<span></span>                <span class="n">flops</span> <span class="o">=</span> <span class="n">thop</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">m</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">thop</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1"># GFLOPs</span>
<span></span>            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<span></span>                <span class="n">flops</span> <span class="o">=</span> <span class="mi">0</span>
<span></span>
<span></span>            <span class="k">try</span><span class="p">:</span>
<span></span>                <span class="n">mem</span> <span class="o">=</span> <span class="mi">0</span>
<span></span>                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span></span>                    <span class="k">with</span> <span class="n">cuda_memory_usage</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">as</span> <span class="n">cuda_info</span><span class="p">:</span>
<span></span>                        <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">time_sync</span><span class="p">()</span>
<span></span>                        <span class="n">y</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span></span>                        <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">time_sync</span><span class="p">()</span>
<span></span>                        <span class="k">try</span><span class="p">:</span>
<span></span>                            <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">yi</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span></span>                            <span class="n">t</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">time_sync</span><span class="p">()</span>
<span></span>                        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>  <span class="c1"># no backward method</span>
<span></span>                            <span class="c1"># print(e)  # for debug</span>
<span></span>                            <span class="n">t</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"nan"</span><span class="p">)</span>
<span></span>                    <span class="n">mem</span> <span class="o">+=</span> <span class="n">cuda_info</span><span class="p">[</span><span class="s2">"memory"</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e9</span>  <span class="c1"># (GB)</span>
<span></span>                    <span class="n">tf</span> <span class="o">+=</span> <span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">/</span> <span class="n">n</span>  <span class="c1"># ms per op forward</span>
<span></span>                    <span class="n">tb</span> <span class="o">+=</span> <span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">/</span> <span class="n">n</span>  <span class="c1"># ms per op backward</span>
<span></span>                    <span class="k">if</span> <span class="n">max_num_obj</span><span class="p">:</span>  <span class="c1"># simulate training with predictions per image grid (for AutoBatch)</span>
<span></span>                        <span class="k">with</span> <span class="n">cuda_memory_usage</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">as</span> <span class="n">cuda_info</span><span class="p">:</span>
<span></span>                            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
<span></span>                                <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span></span>                                <span class="n">max_num_obj</span><span class="p">,</span>
<span></span>                                <span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span><span class="o">.</span><span class="n">tolist</span><span class="p">())),</span>
<span></span>                                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<span></span>                                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<span></span>                            <span class="p">)</span>
<span></span>                        <span class="n">mem</span> <span class="o">+=</span> <span class="n">cuda_info</span><span class="p">[</span><span class="s2">"memory"</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e9</span>  <span class="c1"># (GB)</span>
<span></span>                <span class="n">s_in</span><span class="p">,</span> <span class="n">s_out</span> <span class="o">=</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="s2">"list"</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>  <span class="c1"># shapes</span>
<span></span>                <span class="n">p</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1"># parameters</span>
<span></span>                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s2">12</span><span class="si">}{</span><span class="n">flops</span><span class="si">:</span><span class="s2">12.4g</span><span class="si">}{</span><span class="n">mem</span><span class="si">:</span><span class="s2">&gt;14.3f</span><span class="si">}{</span><span class="n">tf</span><span class="si">:</span><span class="s2">14.4g</span><span class="si">}{</span><span class="n">tb</span><span class="si">:</span><span class="s2">14.4g</span><span class="si">}{</span><span class="n">s_in</span><span class="si">!s:</span><span class="s2">&gt;24s</span><span class="si">}{</span><span class="n">s_out</span><span class="si">!s:</span><span class="s2">&gt;24s</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">p</span><span class="p">,</span> <span class="n">flops</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">tf</span><span class="p">,</span> <span class="n">tb</span><span class="p">,</span> <span class="n">s_in</span><span class="p">,</span> <span class="n">s_out</span><span class="p">])</span>
<span></span>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span></span>                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span></span>                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span></span>            <span class="k">finally</span><span class="p">:</span>
<span></span>                <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="c1"># attempt to free unused memory</span>
<span></span>                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
<span></span>    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></details><p><br/><br/><hr/><br/></p><h2 id="ultralytics.utils.torch_utils.attempt_compile"><span class="doc-kind doc-kind-function">function</span> <code>ultralytics.utils.torch_utils.attempt_compile</code></h2><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">attempt_compile</span><span class="p">(</span>
<span></span>    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<span></span>    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span></span>    <span class="n">imgsz</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span>
<span></span>    <span class="n">use_autocast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">warmup</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"default"</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
</code></pre></div><p>Compile a model with torch.compile and optionally warm up the graph to reduce first-iteration latency.</p><p>This utility attempts to compile the provided model using the inductor backend with dynamic shapes enabled and an autotuning mode. If compilation is unavailable or fails, the original model is returned unchanged. An optional warmup performs a single forward pass on a dummy input to prime the compiled graph and measure compile/warmup time.</p><p><strong>Args</strong></p><table><thead><tr><th>Name</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>model</code></td><td><code>torch.nn.Module</code></td><td>Model to compile.</td><td><em>required</em></td></tr><tr><td><code>device</code></td><td><code>torch.device</code></td><td>Inference device used for warmup and autocast decisions.</td><td><em>required</em></td></tr><tr><td><code>imgsz</code></td><td><code>int, optional</code></td><td>Square input size to create a dummy tensor with shape (1, 3, imgsz, imgsz) for warmup.</td><td><code>640</code></td></tr><tr><td><code>use_autocast</code></td><td><code>bool, optional</code></td><td>Whether to run warmup under autocast on CUDA or MPS devices.</td><td><code>False</code></td></tr><tr><td><code>warmup</code></td><td><code>bool, optional</code></td><td>Whether to execute a single dummy forward pass to warm up the compiled model.</td><td><code>False</code></td></tr><tr><td><code>mode</code></td><td><code>bool | str, optional</code></td><td>torch.compile mode. True â†’ "default", False â†’ no compile, or a string like<br/> "default", "reduce-overhead", "max-autotune-no-cudagraphs".</td><td><code>"default"</code></td></tr></tbody></table><p><strong>Returns</strong></p><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><code>model (torch.nn.Module)</code></td><td>Compiled model if compilation succeeds, otherwise the original unmodified model.</td></tr></tbody></table><p><strong>Examples</strong></p><div class="highlight"><pre><span></span><code><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda:0"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Try to compile and warm up a model with a 640x640 input</span>
<span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">attempt_compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span> <span class="n">use_autocast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><div class="admonition note"><p class="admonition-title">Notes</p><ul><li>If the current PyTorch build does not provide torch.compile, the function returns the input model immediately.</li><li>Warmup runs under torch.inference_mode and may use torch.autocast for CUDA/MPS to align compute precision.</li><li>CUDA devices are synchronized after warmup to account for asynchronous kernel execution.</li></ul></div><details><summary>Source code in <code>ultralytics/utils/torch_utils.py</code></summary><a href="https://github.com/ultralytics/ultralytics/blob/main/ultralytics/utils/torch_utils.py#L908-L984"><i aria-hidden="true" class="fa-brands fa-github" style="margin-right:6px;"></i>View on GitHub</a><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">attempt_compile</span><span class="p">(</span>
<span></span>    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<span></span>    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span></span>    <span class="n">imgsz</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span>
<span></span>    <span class="n">use_autocast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">warmup</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span></span>    <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"default"</span><span class="p">,</span>
<span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Compile a model with torch.compile and optionally warm up the graph to reduce first-iteration latency.</span>
<span></span>
<span></span><span class="sd">    This utility attempts to compile the provided model using the inductor backend with dynamic shapes enabled and an</span>
<span></span><span class="sd">    autotuning mode. If compilation is unavailable or fails, the original model is returned unchanged. An optional</span>
<span></span><span class="sd">    warmup performs a single forward pass on a dummy input to prime the compiled graph and measure compile/warmup time.</span>
<span></span>
<span></span><span class="sd">    Args:</span>
<span></span><span class="sd">        model (torch.nn.Module): Model to compile.</span>
<span></span><span class="sd">        device (torch.device): Inference device used for warmup and autocast decisions.</span>
<span></span><span class="sd">        imgsz (int, optional): Square input size to create a dummy tensor with shape (1, 3, imgsz, imgsz) for warmup.</span>
<span></span><span class="sd">        use_autocast (bool, optional): Whether to run warmup under autocast on CUDA or MPS devices.</span>
<span></span><span class="sd">        warmup (bool, optional): Whether to execute a single dummy forward pass to warm up the compiled model.</span>
<span></span><span class="sd">        mode (bool | str, optional): torch.compile mode. True â†’ "default", False â†’ no compile, or a string like</span>
<span></span><span class="sd">            "default", "reduce-overhead", "max-autotune-no-cudagraphs".</span>
<span></span>
<span></span><span class="sd">    Returns:</span>
<span></span><span class="sd">        model (torch.nn.Module): Compiled model if compilation succeeds, otherwise the original unmodified model.</span>
<span></span>
<span></span><span class="sd">    Examples:</span>
<span></span><span class="sd">        &gt;&gt;&gt; device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")</span>
<span></span><span class="sd">        &gt;&gt;&gt; # Try to compile and warm up a model with a 640x640 input</span>
<span></span><span class="sd">        &gt;&gt;&gt; model = attempt_compile(model, device=device, imgsz=640, use_autocast=True, warmup=True)</span>
<span></span>
<span></span><span class="sd">    Notes:</span>
<span></span><span class="sd">        - If the current PyTorch build does not provide torch.compile, the function returns the input model immediately.</span>
<span></span><span class="sd">        - Warmup runs under torch.inference_mode and may use torch.autocast for CUDA/MPS to align compute precision.</span>
<span></span><span class="sd">        - CUDA devices are synchronized after warmup to account for asynchronous kernel execution.</span>
<span></span><span class="sd">    """</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">"compile"</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">mode</span><span class="p">:</span>
<span></span>        <span class="k">return</span> <span class="n">model</span>
<span></span>
<span></span>    <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
<span></span>        <span class="n">mode</span> <span class="o">=</span> <span class="s2">"default"</span>
<span></span>    <span class="n">prefix</span> <span class="o">=</span> <span class="n">colorstr</span><span class="p">(</span><span class="s2">"compile:"</span><span class="p">)</span>
<span></span>    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> starting torch.compile with '</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">' mode..."</span><span class="p">)</span>
<span></span>    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">"max-autotune"</span><span class="p">:</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> mode='</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">' not recommended, using mode='max-autotune-no-cudagraphs' instead"</span><span class="p">)</span>
<span></span>        <span class="n">mode</span> <span class="o">=</span> <span class="s2">"max-autotune-no-cudagraphs"</span>
<span></span>    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">"inductor"</span><span class="p">)</span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> torch.compile failed, continuing uncompiled: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>        <span class="k">return</span> <span class="n">model</span>
<span></span>    <span class="n">t_compile</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
<span></span>
<span></span>    <span class="n">t_warm</span> <span class="o">=</span> <span class="mf">0.0</span>
<span></span>    <span class="k">if</span> <span class="n">warmup</span><span class="p">:</span>
<span></span>        <span class="c1"># Use a single dummy tensor to build the graph shape state and reduce first-iteration latency</span>
<span></span>        <span class="n">dummy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">imgsz</span><span class="p">,</span> <span class="n">imgsz</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">use_autocast</span> <span class="ow">and</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">"cuda"</span><span class="p">:</span>
<span></span>            <span class="n">dummy</span> <span class="o">=</span> <span class="n">dummy</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
<span></span>        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span></span>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
<span></span>            <span class="k">if</span> <span class="n">use_autocast</span> <span class="ow">and</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">"cuda"</span><span class="p">,</span> <span class="s2">"mps"</span><span class="p">}:</span>
<span></span>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">):</span>
<span></span>                    <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">dummy</span><span class="p">)</span>
<span></span>            <span class="k">else</span><span class="p">:</span>
<span></span>                <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">dummy</span><span class="p">)</span>
<span></span>        <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">"cuda"</span><span class="p">:</span>
<span></span>            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span></span>        <span class="n">t_warm</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t1</span>
<span></span>
<span></span>    <span class="n">total</span> <span class="o">=</span> <span class="n">t_compile</span> <span class="o">+</span> <span class="n">t_warm</span>
<span></span>    <span class="k">if</span> <span class="n">warmup</span><span class="p">:</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> complete in </span><span class="si">{</span><span class="n">total</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s (compile </span><span class="si">{</span><span class="n">t_compile</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s + warmup </span><span class="si">{</span><span class="n">t_warm</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s)"</span><span class="p">)</span>
<span></span>    <span class="k">else</span><span class="p">:</span>
<span></span>        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> compile complete in </span><span class="si">{</span><span class="n">t_compile</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s (no warmup)"</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></details><p><br/><br/></p><br/><br/><div class="git-info"><div class="dates-container"><span class="date-item" title="This page was first created on November 12, 2023"><span class="hover-item">ğŸ“…</span> Created 2 years ago </span><span class="date-item" title="This page was last updated on November 23, 2025"><span class="hover-item">âœï¸</span> Updated 2 months ago </span></div><div class="authors-container"><a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (13 changes)"><img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (3 changes)"><img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Y-T-G" title="Y-T-G (2 changes)"><img alt="Y-T-G" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/32206511?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Burhan-Q" title="Burhan-Q (2 changes)"><img alt="Burhan-Q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62214284?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)"><img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/></a></div></div><div class="share-buttons"><button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https%3A%2F%2Fdocs.ultralytics.com%2Freference%2Futils%2Ftorch_utils%2F', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet </button><button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdocs.ultralytics.com%2Freference%2Futils%2Ftorch_utils%2F', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share </button></div><br/></article></div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div><button class="md-top md-icon" data-md-component="top" hidden="" type="button"><svg class="lucide lucide-circle-arrow-up" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><path d="m16 12-4-4-4 4M12 16V8"></path></svg> Back to top
</button></main><footer class="md-footer"><nav aria-label="Footer" class="md-footer__inner md-grid"><a aria-label="Previous: tal" class="md-footer__link md-footer__link--prev" href="../tal/"><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-left" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12 19-7-7 7-7M19 12H5"></path></svg></div><div class="md-footer__title"><span class="md-footer__direction"> Previous </span><div class="md-ellipsis"> tal </div></div></a><a aria-label="Next: tqdm" class="md-footer__link md-footer__link--next" href="../tqdm/"><div class="md-footer__title"><span class="md-footer__direction"> Next </span><div class="md-ellipsis"> tqdm </div></div><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-right" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 12h14M12 5l7 7-7 7"></path></svg></div></a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-copyright"><div class="md-copyright__highlight"><a href="https://www.ultralytics.com/" target="_blank">Â© 2026 Ultralytics Inc.</a> All rights reserved. </div> Made with <a href="https://zensical.org/" rel="noopener" target="_blank"> Zensical </a></div><div class="md-social"><a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg></a></div></div></div></footer></div><div class="md-dialog" data-md-component="dialog"><div class="md-dialog__inner md-typeset"></div></div><div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"annotate":null,"base":"../../..","features":["content.action.edit","content.code.annotate","content.code.copy","content.tooltips","toc.follow","navigation.top","navigation.tabs","navigation.tabs.sticky","navigation.prune","navigation.footer","navigation.tracking","navigation.instant","navigation.instant.progress","navigation.indexes","navigation.sections","content.tabs.link"],"search":"../../../assets/javascripts/workers/search.e2d2d235.min.js","tags":null,"translations":{"clipboard.copied":"Copied to clipboard","clipboard.copy":"Copy to clipboard","search.result.more.one":"1 more on this page","search.result.more.other":"# more on this page","search.result.none":"No matching documents","search.result.one":"1 matching document","search.result.other":"# matching documents","search.result.placeholder":"Type to start searching","search.result.term.missing":"Missing","select.version":"Select version"},"version":null}</script>
<script src="../../../assets/javascripts/bundle.8ffeb9c9.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ultralytics/llm@v0.1.8/js/chat.min.js"></script>
<script src="https://unpkg.com/tablesort@5.6.0/dist/tablesort.min.js"></script>
<script src="../../../javascript/extra.js"></script>
<script src="../../../javascript/giscus.js"></script>
<script src="../../../javascript/tablesort.js"></script>
</body></html>