 <!DOCTYPE html><html class="no-js" lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="Discover YOLOv7, the breakthrough real-time object detector with top speed and accuracy. Learn about key features, usage, and performance metrics." name="description"/><meta content="Ultralytics" name="author"/><link href="https://docs.ultralytics.com/models/yolov7/" rel="canonical"/><link href="../yolov6/" rel="prev"/><link href="../yolov8/" rel="next"/><link href="/" hreflang="en" rel="alternate"/><link href="/zh/" hreflang="zh" rel="alternate"/><link href="/ko/" hreflang="ko" rel="alternate"/><link href="/ja/" hreflang="ja" rel="alternate"/><link href="/ru/" hreflang="ru" rel="alternate"/><link href="/de/" hreflang="de" rel="alternate"/><link href="/fr/" hreflang="fr" rel="alternate"/><link href="/es/" hreflang="es" rel="alternate"/><link href="/pt/" hreflang="pt" rel="alternate"/><link href="/it/" hreflang="it" rel="alternate"/><link href="/tr/" hreflang="tr" rel="alternate"/><link href="/vi/" hreflang="vi" rel="alternate"/><link href="/ar/" hreflang="ar" rel="alternate"/><link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/><meta content="zensical-0.0.17" name="generator"/><title>YOLOv7: Trainable Bag-of-Freebies - Ultralytics YOLO Docs</title><link href="../../assets/stylesheets/modern/main.d4922b3c.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/modern/palette.dfe2e883.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,500,500i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link href="../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<style data-doc-kind="true">.doc-kind{display:inline-flex;align-items:center;gap:0.25em;padding:0.21em 0.59em;border-radius:999px;font-weight:700;font-size:0.81em;letter-spacing:0.06em;text-transform:uppercase;line-height:1;color:var(--doc-kind-color,#f8fafc);background:var(--doc-kind-bg,rgba(255,255,255,0.12));}.doc-kind-class{--doc-kind-color:#039dfc;--doc-kind-bg:rgba(3,157,252,0.22);}.doc-kind-function{--doc-kind-color:#fc9803;--doc-kind-bg:rgba(252,152,3,0.22);}.doc-kind-method{--doc-kind-color:#ef5eff;--doc-kind-bg:rgba(239,94,255,0.22);}.doc-kind-property{--doc-kind-color:#02e835;--doc-kind-bg:rgba(2,232,53,0.22);}</style><meta content="YOLOv7: Trainable Bag-of-Freebies" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/models/yolov7/" property="og:url"/><meta content="YOLOv7: Trainable Bag-of-Freebies" property="og:title"/><meta content="" property="og:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/models/yolov7/" property="twitter:url"/><meta content="YOLOv7: Trainable Bag-of-Freebies" property="twitter:title"/><meta content="" property="twitter:description"/><meta content="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": ["Article", "FAQPage"], "headline": "YOLOv7: Trainable Bag-of-Freebies", "image": ["https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2026-01-20 01:06:12 +0000", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "", "mainEntity": [{"@type": "Question", "name": "What is YOLOv7 and why is it considered a breakthrough in real-time object detection?", "acceptedAnswer": {"@type": "Answer", "text": "YOLOv7, released in July 2022, was a significant real-time object detection model that achieved excellent speed and accuracy at its time of release. It surpassed contemporary models such as YOLOX, YOLOv5, and PPYOLOE in both parameters usage and inference speed. YOLOv7's distinguishing features include its model re-parameterization and dynamic label assignment, which optimize its performance without increasing inference costs. For more technical details about its architecture and comparison metrics with other state-of-the-art object detectors, refer to the YOLOv7 paper."}}, {"@type": "Question", "name": "How does YOLOv7 improve on previous YOLO models like YOLOv4 and YOLOv5?", "acceptedAnswer": {"@type": "Answer", "text": "YOLOv7 introduces several innovations, including model re-parameterization and dynamic label assignment, which enhance the training process and improve inference accuracy. Compared to YOLOv5, YOLOv7 significantly boosts speed and accuracy. For instance, YOLOv7-X improves accuracy by 2.2% and reduces parameters by 22% compared to YOLOv5-X. Detailed comparisons can be found in the performance table YOLOv7 comparison with SOTA object detectors."}}, {"@type": "Question", "name": "Can I use YOLOv7 with Ultralytics tools and platforms?", "acceptedAnswer": {"@type": "Answer", "text": "As of now, Ultralytics only supports YOLOv7 ONNX and TensorRT inference. To run the ONNX and TensorRT exported version of YOLOv7 with Ultralytics, check the Usage Examples section."}}, {"@type": "Question", "name": "How do I train a custom YOLOv7 model using my dataset?", "acceptedAnswer": {"@type": "Answer", "text": "To install and train a custom YOLOv7 model, follow these steps:"}}, {"@type": "Question", "name": "What are the key features and optimizations introduced in YOLOv7?", "acceptedAnswer": {"@type": "Answer", "text": "YOLOv7 offers several key features that revolutionize real-time object detection: For further details on these features, see the YOLOv7 Overview section."}}]}</script></head><body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" for="__drawer"></label><div data-md-component="skip"><a class="md-skip" href="#yolov7-trainable-bag-of-freebies"> Skip to content </a></div><div data-md-component="announce"><aside class="md-banner"><div class="md-banner__inner md-grid md-typeset"><a class="banner-wrapper" href="https://docs.ultralytics.com/models/yolo26"><div class="banner-content-wrapper"><img alt="Ultralytics YOLO26" height="40" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/6967372a0d67914985d322e7_Ultralytics%20YOLO26%201.svg"/><p>Built End-to-End. Built for the Edge.</p></div></a></div></aside></div><header class="md-header md-header--shadow md-header--lifted" data-md-component="header"><nav aria-label="Header" class="md-header__inner md-grid"><a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a><label class="md-header__button md-icon" for="__drawer"><svg class="lucide lucide-menu" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 5h16M4 12h16M4 19h16"></path></svg></label><div class="md-header__title" data-md-component="header-title"><div class="md-header__ellipsis"><div class="md-header__topic"><span class="md-ellipsis"> Ultralytics YOLO Docs </span></div><div class="md-header__topic" data-md-component="header-topic"><span class="md-ellipsis"> YOLOv7: Trainable Bag-of-Freebies </span></div></div></div><form class="md-header__option" data-md-component="palette"><input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option"><div class="md-select"><button aria-label="Select language" class="md-header__button md-icon"><svg class="lucide lucide-languages" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m5 8 6 6M4 14l6-6 2-3M2 5h12M7 2h1M22 22l-5-10-5 10M14 18h6"></path></svg></button><div class="md-select__inner"><ul class="md-select__list"><li class="md-select__item"><a class="md-select__link" href="/" hreflang="en"> üá¨üáß English </a></li><li class="md-select__item"><a class="md-select__link" href="/zh/" hreflang="zh"> üá®üá≥ ÁÆÄ‰Ωì‰∏≠Êñá </a></li><li class="md-select__item"><a class="md-select__link" href="/ko/" hreflang="ko"> üá∞üá∑ ÌïúÍµ≠Ïñ¥ </a></li><li class="md-select__item"><a class="md-select__link" href="/ja/" hreflang="ja"> üáØüáµ Êó•Êú¨Ë™û </a></li><li class="md-select__item"><a class="md-select__link" href="/ru/" hreflang="ru"> üá∑üá∫ –†—É—Å—Å–∫–∏–π </a></li><li class="md-select__item"><a class="md-select__link" href="/de/" hreflang="de"> üá©üá™ Deutsch </a></li><li class="md-select__item"><a class="md-select__link" href="/fr/" hreflang="fr"> üá´üá∑ Fran√ßais </a></li><li class="md-select__item"><a class="md-select__link" href="/es/" hreflang="es"> üá™üá∏ Espa√±ol </a></li><li class="md-select__item"><a class="md-select__link" href="/pt/" hreflang="pt"> üáµüáπ Portugu√™s </a></li><li class="md-select__item"><a class="md-select__link" href="/it/" hreflang="it"> üáÆüáπ Italiano </a></li><li class="md-select__item"><a class="md-select__link" href="/tr/" hreflang="tr"> üáπüá∑ T√ºrk√ße </a></li><li class="md-select__item"><a class="md-select__link" href="/vi/" hreflang="vi"> üáªüá≥ Ti·∫øng Vi·ªát </a></li><li class="md-select__item"><a class="md-select__link" href="/ar/" hreflang="ar"> üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© </a></li></ul></div></div></div><div class="md-header__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div></nav><nav aria-label="Tabs" class="md-tabs" data-md-component="tabs"><div class="md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a class="md-tabs__link" href="../.."> Home </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../modes/"> Modes </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../tasks/"> Tasks </a></li><li class="md-tabs__item md-tabs__item--active"><a class="md-tabs__link" href="../"> Models </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../datasets/"> Datasets </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../solutions/"> Solutions </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../guides/"> Guides </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../integrations/"> Integrations </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../platform/"> Platform </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../reference/__init__/"> Reference </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../help/"> Help </a></li></ul></div></nav></header><div class="md-container" data-md-component="container"><main class="md-main" data-md-component="main"><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0"><label class="md-nav__title" for="__drawer"><a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a> Ultralytics YOLO Docs </label><div class="md-nav__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../.."><span class="md-ellipsis"> Home </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../modes/"><span class="md-ellipsis"> Ultralytics YOLO26 Modes </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../tasks/"><span class="md-ellipsis"> Computer Vision Tasks Supported by Ultralytics YOLO26 </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../"><span class="md-ellipsis"> Models </span></a><label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="true" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1"><label class="md-nav__title" for="__nav_4"><span class="md-nav__icon md-icon"></span> Models </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../yolov3/"><span class="md-ellipsis"> YOLOv3 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolov4/"><span class="md-ellipsis"> YOLOv4 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolov5/"><span class="md-ellipsis"> YOLOv5 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolov6/"><span class="md-ellipsis"> YOLOv6 </span></a></li><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/><label class="md-nav__link md-nav__link--active" for="__toc"><span class="md-ellipsis"> YOLOv7 </span><span class="md-nav__icon md-icon"></span></label><a class="md-nav__link md-nav__link--active" href="./"><span class="md-ellipsis"> YOLOv7 </span></a><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#comparison-of-sota-object-detectors"><span class="md-ellipsis"> Comparison of SOTA object detectors </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#overview"><span class="md-ellipsis"> Overview </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#key-features"><span class="md-ellipsis"> Key Features </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#usage-examples"><span class="md-ellipsis"> Usage Examples </span></a><nav aria-label="Usage Examples" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#onnx-export"><span class="md-ellipsis"> ONNX Export </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#tensorrt-export"><span class="md-ellipsis"> TensorRT Export </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#citations-and-acknowledgments"><span class="md-ellipsis"> Citations and Acknowledgments </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#what-is-yolov7-and-why-is-it-considered-a-breakthrough-in-real-time-object-detection"><span class="md-ellipsis"> What is YOLOv7 and why is it considered a breakthrough in real-time object detection? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-does-yolov7-improve-on-previous-yolo-models-like-yolov4-and-yolov5"><span class="md-ellipsis"> How does YOLOv7 improve on previous YOLO models like YOLOv4 and YOLOv5? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#can-i-use-yolov7-with-ultralytics-tools-and-platforms"><span class="md-ellipsis"> Can I use YOLOv7 with Ultralytics tools and platforms? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-do-i-train-a-custom-yolov7-model-using-my-dataset"><span class="md-ellipsis"> How do I train a custom YOLOv7 model using my dataset? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#what-are-the-key-features-and-optimizations-introduced-in-yolov7"><span class="md-ellipsis"> What are the key features and optimizations introduced in YOLOv7? </span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../yolov8/"><span class="md-ellipsis"> YOLOv8 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolov9/"><span class="md-ellipsis"> YOLOv9 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolov10/"><span class="md-ellipsis"> YOLOv10 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo11/"><span class="md-ellipsis"> YOLO11 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo12/"><span class="md-ellipsis"> YOLO12 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo26/"><span class="md-ellipsis"> YOLO26 üöÄ </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../sam/"><span class="md-ellipsis"> SAM (Segment Anything Model) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../sam-2/"><span class="md-ellipsis"> SAM 2 (Segment Anything Model 2) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../sam-3/"><span class="md-ellipsis"> SAM 3 (Segment Anything Model 3) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../mobile-sam/"><span class="md-ellipsis"> MobileSAM (Mobile Segment Anything Model) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../fast-sam/"><span class="md-ellipsis"> FastSAM (Fast Segment Anything Model) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo-nas/"><span class="md-ellipsis"> YOLO-NAS (Neural Architecture Search) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../rtdetr/"><span class="md-ellipsis"> RT-DETR (Realtime Detection Transformer) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo-world/"><span class="md-ellipsis"> YOLO-World (Real-Time Open-Vocabulary Object Detection) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yoloe/"><span class="md-ellipsis"> YOLOE (Real-Time Seeing Anything) </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../datasets/"><span class="md-ellipsis"> Datasets </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../solutions/"><span class="md-ellipsis"> Solutions </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../guides/"><span class="md-ellipsis"> Guides </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../integrations/"><span class="md-ellipsis"> Integrations </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../platform/"><span class="md-ellipsis"> Platform </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../reference/__init__/"><span class="md-ellipsis"> Reference </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../help/"><span class="md-ellipsis"> Help </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#comparison-of-sota-object-detectors"><span class="md-ellipsis"> Comparison of SOTA object detectors </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#overview"><span class="md-ellipsis"> Overview </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#key-features"><span class="md-ellipsis"> Key Features </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#usage-examples"><span class="md-ellipsis"> Usage Examples </span></a><nav aria-label="Usage Examples" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#onnx-export"><span class="md-ellipsis"> ONNX Export </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#tensorrt-export"><span class="md-ellipsis"> TensorRT Export </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#citations-and-acknowledgments"><span class="md-ellipsis"> Citations and Acknowledgments </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#what-is-yolov7-and-why-is-it-considered-a-breakthrough-in-real-time-object-detection"><span class="md-ellipsis"> What is YOLOv7 and why is it considered a breakthrough in real-time object detection? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-does-yolov7-improve-on-previous-yolo-models-like-yolov4-and-yolov5"><span class="md-ellipsis"> How does YOLOv7 improve on previous YOLO models like YOLOv4 and YOLOv5? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#can-i-use-yolov7-with-ultralytics-tools-and-platforms"><span class="md-ellipsis"> Can I use YOLOv7 with Ultralytics tools and platforms? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-do-i-train-a-custom-yolov7-model-using-my-dataset"><span class="md-ellipsis"> How do I train a custom YOLOv7 model using my dataset? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#what-are-the-key-features-and-optimizations-introduced-in-yolov7"><span class="md-ellipsis"> What are the key features and optimizations introduced in YOLOv7? </span></a></li></ul></nav></li></ul></nav></div></div></div><div class="md-content" data-md-component="content"><article class="md-content__inner md-typeset"><a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/models/yolov7.md" rel="edit" title="Edit this page"><svg class="lucide lucide-file-pen" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"></path><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"></path></svg></a><a class="md-content__button md-icon" href="javascript:void(0)" onclick="copyMarkdownForLLM(this); return false;" title="Copy page in Markdown format"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></a><h1 id="yolov7-trainable-bag-of-freebies">YOLOv7: Trainable Bag-of-Freebies</h1><p>YOLOv7, released in July 2022, was a significant advancement in real-time object detection at its time of release. It achieved 56.8% AP on GPU V100, setting new benchmarks when introduced. YOLOv7 outperformed contemporary object detectors such as YOLOR, YOLOX, Scaled-YOLOv4, and YOLOv5 in speed and <a href="https://www.ultralytics.com/glossary/accuracy">accuracy</a>. The model is trained on the MS COCO dataset from scratch without using any other datasets or pretrained weights. Source code for YOLOv7 is available on GitHub. Note that newer models like <a href="../yolo11/">YOLO11</a> and <a href="../yolo26/">YOLO26</a> have since achieved higher accuracy with improved efficiency.</p><p><img alt="YOLOv7 comparison with SOTA object detectors" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/yolov7-comparison-sota-object-detectors.avif"/></p><h2 id="comparison-of-sota-object-detectors">Comparison of SOTA object detectors</h2><p>From the results in the YOLO comparison table we know that the proposed method has the best speed-accuracy trade-off comprehensively. If we compare YOLOv7-tiny-SiLU with YOLOv5-N (r6.1), our method is 127 fps faster and 10.7% more accurate on AP. In addition, YOLOv7 has 51.4% AP at frame rate of 161 fps, while PPYOLOE-L with the same AP has only 78 fps frame rate. In terms of parameter usage, YOLOv7 is 41% less than PPYOLOE-L.</p>
<script async="" src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script defer="" src="../../javascript/benchmark.js"></script>
<canvas active-models='["YOLOv7"]' height="400" id="modelComparisonChart" width="1024"></canvas><p>If we compare YOLOv7-X with 114 fps inference speed to YOLOv5-L (r6.1) with 99 fps inference speed, YOLOv7-X can improve AP by 3.9%. If YOLOv7-X is compared with YOLOv5-X (r6.1) of similar scale, the inference speed of YOLOv7-X is 31 fps faster. In addition, in terms the amount of parameters and computation, YOLOv7-X reduces 22% of parameters and 8% of computation compared to YOLOv5-X (r6.1), but improves AP by 2.2% (<a href="https://arxiv.org/pdf/2207.02696">Source</a>).</p><div class="admonition tip"><p class="admonition-title">Performance</p><div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="detection-coco" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="detection-coco">Detection (COCO)</label></div><div class="tabbed-content"><div class="tabbed-block"><table><thead><tr><th>Model</th><th>Params<br/><sup>(M)</sup></th><th>FLOPs<br/><sup>(G)</sup></th><th>Size<br/><sup>(pixels)</sup></th><th>FPS</th><th>AP<sup>test / val<br/>50-95</sup></th><th>AP<sup>test<br/>50</sup></th><th>AP<sup>test<br/>75</sup></th><th>AP<sup>test<br/>S</sup></th><th>AP<sup>test<br/>M</sup></th><th>AP<sup>test<br/>L</sup></th></tr></thead><tbody><tr><td><a href="https://github.com/Megvii-BaseDetection/YOLOX">YOLOX-S</a></td><td><strong>9.0</strong></td><td><strong>26.8</strong></td><td>640</td><td><strong>102</strong></td><td>40.5% / 40.5%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/Megvii-BaseDetection/YOLOX">YOLOX-M</a></td><td>25.3</td><td>73.8</td><td>640</td><td>81</td><td>47.2% / 46.9%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/Megvii-BaseDetection/YOLOX">YOLOX-L</a></td><td>54.2</td><td>155.6</td><td>640</td><td>69</td><td>50.1% / 49.7%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/Megvii-BaseDetection/YOLOX">YOLOX-X</a></td><td>99.1</td><td>281.9</td><td>640</td><td>58</td><td><strong>51.5% / 51.1%</strong></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/PaddlePaddle/PaddleDetection">PPYOLOE-S</a></td><td><strong>7.9</strong></td><td><strong>17.4</strong></td><td>640</td><td><strong>208</strong></td><td>43.1% / 42.7%</td><td>60.5%</td><td>46.6%</td><td>23.2%</td><td>46.4%</td><td>56.9%</td></tr><tr><td><a href="https://github.com/PaddlePaddle/PaddleDetection">PPYOLOE-M</a></td><td>23.4</td><td>49.9</td><td>640</td><td>123</td><td>48.9% / 48.6%</td><td>66.5%</td><td>53.0%</td><td>28.6%</td><td>52.9%</td><td>63.8%</td></tr><tr><td><a href="https://github.com/PaddlePaddle/PaddleDetection">PPYOLOE-L</a></td><td>52.2</td><td>110.1</td><td>640</td><td>78</td><td>51.4% / 50.9%</td><td>68.9%</td><td>55.6%</td><td>31.4%</td><td>55.3%</td><td>66.1%</td></tr><tr><td><a href="https://github.com/PaddlePaddle/PaddleDetection">PPYOLOE-X</a></td><td>98.4</td><td>206.6</td><td>640</td><td>45</td><td><strong>52.2% / 51.9%</strong></td><td><strong>69.9%</strong></td><td><strong>56.5%</strong></td><td><strong>33.3%</strong></td><td><strong>56.3%</strong></td><td><strong>66.4%</strong></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-N (r6.1)</a></td><td><strong>1.9</strong></td><td><strong>4.5</strong></td><td>640</td><td><strong>159</strong></td><td>- / 28.0%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-S (r6.1)</a></td><td>7.2</td><td>16.5</td><td>640</td><td>156</td><td>- / 37.4%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-M (r6.1)</a></td><td>21.2</td><td>49.0</td><td>640</td><td>122</td><td>- / 45.4%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-L (r6.1)</a></td><td>46.5</td><td>109.1</td><td>640</td><td>99</td><td>- / 49.0%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-X (r6.1)</a></td><td>86.7</td><td>205.7</td><td>640</td><td>83</td><td>- / <strong>50.7%</strong></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/WongKinYiu/yolor">YOLOR-CSP</a></td><td>52.9</td><td>120.4</td><td>640</td><td>106</td><td>51.1% / 50.8%</td><td>69.6%</td><td>55.7%</td><td>31.7%</td><td>55.3%</td><td>64.7%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolor">YOLOR-CSP-X</a></td><td>96.9</td><td>226.8</td><td>640</td><td>87</td><td>53.0% / 52.7%</td><td>71.4%</td><td>57.9%</td><td>33.7%</td><td>57.1%</td><td>66.8%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7-tiny-SiLU</a></td><td><strong>6.2</strong></td><td><strong>13.8</strong></td><td>640</td><td><strong>286</strong></td><td>38.7% / 38.7%</td><td>56.7%</td><td>41.7%</td><td>18.8%</td><td>42.4%</td><td>51.9%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7</a></td><td>36.9</td><td>104.7</td><td>640</td><td>161</td><td>51.4% / 51.2%</td><td>69.7%</td><td>55.9%</td><td>31.8%</td><td>55.5%</td><td>65.0%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7-X</a></td><td>71.3</td><td>189.9</td><td>640</td><td>114</td><td><strong>53.1% / 52.9%</strong></td><td><strong>71.2%</strong></td><td><strong>57.8%</strong></td><td><strong>33.8%</strong></td><td><strong>57.1%</strong></td><td><strong>67.4%</strong></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-N6 (r6.1)</a></td><td><strong>3.2</strong></td><td><strong>18.4</strong></td><td>1280</td><td><strong>123</strong></td><td>- / 36.0%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-S6 (r6.1)</a></td><td>12.6</td><td>67.2</td><td>1280</td><td>122</td><td>- / 44.8%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-M6 (r6.1)</a></td><td>35.7</td><td>200.0</td><td>1280</td><td>90</td><td>- / 51.3%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-L6 (r6.1)</a></td><td>76.8</td><td>445.6</td><td>1280</td><td>63</td><td>- / 53.7%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href="https://github.com/ultralytics/yolov5">YOLOv5-X6 (r6.1)</a></td><td>140.7</td><td>839.2</td><td>1280</td><td>38</td><td>- / <strong>55.0%</strong></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/WongKinYiu/yolor">YOLOR-P6</a></td><td><strong>37.2</strong></td><td><strong>325.6</strong></td><td>1280</td><td><strong>76</strong></td><td>53.9% / 53.5%</td><td>71.4%</td><td>58.9%</td><td>36.1%</td><td>57.7%</td><td>65.6%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolor">YOLOR-W6</a></td><td>79.8</td><td>453.2</td><td>1280</td><td>66</td><td>55.2% / 54.8%</td><td>72.7%</td><td>60.5%</td><td>37.7%</td><td>59.1%</td><td>67.1%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolor">YOLOR-E6</a></td><td>115.8</td><td>683.2</td><td>1280</td><td>45</td><td>55.8% / 55.7%</td><td>73.4%</td><td>61.1%</td><td>38.4%</td><td>59.7%</td><td>67.7%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolor">YOLOR-D6</a></td><td>151.7</td><td>935.6</td><td>1280</td><td>34</td><td><strong>56.5% / 56.1%</strong></td><td><strong>74.1%</strong></td><td><strong>61.9%</strong></td><td><strong>38.9%</strong></td><td><strong>60.4%</strong></td><td><strong>68.7%</strong></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7-W6</a></td><td><strong>70.4</strong></td><td><strong>360.0</strong></td><td>1280</td><td><strong>84</strong></td><td>54.9% / 54.6%</td><td>72.6%</td><td>60.1%</td><td>37.3%</td><td>58.7%</td><td>67.1%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7-E6</a></td><td>97.2</td><td>515.2</td><td>1280</td><td>56</td><td>56.0% / 55.9%</td><td>73.5%</td><td>61.2%</td><td>38.0%</td><td>59.9%</td><td>68.4%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7-D6</a></td><td>154.7</td><td>806.8</td><td>1280</td><td>44</td><td>56.6% / 56.3%</td><td>74.0%</td><td>61.8%</td><td>38.8%</td><td>60.1%</td><td>69.5%</td></tr><tr><td><a href="https://github.com/WongKinYiu/yolov7">YOLOv7-E6E</a></td><td>151.7</td><td>843.2</td><td>1280</td><td>36</td><td><strong>56.8% / 56.8%</strong></td><td><strong>74.4%</strong></td><td><strong>62.1%</strong></td><td><strong>39.3%</strong></td><td><strong>60.5%</strong></td><td><strong>69.0%</strong></td></tr></tbody></table></div></div></div></div><h2 id="overview">Overview</h2><p>Real-time object detection is an important component in many <a href="https://www.ultralytics.com/glossary/computer-vision-cv">computer vision</a> systems, including multi-<a href="https://www.ultralytics.com/glossary/object-tracking">object tracking</a>, autonomous driving, <a href="https://www.ultralytics.com/glossary/robotics">robotics</a>, and <a href="https://www.ultralytics.com/glossary/medical-image-analysis">medical image analysis</a>. In recent years, real-time object detection development has focused on designing efficient architectures and improving the inference speed of various CPUs, GPUs, and neural processing units (NPUs). YOLOv7 supports both mobile GPU and GPU devices, from the edge to the cloud.</p><p>Unlike traditional real-time object detectors that focus on architecture optimization, YOLOv7 introduces a focus on the optimization of the training process. This includes modules and optimization methods designed to improve the accuracy of object detection without increasing the inference cost, a concept known as the "trainable bag-of-freebies".</p><h2 id="key-features">Key Features</h2><p>YOLOv7 introduces several key features:</p><ol><li><p><strong>Model Re-parameterization</strong>: YOLOv7 proposes a planned re-parameterized model, which is a strategy applicable to layers in different networks with the concept of gradient propagation path.</p></li><li><p><strong>Dynamic Label Assignment</strong>: The training of the model with multiple output layers presents a new issue: "How to assign dynamic targets for the outputs of different branches?" To solve this problem, YOLOv7 introduces a new label assignment method called coarse-to-fine lead guided label assignment.</p></li><li><p><strong>Extended and Compound Scaling</strong>: YOLOv7 proposes "extend" and "compound scaling" methods for the real-time object detector that can effectively utilize parameters and computation.</p></li><li><p><strong>Efficiency</strong>: The method proposed by YOLOv7 can effectively reduce about 40% parameters and 50% computation of state-of-the-art real-time object detector, and has faster inference speed and higher detection accuracy.</p></li></ol><h2 id="usage-examples">Usage Examples</h2><p>As of the time of writing, Ultralytics only supports ONNX and TensorRT inference for YOLOv7.</p><h3 id="onnx-export">ONNX Export</h3><p>To use YOLOv7 ONNX model with Ultralytics:</p><ol><li><p>(Optional) Install Ultralytics and export an ONNX model to have the required dependencies automatically installed:</p><div class="highlight"><pre><span></span><code><span></span>pip<span class="w"> </span>install<span class="w"> </span>ultralytics
<span></span>yolo<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">model</span><span class="o">=</span>yolo26n.pt<span class="w"> </span><span class="nv">format</span><span class="o">=</span>onnx
</code></pre></div></li><li><p>Export the desired YOLOv7 model by using the exporter in the <a href="https://github.com/WongKinYiu/yolov7">YOLOv7 repo</a>:</p><div class="highlight"><pre><span></span><code><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/WongKinYiu/yolov7
<span></span><span class="nb">cd</span><span class="w"> </span>yolov7
<span></span>python<span class="w"> </span>export.py<span class="w"> </span>--weights<span class="w"> </span>yolov7-tiny.pt<span class="w"> </span>--grid<span class="w"> </span>--end2end<span class="w"> </span>--simplify<span class="w"> </span>--topk-all<span class="w"> </span><span class="m">100</span><span class="w"> </span>--iou-thres<span class="w"> </span><span class="m">0</span>.65<span class="w"> </span>--conf-thres<span class="w"> </span><span class="m">0</span>.35<span class="w"> </span>--img-size<span class="w"> </span><span class="m">640</span><span class="w"> </span><span class="m">640</span><span class="w"> </span>--max-wh<span class="w"> </span><span class="m">640</span>
</code></pre></div></li><li><p>Modify the ONNX model graph to be compatible with Ultralytics using the following script:</p><div class="highlight"><pre><span></span><code><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">onnx</span>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">onnx</span><span class="w"> </span><span class="kn">import</span> <span class="n">helper</span><span class="p">,</span> <span class="n">numpy_helper</span>
<span></span>
<span></span><span class="c1"># Load the ONNX model</span>
<span></span><span class="n">model_path</span> <span class="o">=</span> <span class="s2">"yolov7/yolov7-tiny.onnx"</span>  <span class="c1"># Replace with your model path</span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span></span><span class="n">graph</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span>
<span></span>
<span></span><span class="c1"># Fix input shape to batch size 1</span>
<span></span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span>
<span></span><span class="n">input_shape</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dim_value</span> <span class="o">=</span> <span class="mi">1</span>
<span></span>
<span></span><span class="c1"># Define the output of the original model</span>
<span></span><span class="n">original_output_name</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
<span></span>
<span></span><span class="c1"># Create slicing nodes</span>
<span></span><span class="n">sliced_output_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">original_output_name</span><span class="si">}</span><span class="s2">_sliced"</span>
<span></span>
<span></span><span class="c1"># Define initializers for slicing (remove the first value)</span>
<span></span><span class="n">start</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"slice_start"</span><span class="p">)</span>
<span></span><span class="n">end</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"slice_end"</span><span class="p">)</span>
<span></span><span class="n">axes</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"slice_axes"</span><span class="p">)</span>
<span></span><span class="n">steps</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"slice_steps"</span><span class="p">)</span>
<span></span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">steps</span><span class="p">])</span>
<span></span>
<span></span><span class="n">slice_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Slice"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">original_output_name</span><span class="p">,</span> <span class="s2">"slice_start"</span><span class="p">,</span> <span class="s2">"slice_end"</span><span class="p">,</span> <span class="s2">"slice_axes"</span><span class="p">,</span> <span class="s2">"slice_steps"</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">sliced_output_name</span><span class="p">],</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"SliceNode"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">slice_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Define segment slicing</span>
<span></span><span class="n">seg1_start</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"seg1_start"</span><span class="p">)</span>
<span></span><span class="n">seg1_end</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"seg1_end"</span><span class="p">)</span>
<span></span><span class="n">seg2_start</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"seg2_start"</span><span class="p">)</span>
<span></span><span class="n">seg2_end</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"seg2_end"</span><span class="p">)</span>
<span></span><span class="n">seg3_start</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"seg3_start"</span><span class="p">)</span>
<span></span><span class="n">seg3_end</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"seg3_end"</span><span class="p">)</span>
<span></span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">seg1_start</span><span class="p">,</span> <span class="n">seg1_end</span><span class="p">,</span> <span class="n">seg2_start</span><span class="p">,</span> <span class="n">seg2_end</span><span class="p">,</span> <span class="n">seg3_start</span><span class="p">,</span> <span class="n">seg3_end</span><span class="p">])</span>
<span></span>
<span></span><span class="c1"># Create intermediate tensors for segments</span>
<span></span><span class="n">segment_1_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">sliced_output_name</span><span class="si">}</span><span class="s2">_segment1"</span>
<span></span><span class="n">segment_2_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">sliced_output_name</span><span class="si">}</span><span class="s2">_segment2"</span>
<span></span><span class="n">segment_3_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">sliced_output_name</span><span class="si">}</span><span class="s2">_segment3"</span>
<span></span>
<span></span><span class="c1"># Add segment slicing nodes</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
<span></span>    <span class="p">[</span>
<span></span>        <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>            <span class="s2">"Slice"</span><span class="p">,</span>
<span></span>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">sliced_output_name</span><span class="p">,</span> <span class="s2">"seg1_start"</span><span class="p">,</span> <span class="s2">"seg1_end"</span><span class="p">,</span> <span class="s2">"slice_axes"</span><span class="p">,</span> <span class="s2">"slice_steps"</span><span class="p">],</span>
<span></span>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">segment_1_name</span><span class="p">],</span>
<span></span>            <span class="n">name</span><span class="o">=</span><span class="s2">"SliceSegment1"</span><span class="p">,</span>
<span></span>        <span class="p">),</span>
<span></span>        <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>            <span class="s2">"Slice"</span><span class="p">,</span>
<span></span>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">sliced_output_name</span><span class="p">,</span> <span class="s2">"seg2_start"</span><span class="p">,</span> <span class="s2">"seg2_end"</span><span class="p">,</span> <span class="s2">"slice_axes"</span><span class="p">,</span> <span class="s2">"slice_steps"</span><span class="p">],</span>
<span></span>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">segment_2_name</span><span class="p">],</span>
<span></span>            <span class="n">name</span><span class="o">=</span><span class="s2">"SliceSegment2"</span><span class="p">,</span>
<span></span>        <span class="p">),</span>
<span></span>        <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>            <span class="s2">"Slice"</span><span class="p">,</span>
<span></span>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">sliced_output_name</span><span class="p">,</span> <span class="s2">"seg3_start"</span><span class="p">,</span> <span class="s2">"seg3_end"</span><span class="p">,</span> <span class="s2">"slice_axes"</span><span class="p">,</span> <span class="s2">"slice_steps"</span><span class="p">],</span>
<span></span>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">segment_3_name</span><span class="p">],</span>
<span></span>            <span class="n">name</span><span class="o">=</span><span class="s2">"SliceSegment3"</span><span class="p">,</span>
<span></span>        <span class="p">),</span>
<span></span>    <span class="p">]</span>
<span></span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Concatenate the segments</span>
<span></span><span class="n">concat_output_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">sliced_output_name</span><span class="si">}</span><span class="s2">_concat"</span>
<span></span><span class="n">concat_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Concat"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">segment_1_name</span><span class="p">,</span> <span class="n">segment_3_name</span><span class="p">,</span> <span class="n">segment_2_name</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">concat_output_name</span><span class="p">],</span>
<span></span>    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"ConcatSwapped"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">concat_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Reshape to [1, -1, 6]</span>
<span></span><span class="n">reshape_shape</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"reshape_shape"</span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reshape_shape</span><span class="p">)</span>
<span></span>
<span></span><span class="n">final_output_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">concat_output_name</span><span class="si">}</span><span class="s2">_batched"</span>
<span></span><span class="n">reshape_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Reshape"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">concat_output_name</span><span class="p">,</span> <span class="s2">"reshape_shape"</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">final_output_name</span><span class="p">],</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"AddBatchDimension"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reshape_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Get the shape of the reshaped tensor</span>
<span></span><span class="n">shape_node_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_shape"</span>
<span></span><span class="n">shape_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Shape"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">final_output_name</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">shape_node_name</span><span class="p">],</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"GetShapeDim"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Extract the second dimension</span>
<span></span><span class="n">dim_1_index</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"dim_1_index"</span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dim_1_index</span><span class="p">)</span>
<span></span>
<span></span><span class="n">second_dim_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_dim1"</span>
<span></span><span class="n">gather_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Gather"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">shape_node_name</span><span class="p">,</span> <span class="s2">"dim_1_index"</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">second_dim_name</span><span class="p">],</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"GatherSecondDim"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gather_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Subtract from 100 to determine how many values to pad</span>
<span></span><span class="n">target_size</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">100</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"target_size"</span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_size</span><span class="p">)</span>
<span></span>
<span></span><span class="n">pad_size_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">second_dim_name</span><span class="si">}</span><span class="s2">_padsize"</span>
<span></span><span class="n">sub_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Sub"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">"target_size"</span><span class="p">,</span> <span class="n">second_dim_name</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">pad_size_name</span><span class="p">],</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"CalculatePadSize"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sub_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Build the [2, 3] pad array:</span>
<span></span><span class="c1"># 1st row -&gt; [0, 0, 0] (no padding at the start of any dim)</span>
<span></span><span class="c1"># 2nd row -&gt; [0, pad_size, 0] (pad only at the end of the second dim)</span>
<span></span><span class="n">pad_starts</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"pad_starts"</span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pad_starts</span><span class="p">)</span>
<span></span>
<span></span><span class="n">zero_scalar</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"zero_scalar"</span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_scalar</span><span class="p">)</span>
<span></span>
<span></span><span class="n">pad_ends_name</span> <span class="o">=</span> <span class="s2">"pad_ends"</span>
<span></span><span class="n">concat_pad_ends_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Concat"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">"zero_scalar"</span><span class="p">,</span> <span class="n">pad_size_name</span><span class="p">,</span> <span class="s2">"zero_scalar"</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">pad_ends_name</span><span class="p">],</span>
<span></span>    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"ConcatPadEnds"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">concat_pad_ends_node</span><span class="p">)</span>
<span></span>
<span></span><span class="n">pad_values_name</span> <span class="o">=</span> <span class="s2">"pad_values"</span>
<span></span><span class="n">concat_pad_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Concat"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">"pad_starts"</span><span class="p">,</span> <span class="n">pad_ends_name</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">pad_values_name</span><span class="p">],</span>
<span></span>    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"ConcatPadStartsEnds"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">concat_pad_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Create Pad operator to pad with zeros</span>
<span></span><span class="n">pad_output_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">final_output_name</span><span class="si">}</span><span class="s2">_padded"</span>
<span></span><span class="n">pad_constant_value</span> <span class="o">=</span> <span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span>
<span></span>    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"pad_constant_value"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pad_constant_value</span><span class="p">)</span>
<span></span>
<span></span><span class="n">pad_node</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span></span>    <span class="s2">"Pad"</span><span class="p">,</span>
<span></span>    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">final_output_name</span><span class="p">,</span> <span class="n">pad_values_name</span><span class="p">,</span> <span class="s2">"pad_constant_value"</span><span class="p">],</span>
<span></span>    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">pad_output_name</span><span class="p">],</span>
<span></span>    <span class="n">mode</span><span class="o">=</span><span class="s2">"constant"</span><span class="p">,</span>
<span></span>    <span class="n">name</span><span class="o">=</span><span class="s2">"PadToFixedSize"</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pad_node</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Update the graph's final output to [1, 100, 6]</span>
<span></span><span class="n">new_output_type</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_type_proto</span><span class="p">(</span>
<span></span>    <span class="n">elem_type</span><span class="o">=</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">elem_type</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span></span><span class="p">)</span>
<span></span><span class="n">new_output</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_value_info</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">pad_output_name</span><span class="p">,</span> <span class="n">type_proto</span><span class="o">=</span><span class="n">new_output_type</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Replace the old output with the new one</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
<span></span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">new_output</span><span class="p">])</span>
<span></span>
<span></span><span class="c1"># Save the modified model</span>
<span></span><span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"yolov7-ultralytics.onnx"</span><span class="p">)</span>
</code></pre></div></li><li><p>You can then load the modified ONNX model and run inference with it in Ultralytics normally:</p><div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">ASSETS</span><span class="p">,</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolov7-ultralytics.onnx"</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">"detect"</span><span class="p">)</span>
<span></span>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">ASSETS</span> <span class="o">/</span> <span class="s2">"bus.jpg"</span><span class="p">)</span>
</code></pre></div></li></ol><h3 id="tensorrt-export">TensorRT Export</h3><ol><li><p>Follow steps 1-2 in the <a href="#onnx-export">ONNX Export</a> section.</p></li><li><p>Install the <code>TensorRT</code> Python package:</p><div class="highlight"><pre><span></span><code><span></span>pip<span class="w"> </span>install<span class="w"> </span>tensorrt
</code></pre></div></li><li><p>Run the following script to convert the modified ONNX model to TensorRT engine:</p><div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics.utils.export</span><span class="w"> </span><span class="kn">import</span> <span class="n">export_engine</span>
<span></span>
<span></span><span class="n">export_engine</span><span class="p">(</span><span class="s2">"yolov7-ultralytics.onnx"</span><span class="p">,</span> <span class="n">half</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></li><li><p>Load and run the model in Ultralytics:</p><div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">ASSETS</span><span class="p">,</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolov7-ultralytics.engine"</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">"detect"</span><span class="p">)</span>
<span></span>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">ASSETS</span> <span class="o">/</span> <span class="s2">"bus.jpg"</span><span class="p">)</span>
</code></pre></div></li></ol><h2 id="citations-and-acknowledgments">Citations and Acknowledgments</h2><p>We would like to acknowledge the YOLOv7 authors for their significant contributions in the field of real-time object detection:</p><div class="admonition quote"><div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="bibtex" name="__tabbed_2" type="radio"/><div class="tabbed-labels"><label for="bibtex">BibTeX</label></div><div class="tabbed-content"><div class="tabbed-block"><div class="highlight"><pre><span></span><code><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2022yolov7</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2207.02696}</span><span class="p">,</span>
<span></span><span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2022}</span>
<span></span><span class="p">}</span>
</code></pre></div></div></div></div></div><p>The original YOLOv7 paper can be found on <a href="https://arxiv.org/pdf/2207.02696">arXiv</a>. The authors have made their work publicly available, and the codebase can be accessed on <a href="https://github.com/WongKinYiu/yolov7">GitHub</a>. We appreciate their efforts in advancing the field and making their work accessible to the broader community.</p><h2 id="faq">FAQ</h2><h3 id="what-is-yolov7-and-why-is-it-considered-a-breakthrough-in-real-time-object-detection">What is YOLOv7 and why is it considered a breakthrough in real-time <a href="https://www.ultralytics.com/glossary/object-detection">object detection</a>?</h3><p>YOLOv7, released in July 2022, was a significant real-time object detection model that achieved excellent speed and accuracy at its time of release. It surpassed contemporary models such as YOLOX, YOLOv5, and PPYOLOE in both parameters usage and inference speed. YOLOv7's distinguishing features include its model re-parameterization and dynamic label assignment, which optimize its performance without increasing inference costs. For more technical details about its architecture and comparison metrics with other state-of-the-art object detectors, refer to the <a href="https://arxiv.org/pdf/2207.02696">YOLOv7 paper</a>.</p><h3 id="how-does-yolov7-improve-on-previous-yolo-models-like-yolov4-and-yolov5">How does YOLOv7 improve on previous YOLO models like YOLOv4 and YOLOv5?</h3><p>YOLOv7 introduces several innovations, including model re-parameterization and dynamic label assignment, which enhance the training process and improve inference accuracy. Compared to YOLOv5, YOLOv7 significantly boosts speed and accuracy. For instance, YOLOv7-X improves accuracy by 2.2% and reduces parameters by 22% compared to YOLOv5-X. Detailed comparisons can be found in the performance table <a href="#comparison-of-sota-object-detectors">YOLOv7 comparison with SOTA object detectors</a>.</p><h3 id="can-i-use-yolov7-with-ultralytics-tools-and-platforms">Can I use YOLOv7 with Ultralytics tools and platforms?</h3><p>As of now, Ultralytics only supports YOLOv7 ONNX and TensorRT inference. To run the ONNX and TensorRT exported version of YOLOv7 with Ultralytics, check the <a href="#usage-examples">Usage Examples</a> section.</p><h3 id="how-do-i-train-a-custom-yolov7-model-using-my-dataset">How do I train a custom YOLOv7 model using my dataset?</h3><p>To install and train a custom YOLOv7 model, follow these steps:</p><ol><li>Clone the YOLOv7 repository: <div class="highlight"><pre><span></span><code><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/WongKinYiu/yolov7
</code></pre></div></li><li>Navigate to the cloned directory and install dependencies: <div class="highlight"><pre><span></span><code><span></span><span class="nb">cd</span><span class="w"> </span>yolov7
<span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</code></pre></div></li><li><p>Prepare your dataset and configure the model parameters according to the <a href="https://github.com/WongKinYiu/yolov7">usage instructions</a> provided in the repository. For further guidance, visit the YOLOv7 GitHub repository for the latest information and updates.</p></li><li><p>After training, you can export the model to ONNX or TensorRT for use in Ultralytics as shown in <a href="#usage-examples">Usage Examples</a>.</p></li></ol><h3 id="what-are-the-key-features-and-optimizations-introduced-in-yolov7">What are the key features and optimizations introduced in YOLOv7?</h3><p>YOLOv7 offers several key features that revolutionize real-time object detection:</p><ul><li><strong>Model Re-parameterization</strong>: Enhances the model's performance by optimizing gradient propagation paths.</li><li><strong>Dynamic Label Assignment</strong>: Uses a coarse-to-fine lead guided method to assign dynamic targets for outputs across different branches, improving accuracy.</li><li><strong>Extended and Compound Scaling</strong>: Efficiently utilizes parameters and computation to scale the model for various real-time applications.</li><li><strong>Efficiency</strong>: Reduces parameter count by 40% and computation by 50% compared to other state-of-the-art models while achieving faster inference speeds.</li></ul><p>For further details on these features, see the <a href="#overview">YOLOv7 Overview</a> section.</p><br/><br/><div class="git-info"><div class="dates-container"><span class="date-item" title="This page was first created on November 12, 2023"><span class="hover-item">üìÖ</span> Created 2 years ago </span><span class="date-item" title="This page was last updated on January 20, 2026"><span class="hover-item">‚úèÔ∏è</span> Updated 3 days ago </span></div><div class="authors-container"><a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (17 changes)"><img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (4 changes)"><img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Y-T-G" title="Y-T-G (2 changes)"><img alt="Y-T-G" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/32206511?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/pderrenger" title="pderrenger (1 change)"><img alt="pderrenger" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/107626595?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/MatthewNoyce" title="MatthewNoyce (1 change)"><img alt="MatthewNoyce" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/131261051?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/RizwanMunawar" title="RizwanMunawar (1 change)"><img alt="RizwanMunawar" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62513924?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/ambitious-octopus" title="ambitious-octopus (1 change)"><img alt="ambitious-octopus" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/3855193?v=4&amp;s=96"/></a></div></div><div class="share-buttons"><button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https%3A%2F%2Fdocs.ultralytics.com%2Fmodels%2Fyolov7%2F', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet </button><button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdocs.ultralytics.com%2Fmodels%2Fyolov7%2F', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share </button></div><br/><h2 id="__comments">Comments</h2><div id="giscus-container"></div></article></div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div><button class="md-top md-icon" data-md-component="top" hidden="" type="button"><svg class="lucide lucide-circle-arrow-up" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><path d="m16 12-4-4-4 4M12 16V8"></path></svg> Back to top
</button></main><footer class="md-footer"><nav aria-label="Footer" class="md-footer__inner md-grid"><a aria-label="Previous: YOLOv6" class="md-footer__link md-footer__link--prev" href="../yolov6/"><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-left" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12 19-7-7 7-7M19 12H5"></path></svg></div><div class="md-footer__title"><span class="md-footer__direction"> Previous </span><div class="md-ellipsis"> YOLOv6 </div></div></a><a aria-label="Next: YOLOv8" class="md-footer__link md-footer__link--next" href="../yolov8/"><div class="md-footer__title"><span class="md-footer__direction"> Next </span><div class="md-ellipsis"> YOLOv8 </div></div><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-right" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 12h14M12 5l7 7-7 7"></path></svg></div></a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-copyright"><div class="md-copyright__highlight"><a href="https://www.ultralytics.com/" target="_blank">¬© 2026 Ultralytics Inc.</a> All rights reserved. </div> Made with <a href="https://zensical.org/" rel="noopener" target="_blank"> Zensical </a></div><div class="md-social"><a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg></a></div></div></div></footer></div><div class="md-dialog" data-md-component="dialog"><div class="md-dialog__inner md-typeset"></div></div><div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"annotate":null,"base":"../..","features":["content.action.edit","content.code.annotate","content.code.copy","content.tooltips","toc.follow","navigation.top","navigation.tabs","navigation.tabs.sticky","navigation.prune","navigation.footer","navigation.tracking","navigation.instant","navigation.instant.progress","navigation.indexes","navigation.sections","content.tabs.link"],"search":"../../assets/javascripts/workers/search.e2d2d235.min.js","tags":null,"translations":{"clipboard.copied":"Copied to clipboard","clipboard.copy":"Copy to clipboard","search.result.more.one":"1 more on this page","search.result.more.other":"# more on this page","search.result.none":"No matching documents","search.result.one":"1 matching document","search.result.other":"# matching documents","search.result.placeholder":"Type to start searching","search.result.term.missing":"Missing","select.version":"Select version"},"version":null}</script>
<script src="../../assets/javascripts/bundle.8ffeb9c9.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ultralytics/llm@v0.1.8/js/chat.min.js"></script>
<script src="https://unpkg.com/tablesort@5.6.0/dist/tablesort.min.js"></script>
<script src="../../javascript/extra.js"></script>
<script src="../../javascript/giscus.js"></script>
<script src="../../javascript/tablesort.js"></script>
<script>
            async function copyMarkdownForLLM(button) {
                const editBtn = document.querySelector('a[title="Edit this page"]');
                if (!editBtn) return;

                const originalHTML = button.innerHTML;
                const checkIcon = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19L21 7l-1.41-1.41L9 16.17z"></path></svg>';

                let rawUrl = editBtn.href.replace('github.com', 'raw.githubusercontent.com');
                rawUrl = rawUrl.replace('/blob/', '/').replace('/tree/', '/');

                try {
                    const response = await fetch(rawUrl);
                    let markdown = await response.text();

                    if (markdown.startsWith('---')) {
                        const frontMatterEnd = markdown.indexOf('\n---\n', 3);
                        if (frontMatterEnd !== -1) {
                            markdown = markdown.substring(frontMatterEnd + 5).trim();
                        }
                    }

                    const title = document.querySelector('h1')?.textContent || document.title;
                    const content = `# ${title}\n\nSource: ${window.location.href}\n\n---\n\n${markdown}`;

                    await navigator.clipboard.writeText(content);
                    button.innerHTML = checkIcon + ' Copied!';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                } catch (err) {
                    button.innerHTML = '‚ùå Failed';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                }
            }
            </script></body></html>