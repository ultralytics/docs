<!doctypehtml><html class=no-js lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1 name=viewport><meta content="Learn how to efficiently train object detection models using YOLO11 with comprehensive instructions on settings, augmentation, and hardware utilization."name=description><meta content=Ultralytics name=author><link href=https://docs.ultralytics.com/modes/train/ rel=canonical><link href=../ rel=prev><link href=../val/ rel=next><link href=../../assets/favicon.ico rel=icon><meta content="mkdocs-1.6.1, mkdocs-material-9.5.45"name=generator><title>Train - Ultralytics YOLO Docs</title><link href=../../assets/stylesheets/main.0253249f.min.css rel=stylesheet><link href=../../assets/stylesheets/palette.06af60db.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href=https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href=../../assets/_mkdocstrings.css rel=stylesheet><link href=../../stylesheets/style.css rel=stylesheet><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta content=Train name=title><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css rel=stylesheet><meta content="Ultralytics, YOLO11, model training, deep learning, object detection, GPU training, dataset augmentation, hyperparameter tuning, model performance, apple silicon training"name=keywords><meta content=website property=og:type><meta content=https://docs.ultralytics.com/modes/train property=og:url><meta content=Train property=og:title><meta content="Learn how to efficiently train object detection models using YOLO11 with comprehensive instructions on settings, augmentation, and hardware utilization."property=og:description><meta content=https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-ecosystem-integrations.avif property=og:image><meta content=summary_large_image property=twitter:card><meta content=https://docs.ultralytics.com/modes/train property=twitter:url><meta content=Train property=twitter:title><meta content="Learn how to efficiently train object detection models using YOLO11 with comprehensive instructions on settings, augmentation, and hardware utilization."property=twitter:description><meta content=https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-ecosystem-integrations.avif property=twitter:image><script type=application/ld+json>{"@context": "https://schema.org", "@type": ["Article", "FAQPage"], "headline": "Train", "image": ["https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-ecosystem-integrations.avif"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2024-11-05 05:52:21 +0530", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "Learn how to efficiently train object detection models using YOLO11 with comprehensive instructions on settings, augmentation, and hardware utilization.", "mainEntity": [{"@type": "Question", "name": "How do I train an object detection model using Ultralytics YOLO11?", "acceptedAnswer": {"@type": "Answer", "text": "To train an object detection model using Ultralytics YOLO11, you can either use the Python API or the CLI. Below is an example for both: For more details, refer to the Train Settings section."}}, {"@type": "Question", "name": "What are the key features of Ultralytics YOLO11's Train mode?", "acceptedAnswer": {"@type": "Answer", "text": "The key features of Ultralytics YOLO11's Train mode include: These features make training efficient and customizable to your needs. For more details, see the Key Features of Train Mode section."}}, {"@type": "Question", "name": "How do I resume training from an interrupted session in Ultralytics YOLO11?", "acceptedAnswer": {"@type": "Answer", "text": "To resume training from an interrupted session, set the resume argument to True and specify the path to the last saved checkpoint. Check the section on Resuming Interrupted Trainings for more information."}}, {"@type": "Question", "name": "Can I train YOLO11 models on Apple silicon chips?", "acceptedAnswer": {"@type": "Answer", "text": "Yes, Ultralytics YOLO11 supports training on Apple silicon chips utilizing the Metal Performance Shaders (MPS) framework. Specify 'mps' as your training device. For more details, refer to the Apple Silicon MPS Training section."}}, {"@type": "Question", "name": "What are the common training settings, and how do I configure them?", "acceptedAnswer": {"@type": "Answer", "text": "Ultralytics YOLO11 allows you to configure a variety of training settings such as batch size, learning rate, epochs, and more through arguments. Here's a brief overview: For an in-depth guide on training settings, check the Train Settings section."}}]}</script><body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default dir=ltr><input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox><input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox><label class=md-overlay for=__drawer></label><div data-md-component=skip><a class=md-skip href=#model-training-with-ultralytics-yolo> Skip to content </a></div><div data-md-component=announce><aside class=md-banner><div class="md-banner__inner md-grid md-typeset"><div class=banner-wrapper><div class=banner-content-wrapper><p>YOLO Vision 2024 is here!<div class=banner-info-wrapper><img alt="YOLO Vision 24"height=20 loading=lazy src=https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/66e9a87cfc78245ffa51d6f0_w_yv24.svg width=20><p>September 27, 2024</div><div class=banner-info-wrapper><img alt="YOLO Vision 24"height=20 loading=lazy src=https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/66e9a87cdfbd25e409560ed8_l_yv24.svg width=20><p>Free hybrid event</div></div><div class=banner-button-wrapper><div class="banner-button-wrapper large"><button onclick="window.open('https://www.ultralytics.com/events/yolovision', '_blank')">Register now</button></div></div></div></div></aside></div><header class="md-header md-header--shadow md-header--lifted"data-md-component=header><nav class="md-header__inner md-grid"aria-label=Header><a aria-label="Ultralytics YOLO Docs"class="md-header__button md-logo"title="Ultralytics YOLO Docs"data-md-component=logo href=../..> <img alt=logo src=https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg> </a><label class="md-header__button md-icon"for=__drawer><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg></label><div class=md-header__title data-md-component=header-title><div class=md-header__ellipsis><div class=md-header__topic><span class=md-ellipsis> Ultralytics YOLO Docs </span></div><div class=md-header__topic data-md-component=header-topic><span class=md-ellipsis> Train </span></div></div></div><form class=md-header__option data-md-component=palette><input aria-label="Switch to light mode"class=md-option data-md-color-accent=indigo data-md-color-media=(prefers-color-scheme) data-md-color-primary=indigo data-md-color-scheme=default id=__palette_0 name=__palette type=radio><label class="md-header__button md-icon"title="Switch to light mode"for=__palette_1 hidden><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference"data-md-color-media="(prefers-color-scheme: dark)"class=md-option data-md-color-accent=indigo data-md-color-primary=black data-md-color-scheme=slate id=__palette_1 name=__palette type=radio><label class="md-header__button md-icon"title="Switch to system preference"for=__palette_2 hidden><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode"data-md-color-media="(prefers-color-scheme: light)"class=md-option data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default id=__palette_2 name=__palette type=radio><label class="md-header__button md-icon"title="Switch to dark mode"for=__palette_0 hidden><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form><script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script><div class=md-header__source><a title="Go to repository"class=md-source data-md-component=source href=https://github.com/ultralytics/ultralytics> <div class="md-source__icon md-icon"><svg viewbox="0 0 496 512"xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg></div> <div class=md-source__repository>ultralytics/ultralytics</div> </a></div></nav><nav aria-label=Tabs class=md-tabs data-md-component=tabs><div class=md-grid><ul class=md-tabs__list><li class=md-tabs__item><a class=md-tabs__link href=../..> Home </a><li class=md-tabs__item><a class=md-tabs__link href=../../quickstart/> Quickstart </a><li class=md-tabs__item><a class=md-tabs__link href=../> Modes </a><li class="md-tabs__item md-tabs__item--active"><a class=md-tabs__link href=../../tasks/> Tasks </a><li class=md-tabs__item><a class=md-tabs__link href=../../models/> Models </a><li class=md-tabs__item><a class=md-tabs__link href=../../datasets/> Datasets </a><li class=md-tabs__item><a class=md-tabs__link href=../../solutions/> Solutions ðŸš€ NEW </a><li class=md-tabs__item><a class=md-tabs__link href=../../guides/> Guides </a><li class=md-tabs__item><a class=md-tabs__link href=../../integrations/> Integrations </a><li class=md-tabs__item><a class=md-tabs__link href=../../hub/> HUB </a><li class=md-tabs__item><a class=md-tabs__link href=../../reference/cfg/__init__/> Reference </a><li class=md-tabs__item><a class=md-tabs__link href=../../help/> Help </a></ul></div></nav></header><div class=md-container data-md-component=container><main class=md-main data-md-component=main><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary"data-md-component=sidebar data-md-type=navigation><div class=md-sidebar__scrollwrap><div class=md-sidebar__inner><nav class="md-nav md-nav--primary md-nav--lifted"aria-label=Navigation data-md-level=0><label class=md-nav__title for=__drawer><a aria-label="Ultralytics YOLO Docs"class="md-nav__button md-logo"title="Ultralytics YOLO Docs"data-md-component=logo href=../..> <img alt=logo src=https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg> </a> Ultralytics YOLO Docs</label><div class=md-nav__source><a title="Go to repository"class=md-source data-md-component=source href=https://github.com/ultralytics/ultralytics> <div class="md-source__icon md-icon"><svg viewbox="0 0 496 512"xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg></div> <div class=md-source__repository>ultralytics/ultralytics</div> </a></div><ul class=md-nav__list data-md-scrollfix><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../..> <span class=md-ellipsis> Home </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../quickstart/> <span class=md-ellipsis> Quickstart </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../> <span class=md-ellipsis> Modes </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle"checked id=__nav_4 type=checkbox> <div class="md-nav__link md-nav__container"><a class=md-nav__link href=../../tasks/> <span class=md-ellipsis> Tasks </span> </a><label class=md-nav__link for=__nav_4 id=__nav_4_label><span class="md-nav__icon md-icon"></span></label></div> <nav aria-expanded=true aria-labelledby=__nav_4_label class=md-nav data-md-level=1><label class=md-nav__title for=__nav_4><span class="md-nav__icon md-icon"></span> Tasks</label><ul class=md-nav__list data-md-scrollfix><li class=md-nav__item><a class=md-nav__link href=../../tasks/detect/> <span class=md-ellipsis> Detect </span> </a><li class=md-nav__item><a class=md-nav__link href=../../tasks/segment/> <span class=md-ellipsis> Segment </span> </a><li class=md-nav__item><a class=md-nav__link href=../../tasks/classify/> <span class=md-ellipsis> Classify </span> </a><li class=md-nav__item><a class=md-nav__link href=../../tasks/pose/> <span class=md-ellipsis> Pose </span> </a><li class=md-nav__item><a class=md-nav__link href=../../tasks/obb/> <span class=md-ellipsis> OBB </span> </a><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle"checked id=__nav_4_7 type=checkbox> <div class="md-nav__link md-nav__container"><a class=md-nav__link href=../> <span class=md-ellipsis> Modes </span> </a><label class=md-nav__link for=__nav_4_7 id=__nav_4_7_label><span class="md-nav__icon md-icon"></span></label></div> <nav aria-expanded=true aria-labelledby=__nav_4_7_label class=md-nav data-md-level=2><label class=md-nav__title for=__nav_4_7><span class="md-nav__icon md-icon"></span> Modes</label><ul class=md-nav__list data-md-scrollfix><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle"id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active"for=__toc><span class=md-ellipsis> Train </span> <span class="md-nav__icon md-icon"></span></label> <a class="md-nav__link md-nav__link--active"href=./> <span class=md-ellipsis> Train </span> </a> <nav aria-label="Table of contents"class="md-nav md-nav--secondary"><label class=md-nav__title for=__toc><span class="md-nav__icon md-icon"></span> Table of contents</label><ul class=md-nav__list data-md-component=toc data-md-scrollfix><li class=md-nav__item><a class=md-nav__link href=#introduction> <span class=md-ellipsis> Introduction </span> </a><li class=md-nav__item><a class=md-nav__link href=#why-choose-ultralytics-yolo-for-training> <span class=md-ellipsis> Why Choose Ultralytics YOLO for Training? </span> </a> <nav aria-label="Why Choose Ultralytics YOLO for Training?"class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#key-features-of-train-mode> <span class=md-ellipsis> Key Features of Train Mode </span> </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#usage-examples> <span class=md-ellipsis> Usage Examples </span> </a> <nav aria-label="Usage Examples"class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#multi-gpu-training> <span class=md-ellipsis> Multi-GPU Training </span> </a><li class=md-nav__item><a class=md-nav__link href=#apple-silicon-mps-training> <span class=md-ellipsis> Apple Silicon MPS Training </span> </a><li class=md-nav__item><a class=md-nav__link href=#resuming-interrupted-trainings> <span class=md-ellipsis> Resuming Interrupted Trainings </span> </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#train-settings> <span class=md-ellipsis> Train Settings </span> </a><li class=md-nav__item><a class=md-nav__link href=#augmentation-settings-and-hyperparameters> <span class=md-ellipsis> Augmentation Settings and Hyperparameters </span> </a><li class=md-nav__item><a class=md-nav__link href=#logging> <span class=md-ellipsis> Logging </span> </a> <nav aria-label=Logging class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#comet> <span class=md-ellipsis> Comet </span> </a><li class=md-nav__item><a class=md-nav__link href=#clearml> <span class=md-ellipsis> ClearML </span> </a><li class=md-nav__item><a class=md-nav__link href=#tensorboard> <span class=md-ellipsis> TensorBoard </span> </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#faq> <span class=md-ellipsis> FAQ </span> </a> <nav aria-label=FAQ class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#how-do-i-train-an-object-detection-model-using-ultralytics-yolo11> <span class=md-ellipsis> How do I train an object detection model using Ultralytics YOLO11? </span> </a><li class=md-nav__item><a class=md-nav__link href=#what-are-the-key-features-of-ultralytics-yolo11s-train-mode> <span class=md-ellipsis> What are the key features of Ultralytics YOLO11's Train mode? </span> </a><li class=md-nav__item><a class=md-nav__link href=#how-do-i-resume-training-from-an-interrupted-session-in-ultralytics-yolo11> <span class=md-ellipsis> How do I resume training from an interrupted session in Ultralytics YOLO11? </span> </a><li class=md-nav__item><a class=md-nav__link href=#can-i-train-yolo11-models-on-apple-silicon-chips> <span class=md-ellipsis> Can I train YOLO11 models on Apple silicon chips? </span> </a><li class=md-nav__item><a class=md-nav__link href=#what-are-the-common-training-settings-and-how-do-i-configure-them> <span class=md-ellipsis> What are the common training settings, and how do I configure them? </span> </a></ul></nav></ul></nav><li class=md-nav__item><a class=md-nav__link href=../val/> <span class=md-ellipsis> Val </span> </a><li class=md-nav__item><a class=md-nav__link href=../predict/> <span class=md-ellipsis> Predict </span> </a><li class=md-nav__item><a class=md-nav__link href=../export/> <span class=md-ellipsis> Export </span> </a><li class=md-nav__item><a class=md-nav__link href=../track/> <span class=md-ellipsis> Track </span> </a><li class=md-nav__item><a class=md-nav__link href=../benchmark/> <span class=md-ellipsis> Benchmark </span> </a></ul></nav></ul></nav><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../models/> <span class=md-ellipsis> Models </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../datasets/> <span class=md-ellipsis> Datasets </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../solutions/> <span class=md-ellipsis> Solutions ðŸš€ NEW </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../guides/> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../integrations/> <span class=md-ellipsis> Integrations </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../hub/> <span class=md-ellipsis> HUB </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../reference/cfg/__init__/> <span class=md-ellipsis> Reference </span> <span class="md-nav__icon md-icon"></span> </a><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class=md-nav__link href=../../help/> <span class=md-ellipsis> Help </span> <span class="md-nav__icon md-icon"></span> </a></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary"data-md-component=sidebar data-md-type=toc><div class=md-sidebar__scrollwrap><div class=md-sidebar__inner><nav aria-label="Table of contents"class="md-nav md-nav--secondary"><label class=md-nav__title for=__toc><span class="md-nav__icon md-icon"></span> Table of contents</label><ul class=md-nav__list data-md-component=toc data-md-scrollfix><li class=md-nav__item><a class=md-nav__link href=#introduction> <span class=md-ellipsis> Introduction </span> </a><li class=md-nav__item><a class=md-nav__link href=#why-choose-ultralytics-yolo-for-training> <span class=md-ellipsis> Why Choose Ultralytics YOLO for Training? </span> </a> <nav aria-label="Why Choose Ultralytics YOLO for Training?"class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#key-features-of-train-mode> <span class=md-ellipsis> Key Features of Train Mode </span> </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#usage-examples> <span class=md-ellipsis> Usage Examples </span> </a> <nav aria-label="Usage Examples"class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#multi-gpu-training> <span class=md-ellipsis> Multi-GPU Training </span> </a><li class=md-nav__item><a class=md-nav__link href=#apple-silicon-mps-training> <span class=md-ellipsis> Apple Silicon MPS Training </span> </a><li class=md-nav__item><a class=md-nav__link href=#resuming-interrupted-trainings> <span class=md-ellipsis> Resuming Interrupted Trainings </span> </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#train-settings> <span class=md-ellipsis> Train Settings </span> </a><li class=md-nav__item><a class=md-nav__link href=#augmentation-settings-and-hyperparameters> <span class=md-ellipsis> Augmentation Settings and Hyperparameters </span> </a><li class=md-nav__item><a class=md-nav__link href=#logging> <span class=md-ellipsis> Logging </span> </a> <nav aria-label=Logging class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#comet> <span class=md-ellipsis> Comet </span> </a><li class=md-nav__item><a class=md-nav__link href=#clearml> <span class=md-ellipsis> ClearML </span> </a><li class=md-nav__item><a class=md-nav__link href=#tensorboard> <span class=md-ellipsis> TensorBoard </span> </a></ul></nav><li class=md-nav__item><a class=md-nav__link href=#faq> <span class=md-ellipsis> FAQ </span> </a> <nav aria-label=FAQ class=md-nav><ul class=md-nav__list><li class=md-nav__item><a class=md-nav__link href=#how-do-i-train-an-object-detection-model-using-ultralytics-yolo11> <span class=md-ellipsis> How do I train an object detection model using Ultralytics YOLO11? </span> </a><li class=md-nav__item><a class=md-nav__link href=#what-are-the-key-features-of-ultralytics-yolo11s-train-mode> <span class=md-ellipsis> What are the key features of Ultralytics YOLO11's Train mode? </span> </a><li class=md-nav__item><a class=md-nav__link href=#how-do-i-resume-training-from-an-interrupted-session-in-ultralytics-yolo11> <span class=md-ellipsis> How do I resume training from an interrupted session in Ultralytics YOLO11? </span> </a><li class=md-nav__item><a class=md-nav__link href=#can-i-train-yolo11-models-on-apple-silicon-chips> <span class=md-ellipsis> Can I train YOLO11 models on Apple silicon chips? </span> </a><li class=md-nav__item><a class=md-nav__link href=#what-are-the-common-training-settings-and-how-do-i-configure-them> <span class=md-ellipsis> What are the common training settings, and how do I configure them? </span> </a></ul></nav></ul></nav></div></div></div><div class=md-content data-md-component=content><article class="md-content__inner md-typeset"><a class="md-content__button md-icon"title="Edit this page"href=https://github.com/ultralytics/ultralytics/tree/main/docs/en/modes/train.md> <svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg> </a><h1 id=model-training-with-ultralytics-yolo>Model Training with Ultralytics YOLO</h1><p><img alt="Ultralytics YOLO ecosystem and integrations"src=https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-ecosystem-integrations.avif width=1024><h2 id=introduction>Introduction</h2><p>Training a <a href=https://www.ultralytics.com/glossary/deep-learning-dl>deep learning</a> model involves feeding it data and adjusting its parameters so that it can make accurate predictions. Train mode in Ultralytics YOLO11 is engineered for effective and efficient training of object detection models, fully utilizing modern hardware capabilities. This guide aims to cover all the details you need to get started with training your own models using YOLO11's robust set of features.<p align=center><br> <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"title="YouTube video player"allowfullscreen frameborder=0 height=405 loading=lazy src=https://www.youtube.com/embed/LNwODJXcvt4?si=7n1UvGRLSd9p5wKs width=720></iframe> <br> <strong>Watch:</strong> How to Train a YOLO model on Your Custom Dataset in Google Colab.<h2 id=why-choose-ultralytics-yolo-for-training>Why Choose Ultralytics YOLO for Training?</h2><p>Here are some compelling reasons to opt for YOLO11's Train mode:<ul><li><strong>Efficiency:</strong> Make the most out of your hardware, whether you're on a single-GPU setup or scaling across multiple GPUs.<li><strong>Versatility:</strong> Train on custom datasets in addition to readily available ones like COCO, VOC, and ImageNet.<li><strong>User-Friendly:</strong> Simple yet powerful CLI and Python interfaces for a straightforward training experience.<li><strong>Hyperparameter Flexibility:</strong> A broad range of customizable hyperparameters to fine-tune model performance.</ul><h3 id=key-features-of-train-mode>Key Features of Train Mode</h3><p>The following are some notable features of YOLO11's Train mode:<ul><li><strong>Automatic Dataset Download:</strong> Standard datasets like COCO, VOC, and ImageNet are downloaded automatically on first use.<li><strong>Multi-GPU Support:</strong> Scale your training efforts seamlessly across multiple GPUs to expedite the process.<li><strong>Hyperparameter Configuration:</strong> The option to modify hyperparameters through YAML configuration files or CLI arguments.<li><strong>Visualization and Monitoring:</strong> Real-time tracking of training metrics and visualization of the learning process for better insights.</ul><div class="admonition tip"><p class=admonition-title>Tip<ul><li>YOLO11 datasets like COCO, VOC, ImageNet and many others automatically download on first use, i.e. <code>yolo train data=coco.yaml</code></ul></div><h2 id=usage-examples>Usage Examples</h2><p>Train YOLO11n on the COCO8 dataset for 100 <a href=https://www.ultralytics.com/glossary/epoch>epochs</a> at image size 640. The training device can be specified using the <code>device</code> argument. If no argument is passed GPU <code>device=0</code> will be used if available, otherwise <code>device='cpu'</code> will be used. See Arguments section below for a full list of training arguments.<div class="admonition example"><p class=admonition-title>Single-GPU and CPU Training Example<p>Device is determined automatically. If a GPU is available then it will be used, otherwise training will start on CPU.<div class="tabbed-set tabbed-alternate"data-tabs=1:2><input checked id=__tabbed_1_1 name=__tabbed_1 type=radio><input id=__tabbed_1_2 name=__tabbed_1 type=radio><div class=tabbed-labels><label for=__tabbed_1_1>Python</label><label for=__tabbed_1_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-0-1 id=__codelineno-0-1 name=__codelineno-0-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-0-2 id=__codelineno-0-2 name=__codelineno-0-2></a>
<a href=#__codelineno-0-3 id=__codelineno-0-3 name=__codelineno-0-3></a><span class=c1># Load a model</span>
<a href=#__codelineno-0-4 id=__codelineno-0-4 name=__codelineno-0-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.yaml"</span><span class=p>)</span>  <span class=c1># build a new model from YAML</span>
<a href=#__codelineno-0-5 id=__codelineno-0-5 name=__codelineno-0-5></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.pt"</span><span class=p>)</span>  <span class=c1># load a pretrained model (recommended for training)</span>
<a href=#__codelineno-0-6 id=__codelineno-0-6 name=__codelineno-0-6></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.yaml"</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>"yolo11n.pt"</span><span class=p>)</span>  <span class=c1># build from YAML and transfer weights</span>
<a href=#__codelineno-0-7 id=__codelineno-0-7 name=__codelineno-0-7></a>
<a href=#__codelineno-0-8 id=__codelineno-0-8 name=__codelineno-0-8></a><span class=c1># Train the model</span>
<a href=#__codelineno-0-9 id=__codelineno-0-9 name=__codelineno-0-9></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s2>"coco8.yaml"</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>)</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-1-1 id=__codelineno-1-1 name=__codelineno-1-1></a><span class=c1># Build a new model from YAML and start training from scratch</span>
<a href=#__codelineno-1-2 id=__codelineno-1-2 name=__codelineno-1-2></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.yaml<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span>
<a href=#__codelineno-1-3 id=__codelineno-1-3 name=__codelineno-1-3></a>
<a href=#__codelineno-1-4 id=__codelineno-1-4 name=__codelineno-1-4></a><span class=c1># Start training from a pretrained *.pt model</span>
<a href=#__codelineno-1-5 id=__codelineno-1-5 name=__codelineno-1-5></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.pt<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span>
<a href=#__codelineno-1-6 id=__codelineno-1-6 name=__codelineno-1-6></a>
<a href=#__codelineno-1-7 id=__codelineno-1-7 name=__codelineno-1-7></a><span class=c1># Build a new model from YAML, transfer pretrained weights to it and start training</span>
<a href=#__codelineno-1-8 id=__codelineno-1-8 name=__codelineno-1-8></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.yaml<span class=w> </span><span class=nv>pretrained</span><span class=o>=</span>yolo11n.pt<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span>
</code></pre></div></div></div></div></div><h3 id=multi-gpu-training>Multi-GPU Training</h3><p>Multi-GPU training allows for more efficient utilization of available hardware resources by distributing the training load across multiple GPUs. This feature is available through both the Python API and the command-line interface. To enable multi-GPU training, specify the GPU device IDs you wish to use.<div class="admonition example"><p class=admonition-title>Multi-GPU Training Example<p>To train with 2 GPUs, CUDA devices 0 and 1 use the following commands. Expand to additional GPUs as required.<div class="tabbed-set tabbed-alternate"data-tabs=2:2><input checked id=__tabbed_2_1 name=__tabbed_2 type=radio><input id=__tabbed_2_2 name=__tabbed_2 type=radio><div class=tabbed-labels><label for=__tabbed_2_1>Python</label><label for=__tabbed_2_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-2-1 id=__codelineno-2-1 name=__codelineno-2-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-2-2 id=__codelineno-2-2 name=__codelineno-2-2></a>
<a href=#__codelineno-2-3 id=__codelineno-2-3 name=__codelineno-2-3></a><span class=c1># Load a model</span>
<a href=#__codelineno-2-4 id=__codelineno-2-4 name=__codelineno-2-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.pt"</span><span class=p>)</span>  <span class=c1># load a pretrained model (recommended for training)</span>
<a href=#__codelineno-2-5 id=__codelineno-2-5 name=__codelineno-2-5></a>
<a href=#__codelineno-2-6 id=__codelineno-2-6 name=__codelineno-2-6></a><span class=c1># Train the model with 2 GPUs</span>
<a href=#__codelineno-2-7 id=__codelineno-2-7 name=__codelineno-2-7></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s2>"coco8.yaml"</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-3-1 id=__codelineno-3-1 name=__codelineno-3-1></a><span class=c1># Start training from a pretrained *.pt model using GPUs 0 and 1</span>
<a href=#__codelineno-3-2 id=__codelineno-3-2 name=__codelineno-3-2></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.pt<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span><span class=w> </span><span class=nv>device</span><span class=o>=</span><span class=m>0</span>,1
</code></pre></div></div></div></div></div><h3 id=apple-silicon-mps-training>Apple Silicon MPS Training</h3><p>With the support for Apple silicon chips integrated in the Ultralytics YOLO models, it's now possible to train your models on devices utilizing the powerful Metal Performance Shaders (MPS) framework. The MPS offers a high-performance way of executing computation and image processing tasks on Apple's custom silicon.<p>To enable training on Apple silicon chips, you should specify 'mps' as your device when initiating the training process. Below is an example of how you could do this in Python and via the command line:<div class="admonition example"><p class=admonition-title>MPS Training Example<div class="tabbed-set tabbed-alternate"data-tabs=3:2><input checked id=__tabbed_3_1 name=__tabbed_3 type=radio><input id=__tabbed_3_2 name=__tabbed_3 type=radio><div class=tabbed-labels><label for=__tabbed_3_1>Python</label><label for=__tabbed_3_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-4-1 id=__codelineno-4-1 name=__codelineno-4-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-4-2 id=__codelineno-4-2 name=__codelineno-4-2></a>
<a href=#__codelineno-4-3 id=__codelineno-4-3 name=__codelineno-4-3></a><span class=c1># Load a model</span>
<a href=#__codelineno-4-4 id=__codelineno-4-4 name=__codelineno-4-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.pt"</span><span class=p>)</span>  <span class=c1># load a pretrained model (recommended for training)</span>
<a href=#__codelineno-4-5 id=__codelineno-4-5 name=__codelineno-4-5></a>
<a href=#__codelineno-4-6 id=__codelineno-4-6 name=__codelineno-4-6></a><span class=c1># Train the model with MPS</span>
<a href=#__codelineno-4-7 id=__codelineno-4-7 name=__codelineno-4-7></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s2>"coco8.yaml"</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s2>"mps"</span><span class=p>)</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-5-1 id=__codelineno-5-1 name=__codelineno-5-1></a><span class=c1># Start training from a pretrained *.pt model using MPS</span>
<a href=#__codelineno-5-2 id=__codelineno-5-2 name=__codelineno-5-2></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.pt<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span><span class=w> </span><span class=nv>device</span><span class=o>=</span>mps
</code></pre></div></div></div></div></div><p>While leveraging the computational power of the Apple silicon chips, this enables more efficient processing of the training tasks. For more detailed guidance and advanced configuration options, please refer to the <a href=https://pytorch.org/docs/stable/notes/mps.html>PyTorch MPS documentation</a>.<h3 id=resuming-interrupted-trainings>Resuming Interrupted Trainings</h3><p>Resuming training from a previously saved state is a crucial feature when working with deep learning models. This can come in handy in various scenarios, like when the training process has been unexpectedly interrupted, or when you wish to continue training a model with new data or for more epochs.<p>When training is resumed, Ultralytics YOLO loads the weights from the last saved model and also restores the optimizer state, <a href=https://www.ultralytics.com/glossary/learning-rate>learning rate</a> scheduler, and the epoch number. This allows you to continue the training process seamlessly from where it was left off.<p>You can easily resume training in Ultralytics YOLO by setting the <code>resume</code> argument to <code>True</code> when calling the <code>train</code> method, and specifying the path to the <code>.pt</code> file containing the partially trained model weights.<p>Below is an example of how to resume an interrupted training using Python and via the command line:<div class="admonition example"><p class=admonition-title>Resume Training Example<div class="tabbed-set tabbed-alternate"data-tabs=4:2><input checked id=__tabbed_4_1 name=__tabbed_4 type=radio><input id=__tabbed_4_2 name=__tabbed_4 type=radio><div class=tabbed-labels><label for=__tabbed_4_1>Python</label><label for=__tabbed_4_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-6-1 id=__codelineno-6-1 name=__codelineno-6-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-6-2 id=__codelineno-6-2 name=__codelineno-6-2></a>
<a href=#__codelineno-6-3 id=__codelineno-6-3 name=__codelineno-6-3></a><span class=c1># Load a model</span>
<a href=#__codelineno-6-4 id=__codelineno-6-4 name=__codelineno-6-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"path/to/last.pt"</span><span class=p>)</span>  <span class=c1># load a partially trained model</span>
<a href=#__codelineno-6-5 id=__codelineno-6-5 name=__codelineno-6-5></a>
<a href=#__codelineno-6-6 id=__codelineno-6-6 name=__codelineno-6-6></a><span class=c1># Resume training</span>
<a href=#__codelineno-6-7 id=__codelineno-6-7 name=__codelineno-6-7></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>resume</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-7-1 id=__codelineno-7-1 name=__codelineno-7-1></a><span class=c1># Resume an interrupted training</span>
<a href=#__codelineno-7-2 id=__codelineno-7-2 name=__codelineno-7-2></a>yolo<span class=w> </span>train<span class=w> </span>resume<span class=w> </span><span class=nv>model</span><span class=o>=</span>path/to/last.pt
</code></pre></div></div></div></div></div><p>By setting <code>resume=True</code>, the <code>train</code> function will continue training from where it left off, using the state stored in the 'path/to/last.pt' file. If the <code>resume</code> argument is omitted or set to <code>False</code>, the <code>train</code> function will start a new training session.<p>Remember that checkpoints are saved at the end of every epoch by default, or at fixed intervals using the <code>save_period</code> argument, so you must complete at least 1 epoch to resume a training run.<h2 id=train-settings>Train Settings</h2><p>The training settings for YOLO models encompass various hyperparameters and configurations used during the training process. These settings influence the model's performance, speed, and <a href=https://www.ultralytics.com/glossary/accuracy>accuracy</a>. Key training settings include batch size, learning rate, momentum, and weight decay. Additionally, the choice of optimizer, <a href=https://www.ultralytics.com/glossary/loss-function>loss function</a>, and training dataset composition can impact the training process. Careful tuning and experimentation with these settings are crucial for optimizing performance.<table><thead><tr><th>Argument<th>Default<th>Description<tbody><tr><td><code>model</code><td><code>None</code><td>Specifies the model file for training. Accepts a path to either a <code>.pt</code> pretrained model or a <code>.yaml</code> configuration file. Essential for defining the model structure or initializing weights.<tr><td><code>data</code><td><code>None</code><td>Path to the dataset configuration file (e.g., <code>coco8.yaml</code>). This file contains dataset-specific parameters, including paths to training and <a href=https://www.ultralytics.com/glossary/validation-data>validation data</a>, class names, and number of classes.<tr><td><code>epochs</code><td><code>100</code><td>Total number of training epochs. Each <a href=https://www.ultralytics.com/glossary/epoch>epoch</a> represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance.<tr><td><code>time</code><td><code>None</code><td>Maximum training time in hours. If set, this overrides the <code>epochs</code> argument, allowing training to automatically stop after the specified duration. Useful for time-constrained training scenarios.<tr><td><code>patience</code><td><code>100</code><td>Number of epochs to wait without improvement in validation metrics before early stopping the training. Helps prevent <a href=https://www.ultralytics.com/glossary/overfitting>overfitting</a> by stopping training when performance plateaus.<tr><td><code>batch</code><td><code>16</code><td><a href=https://www.ultralytics.com/glossary/batch-size>Batch size</a>, with three modes: set as an integer (e.g., <code>batch=16</code>), auto mode for 60% GPU memory utilization (<code>batch=-1</code>), or auto mode with specified utilization fraction (<code>batch=0.70</code>).<tr><td><code>imgsz</code><td><code>640</code><td>Target image size for training. All images are resized to this dimension before being fed into the model. Affects model <a href=https://www.ultralytics.com/glossary/accuracy>accuracy</a> and computational complexity.<tr><td><code>save</code><td><code>True</code><td>Enables saving of training checkpoints and final model weights. Useful for resuming training or <a href=https://www.ultralytics.com/glossary/model-deployment>model deployment</a>.<tr><td><code>save_period</code><td><code>-1</code><td>Frequency of saving model checkpoints, specified in epochs. A value of -1 disables this feature. Useful for saving interim models during long training sessions.<tr><td><code>cache</code><td><code>False</code><td>Enables caching of dataset images in memory (<code>True</code>/<code>ram</code>), on disk (<code>disk</code>), or disables it (<code>False</code>). Improves training speed by reducing disk I/O at the cost of increased memory usage.<tr><td><code>device</code><td><code>None</code><td>Specifies the computational device(s) for training: a single GPU (<code>device=0</code>), multiple GPUs (<code>device=0,1</code>), CPU (<code>device=cpu</code>), or MPS for Apple silicon (<code>device=mps</code>).<tr><td><code>workers</code><td><code>8</code><td>Number of worker threads for data loading (per <code>RANK</code> if Multi-GPU training). Influences the speed of data preprocessing and feeding into the model, especially useful in multi-GPU setups.<tr><td><code>project</code><td><code>None</code><td>Name of the project directory where training outputs are saved. Allows for organized storage of different experiments.<tr><td><code>name</code><td><code>None</code><td>Name of the training run. Used for creating a subdirectory within the project folder, where training logs and outputs are stored.<tr><td><code>exist_ok</code><td><code>False</code><td>If True, allows overwriting of an existing project/name directory. Useful for iterative experimentation without needing to manually clear previous outputs.<tr><td><code>pretrained</code><td><code>True</code><td>Determines whether to start training from a pretrained model. Can be a boolean value or a string path to a specific model from which to load weights. Enhances training efficiency and model performance.<tr><td><code>optimizer</code><td><code>'auto'</code><td>Choice of optimizer for training. Options include <code>SGD</code>, <code>Adam</code>, <code>AdamW</code>, <code>NAdam</code>, <code>RAdam</code>, <code>RMSProp</code> etc., or <code>auto</code> for automatic selection based on model configuration. Affects convergence speed and stability.<tr><td><code>seed</code><td><code>0</code><td>Sets the random seed for training, ensuring reproducibility of results across runs with the same configurations.<tr><td><code>deterministic</code><td><code>True</code><td>Forces deterministic algorithm use, ensuring reproducibility but may affect performance and speed due to the restriction on non-deterministic algorithms.<tr><td><code>single_cls</code><td><code>False</code><td>Treats all classes in multi-class datasets as a single class during training. Useful for binary classification tasks or when focusing on object presence rather than classification.<tr><td><code>rect</code><td><code>False</code><td>Enables rectangular training, optimizing batch composition for minimal padding. Can improve efficiency and speed but may affect model accuracy.<tr><td><code>cos_lr</code><td><code>False</code><td>Utilizes a cosine <a href=https://www.ultralytics.com/glossary/learning-rate>learning rate</a> scheduler, adjusting the learning rate following a cosine curve over epochs. Helps in managing learning rate for better convergence.<tr><td><code>close_mosaic</code><td><code>10</code><td>Disables mosaic <a href=https://www.ultralytics.com/glossary/data-augmentation>data augmentation</a> in the last N epochs to stabilize training before completion. Setting to 0 disables this feature.<tr><td><code>resume</code><td><code>False</code><td>Resumes training from the last saved checkpoint. Automatically loads model weights, optimizer state, and epoch count, continuing training seamlessly.<tr><td><code>amp</code><td><code>True</code><td>Enables Automatic <a href=https://www.ultralytics.com/glossary/mixed-precision>Mixed Precision</a> (AMP) training, reducing memory usage and possibly speeding up training with minimal impact on accuracy.<tr><td><code>fraction</code><td><code>1.0</code><td>Specifies the fraction of the dataset to use for training. Allows for training on a subset of the full dataset, useful for experiments or when resources are limited.<tr><td><code>profile</code><td><code>False</code><td>Enables profiling of ONNX and TensorRT speeds during training, useful for optimizing model deployment.<tr><td><code>freeze</code><td><code>None</code><td>Freezes the first N layers of the model or specified layers by index, reducing the number of trainable parameters. Useful for fine-tuning or <a href=https://www.ultralytics.com/glossary/transfer-learning>transfer learning</a>.<tr><td><code>lr0</code><td><code>0.01</code><td>Initial learning rate (i.e. <code>SGD=1E-2</code>, <code>Adam=1E-3</code>) . Adjusting this value is crucial for the optimization process, influencing how rapidly model weights are updated.<tr><td><code>lrf</code><td><code>0.01</code><td>Final learning rate as a fraction of the initial rate = (<code>lr0 * lrf</code>), used in conjunction with schedulers to adjust the learning rate over time.<tr><td><code>momentum</code><td><code>0.937</code><td>Momentum factor for SGD or beta1 for <a href=https://www.ultralytics.com/glossary/adam-optimizer>Adam optimizers</a>, influencing the incorporation of past gradients in the current update.<tr><td><code>weight_decay</code><td><code>0.0005</code><td>L2 <a href=https://www.ultralytics.com/glossary/regularization>regularization</a> term, penalizing large weights to prevent overfitting.<tr><td><code>warmup_epochs</code><td><code>3.0</code><td>Number of epochs for learning rate warmup, gradually increasing the learning rate from a low value to the initial learning rate to stabilize training early on.<tr><td><code>warmup_momentum</code><td><code>0.8</code><td>Initial momentum for warmup phase, gradually adjusting to the set momentum over the warmup period.<tr><td><code>warmup_bias_lr</code><td><code>0.1</code><td>Learning rate for bias parameters during the warmup phase, helping stabilize model training in the initial epochs.<tr><td><code>box</code><td><code>7.5</code><td>Weight of the box loss component in the <a href=https://www.ultralytics.com/glossary/loss-function>loss function</a>, influencing how much emphasis is placed on accurately predicting <a href=https://www.ultralytics.com/glossary/bounding-box>bounding box</a> coordinates.<tr><td><code>cls</code><td><code>0.5</code><td>Weight of the classification loss in the total loss function, affecting the importance of correct class prediction relative to other components.<tr><td><code>dfl</code><td><code>1.5</code><td>Weight of the distribution focal loss, used in certain YOLO versions for fine-grained classification.<tr><td><code>pose</code><td><code>12.0</code><td>Weight of the pose loss in models trained for pose estimation, influencing the emphasis on accurately predicting pose keypoints.<tr><td><code>kobj</code><td><code>2.0</code><td>Weight of the keypoint objectness loss in pose estimation models, balancing detection confidence with pose accuracy.<tr><td><code>label_smoothing</code><td><code>0.0</code><td>Applies label smoothing, softening hard labels to a mix of the target label and a uniform distribution over labels, can improve generalization.<tr><td><code>nbs</code><td><code>64</code><td>Nominal batch size for normalization of loss.<tr><td><code>overlap_mask</code><td><code>True</code><td>Determines whether object masks should be merged into a single mask for training, or kept separate for each object. In case of overlap, the smaller mask is overlayed on top of the larger mask during merge.<tr><td><code>mask_ratio</code><td><code>4</code><td>Downsample ratio for segmentation masks, affecting the resolution of masks used during training.<tr><td><code>dropout</code><td><code>0.0</code><td>Dropout rate for regularization in classification tasks, preventing overfitting by randomly omitting units during training.<tr><td><code>val</code><td><code>True</code><td>Enables validation during training, allowing for periodic evaluation of model performance on a separate dataset.<tr><td><code>plots</code><td><code>False</code><td>Generates and saves plots of training and validation metrics, as well as prediction examples, providing visual insights into model performance and learning progression.</table><div class="admonition info"><p class=admonition-title>Note on Batch-size Settings<p>The <code>batch</code> argument can be configured in three ways:<ul><li><strong>Fixed <a href=https://www.ultralytics.com/glossary/batch-size>Batch Size</a></strong>: Set an integer value (e.g., <code>batch=16</code>), specifying the number of images per batch directly.<li><strong>Auto Mode (60% GPU Memory)</strong>: Use <code>batch=-1</code> to automatically adjust batch size for approximately 60% CUDA memory utilization.<li><strong>Auto Mode with Utilization Fraction</strong>: Set a fraction value (e.g., <code>batch=0.70</code>) to adjust batch size based on the specified fraction of GPU memory usage.</ul></div><h2 id=augmentation-settings-and-hyperparameters>Augmentation Settings and Hyperparameters</h2><p>Augmentation techniques are essential for improving the robustness and performance of YOLO models by introducing variability into the <a href=https://www.ultralytics.com/glossary/training-data>training data</a>, helping the model generalize better to unseen data. The following table outlines the purpose and effect of each augmentation argument:<table><thead><tr><th>Argument<th>Type<th>Default<th>Range<th>Description<tbody><tr><td><code>hsv_h</code><td><code>float</code><td><code>0.015</code><td><code>0.0 - 1.0</code><td>Adjusts the hue of the image by a fraction of the color wheel, introducing color variability. Helps the model generalize across different lighting conditions.<tr><td><code>hsv_s</code><td><code>float</code><td><code>0.7</code><td><code>0.0 - 1.0</code><td>Alters the saturation of the image by a fraction, affecting the intensity of colors. Useful for simulating different environmental conditions.<tr><td><code>hsv_v</code><td><code>float</code><td><code>0.4</code><td><code>0.0 - 1.0</code><td>Modifies the value (brightness) of the image by a fraction, helping the model to perform well under various lighting conditions.<tr><td><code>degrees</code><td><code>float</code><td><code>0.0</code><td><code>-180 - +180</code><td>Rotates the image randomly within the specified degree range, improving the model's ability to recognize objects at various orientations.<tr><td><code>translate</code><td><code>float</code><td><code>0.1</code><td><code>0.0 - 1.0</code><td>Translates the image horizontally and vertically by a fraction of the image size, aiding in learning to detect partially visible objects.<tr><td><code>scale</code><td><code>float</code><td><code>0.5</code><td><code>>=0.0</code><td>Scales the image by a gain factor, simulating objects at different distances from the camera.<tr><td><code>shear</code><td><code>float</code><td><code>0.0</code><td><code>-180 - +180</code><td>Shears the image by a specified degree, mimicking the effect of objects being viewed from different angles.<tr><td><code>perspective</code><td><code>float</code><td><code>0.0</code><td><code>0.0 - 0.001</code><td>Applies a random perspective transformation to the image, enhancing the model's ability to understand objects in 3D space.<tr><td><code>flipud</code><td><code>float</code><td><code>0.0</code><td><code>0.0 - 1.0</code><td>Flips the image upside down with the specified probability, increasing the data variability without affecting the object's characteristics.<tr><td><code>fliplr</code><td><code>float</code><td><code>0.5</code><td><code>0.0 - 1.0</code><td>Flips the image left to right with the specified probability, useful for learning symmetrical objects and increasing dataset diversity.<tr><td><code>bgr</code><td><code>float</code><td><code>0.0</code><td><code>0.0 - 1.0</code><td>Flips the image channels from RGB to BGR with the specified probability, useful for increasing robustness to incorrect channel ordering.<tr><td><code>mosaic</code><td><code>float</code><td><code>1.0</code><td><code>0.0 - 1.0</code><td>Combines four training images into one, simulating different scene compositions and object interactions. Highly effective for complex scene understanding.<tr><td><code>mixup</code><td><code>float</code><td><code>0.0</code><td><code>0.0 - 1.0</code><td>Blends two images and their labels, creating a composite image. Enhances the model's ability to generalize by introducing label noise and visual variability.<tr><td><code>copy_paste</code><td><code>float</code><td><code>0.0</code><td><code>0.0 - 1.0</code><td>Copies objects from one image and pastes them onto another, useful for increasing object instances and learning object occlusion.<tr><td><code>copy_paste_mode</code><td><code>str</code><td><code>flip</code><td>-<td>Copy-Paste augmentation method selection among the options of (<code>"flip"</code>, <code>"mixup"</code>).<tr><td><code>auto_augment</code><td><code>str</code><td><code>randaugment</code><td>-<td>Automatically applies a predefined augmentation policy (<code>randaugment</code>, <code>autoaugment</code>, <code>augmix</code>), optimizing for classification tasks by diversifying the visual features.<tr><td><code>erasing</code><td><code>float</code><td><code>0.4</code><td><code>0.0 - 0.9</code><td>Randomly erases a portion of the image during classification training, encouraging the model to focus on less obvious features for recognition.<tr><td><code>crop_fraction</code><td><code>float</code><td><code>1.0</code><td><code>0.1 - 1.0</code><td>Crops the classification image to a fraction of its size to emphasize central features and adapt to object scales, reducing background distractions.</table><p>These settings can be adjusted to meet the specific requirements of the dataset and task at hand. Experimenting with different values can help find the optimal augmentation strategy that leads to the best model performance.<div class="admonition info"><p class=admonition-title>Info<p>For more information about training augmentation operations, see the <a href=../../reference/data/augment/>reference section</a>.</div><h2 id=logging>Logging</h2><p>In training a YOLO11 model, you might find it valuable to keep track of the model's performance over time. This is where logging comes into play. Ultralytics' YOLO provides support for three types of loggers - Comet, ClearML, and TensorBoard.<p>To use a logger, select it from the dropdown menu in the code snippet above and run it. The chosen logger will be installed and initialized.<h3 id=comet>Comet</h3><p><a href=../../integrations/comet/>Comet</a> is a platform that allows data scientists and developers to track, compare, explain and optimize experiments and models. It provides functionalities such as real-time metrics, code diffs, and hyperparameters tracking.<p>To use Comet:<div class="admonition example"><p class=admonition-title>Example<div class="tabbed-set tabbed-alternate"data-tabs=5:1><input checked id=__tabbed_5_1 name=__tabbed_5 type=radio><div class=tabbed-labels><label for=__tabbed_5_1>Python</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-8-1 id=__codelineno-8-1 name=__codelineno-8-1></a><span class=c1># pip install comet_ml</span>
<a href=#__codelineno-8-2 id=__codelineno-8-2 name=__codelineno-8-2></a><span class=kn>import</span> <span class=nn>comet_ml</span>
<a href=#__codelineno-8-3 id=__codelineno-8-3 name=__codelineno-8-3></a>
<a href=#__codelineno-8-4 id=__codelineno-8-4 name=__codelineno-8-4></a><span class=n>comet_ml</span><span class=o>.</span><span class=n>init</span><span class=p>()</span>
</code></pre></div></div></div></div></div><p>Remember to sign in to your Comet account on their website and get your API key. You will need to add this to your environment variables or your script to log your experiments.<h3 id=clearml>ClearML</h3><p><a href=https://clear.ml/>ClearML</a> is an open-source platform that automates tracking of experiments and helps with efficient sharing of resources. It is designed to help teams manage, execute, and reproduce their ML work more efficiently.<p>To use ClearML:<div class="admonition example"><p class=admonition-title>Example<div class="tabbed-set tabbed-alternate"data-tabs=6:1><input checked id=__tabbed_6_1 name=__tabbed_6 type=radio><div class=tabbed-labels><label for=__tabbed_6_1>Python</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-9-1 id=__codelineno-9-1 name=__codelineno-9-1></a><span class=c1># pip install clearml</span>
<a href=#__codelineno-9-2 id=__codelineno-9-2 name=__codelineno-9-2></a><span class=kn>import</span> <span class=nn>clearml</span>
<a href=#__codelineno-9-3 id=__codelineno-9-3 name=__codelineno-9-3></a>
<a href=#__codelineno-9-4 id=__codelineno-9-4 name=__codelineno-9-4></a><span class=n>clearml</span><span class=o>.</span><span class=n>browser_login</span><span class=p>()</span>
</code></pre></div></div></div></div></div><p>After running this script, you will need to sign in to your ClearML account on the browser and authenticate your session.<h3 id=tensorboard>TensorBoard</h3><p><a href=https://www.tensorflow.org/tensorboard>TensorBoard</a> is a visualization toolkit for <a href=https://www.ultralytics.com/glossary/tensorflow>TensorFlow</a>. It allows you to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it.<p>To use TensorBoard in <a href=https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb>Google Colab</a>:<div class="admonition example"><p class=admonition-title>Example<div class="tabbed-set tabbed-alternate"data-tabs=7:1><input checked id=__tabbed_7_1 name=__tabbed_7 type=radio><div class=tabbed-labels><label for=__tabbed_7_1>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-10-1 id=__codelineno-10-1 name=__codelineno-10-1></a>load_ext<span class=w> </span>tensorboard
<a href=#__codelineno-10-2 id=__codelineno-10-2 name=__codelineno-10-2></a>tensorboard<span class=w> </span>--logdir<span class=w> </span>ultralytics/runs<span class=w>  </span><span class=c1># replace with 'runs' directory</span>
</code></pre></div></div></div></div></div><p>To use TensorBoard locally run the below command and view results at <a href=http://localhost:6006/>http://localhost:6006/</a>.<div class="admonition example"><p class=admonition-title>Example<div class="tabbed-set tabbed-alternate"data-tabs=8:1><input checked id=__tabbed_8_1 name=__tabbed_8 type=radio><div class=tabbed-labels><label for=__tabbed_8_1>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-11-1 id=__codelineno-11-1 name=__codelineno-11-1></a>tensorboard<span class=w> </span>--logdir<span class=w> </span>ultralytics/runs<span class=w>  </span><span class=c1># replace with 'runs' directory</span>
</code></pre></div></div></div></div></div><p>This will load TensorBoard and direct it to the directory where your training logs are saved.<p>After setting up your logger, you can then proceed with your model training. All training metrics will be automatically logged in your chosen platform, and you can access these logs to monitor your model's performance over time, compare different models, and identify areas for improvement.<h2 id=faq>FAQ</h2><h3 id=how-do-i-train-an-object-detection-model-using-ultralytics-yolo11>How do I train an <a href=https://www.ultralytics.com/glossary/object-detection>object detection</a> model using Ultralytics YOLO11?</h3><p>To train an object detection model using Ultralytics YOLO11, you can either use the Python API or the CLI. Below is an example for both:<div class="admonition example"><p class=admonition-title>Single-GPU and CPU Training Example<div class="tabbed-set tabbed-alternate"data-tabs=9:2><input checked id=__tabbed_9_1 name=__tabbed_9 type=radio><input id=__tabbed_9_2 name=__tabbed_9 type=radio><div class=tabbed-labels><label for=__tabbed_9_1>Python</label><label for=__tabbed_9_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-12-1 id=__codelineno-12-1 name=__codelineno-12-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-12-2 id=__codelineno-12-2 name=__codelineno-12-2></a>
<a href=#__codelineno-12-3 id=__codelineno-12-3 name=__codelineno-12-3></a><span class=c1># Load a model</span>
<a href=#__codelineno-12-4 id=__codelineno-12-4 name=__codelineno-12-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.pt"</span><span class=p>)</span>  <span class=c1># load a pretrained model (recommended for training)</span>
<a href=#__codelineno-12-5 id=__codelineno-12-5 name=__codelineno-12-5></a>
<a href=#__codelineno-12-6 id=__codelineno-12-6 name=__codelineno-12-6></a><span class=c1># Train the model</span>
<a href=#__codelineno-12-7 id=__codelineno-12-7 name=__codelineno-12-7></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s2>"coco8.yaml"</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>)</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-13-1 id=__codelineno-13-1 name=__codelineno-13-1></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.pt<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span>
</code></pre></div></div></div></div></div><p>For more details, refer to the <a href=#train-settings>Train Settings</a> section.<h3 id=what-are-the-key-features-of-ultralytics-yolo11s-train-mode>What are the key features of Ultralytics YOLO11's Train mode?</h3><p>The key features of Ultralytics YOLO11's Train mode include:<ul><li><strong>Automatic Dataset Download:</strong> Automatically downloads standard datasets like COCO, VOC, and ImageNet.<li><strong>Multi-GPU Support:</strong> Scale training across multiple GPUs for faster processing.<li><strong>Hyperparameter Configuration:</strong> Customize hyperparameters through YAML files or CLI arguments.<li><strong>Visualization and Monitoring:</strong> Real-time tracking of training metrics for better insights.</ul><p>These features make training efficient and customizable to your needs. For more details, see the <a href=#key-features-of-train-mode>Key Features of Train Mode</a> section.<h3 id=how-do-i-resume-training-from-an-interrupted-session-in-ultralytics-yolo11>How do I resume training from an interrupted session in Ultralytics YOLO11?</h3><p>To resume training from an interrupted session, set the <code>resume</code> argument to <code>True</code> and specify the path to the last saved checkpoint.<div class="admonition example"><p class=admonition-title>Resume Training Example<div class="tabbed-set tabbed-alternate"data-tabs=10:2><input checked id=__tabbed_10_1 name=__tabbed_10 type=radio><input id=__tabbed_10_2 name=__tabbed_10 type=radio><div class=tabbed-labels><label for=__tabbed_10_1>Python</label><label for=__tabbed_10_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-14-1 id=__codelineno-14-1 name=__codelineno-14-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-14-2 id=__codelineno-14-2 name=__codelineno-14-2></a>
<a href=#__codelineno-14-3 id=__codelineno-14-3 name=__codelineno-14-3></a><span class=c1># Load the partially trained model</span>
<a href=#__codelineno-14-4 id=__codelineno-14-4 name=__codelineno-14-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"path/to/last.pt"</span><span class=p>)</span>
<a href=#__codelineno-14-5 id=__codelineno-14-5 name=__codelineno-14-5></a>
<a href=#__codelineno-14-6 id=__codelineno-14-6 name=__codelineno-14-6></a><span class=c1># Resume training</span>
<a href=#__codelineno-14-7 id=__codelineno-14-7 name=__codelineno-14-7></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>resume</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-15-1 id=__codelineno-15-1 name=__codelineno-15-1></a>yolo<span class=w> </span>train<span class=w> </span>resume<span class=w> </span><span class=nv>model</span><span class=o>=</span>path/to/last.pt
</code></pre></div></div></div></div></div><p>Check the section on <a href=#resuming-interrupted-trainings>Resuming Interrupted Trainings</a> for more information.<h3 id=can-i-train-yolo11-models-on-apple-silicon-chips>Can I train YOLO11 models on Apple silicon chips?</h3><p>Yes, Ultralytics YOLO11 supports training on Apple silicon chips utilizing the Metal Performance Shaders (MPS) framework. Specify 'mps' as your training device.<div class="admonition example"><p class=admonition-title>MPS Training Example<div class="tabbed-set tabbed-alternate"data-tabs=11:2><input checked id=__tabbed_11_1 name=__tabbed_11 type=radio><input id=__tabbed_11_2 name=__tabbed_11 type=radio><div class=tabbed-labels><label for=__tabbed_11_1>Python</label><label for=__tabbed_11_2>CLI</label></div><div class=tabbed-content><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-16-1 id=__codelineno-16-1 name=__codelineno-16-1></a><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
<a href=#__codelineno-16-2 id=__codelineno-16-2 name=__codelineno-16-2></a>
<a href=#__codelineno-16-3 id=__codelineno-16-3 name=__codelineno-16-3></a><span class=c1># Load a pretrained model</span>
<a href=#__codelineno-16-4 id=__codelineno-16-4 name=__codelineno-16-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s2>"yolo11n.pt"</span><span class=p>)</span>
<a href=#__codelineno-16-5 id=__codelineno-16-5 name=__codelineno-16-5></a>
<a href=#__codelineno-16-6 id=__codelineno-16-6 name=__codelineno-16-6></a><span class=c1># Train the model on Apple silicon chip (M1/M2/M3/M4)</span>
<a href=#__codelineno-16-7 id=__codelineno-16-7 name=__codelineno-16-7></a><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s2>"coco8.yaml"</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s2>"mps"</span><span class=p>)</span>
</code></pre></div></div><div class=tabbed-block><div class=highlight><pre><span></span><code><a href=#__codelineno-17-1 id=__codelineno-17-1 name=__codelineno-17-1></a>yolo<span class=w> </span>detect<span class=w> </span>train<span class=w> </span><span class=nv>data</span><span class=o>=</span>coco8.yaml<span class=w> </span><span class=nv>model</span><span class=o>=</span>yolo11n.pt<span class=w> </span><span class=nv>epochs</span><span class=o>=</span><span class=m>100</span><span class=w> </span><span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span><span class=w> </span><span class=nv>device</span><span class=o>=</span>mps
</code></pre></div></div></div></div></div><p>For more details, refer to the <a href=#apple-silicon-mps-training>Apple Silicon MPS Training</a> section.<h3 id=what-are-the-common-training-settings-and-how-do-i-configure-them>What are the common training settings, and how do I configure them?</h3><p>Ultralytics YOLO11 allows you to configure a variety of training settings such as batch size, learning rate, epochs, and more through arguments. Here's a brief overview:<table><thead><tr><th>Argument<th>Default<th>Description<tbody><tr><td><code>model</code><td><code>None</code><td>Path to the model file for training.<tr><td><code>data</code><td><code>None</code><td>Path to the dataset configuration file (e.g., <code>coco8.yaml</code>).<tr><td><code>epochs</code><td><code>100</code><td>Total number of training epochs.<tr><td><code>batch</code><td><code>16</code><td>Batch size, adjustable as integer or auto mode.<tr><td><code>imgsz</code><td><code>640</code><td>Target image size for training.<tr><td><code>device</code><td><code>None</code><td>Computational device(s) for training like <code>cpu</code>, <code>0</code>, <code>0,1</code>, or <code>mps</code>.<tr><td><code>save</code><td><code>True</code><td>Enables saving of training checkpoints and final model weights.</table><p>For an in-depth guide on training settings, check the <a href=#train-settings>Train Settings</a> section.<div class=git-info><div class=dates-container><span title="This page was first created on November 12, 2023"class=date-item> <span class=hover-item>ðŸ“…</span> Created 1 year ago </span><span title="This page was last updated on November 05, 2024"class=date-item> <span class=hover-item>âœï¸</span> Updated 15 days ago </span></div><div class=authors-container><a title="JairajJangle (1 change)"class=author-link href=https://github.com/JairajJangle> <img alt=JairajJangle class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/25704330?v=4&s=96> </a><a title="UltralyticsAssistant (2 changes)"class=author-link href=https://github.com/UltralyticsAssistant> <img alt=UltralyticsAssistant class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/135830346?v=4&s=96> </a><a title="glenn-jocher (17 changes)"class=author-link href=https://github.com/glenn-jocher> <img alt=glenn-jocher class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/26833433?v=4&s=96> </a><a title="jk4e (1 change)"class=author-link href=https://github.com/jk4e> <img alt=jk4e class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/116908874?v=4&s=96> </a><a title="MatthewNoyce (2 changes)"class=author-link href=https://github.com/MatthewNoyce> <img alt=MatthewNoyce class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/131261051?v=4&s=96> </a><a title="RizwanMunawar (1 change)"class=author-link href=https://github.com/RizwanMunawar> <img alt=RizwanMunawar class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/62513924?v=4&s=96> </a><a title="dependabot (1 change)"class=author-link href=https://github.com/dependabot> <img alt=dependabot class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/27347476?v=4&s=96> </a><a title="fcakyon (1 change)"class=author-link href=https://github.com/fcakyon> <img alt=fcakyon class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/34196005?v=4&s=96> </a><a title="Laughing-q (2 changes)"class=author-link href=https://github.com/Laughing-q> <img alt=Laughing-q class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/61612323?v=4&s=96> </a><a title="Burhan-Q (1 change)"class=author-link href=https://github.com/Burhan-Q> <img alt=Burhan-Q class=hover-item loading=lazy src=https://avatars.githubusercontent.com/u/62214284?v=4&s=96> </a></div></div><div class=share-buttons><button class="share-button hover-item"onclick="window.open('https://twitter.com/intent/tweet?url=https://docs.ultralytics.com/modes/train', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet</button><button class="share-button hover-item linkedin"onclick="window.open('https://www.linkedin.com/shareArticle?url=https://docs.ultralytics.com/modes/train', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share</button></div><h2 id=__comments>Comments</h2><div id=giscus-container></div></article></div><script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script><script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script></div><button class="md-top md-icon"data-md-component=top hidden type=button><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top</button></main><footer class=md-footer><nav class="md-footer__inner md-grid"aria-label=Footer><a aria-label="Previous: Ultralytics YOLO11 Modes"class="md-footer__link md-footer__link--prev"href=../> <div class="md-footer__button md-icon"><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg></div> <div class=md-footer__title><span class=md-footer__direction> Previous </span><div class=md-ellipsis>Ultralytics YOLO11 Modes</div></div> </a><a aria-label="Next: Val"class="md-footer__link md-footer__link--next"href=../val/> <div class=md-footer__title><span class=md-footer__direction> Next </span><div class=md-ellipsis>Val</div></div> <div class="md-footer__button md-icon"><svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg></div> </a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class=md-copyright><div class=md-copyright__highlight><a href=https://ultralytics.com target=_blank>Â© 2024 Ultralytics Inc.</a> All rights reserved.</div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ rel=noopener target=_blank> Material for MkDocs </a></div><div class=md-social><a class=md-social__link href=https://github.com/ultralytics rel=noopener target=_blank title=github.com> <svg viewbox="0 0 496 512"xmlns=http://www.w3.org/2000/svg><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </a><a class=md-social__link href=https://www.linkedin.com/company/ultralytics/ rel=noopener target=_blank title=www.linkedin.com> <svg viewbox="0 0 448 512"xmlns=http://www.w3.org/2000/svg><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg> </a><a class=md-social__link href=https://twitter.com/ultralytics rel=noopener target=_blank title=twitter.com> <svg viewbox="0 0 512 512"xmlns=http://www.w3.org/2000/svg><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"></path></svg> </a><a class=md-social__link href=https://youtube.com/ultralytics?sub_confirmation=1 rel=noopener target=_blank title=youtube.com> <svg viewbox="0 0 576 512"xmlns=http://www.w3.org/2000/svg><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"></path></svg> </a><a class=md-social__link href=https://hub.docker.com/r/ultralytics/ultralytics/ rel=noopener target=_blank title=hub.docker.com> <svg viewbox="0 0 640 512"xmlns=http://www.w3.org/2000/svg><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"></path></svg> </a><a class=md-social__link href=https://pypi.org/project/ultralytics/ rel=noopener target=_blank title=pypi.org> <svg viewbox="0 0 448 512"xmlns=http://www.w3.org/2000/svg><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"></path></svg> </a><a class=md-social__link href=https://ultralytics.com/discord rel=noopener target=_blank title=ultralytics.com> <svg viewbox="0 0 640 512"xmlns=http://www.w3.org/2000/svg><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"></path></svg> </a><a class=md-social__link href=https://reddit.com/r/ultralytics rel=noopener target=_blank title=reddit.com> <svg viewbox="0 0 512 512"xmlns=http://www.w3.org/2000/svg><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5"></path></svg> </a></div></div></div></footer></div><div class=md-dialog data-md-component=dialog><div class="md-dialog__inner md-typeset"></div></div><div class=md-progress data-md-component=progress role=progressbar></div><script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tooltips", "search.highlight", "search.share", "search.suggest", "toc.follow", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "navigation.indexes", "navigation.sections", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script><script src=../../assets/javascripts/bundle.83f73b43.min.js></script><script src=../../javascript/extra.js></script><script src=../../javascript/giscus.js></script>