<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Learn how to use Albumentations with YOLO11 to enhance data augmentation, improve model performance, and streamline your computer vision projects." name="description"/>
<meta content="Ultralytics" name="author"/>
<link href="https://docs.ultralytics.com/integrations/albumentations.html" rel="canonical"/>
<link href="weights-biases.html" rel="prev"/>
<link href="torchscript.html" rel="next"/>
<link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.16" name="generator"/>
<title>Enhance Your Dataset to Train YOLO11 Using Albumentations</title>
<link href="../assets/stylesheets/main.7e37652d.min.css" rel="stylesheet"/>
<link href="../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="Albumentations" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="Albumentations, YOLO11, data augmentation, Ultralytics, computer vision, object detection, model training, image transformations, machine learning" name="keywords"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/integrations/albumentations.html" property="og:url"/><meta content="Albumentations" property="og:title"/><meta content="Learn how to use Albumentations with YOLO11 to enhance data augmentation, improve model performance, and streamline your computer vision projects." property="og:description"/><meta content="https://github.com/ultralytics/docs/releases/download/0/albumentations-augmentation.avif" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/integrations/albumentations.html" property="twitter:url"/><meta content="Albumentations" property="twitter:title"/><meta content="Learn how to use Albumentations with YOLO11 to enhance data augmentation, improve model performance, and streamline your computer vision projects." property="twitter:description"/><meta content="https://github.com/ultralytics/docs/releases/download/0/albumentations-augmentation.avif" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": ["Article", "FAQPage"], "headline": "Albumentations", "image": ["https://github.com/ultralytics/docs/releases/download/0/albumentations-augmentation.avif"], "datePublished": "2024-11-05 05:52:46 +0530", "dateModified": "2025-06-22 19:21:22 +0100", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "Learn how to use Albumentations with YOLO11 to enhance data augmentation, improve model performance, and streamline your computer vision projects.", "mainEntity": [{"@type": "Question", "name": "How can I integrate Albumentations with YOLO11 for improved data augmentation?", "acceptedAnswer": {"@type": "Answer", "text": "Albumentations integrates seamlessly with YOLO11 and applies automatically during training if you have the package installed. Here's how to get started: The integration includes optimized augmentations like blur, median blur, grayscale conversion, and CLAHE with carefully tuned probabilities to enhance model performance."}}, {"@type": "Question", "name": "What are the key benefits of using Albumentations over other augmentation libraries?", "acceptedAnswer": {"@type": "Answer", "text": "Albumentations stands out for several reasons:"}}, {"@type": "Question", "name": "What types of computer vision tasks can benefit from Albumentations augmentation?", "acceptedAnswer": {"@type": "Answer", "text": "Albumentations enhances various computer vision tasks including: The library's diverse augmentation options make it valuable for any vision task requiring robust model performance."}}]}</script></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#enhance-your-dataset-to-train-yolo11-using-albumentations">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<div class="banner-wrapper">
<div class="banner-content-wrapper" onclick="window.open('https://docs.ultralytics.com/models/yolo11/')">
<p>Introducing</p>
<img alt="Ultralytics YOLO11" height="40" loading="lazy" src="https://assets-global.website-files.com/646dd1f1a3703e451ba81ecc/67d044caa316aa50fba40a08_Ultralytics_YOLO11_Logotype_Reverse.svg"/>
</div>
</div>
</div>
</aside>
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Ultralytics YOLO Docs
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
              Albumentations
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg>
</label>
<input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option">
<div class="md-select">
<button aria-label="Select language" class="md-header__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg>
</button>
<div class="md-select__inner">
<ul class="md-select__list">
<li class="md-select__item">
<a class="md-select__link" href="/" hreflang="en">
              🇬🇧 English
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/zh/" hreflang="zh">
              🇨🇳 简体中文
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ko/" hreflang="ko">
              🇰🇷 한국어
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ja/" hreflang="ja">
              🇯🇵 日本語
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ru/" hreflang="ru">
              🇷🇺 Русский
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/de/" hreflang="de">
              🇩🇪 Deutsch
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/fr/" hreflang="fr">
              🇫🇷 Français
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/es/" hreflang="es">
              🇪🇸 Español
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/pt/" hreflang="pt">
              🇵🇹 Português
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/it/" hreflang="it">
              🇮🇹 Italiano
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/tr/" hreflang="tr">
              🇹🇷 Türkçe
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/vi/" hreflang="vi">
              🇻🇳 Tiếng Việt
            </a>
</li>
<li class="md-select__item">
<a class="md-select__link" href="/ar/" hreflang="ar">
              🇸🇦 العربية
            </a>
</li>
</ul>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../index.html">
  Home
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../quickstart.html">
  Quickstart
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../modes/index.html">
  Modes
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../tasks/index.html">
  Tasks
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../models/index.html">
  Models
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../datasets/index.html">
  Datasets
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../solutions/index.html">
  Solutions 🚀
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../guides/index.html">
  Guides
        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="index.html">
  Integrations
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../hub/index.html">
  HUB
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../reference/cfg/__init__.html">
  Reference
        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../help/index.html">
  Help
        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs">
<img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/>
</a>
    Ultralytics YOLO Docs
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    ultralytics/ultralytics
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../index.html">
<span class="md-ellipsis">
    Home
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../quickstart.html">
<span class="md-ellipsis">
    Quickstart
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../modes/index.html">
<span class="md-ellipsis">
    Modes
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../tasks/index.html">
<span class="md-ellipsis">
    Tasks
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../models/index.html">
<span class="md-ellipsis">
    Models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../datasets/index.html">
<span class="md-ellipsis">
    Datasets
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../solutions/index.html">
<span class="md-ellipsis">
    Solutions 🚀
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../guides/index.html">
<span class="md-ellipsis">
    Guides
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="index.html">
<span class="md-ellipsis">
    Integrations
  </span>
</a>
<label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_9">
<span class="md-nav__icon md-icon"></span>
            Integrations
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="sony-imx500.html">
<span class="md-ellipsis">
    SONY IMX500
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="amazon-sagemaker.html">
<span class="md-ellipsis">
    Amazon SageMaker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="clearml.html">
<span class="md-ellipsis">
    ClearML
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="comet.html">
<span class="md-ellipsis">
    Comet ML
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="dvc.html">
<span class="md-ellipsis">
    DVC
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="google-colab.html">
<span class="md-ellipsis">
    Google Colab
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="ibm-watsonx.html">
<span class="md-ellipsis">
    IBM Watsonx
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="jupyterlab.html">
<span class="md-ellipsis">
    JupyterLab
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="kaggle.html">
<span class="md-ellipsis">
    Kaggle
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="mlflow.html">
<span class="md-ellipsis">
    MLflow
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="paperspace.html">
<span class="md-ellipsis">
    Paperspace Gradient
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="ray-tune.html">
<span class="md-ellipsis">
    Ray Tune
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tensorboard.html">
<span class="md-ellipsis">
    TensorBoard
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="vscode.html">
<span class="md-ellipsis">
    VS Code
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="weights-biases.html">
<span class="md-ellipsis">
    Weights &amp; Biases
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Albumentations
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="albumentations.html">
<span class="md-ellipsis">
    Albumentations
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#albumentations-for-image-augmentation">
<span class="md-ellipsis">
      Albumentations for Image Augmentation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key-features-of-albumentations">
<span class="md-ellipsis">
      Key Features of Albumentations
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#why-should-you-use-albumentations-for-your-vision-ai-projects">
<span class="md-ellipsis">
      Why Should You Use Albumentations for Your Vision AI Projects?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#how-to-use-albumentations-to-augment-data-for-yolo11-training">
<span class="md-ellipsis">
      How to Use Albumentations to Augment Data for YOLO11 Training
    </span>
</a>
<nav aria-label="How to Use Albumentations to Augment Data for YOLO11 Training" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#installation">
<span class="md-ellipsis">
      Installation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#usage">
<span class="md-ellipsis">
      Usage
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#blur">
<span class="md-ellipsis">
      Blur
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#median-blur">
<span class="md-ellipsis">
      Median Blur
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#grayscale">
<span class="md-ellipsis">
      Grayscale
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#contrast-limited-adaptive-histogram-equalization-clahe">
<span class="md-ellipsis">
      Contrast Limited Adaptive Histogram Equalization (CLAHE)
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#keep-learning-about-albumentations">
<span class="md-ellipsis">
      Keep Learning about Albumentations
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key-takeaways">
<span class="md-ellipsis">
      Key Takeaways
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#faq">
<span class="md-ellipsis">
      FAQ
    </span>
</a>
<nav aria-label="FAQ" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#how-can-i-integrate-albumentations-with-yolo11-for-improved-data-augmentation">
<span class="md-ellipsis">
      How can I integrate Albumentations with YOLO11 for improved data augmentation?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#what-are-the-key-benefits-of-using-albumentations-over-other-augmentation-libraries">
<span class="md-ellipsis">
      What are the key benefits of using Albumentations over other augmentation libraries?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#what-types-of-computer-vision-tasks-can-benefit-from-albumentations-augmentation">
<span class="md-ellipsis">
      What types of computer vision tasks can benefit from Albumentations augmentation?
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="torchscript.html">
<span class="md-ellipsis">
    TorchScript
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="onnx.html">
<span class="md-ellipsis">
    ONNX
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="openvino.html">
<span class="md-ellipsis">
    OpenVINO
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tensorrt.html">
<span class="md-ellipsis">
    TensorRT
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="coreml.html">
<span class="md-ellipsis">
    CoreML
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tf-savedmodel.html">
<span class="md-ellipsis">
    TF SavedModel
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tf-graphdef.html">
<span class="md-ellipsis">
    TF GraphDef
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tflite.html">
<span class="md-ellipsis">
    TFLite
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="edge-tpu.html">
<span class="md-ellipsis">
    TFLite Edge TPU
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tfjs.html">
<span class="md-ellipsis">
    TF.js
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="paddlepaddle.html">
<span class="md-ellipsis">
    PaddlePaddle
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="mnn.html">
<span class="md-ellipsis">
    MNN
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="ncnn.html">
<span class="md-ellipsis">
    NCNN
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="rockchip-rknn.html">
<span class="md-ellipsis">
    Rockchip RKNN
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="neural-magic.html">
<span class="md-ellipsis">
    Neural Magic
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="seeedstudio-recamera.html">
<span class="md-ellipsis">
    Seeed Studio reCamera
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="gradio.html">
<span class="md-ellipsis">
    Gradio
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="roboflow.html">
<span class="md-ellipsis">
    Roboflow
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../hub/index.html">
<span class="md-ellipsis">
    HUB
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../reference/cfg/__init__.html">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../help/index.html">
<span class="md-ellipsis">
    Help
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#albumentations-for-image-augmentation">
<span class="md-ellipsis">
      Albumentations for Image Augmentation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key-features-of-albumentations">
<span class="md-ellipsis">
      Key Features of Albumentations
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#why-should-you-use-albumentations-for-your-vision-ai-projects">
<span class="md-ellipsis">
      Why Should You Use Albumentations for Your Vision AI Projects?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#how-to-use-albumentations-to-augment-data-for-yolo11-training">
<span class="md-ellipsis">
      How to Use Albumentations to Augment Data for YOLO11 Training
    </span>
</a>
<nav aria-label="How to Use Albumentations to Augment Data for YOLO11 Training" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#installation">
<span class="md-ellipsis">
      Installation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#usage">
<span class="md-ellipsis">
      Usage
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#blur">
<span class="md-ellipsis">
      Blur
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#median-blur">
<span class="md-ellipsis">
      Median Blur
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#grayscale">
<span class="md-ellipsis">
      Grayscale
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#contrast-limited-adaptive-histogram-equalization-clahe">
<span class="md-ellipsis">
      Contrast Limited Adaptive Histogram Equalization (CLAHE)
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#keep-learning-about-albumentations">
<span class="md-ellipsis">
      Keep Learning about Albumentations
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#key-takeaways">
<span class="md-ellipsis">
      Key Takeaways
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#faq">
<span class="md-ellipsis">
      FAQ
    </span>
</a>
<nav aria-label="FAQ" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#how-can-i-integrate-albumentations-with-yolo11-for-improved-data-augmentation">
<span class="md-ellipsis">
      How can I integrate Albumentations with YOLO11 for improved data augmentation?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#what-are-the-key-benefits-of-using-albumentations-over-other-augmentation-libraries">
<span class="md-ellipsis">
      What are the key benefits of using Albumentations over other augmentation libraries?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#what-types-of-computer-vision-tasks-can-benefit-from-albumentations-augmentation">
<span class="md-ellipsis">
      What types of computer vision tasks can benefit from Albumentations augmentation?
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/integrations/albumentations.md" rel="edit" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a><a class="md-content__button md-icon" href="javascript:void(0)" onclick="copyMarkdownForLLM(this); return false;" title="Copy page in Markdown format"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></a>
<h1 id="enhance-your-dataset-to-train-yolo11-using-albumentations">Enhance Your Dataset to Train YOLO11 Using Albumentations</h1>
<p>When you are building <a href="../models/index.html">computer vision models</a>, the quality and variety of your <a href="../datasets/index.html">training data</a> can play a big role in how well your model performs. Albumentations offers a fast, flexible, and efficient way to apply a wide range of image transformations that can improve your model's ability to adapt to real-world scenarios. It easily integrates with <a href="https://github.com/ultralytics/ultralytics">Ultralytics YOLO11</a> and can help you create robust datasets for <a href="../tasks/detect.html">object detection</a>, <a href="../tasks/segment.html">segmentation</a>, and <a href="../tasks/classify.html">classification</a> tasks.</p>
<p>By using Albumentations, you can boost your YOLO11 training data with techniques like geometric transformations and color adjustments. In this article, we'll see how Albumentations can improve your <a href="../guides/preprocessing_annotated_data.html">data augmentation</a> process and make your <a href="../solutions/index.html">YOLO11 projects</a> even more impactful. Let's get started!</p>
<h2 id="albumentations-for-image-augmentation">Albumentations for Image Augmentation</h2>
<p><a href="https://albumentations.ai/">Albumentations</a> is an open-source image augmentation library created in <a href="https://arxiv.org/pdf/1809.06839">June 2018</a>. It is designed to simplify and accelerate the image augmentation process in <a href="https://www.ultralytics.com/blog/exploring-image-processing-computer-vision-and-machine-vision">computer vision</a>. Created with <a href="https://www.ultralytics.com/blog/measuring-ai-performance-to-weigh-the-impact-of-your-innovations">performance</a> and flexibility in mind, it supports many diverse augmentation techniques, ranging from simple transformations like rotations and flips to more complex adjustments like brightness and contrast changes. Albumentations helps developers generate rich, varied datasets for tasks like <a href="https://www.youtube.com/watch?v=5BO0Il_YYAg">image classification</a>, <a href="https://www.youtube.com/watch?v=5ku7npMrW40&amp;t=1s">object detection</a>, and <a href="https://www.youtube.com/watch?v=o4Zd-IeMlSY">segmentation</a>.</p>
<p>You can use Albumentations to easily apply augmentations to images, <a href="https://www.ultralytics.com/glossary/image-segmentation">segmentation masks</a>, <a href="https://www.ultralytics.com/glossary/bounding-box">bounding boxes</a>, and <a href="../datasets/pose/index.html">key points</a>, and make sure that all elements of your dataset are transformed together. It works seamlessly with popular deep learning frameworks like <a href="torchscript.html">PyTorch</a> and <a href="tensorboard.html">TensorFlow</a>, making it accessible for a wide range of projects.</p>
<p>Also, Albumentations is a great option for augmentation whether you're handling small datasets or large-scale <a href="../tasks/index.html">computer vision tasks</a>. It ensures fast and efficient processing, cutting down the time spent on data preparation. At the same time, it helps improve <a href="../guides/yolo-performance-metrics.html">model performance</a>, making your models more effective in real-world applications.</p>
<h2 id="key-features-of-albumentations">Key Features of Albumentations</h2>
<p>Albumentations offers many useful features that simplify complex image augmentations for a wide range of <a href="https://www.ultralytics.com/blog/exploring-how-the-applications-of-computer-vision-work">computer vision applications</a>. Here are some of the key features:</p>
<ul>
<li><strong>Wide Range of Transformations</strong>: Albumentations offers over <a href="https://github.com/albumentations-team/albumentations?tab=readme-ov-file#list-of-augmentations">70 different transformations</a>, including geometric changes (e.g., rotation, flipping), color adjustments (e.g., brightness, contrast), and noise addition (e.g., Gaussian noise). Having multiple options enables the creation of highly diverse and robust training datasets.</li>
</ul>
<p align="center">
<img alt="Example of Image Augmentations" src="https://github.com/ultralytics/docs/releases/download/0/albumentations-augmentation.avif" width="100%"/>
</p>
<ul>
<li>
<p><strong>High Performance Optimization</strong>: Built on OpenCV and NumPy, Albumentations uses advanced optimization techniques like SIMD (Single Instruction, Multiple Data), which processes multiple data points simultaneously to speed up processing. It handles large datasets quickly, making it one of the fastest options available for image augmentation.</p>
</li>
<li>
<p><strong>Three Levels of Augmentation</strong>: Albumentations supports three levels of augmentation: pixel-level transformations, spatial-level transformations, and mixing-level transformation. Pixel-level transformations only affect the input images without altering masks, bounding boxes, or key points. Meanwhile, both the image and its elements, like masks and bounding boxes, are transformed using spatial-level transformations. Furthermore, mixing-level transformations are a unique way to augment data as it combines multiple images into one.</p>
</li>
</ul>
<p><img alt="Overview of the Different Levels of Augmentations" src="https://github.com/ultralytics/docs/releases/download/0/levels-of-augmentation.avif"/></p>
<ul>
<li><strong><a href="https://albumentations.ai/docs/benchmarks/image-benchmarks/">Benchmarking Results</a></strong>: When it comes to benchmarking, Albumentations consistently outperforms other libraries, especially with large datasets.</li>
</ul>
<h2 id="why-should-you-use-albumentations-for-your-vision-ai-projects">Why Should You Use Albumentations for Your Vision AI Projects?</h2>
<p>With respect to image augmentation, Albumentations stands out as a reliable tool for computer vision tasks. Here are a few key reasons why you should consider using it for your Vision AI projects:</p>
<ul>
<li>
<p><strong>Easy-to-Use API</strong>: Albumentations provides a single, straightforward API for applying a wide range of augmentations to images, masks, bounding boxes, and keypoints. It's designed to adapt easily to different datasets, making <a href="../guides/data-collection-and-annotation.html">data preparation</a> simpler and more efficient.</p>
</li>
<li>
<p><strong>Rigorous Bug Testing</strong>: Bugs in the augmentation pipeline can silently corrupt input data, often going unnoticed but ultimately degrading model performance. Albumentations addresses this with a thorough test suite that helps catch bugs early in development.</p>
</li>
<li>
<p><strong>Extensibility</strong>: Albumentations can be used to easily add new augmentations and use them in computer vision pipelines through a single interface along with built-in transformations.</p>
</li>
</ul>
<h2 id="how-to-use-albumentations-to-augment-data-for-yolo11-training">How to Use Albumentations to Augment Data for YOLO11 Training</h2>
<p>Now that we've covered what Albumentations is and what it can do, let's look at how to use it to augment your data for YOLO11 model training. It's easy to set up because it integrates directly into <a href="../modes/train.html">Ultralytics' training mode</a> and applies automatically if you have the Albumentations package installed.</p>
<h3 id="installation">Installation</h3>
<p>To use Albumentations with YOLO11, start by making sure you have the necessary packages installed. If Albumentations isn't installed, the augmentations won't be applied during training. Once set up, you'll be ready to create an augmented dataset for training, with Albumentations integrated to enhance your model automatically.</p>
<div class="admonition tip">
<p class="admonition-title">Installation</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="__tabbed_1_1">CLI</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span></span><span class="c1"># Install the required packages</span>
<span></span>pip<span class="w"> </span>install<span class="w"> </span>albumentations<span class="w"> </span>ultralytics
</code></pre></div>
</div>
</div>
</div>
</div>
<p>For detailed instructions and best practices related to the installation process, check our <a href="../quickstart.html">Ultralytics Installation guide</a>. While installing the required packages for YOLO11, if you encounter any difficulties, consult our <a href="../guides/yolo-common-issues.html">Common Issues guide</a> for solutions and tips.</p>
<h3 id="usage">Usage</h3>
<p>After installing the necessary packages, you're ready to start using Albumentations with YOLO11. When you train YOLO11, a set of augmentations is automatically applied through its integration with Albumentations, making it easy to enhance your model's performance.</p>
<div class="admonition example">
<p class="admonition-title">Usage</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio"/><div class="tabbed-labels"><label for="__tabbed_2_1">Python</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="c1"># Load a pre-trained model</span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolo11n.pt"</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Train the model</span>
<span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s2">"coco8.yaml"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
</div>
<p>Next, let's take look a closer look at the specific augmentations that are applied during training.</p>
<h3 id="blur">Blur</h3>
<p>The Blur transformation in Albumentations applies a simple blur effect to the image by averaging pixel values within a small square area, or kernel. This is done using OpenCV <code>cv2.blur</code> function, which helps reduce noise in the image, though it also slightly reduces image details.</p>
<p>Here are the parameters and values used in this integration:</p>
<ul>
<li>
<p><strong>blur_limit</strong>: This controls the size range of the blur effect. The default range is (3, 7), meaning the kernel size for the blur can vary between 3 and 7 pixels, with only odd numbers allowed to keep the blur centered.</p>
</li>
<li>
<p><strong>p</strong>: The probability of applying the blur. In the integration, p=0.01, so there's a 1% chance that this blur will be applied to each image. The low probability allows for occasional blur effects, introducing a bit of variation to help the model generalize without over-blurring the images.</p>
</li>
</ul>
<p><img alt="An Example of the Blur Augmentation" src="https://github.com/ultralytics/docs/releases/download/0/albumentations-blur.avif" width="776"/></p>
<h3 id="median-blur">Median Blur</h3>
<p>The MedianBlur transformation in Albumentations applies a median blur effect to the image, which is particularly useful for reducing noise while preserving edges. Unlike typical blurring methods, MedianBlur uses a median filter, which is especially effective at removing salt-and-pepper noise while maintaining sharpness around the edges.</p>
<p>Here are the parameters and values used in this integration:</p>
<ul>
<li>
<p><strong>blur_limit</strong>: This parameter controls the maximum size of the blurring kernel. In this integration, it defaults to a range of (3, 7), meaning the kernel size for the blur is randomly chosen between 3 and 7 pixels, with only odd values allowed to ensure proper alignment.</p>
</li>
<li>
<p><strong>p</strong>: Sets the probability of applying the median blur. Here, p=0.01, so the transformation has a 1% chance of being applied to each image. This low probability ensures that the median blur is used sparingly, helping the model generalize by occasionally seeing images with reduced noise and preserved edges.</p>
</li>
</ul>
<p>The image below shows an example of this augmentation applied to an image.</p>
<p><img alt="An Example of the MedianBlur Augmentation" src="https://github.com/ultralytics/docs/releases/download/0/albumentations-median-blur.avif" width="764"/></p>
<h3 id="grayscale">Grayscale</h3>
<p>The ToGray transformation in Albumentations converts an image to grayscale, reducing it to a single-channel format and optionally replicating this channel to match a specified number of output channels. Different methods can be used to adjust how grayscale brightness is calculated, ranging from simple averaging to more advanced techniques for realistic perception of contrast and brightness.</p>
<p>Here are the parameters and values used in this integration:</p>
<ul>
<li>
<p><strong>num_output_channels</strong>: Sets the number of channels in the output image. If this value is more than 1, the single grayscale channel will be replicated to create a multichannel grayscale image. By default, it's set to 3, giving a grayscale image with three identical channels.</p>
</li>
<li>
<p><strong>method</strong>: Defines the grayscale conversion method. The default method, "weighted_average", applies a formula (0.299R + 0.587G + 0.114B) that closely aligns with human perception, providing a natural-looking grayscale effect. Other options, like "from_lab", "desaturation", "average", "max", and "pca", offer alternative ways to create grayscale images based on various needs for speed, brightness emphasis, or detail preservation.</p>
</li>
<li>
<p><strong>p</strong>: Controls how often the grayscale transformation is applied. With p=0.01, there is a 1% chance of converting each image to grayscale, making it possible for a mix of color and grayscale images to help the model generalize better.</p>
</li>
</ul>
<p>The image below shows an example of this grayscale transformation applied.</p>
<p><img alt="An Example of the ToGray Augmentation" src="https://github.com/ultralytics/docs/releases/download/0/albumentations-grayscale.avif" width="759"/></p>
<h3 id="contrast-limited-adaptive-histogram-equalization-clahe">Contrast Limited Adaptive Histogram Equalization (CLAHE)</h3>
<p>The CLAHE transformation in Albumentations applies Contrast Limited Adaptive Histogram Equalization (CLAHE), a technique that enhances image contrast by equalizing the histogram in localized regions (tiles) instead of across the whole image. CLAHE produces a balanced enhancement effect, avoiding the overly amplified contrast that can result from standard histogram equalization, especially in areas with initially low contrast.</p>
<p>Here are the parameters and values used in this integration:</p>
<ul>
<li>
<p><strong>clip_limit</strong>: Controls the contrast enhancement range. Set to a default range of (1, 4), it determines the maximum contrast allowed in each tile. Higher values are used for more contrast but may also introduce noise.</p>
</li>
<li>
<p><strong>tile_grid_size</strong>: Defines the size of the grid of tiles, typically as (rows, columns). The default value is (8, 8), meaning the image is divided into a 8x8 grid. Smaller tile sizes provide more localized adjustments, while larger ones create effects closer to global equalization.</p>
</li>
<li>
<p><strong>p</strong>: The probability of applying CLAHE. Here, p=0.01 introduces the enhancement effect only 1% of the time, ensuring that contrast adjustments are applied sparingly for occasional variation in training images.</p>
</li>
</ul>
<p>The image below shows an example of the CLAHE transformation applied.</p>
<p><img alt="An Example of the CLAHE Augmentation" src="https://github.com/ultralytics/docs/releases/download/0/albumentations-CLAHE.avif" width="760"/></p>
<h2 id="keep-learning-about-albumentations">Keep Learning about Albumentations</h2>
<p>If you are interested in learning more about Albumentations, check out the following resources for more in-depth instructions and examples:</p>
<ul>
<li>
<p><strong><a href="https://albumentations.ai/docs/">Albumentations Documentation</a></strong>: The official documentation provides a full range of supported transformations and advanced usage techniques.</p>
</li>
<li>
<p><strong><a href="https://docs.ultralytics.com/reference/data/augment/?h=albumentation#ultralytics.data.augment.Albumentations">Ultralytics Albumentations Guide</a></strong>: Get a closer look at the details of the function that facilitate this integration.</p>
</li>
<li>
<p><strong><a href="https://github.com/albumentations-team/albumentations/">Albumentations GitHub Repository</a></strong>: The repository includes examples, benchmarks, and discussions to help you get started with customizing augmentations.</p>
</li>
</ul>
<h2 id="key-takeaways">Key Takeaways</h2>
<p>In this guide, we explored the key aspects of Albumentations, a great Python library for image augmentation. We discussed its wide range of transformations, optimized performance, and how you can use it in your next YOLO11 project.</p>
<p>Also, if you'd like to know more about other Ultralytics YOLO11 integrations, visit our <a href="index.html">integration guide page</a>. You'll find valuable resources and insights there.</p>
<h2 id="faq">FAQ</h2>
<h3 id="how-can-i-integrate-albumentations-with-yolo11-for-improved-data-augmentation">How can I integrate Albumentations with YOLO11 for improved data augmentation?</h3>
<p>Albumentations integrates seamlessly with YOLO11 and applies automatically during training if you have the package installed. Here's how to get started:</p>
<div class="highlight"><pre><span></span><code><span></span><span class="c1"># Install required packages</span>
<span></span><span class="c1"># !pip install albumentations ultralytics</span>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="c1"># Load and train model with automatic augmentations</span>
<span></span><span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolo11n.pt"</span><span class="p">)</span>
<span></span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s2">"coco8.yaml"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div>
<p>The integration includes optimized augmentations like blur, median blur, grayscale conversion, and CLAHE with carefully tuned probabilities to enhance model performance.</p>
<h3 id="what-are-the-key-benefits-of-using-albumentations-over-other-augmentation-libraries">What are the key benefits of using Albumentations over other augmentation libraries?</h3>
<p>Albumentations stands out for several reasons:</p>
<ol>
<li>Performance: Built on OpenCV and NumPy with SIMD optimization for superior speed</li>
<li>Flexibility: Supports 70+ transformations across pixel-level, spatial-level, and mixing-level augmentations</li>
<li>Compatibility: Works seamlessly with popular frameworks like <a href="torchscript.html">PyTorch</a> and <a href="tensorboard.html">TensorFlow</a></li>
<li>Reliability: Extensive test suite prevents silent data corruption</li>
<li>Ease of use: Single unified API for all augmentation types</li>
</ol>
<h3 id="what-types-of-computer-vision-tasks-can-benefit-from-albumentations-augmentation">What types of computer vision tasks can benefit from Albumentations augmentation?</h3>
<p>Albumentations enhances various <a href="../tasks/index.html">computer vision tasks</a> including:</p>
<ul>
<li><a href="../tasks/detect.html">Object Detection</a>: Improves model robustness to lighting, scale, and orientation variations</li>
<li><a href="../tasks/segment.html">Instance Segmentation</a>: Enhances mask prediction accuracy through diverse transformations</li>
<li><a href="../tasks/classify.html">Classification</a>: Increases model generalization with color and geometric augmentations</li>
<li><a href="../tasks/pose.html">Pose Estimation</a>: Helps models adapt to different viewpoints and lighting conditions</li>
</ul>
<p>The library's diverse augmentation options make it valuable for any vision task requiring robust model performance.</p>
<br/><br/>
<div class="git-info">
<div class="dates-container">
<span class="date-item" title="This page was first created on November 05, 2024">
<span class="hover-item">📅</span> Created 9 months ago
    </span>
<span class="date-item" title="This page was last updated on June 22, 2025">
<span class="hover-item">✏️</span> Updated 1 month ago
    </span>
</div>
<div class="authors-container">
<a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (4 changes)">
<img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/RizwanMunawar" title="RizwanMunawar (3 changes)">
<img alt="RizwanMunawar" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62513924?v=4&amp;s=96"/>
</a>
<a class="author-link" href="https://github.com/abirami-vina" title="abirami-vina (1 change)">
<img alt="abirami-vina" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/25847604?v=4&amp;s=96"/>
</a>
</div></div><div class="share-buttons">
<button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https://docs.ultralytics.com/integrations/albumentations.html', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-x-twitter"></i> Tweet
    </button>
<button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https://docs.ultralytics.com/integrations/albumentations.html', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;">
<i class="fa-brands fa-linkedin-in"></i> Share
    </button>
</div>
<br/>
<h2 id="__comments">Comments</h2>
<div id="giscus-container"></div>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: Weights &amp; Biases" class="md-footer__link md-footer__link--prev" href="weights-biases.html">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                Weights &amp; Biases
              </div>
</div>
</a>
<a aria-label="Next: TorchScript" class="md-footer__link md-footer__link--next" href="torchscript.html">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                TorchScript
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
<a href="https://www.ultralytics.com/" target="_blank">© 2025 Ultralytics Inc.</a> All rights reserved.
    </div>
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com">
<svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tooltips", "toc.follow", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.instant", "navigation.instant.progress", "navigation.indexes", "navigation.sections", "content.tabs.link"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
<script src="../assets/javascripts/bundle.50899def.min.js"></script>
<script src="../javascript/extra.js"></script>
<script src="../javascript/giscus.js"></script>
<script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
<script src="../javascript/tablesort.js"></script>
<script>
                    async function copyMarkdownForLLM(button) {
                        const editBtn = document.querySelector('a[title="Edit this page"]');
                        if (!editBtn) return;
                        const originalHTML = button.innerHTML;
                        const checkIcon = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19L21 7l-1.41-1.41L9 16.17z"></path></svg>';
                        // Handle both /blob/ and /tree/ in GitHub URLs
                        let rawUrl = editBtn.href.replace('github.com', 'raw.githubusercontent.com');
                        // Remove /blob/ or /tree/ from the URL
                        rawUrl = rawUrl.replace('/blob/', '/').replace('/tree/', '/');
                        try {
                            const response = await fetch(rawUrl);
                            let markdown = await response.text();
                            // Remove YAML front matter if present
                            if (markdown.startsWith('---')) {
                                const frontMatterEnd = markdown.indexOf('\n---\n', 3);
                                if (frontMatterEnd !== -1) {
                                    markdown = markdown.substring(frontMatterEnd + 5).trim();
                                }
                            }
                            const title = document.querySelector('h1')?.textContent || document.title;
                            const content = `# ${title}\n\nSource: ${window.location.href}\n\n---\n\n${markdown}`;
                            await navigator.clipboard.writeText(content);
                            button.innerHTML = checkIcon + ' Copied!';
                            setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                        } catch (err) {
                            button.innerHTML = '❌ Failed';
                            setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                        }
                    }
                    </script></body>
</html>