 <!DOCTYPE html><html class="no-js" lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="Learn how to train YOLOv5 on your own custom datasets with easy-to-follow steps. Detailed guide on dataset preparation, model selection, and training process." name="description"/><meta content="Ultralytics" name="author"/><link href="https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/" rel="canonical"/><link href="../../environments/docker_image_quickstart_tutorial/" rel="prev"/><link href="../tips_for_best_training_results/" rel="next"/><link href="/" hreflang="en" rel="alternate"/><link href="/zh/" hreflang="zh" rel="alternate"/><link href="/ko/" hreflang="ko" rel="alternate"/><link href="/ja/" hreflang="ja" rel="alternate"/><link href="/ru/" hreflang="ru" rel="alternate"/><link href="/de/" hreflang="de" rel="alternate"/><link href="/fr/" hreflang="fr" rel="alternate"/><link href="/es/" hreflang="es" rel="alternate"/><link href="/pt/" hreflang="pt" rel="alternate"/><link href="/it/" hreflang="it" rel="alternate"/><link href="/tr/" hreflang="tr" rel="alternate"/><link href="/vi/" hreflang="vi" rel="alternate"/><link href="/ar/" hreflang="ar" rel="alternate"/><link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/><meta content="zensical-0.0.17" name="generator"/><title>Train YOLOv5 on Custom Data - Ultralytics YOLO Docs</title><link href="../../../assets/stylesheets/modern/main.d4922b3c.min.css" rel="stylesheet"/><link href="../../../assets/stylesheets/modern/palette.dfe2e883.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,500,500i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link href="../../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<style data-doc-kind="true">.doc-kind{display:inline-flex;align-items:center;gap:0.25em;padding:0.21em 0.59em;border-radius:999px;font-weight:700;font-size:0.81em;letter-spacing:0.06em;text-transform:uppercase;line-height:1;color:var(--doc-kind-color,#f8fafc);background:var(--doc-kind-bg,rgba(255,255,255,0.12));}.doc-kind-class{--doc-kind-color:#039dfc;--doc-kind-bg:rgba(3,157,252,0.22);}.doc-kind-function{--doc-kind-color:#fc9803;--doc-kind-bg:rgba(252,152,3,0.22);}.doc-kind-method{--doc-kind-color:#ef5eff;--doc-kind-bg:rgba(239,94,255,0.22);}.doc-kind-property{--doc-kind-color:#02e835;--doc-kind-bg:rgba(2,232,53,0.22);}</style><meta content="Train YOLOv5 on Custom Data" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/" property="og:url"/><meta content="Train YOLOv5 on Custom Data" property="og:title"/><meta content="" property="og:description"/><meta content="https://colab.research.google.com/assets/colab-badge.svg" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/" property="twitter:url"/><meta content="Train YOLOv5 on Custom Data" property="twitter:title"/><meta content="" property="twitter:description"/><meta content="https://colab.research.google.com/assets/colab-badge.svg" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": ["Article", "FAQPage"], "headline": "Train YOLOv5 on Custom Data", "image": ["https://colab.research.google.com/assets/colab-badge.svg"], "datePublished": "2023-11-12 02:49:37 +0100", "dateModified": "2026-01-20 01:51:10 +0000", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "", "mainEntity": [{"@type": "Question", "name": "How do I train YOLOv5 on my custom dataset?", "acceptedAnswer": {"@type": "Answer", "text": "Training YOLOv5 on a custom dataset involves several key steps:"}}, {"@type": "Question", "name": "Why should I use Ultralytics Platform for training my YOLO models?", "acceptedAnswer": {"@type": "Answer", "text": "Ultralytics Platform is a comprehensive platform designed to streamline the entire YOLO model development lifecycle, often without needing to write any code. Key benefits include: For a practical walkthrough, check out our blog post: How to Train Your Custom Models with Ultralytics Platform."}}, {"@type": "Question", "name": "How do I convert my annotated data to the YOLOv5 format?", "acceptedAnswer": {"@type": "Answer", "text": "Whether you annotate manually or use automated tools (like those mentioned in Section 1.2), the final labels must be in the specific YOLO format required by YOLOv5: Many manual annotation tools offer direct export to YOLO format. If using automated models, you will need scripts or processes to convert their output (e.g., bounding box coordinates, segmentation masks) into this specific normalized text format. Ensure your final dataset structure adheres to the example provided in the guide. For more details, see our Data Collection and Annotation Guide."}}, {"@type": "Question", "name": "What are the licensing options for using YOLOv5 in commercial applications?", "acceptedAnswer": {"@type": "Answer", "text": "Ultralytics provides flexible licensing tailored to different needs: Select the license that aligns best with your project's requirements and distribution model."}}]}</script></head><body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" for="__drawer"></label><div data-md-component="skip"><a class="md-skip" href="#train-yolov5-on-custom-data"> Skip to content </a></div><div data-md-component="announce"><aside class="md-banner"><div class="md-banner__inner md-grid md-typeset"><a class="banner-wrapper" href="https://docs.ultralytics.com/models/yolo26"><div class="banner-content-wrapper"><img alt="Ultralytics YOLO26" height="40" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/6967372a0d67914985d322e7_Ultralytics%20YOLO26%201.svg"/><p>Built End-to-End. Built for the Edge.</p></div></a></div></aside></div><header class="md-header md-header--shadow md-header--lifted" data-md-component="header"><nav aria-label="Header" class="md-header__inner md-grid"><a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a><label class="md-header__button md-icon" for="__drawer"><svg class="lucide lucide-menu" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 5h16M4 12h16M4 19h16"></path></svg></label><div class="md-header__title" data-md-component="header-title"><div class="md-header__ellipsis"><div class="md-header__topic"><span class="md-ellipsis"> Ultralytics YOLO Docs </span></div><div class="md-header__topic" data-md-component="header-topic"><span class="md-ellipsis"> Train YOLOv5 on Custom Data </span></div></div></div><form class="md-header__option" data-md-component="palette"><input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option"><div class="md-select"><button aria-label="Select language" class="md-header__button md-icon"><svg class="lucide lucide-languages" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m5 8 6 6M4 14l6-6 2-3M2 5h12M7 2h1M22 22l-5-10-5 10M14 18h6"></path></svg></button><div class="md-select__inner"><ul class="md-select__list"><li class="md-select__item"><a class="md-select__link" href="/" hreflang="en"> üá¨üáß English </a></li><li class="md-select__item"><a class="md-select__link" href="/zh/" hreflang="zh"> üá®üá≥ ÁÆÄ‰Ωì‰∏≠Êñá </a></li><li class="md-select__item"><a class="md-select__link" href="/ko/" hreflang="ko"> üá∞üá∑ ÌïúÍµ≠Ïñ¥ </a></li><li class="md-select__item"><a class="md-select__link" href="/ja/" hreflang="ja"> üáØüáµ Êó•Êú¨Ë™û </a></li><li class="md-select__item"><a class="md-select__link" href="/ru/" hreflang="ru"> üá∑üá∫ –†—É—Å—Å–∫–∏–π </a></li><li class="md-select__item"><a class="md-select__link" href="/de/" hreflang="de"> üá©üá™ Deutsch </a></li><li class="md-select__item"><a class="md-select__link" href="/fr/" hreflang="fr"> üá´üá∑ Fran√ßais </a></li><li class="md-select__item"><a class="md-select__link" href="/es/" hreflang="es"> üá™üá∏ Espa√±ol </a></li><li class="md-select__item"><a class="md-select__link" href="/pt/" hreflang="pt"> üáµüáπ Portugu√™s </a></li><li class="md-select__item"><a class="md-select__link" href="/it/" hreflang="it"> üáÆüáπ Italiano </a></li><li class="md-select__item"><a class="md-select__link" href="/tr/" hreflang="tr"> üáπüá∑ T√ºrk√ße </a></li><li class="md-select__item"><a class="md-select__link" href="/vi/" hreflang="vi"> üáªüá≥ Ti·∫øng Vi·ªát </a></li><li class="md-select__item"><a class="md-select__link" href="/ar/" hreflang="ar"> üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© </a></li></ul></div></div></div><div class="md-header__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div></nav><nav aria-label="Tabs" class="md-tabs" data-md-component="tabs"><div class="md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a class="md-tabs__link" href="../../.."> Home </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../modes/"> Modes </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../tasks/"> Tasks </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../models/"> Models </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../datasets/"> Datasets </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../solutions/"> Solutions </a></li><li class="md-tabs__item md-tabs__item--active"><a class="md-tabs__link" href="../../../guides/"> Guides </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../integrations/"> Integrations </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../platform/"> Platform </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../reference/__init__/"> Reference </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../../help/"> Help </a></li></ul></div></nav></header><div class="md-container" data-md-component="container"><main class="md-main" data-md-component="main"><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0"><label class="md-nav__title" for="__drawer"><a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a> Ultralytics YOLO Docs </label><div class="md-nav__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../.."><span class="md-ellipsis"> Home </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../modes/"><span class="md-ellipsis"> Ultralytics YOLO26 Modes </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../tasks/"><span class="md-ellipsis"> Computer Vision Tasks Supported by Ultralytics YOLO26 </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../models/"><span class="md-ellipsis"> Models </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../datasets/"><span class="md-ellipsis"> Datasets </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../solutions/"><span class="md-ellipsis"> Solutions </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_7" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../../guides/"><span class="md-ellipsis"> Guides </span></a><label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="true" aria-labelledby="__nav_7_label" class="md-nav" data-md-level="1"><label class="md-nav__title" for="__nav_7"><span class="md-nav__icon md-icon"></span> Guides </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-testing/"><span class="md-ellipsis"> A Guide on Model Testing </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/azureml-quickstart/"><span class="md-ellipsis"> AzureML Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-deployment-practices/"><span class="md-ellipsis"> Best Practices for Model Deployment </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/conda-quickstart/"><span class="md-ellipsis"> Conda Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/data-collection-and-annotation/"><span class="md-ellipsis"> Data Collection and Annotation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/deepstream-nvidia-jetson/"><span class="md-ellipsis"> DeepStream on NVIDIA Jetson </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/defining-project-goals/"><span class="md-ellipsis"> Defining A Computer Vision Project's Goals </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/vertex-ai-deployment-with-docker/"><span class="md-ellipsis"> Deploying YOLO on Vertex AI in Docker container </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/docker-quickstart/"><span class="md-ellipsis"> Docker Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/coral-edge-tpu-on-raspberry-pi/"><span class="md-ellipsis"> Edge TPU on Raspberry Pi </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/hyperparameter-tuning/"><span class="md-ellipsis"> Hyperparameter Tuning </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-evaluation-insights/"><span class="md-ellipsis"> Insights on Model Evaluation and Fine-Tuning </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/isolating-segmentation-objects/"><span class="md-ellipsis"> Isolating Segmentation Objects </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/kfold-cross-validation/"><span class="md-ellipsis"> K-Fold Cross Validation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-monitoring-and-maintenance/"><span class="md-ellipsis"> Maintaining Your Computer Vision Model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-deployment-options/"><span class="md-ellipsis"> Model Deployment Options </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-yaml-config/"><span class="md-ellipsis"> Model YAML Configuration Guide </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/nvidia-dgx-spark/"><span class="md-ellipsis"> NVIDIA DGX Spark </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/nvidia-jetson/"><span class="md-ellipsis"> NVIDIA Jetson </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/optimizing-openvino-latency-vs-throughput-modes/"><span class="md-ellipsis"> OpenVINO Latency vs Throughput modes </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/preprocessing_annotated_data/"><span class="md-ellipsis"> Preprocessing Annotated Data </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/raspberry-pi/"><span class="md-ellipsis"> Raspberry Pi </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/ros-quickstart/"><span class="md-ellipsis"> ROS Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/sahi-tiled-inference/"><span class="md-ellipsis"> SAHI Tiled Inference </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/steps-of-a-cv-project/"><span class="md-ellipsis"> Steps of a Computer Vision Project </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/model-training-tips/"><span class="md-ellipsis"> Tips for Model Training </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/triton-inference-server/"><span class="md-ellipsis"> Triton Inference Server </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/view-results-in-terminal/"><span class="md-ellipsis"> Viewing Inference Images in a Terminal </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/yolo-common-issues/"><span class="md-ellipsis"> YOLO Common Issues </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/yolo-data-augmentation/"><span class="md-ellipsis"> YOLO Data Augmentation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/yolo-performance-metrics/"><span class="md-ellipsis"> YOLO Performance Metrics </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../guides/yolo-thread-safe-inference/"><span class="md-ellipsis"> YOLO Thread-Safe Inference </span></a></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_7_34" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../../datasets/explorer/"><span class="md-ellipsis"> Explorer </span></a><label class="md-nav__link" for="__nav_7_34" id="__nav_7_34_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_7_34_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_7_34"><span class="md-nav__icon md-icon"></span> Explorer </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../../datasets/explorer/api/"><span class="md-ellipsis"> Explorer API </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../datasets/explorer/dashboard/"><span class="md-ellipsis"> Explorer Dashboard Demo </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../../datasets/explorer/explorer/"><span class="md-ellipsis"> VOC Exploration Example </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_7_35" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../"><span class="md-ellipsis"> YOLOv5 </span></a><label class="md-nav__link" for="__nav_7_35" id="__nav_7_35_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="true" aria-labelledby="__nav_7_35_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_7_35"><span class="md-nav__icon md-icon"></span> YOLOv5 </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../quickstart_tutorial/"><span class="md-ellipsis"> Quickstart </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../environments/aws_quickstart_tutorial/"><span class="md-ellipsis"> Environments </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_7_35_4" type="checkbox"/><label class="md-nav__link" for="__nav_7_35_4" id="__nav_7_35_4_label" tabindex="0"><span class="md-ellipsis"> Tutorials </span><span class="md-nav__icon md-icon"></span></label><nav aria-expanded="true" aria-labelledby="__nav_7_35_4_label" class="md-nav" data-md-level="3"><label class="md-nav__title" for="__nav_7_35_4"><span class="md-nav__icon md-icon"></span> Tutorials </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/><label class="md-nav__link md-nav__link--active" for="__toc"><span class="md-ellipsis"> Train Custom Data </span><span class="md-nav__icon md-icon"></span></label><a class="md-nav__link md-nav__link--active" href="./"><span class="md-ellipsis"> Train Custom Data </span></a><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#before-you-start"><span class="md-ellipsis"> Before You Start </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#train-on-custom-data"><span class="md-ellipsis"> Train On Custom Data </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#1-create-a-dataset"><span class="md-ellipsis"> 1. Create a Dataset </span></a><nav aria-label="1. Create a Dataset" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#11-create-datasetyaml"><span class="md-ellipsis"> 1.1 Create dataset.yaml </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#12-leverage-models-for-automated-labeling"><span class="md-ellipsis"> 1.2 Leverage Models for Automated Labeling </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#13-organize-directories"><span class="md-ellipsis"> 1.3 Organize Directories </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#2-select-a-model"><span class="md-ellipsis"> 2. Select a Model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#3-train"><span class="md-ellipsis"> 3. Train </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#4-visualize"><span class="md-ellipsis"> 4. Visualize </span></a><nav aria-label="4. Visualize" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#comet-logging-and-visualization-new"><span class="md-ellipsis"> Comet Logging and Visualization üåü NEW </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#clearml-logging-and-automation-new"><span class="md-ellipsis"> ClearML Logging and Automation üåü NEW </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#local-logging"><span class="md-ellipsis"> Local Logging </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#5-next-steps"><span class="md-ellipsis"> 5. Next Steps </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#supported-environments"><span class="md-ellipsis"> Supported Environments </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#project-status"><span class="md-ellipsis"> Project Status </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#how-do-i-train-yolov5-on-my-custom-dataset"><span class="md-ellipsis"> How do I train YOLOv5 on my custom dataset? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#why-should-i-use-ultralytics-platform-for-training-my-yolo-models"><span class="md-ellipsis"> Why should I use Ultralytics Platform for training my YOLO models? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-do-i-convert-my-annotated-data-to-the-yolov5-format"><span class="md-ellipsis"> How do I convert my annotated data to the YOLOv5 format? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#what-are-the-licensing-options-for-using-yolov5-in-commercial-applications"><span class="md-ellipsis"> What are the licensing options for using YOLOv5 in commercial applications? </span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../tips_for_best_training_results/"><span class="md-ellipsis"> Tips for Best Training Results </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../multi_gpu_training/"><span class="md-ellipsis"> Multi-GPU Training </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../pytorch_hub_model_loading/"><span class="md-ellipsis"> PyTorch Hub </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model_export/"><span class="md-ellipsis"> TFLite, ONNX, CoreML, TensorRT Export </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../test_time_augmentation/"><span class="md-ellipsis"> Test-Time Augmentation (TTA) </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model_ensembling/"><span class="md-ellipsis"> Model Ensembling </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model_pruning_and_sparsity/"><span class="md-ellipsis"> Pruning/Sparsity Tutorial </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../hyperparameter_evolution/"><span class="md-ellipsis"> Hyperparameter evolution </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../transfer_learning_with_frozen_layers/"><span class="md-ellipsis"> Transfer learning with frozen layers </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../architecture_description/"><span class="md-ellipsis"> Architecture Summary </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../neural_magic_pruning_quantization/"><span class="md-ellipsis"> Neural Magic's DeepSparse </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../comet_logging_integration/"><span class="md-ellipsis"> Comet Logging </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../clearml_logging_integration/"><span class="md-ellipsis"> Clearml Logging </span></a></li></ul></nav></li></ul></nav></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../integrations/"><span class="md-ellipsis"> Integrations </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../platform/"><span class="md-ellipsis"> Platform </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../reference/__init__/"><span class="md-ellipsis"> Reference </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../../help/"><span class="md-ellipsis"> Help </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#before-you-start"><span class="md-ellipsis"> Before You Start </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#train-on-custom-data"><span class="md-ellipsis"> Train On Custom Data </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#1-create-a-dataset"><span class="md-ellipsis"> 1. Create a Dataset </span></a><nav aria-label="1. Create a Dataset" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#11-create-datasetyaml"><span class="md-ellipsis"> 1.1 Create dataset.yaml </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#12-leverage-models-for-automated-labeling"><span class="md-ellipsis"> 1.2 Leverage Models for Automated Labeling </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#13-organize-directories"><span class="md-ellipsis"> 1.3 Organize Directories </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#2-select-a-model"><span class="md-ellipsis"> 2. Select a Model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#3-train"><span class="md-ellipsis"> 3. Train </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#4-visualize"><span class="md-ellipsis"> 4. Visualize </span></a><nav aria-label="4. Visualize" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#comet-logging-and-visualization-new"><span class="md-ellipsis"> Comet Logging and Visualization üåü NEW </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#clearml-logging-and-automation-new"><span class="md-ellipsis"> ClearML Logging and Automation üåü NEW </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#local-logging"><span class="md-ellipsis"> Local Logging </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#5-next-steps"><span class="md-ellipsis"> 5. Next Steps </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#supported-environments"><span class="md-ellipsis"> Supported Environments </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#project-status"><span class="md-ellipsis"> Project Status </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#how-do-i-train-yolov5-on-my-custom-dataset"><span class="md-ellipsis"> How do I train YOLOv5 on my custom dataset? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#why-should-i-use-ultralytics-platform-for-training-my-yolo-models"><span class="md-ellipsis"> Why should I use Ultralytics Platform for training my YOLO models? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#how-do-i-convert-my-annotated-data-to-the-yolov5-format"><span class="md-ellipsis"> How do I convert my annotated data to the YOLOv5 format? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#what-are-the-licensing-options-for-using-yolov5-in-commercial-applications"><span class="md-ellipsis"> What are the licensing options for using YOLOv5 in commercial applications? </span></a></li></ul></nav></li></ul></nav></div></div></div><div class="md-content" data-md-component="content"><article class="md-content__inner md-typeset"><a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/yolov5/tutorials/train_custom_data.md" rel="edit" title="Edit this page"><svg class="lucide lucide-file-pen" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"></path><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"></path></svg></a><a class="md-content__button md-icon" href="javascript:void(0)" onclick="copyMarkdownForLLM(this); return false;" title="Copy page in Markdown format"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></a><h1 id="train-yolov5-on-custom-data">Train YOLOv5 on Custom Data</h1><p>üìö This guide explains how to train your own <strong>custom dataset</strong> using the <a href="https://github.com/ultralytics/yolov5">YOLOv5</a> model üöÄ. Training custom models is a fundamental step in tailoring <a href="https://www.ultralytics.com/glossary/computer-vision-cv">computer vision</a> solutions to specific real-world applications beyond generic <a href="https://docs.ultralytics.com/tasks/detect/">object detection</a>.</p><h2 id="before-you-start">Before You Start</h2><p>First, ensure you have the necessary environment set up. Clone the YOLOv5 repository and install the required dependencies from <code>requirements.txt</code>. A <a href="https://www.python.org/"><strong>Python&gt;=3.8.0</strong></a> environment with <a href="https://pytorch.org/get-started/locally/"><strong>PyTorch&gt;=1.8</strong></a> is essential. Models and datasets are automatically downloaded from the latest YOLOv5 <a href="https://github.com/ultralytics/yolov5/releases">release</a> if they are not found locally.</p><div class="highlight"><pre><span></span><code><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ultralytics/yolov5<span class="w"> </span><span class="c1"># Clone the repository</span>
<span></span><span class="nb">cd</span><span class="w"> </span>yolov5
<span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt<span class="w"> </span><span class="c1"># Install dependencies</span>
</code></pre></div><h2 id="train-on-custom-data">Train On Custom Data</h2><p><a href="https://platform.ultralytics.com" target="_blank"><img alt="Ultralytics active learning loop diagram" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/ultralytics-active-learning-loop.avif" width="100%"/></a><br/><br/></p><p>Developing a custom <a href="https://docs.ultralytics.com/tasks/detect/">object detection</a> model is an iterative process:</p><ol><li><strong>Collect &amp; Organize Images</strong>: Gather images relevant to your specific task. High-quality, diverse data is crucial. See our guide on <a href="https://docs.ultralytics.com/guides/data-collection-and-annotation/">Data Collection and Annotation</a>.</li><li><strong>Label Objects</strong>: Annotate the objects of interest within your images accurately.</li><li><strong>Train a Model</strong>: Use the labeled data to <a href="https://docs.ultralytics.com/modes/train/">train</a> your YOLOv5 model. Leverage <a href="https://www.ultralytics.com/glossary/transfer-learning">transfer learning</a> by starting with pretrained weights.</li><li><strong>Deploy &amp; Predict</strong>: Utilize the trained model for <a href="https://docs.ultralytics.com/modes/predict/">inference</a> on new, unseen data.</li><li><strong>Collect Edge Cases</strong>: Identify scenarios where the model performs poorly (<a href="https://en.wikipedia.org/wiki/Edge_case">edge cases</a>) and add similar data to your dataset to improve robustness. Repeat the cycle.</li></ol><p><a href="https://docs.ultralytics.com/platform/">Ultralytics Platform</a> offers a streamlined, no-code solution for this entire <a href="https://www.ultralytics.com/glossary/machine-learning-operations-mlops">machine learning operations (MLOps)</a> cycle, including dataset management, model training, and deployment.</p><div class="admonition question"><p class="admonition-title">Licensing</p><p>Ultralytics provides two licensing options to accommodate diverse usage scenarios:</p><ul><li><strong>AGPL-3.0 License</strong>: This <a href="https://opensource.org/license/agpl-v3">OSI-approved</a> open-source license is ideal for students, researchers, and enthusiasts passionate about open collaboration and knowledge sharing. It requires derived works to be shared under the same license. See the <a href="https://github.com/ultralytics/ultralytics/blob/main/LICENSE">LICENSE</a> file for full details.</li><li><strong>Enterprise License</strong>: Designed for commercial applications, this license permits the seamless integration of Ultralytics software and AI models into commercial products and services without the open-source stipulations of AGPL-3.0. If your project requires commercial deployment, request an <a href="https://www.ultralytics.com/license">Enterprise License</a>.</li></ul><p>Explore our licensing options further on the <a href="https://www.ultralytics.com/license">Ultralytics Licensing</a> page.</p></div><p>Before initiating the training, dataset preparation is essential.</p><h2 id="1-create-a-dataset">1. Create a Dataset</h2><p>YOLOv5 models require labeled data to learn the visual characteristics of object classes. Organizing your dataset correctly is key.</p><h3 id="11-create-datasetyaml">1.1 Create <code>dataset.yaml</code></h3><p>The dataset configuration file (e.g., <code>coco128.yaml</code>) outlines the dataset's structure, class names, and paths to image directories. <a href="https://docs.ultralytics.com/datasets/detect/coco128/">COCO128</a> serves as a small example dataset, comprising the first 128 images from the extensive <a href="https://docs.ultralytics.com/datasets/detect/coco/">COCO</a> dataset. It's useful for quickly testing the training pipeline and diagnosing potential issues like <a href="https://www.ultralytics.com/glossary/overfitting">overfitting</a>.</p><p>The <code>dataset.yaml</code> file structure includes:</p><ul><li><code>path</code>: The root directory containing the dataset.</li><li><code>train</code>, <code>val</code>, <code>test</code>: Relative paths from <code>path</code> to directories containing images or text files listing image paths for training, validation, and testing sets.</li><li><code>names</code>: A dictionary mapping class indices (starting from 0) to their corresponding class names.</li></ul><p>You can set <code>path</code> to either an absolute directory (e.g., <code>/home/user/datasets/coco128</code>) or a relative path such as <code>../datasets/coco128</code> when launching training from the YOLOv5 repository root.</p><p>Below is the structure for <code>coco128.yaml</code> (<a href="https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml">view on GitHub</a>):</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Dataset root directory relative to the yolov5 directory</span>
<span></span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">coco128</span>
<span></span>
<span></span><span class="c1"># Train/val/test sets: specify directories, *.txt files, or lists</span>
<span></span><span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">images/train2017</span><span class="w"> </span><span class="c1"># 128 images for training</span>
<span></span><span class="nt">val</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">images/train2017</span><span class="w"> </span><span class="c1"># 128 images for validation</span>
<span></span><span class="nt">test</span><span class="p">:</span><span class="w"> </span><span class="c1"># Optional path to test images</span>
<span></span>
<span></span><span class="c1"># Classes (example using 80 COCO classes)</span>
<span></span><span class="nt">names</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="nt">0</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">person</span>
<span></span><span class="w">    </span><span class="nt">1</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bicycle</span>
<span></span><span class="w">    </span><span class="nt">2</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">car</span>
<span></span><span class="w">    </span><span class="c1"># ... (remaining COCO classes)</span>
<span></span><span class="w">    </span><span class="nt">77</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">teddy bear</span>
<span></span><span class="w">    </span><span class="nt">78</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hair drier</span>
<span></span><span class="w">    </span><span class="nt">79</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">toothbrush</span>
</code></pre></div><h3 id="12-leverage-models-for-automated-labeling">1.2 Leverage Models for Automated Labeling</h3><p>While manual labeling using tools is a common approach, the process can be time-consuming. Recent advancements in foundation models offer possibilities for automating or semi-automating the annotation process, potentially speeding up dataset creation significantly. Here are a few examples of models that can assist with generating labels:</p><ul><li><strong><a href="https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-use-google-gemini-models-for-object-detection-image-captioning-and-ocr.ipynb">Google Gemini</a></strong>: Large multimodal models like Gemini possess powerful image understanding capabilities. They can be prompted to identify and locate objects within images, generating bounding boxes or descriptions that can be converted into YOLO format labels. Explore its potential in the provided tutorial notebook.</li><li><strong><a href="https://docs.ultralytics.com/models/sam-2/">SAM2 (Segment Anything Model 2)</a></strong>: Foundation models focused on segmentation, like SAM2, can identify and delineate objects with high precision. While primarily for segmentation, the resulting masks can often be converted into bounding box annotations suitable for object detection tasks.</li><li><strong><a href="https://docs.ultralytics.com/models/yolo-world/">YOLOWorld</a></strong>: This model offers open-vocabulary detection capabilities. You can provide text descriptions of the objects you're interested in, and YOLOWorld can locate them in images <em>without</em> prior training on those specific classes. This can be used as a starting point for generating initial labels, which can then be refined.</li></ul><p>Using these models can provide a "pre-labeling" step, reducing the manual effort required. However, it's crucial to review and refine automatically generated labels to ensure accuracy and consistency, as the quality directly impacts the performance of your trained YOLOv5 model. After generating (and potentially refining) your labels, ensure they adhere to the <strong>YOLO format</strong>: one <code>*.txt</code> file per image, with each line representing an object as <code>class_index x_center y_center width height</code> (normalized coordinates, zero-indexed class). If an image has no objects of interest, no corresponding <code>*.txt</code> file is needed.</p><p>The YOLO format <code>*.txt</code> file specifications are precise:</p><ul><li>One row per object <a href="https://www.ultralytics.com/glossary/bounding-box">bounding box</a>.</li><li>Each row must contain: <code>class_index x_center y_center width height</code>.</li><li>Coordinates must be <strong>normalized</strong> to a range between 0 and 1. To achieve this, divide the pixel values of <code>x_center</code> and <code>width</code> by the image's total width, and divide <code>y_center</code> and <code>height</code> by the image's total height.</li><li>Class indices are zero-indexed (i.e., the first class is represented by <code>0</code>, the second by <code>1</code>, and so forth).</li></ul><p align="center"><img alt="Example image with two persons and a tie annotated" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/two-persons-tie.avif" width="750"/></p><p>The label file corresponding to the image above, containing two 'person' objects (class index <code>0</code>) and one 'tie' object (class index <code>27</code>), would look like this:</p><p align="center"><img alt="YOLO format label file content example" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/two-persons-tie-1.avif" width="428"/></p><h3 id="13-organize-directories">1.3 Organize Directories</h3><p>Structure your <a href="https://docs.ultralytics.com/datasets/">datasets</a> directory as illustrated below. By default, YOLOv5 anticipates the dataset directory (e.g., <code>/coco128</code>) to reside within a <code>/datasets</code> folder located <strong>adjacent to</strong> the <code>/yolov5</code> repository directory.</p><p>YOLOv5 automatically locates the labels for each image by substituting the last instance of <code>/images/</code> in the image path with <code>/labels/</code>. For example:</p><div class="highlight"><pre><span></span><code><span></span>../datasets/coco128/images/im0.jpg<span class="w"> </span><span class="c1"># Path to the image file</span>
<span></span>../datasets/coco128/labels/im0.txt<span class="w"> </span><span class="c1"># Path to the corresponding label file</span>
</code></pre></div><p>The recommended directory structure is:</p><div class="highlight"><pre><span></span><code><span></span>/datasets/
<span></span>‚îî‚îÄ‚îÄ coco128/  # Dataset root
<span></span>    ‚îú‚îÄ‚îÄ images/
<span></span>    ‚îÇ   ‚îú‚îÄ‚îÄ train2017/  # Training images
<span></span>    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 000000000009.jpg
<span></span>    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
<span></span>    ‚îÇ   ‚îî‚îÄ‚îÄ val2017/    # Validation images (optional if using same set for train/val)
<span></span>    ‚îÇ       ‚îî‚îÄ‚îÄ ...
<span></span>    ‚îî‚îÄ‚îÄ labels/
<span></span>        ‚îú‚îÄ‚îÄ train2017/  # Training labels
<span></span>        ‚îÇ   ‚îú‚îÄ‚îÄ 000000000009.txt
<span></span>        ‚îÇ   ‚îî‚îÄ‚îÄ ...
<span></span>        ‚îî‚îÄ‚îÄ val2017/    # Validation labels (optional if using same set for train/val)
<span></span>            ‚îî‚îÄ‚îÄ ...
</code></pre></div><p align="center"><img alt="YOLOv5 recommended dataset directory structure" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/yolov5-dataset-structure.avif" width="700"/></p><h2 id="2-select-a-model">2. Select a Model</h2><p>Choose a <a href="https://docs.ultralytics.com/models/">pretrained model</a> to initiate the training process. Starting with pretrained weights significantly accelerates learning and improves performance compared to training from scratch. YOLOv5 offers various model sizes, each balancing speed and accuracy differently. For example, <a href="https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml">YOLOv5s</a> is the second-smallest and fastest model, suitable for resource-constrained environments. Consult the <a href="https://github.com/ultralytics/yolov5#pretrained-checkpoints">README table</a> for a detailed comparison of all available <a href="https://docs.ultralytics.com/models/">models</a>.</p><p align="center"><img alt="Comparison chart of YOLOv5 models showing size, speed, and accuracy" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/yolov5-model-comparison.avif" width="800"/></p><h2 id="3-train">3. Train</h2><p>Begin the <a href="https://docs.ultralytics.com/modes/train/">model training</a> using the <code>train.py</code> script. Essential arguments include:</p><ul><li><code>--img</code>: Defines the input <a href="https://docs.ultralytics.com/usage/cfg/#image-size">image size</a> (e.g., <code>--img 640</code>). Larger sizes generally yield better accuracy but require more GPU memory.</li><li><code>--batch</code>: Determines the <a href="https://www.ultralytics.com/glossary/batch-size">batch size</a> (e.g., <code>--batch 16</code>). Choose the largest size your GPU can handle.</li><li><code>--epochs</code>: Specifies the total number of training <a href="https://www.ultralytics.com/glossary/epoch">epochs</a> (e.g., <code>--epochs 100</code>). One epoch represents a full pass over the entire training dataset.</li><li><code>--data</code>: Path to your <code>dataset.yaml</code> file (e.g., <code>--data coco128.yaml</code>).</li><li><code>--weights</code>: Path to the initial weights file. Using pretrained weights (e.g., <code>--weights yolov5s.pt</code>) is highly recommended for faster convergence and superior results. To train from scratch (not advised unless you have a very large dataset and specific needs), use <code>--weights '' --cfg yolov5s.yaml</code>.</li></ul><p>Pretrained weights are automatically downloaded from the <a href="https://github.com/ultralytics/yolov5/releases">latest YOLOv5 release</a> if not found locally.</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Example: Train YOLOv5s on the COCO128 dataset for 3 epochs</span>
<span></span>python<span class="w"> </span>train.py<span class="w"> </span>--img<span class="w"> </span><span class="m">640</span><span class="w"> </span>--batch<span class="w"> </span><span class="m">16</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span>--data<span class="w"> </span>coco128.yaml<span class="w"> </span>--weights<span class="w"> </span>yolov5s.pt
</code></pre></div><div class="admonition tip"><p class="admonition-title">Optimize Training Speed</p><p>üí° Employ <code>--cache ram</code> or <code>--cache disk</code> to cache dataset images in <a href="https://en.wikipedia.org/wiki/Random-access_memory">RAM</a> or local disk, respectively. This dramatically accelerates training, particularly when dataset I/O (Input/Output) operations are a bottleneck. Note that this requires substantial RAM or disk space.</p></div><div class="admonition tip"><p class="admonition-title">Local Data Storage</p><p>üí° Always train using datasets stored locally. Accessing data from network drives (like Google Drive) or remote storage can be significantly slower and impede training performance. Copying your dataset to a local SSD is often the best practice.</p></div><p>All training outputs, including weights and logs, are saved in the <code>runs/train/</code> directory. Each training session creates a new subdirectory (e.g., <code>runs/train/exp</code>, <code>runs/train/exp2</code>, etc.). For an interactive, hands-on experience, explore the training section in our official tutorial notebooks: <a href="https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a><a href="https://www.kaggle.com/models/ultralytics/yolov5"><img alt="Open In Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p><h2 id="4-visualize">4. Visualize</h2><p>YOLOv5 seamlessly integrates with various tools for visualizing training progress, evaluating results, and monitoring performance in real-time.</p><h3 id="comet-logging-and-visualization-new">Comet Logging and Visualization üåü NEW</h3><p><a href="https://docs.ultralytics.com/integrations/comet/">Comet</a> is fully integrated for comprehensive experiment tracking. Visualize metrics live, save hyperparameters, manage datasets and model checkpoints, and analyze model predictions using interactive <a href="https://bit.ly/yolov5-colab-comet-panels">Comet Custom Panels</a>.</p><p>Getting started is straightforward:</p><div class="highlight"><pre><span></span><code><span></span>pip<span class="w"> </span>install<span class="w"> </span>comet_ml<span class="w">                                                          </span><span class="c1"># 1. Install Comet library</span>
<span></span><span class="nb">export</span><span class="w"> </span><span class="nv">COMET_API_KEY</span><span class="o">=</span>YOUR_API_KEY_HERE<span class="w">                                        </span><span class="c1"># 2. Set your Comet API key (create a free account at Comet.ml)</span>
<span></span>python<span class="w"> </span>train.py<span class="w"> </span>--img<span class="w"> </span><span class="m">640</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span>--data<span class="w"> </span>coco128.yaml<span class="w"> </span>--weights<span class="w"> </span>yolov5s.pt<span class="w"> </span><span class="c1"># 3. Train your model - Comet automatically logs everything!</span>
</code></pre></div><p>Dive deeper into the supported features in our <a href="https://docs.ultralytics.com/integrations/comet/">Comet Integration Guide</a>. Learn more about Comet's capabilities from their official <a href="https://bit.ly/yolov5-colab-comet-docs">documentation</a>. Try the Comet Colab Notebook for a live demo: <a href="https://colab.research.google.com/drive/1RG0WOQyxlDlo5Km8GogJpIEJlg_5lyYO?usp=sharing"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p><p><img alt="Comet UI showing YOLOv5 training metrics and visualizations" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/yolo-ui.avif" width="1920"/></p><h3 id="clearml-logging-and-automation-new">ClearML Logging and Automation üåü NEW</h3><p><a href="https://docs.ultralytics.com/integrations/clearml/">ClearML</a> integration enables detailed experiment tracking, dataset version management, and even remote execution of training runs. Activate ClearML with these simple steps:</p><ul><li>Install the package: <code>pip install clearml</code></li><li>Initialize ClearML: Run <code>clearml-init</code> once to connect to your ClearML server (either self-hosted or the <a href="https://clear.ml/">free tier</a>).</li></ul><p>ClearML automatically captures experiment details, model uploads, comparisons, uncommitted code changes, and installed packages, ensuring full reproducibility. You can easily schedule training tasks on remote agents and manage dataset versions using ClearML Data. Explore the <a href="https://docs.ultralytics.com/integrations/clearml/">ClearML Integration Guide</a> for comprehensive details.</p><p><a href="https://clear.ml/"><img alt="ClearML experiment management UI for YOLOv5" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/clearml-experiment-management-ui.avif" width="1280"/></a></p><h3 id="local-logging">Local Logging</h3><p>Training results are automatically logged using <a href="https://docs.ultralytics.com/integrations/tensorboard/">TensorBoard</a> and saved as <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> files within the specific experiment directory (e.g., <code>runs/train/exp</code>). Logged data includes:</p><ul><li>Training and validation loss and performance metrics.</li><li>Sample images showing applied augmentations (like mosaics).</li><li>Ground truth labels alongside model predictions for visual inspection.</li><li>Key evaluation metrics such as <a href="https://www.ultralytics.com/glossary/precision">Precision</a>-<a href="https://www.ultralytics.com/glossary/recall">Recall</a> (PR) curves.</li><li><a href="https://www.ultralytics.com/glossary/confusion-matrix">Confusion matrices</a> for detailed class-wise performance analysis.</li></ul><p><img alt="YOLOv5 local logging results with charts and mosaics" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/local-logging-results.avif" width="1280"/></p><p>The <code>results.csv</code> file is updated after every epoch and is plotted as <code>results.png</code> once training concludes. You can also plot any <code>results.csv</code> file manually using the provided utility function:</p><div class="highlight"><pre><span></span><code><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">utils.plots</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_results</span>
<span></span>
<span></span><span class="c1"># Plot results from a specific training run directory</span>
<span></span><span class="n">plot_results</span><span class="p">(</span><span class="s2">"runs/train/exp/results.csv"</span><span class="p">)</span>  <span class="c1"># This will generate 'results.png' in the same directory</span>
</code></pre></div><p align="center"><img alt="YOLOv5 results.png training metrics plot" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/yolov5-training-results-plot.avif" width="800"/></p><h2 id="5-next-steps">5. Next Steps</h2><p>Upon successful completion of training, the best performing model checkpoint (<code>best.pt</code>) is saved and ready for deployment or further refinement. Potential next steps include:</p><ul><li>Run <a href="https://docs.ultralytics.com/modes/predict/">inference</a> on new images or videos using the trained model via the <a href="https://github.com/ultralytics/yolov5#quick-start-examples">CLI</a> or <a href=".././pytorch_hub_model_loading/">Python</a>.</li><li>Perform <a href="https://docs.ultralytics.com/modes/val/">validation</a> to evaluate the model's <a href="https://www.ultralytics.com/glossary/accuracy">accuracy</a> and generalization capabilities on different data splits (e.g., a held-out test set).</li><li><a href="https://docs.ultralytics.com/modes/export/">Export</a> the model to various deployment formats like <a href="https://docs.ultralytics.com/integrations/onnx/">ONNX</a>, <a href="https://docs.ultralytics.com/integrations/tf-savedmodel/">TensorFlow SavedModel</a>, or <a href="https://docs.ultralytics.com/integrations/tensorrt/">TensorRT</a> for optimized inference on diverse platforms.</li><li>Employ <a href="https://docs.ultralytics.com/guides/hyperparameter-tuning/">hyperparameter tuning</a> techniques to potentially squeeze out additional performance gains.</li><li>Continue improving your model by following our <a href="https://docs.ultralytics.com/guides/model-training-tips/">Tips for Best Training Results</a> and iteratively adding more diverse and challenging data based on performance analysis.</li></ul><h2 id="supported-environments">Supported Environments</h2><p>Ultralytics provides ready-to-use environments equipped with essential dependencies like <a href="https://developer.nvidia.com/cuda">CUDA</a>, <a href="https://developer.nvidia.com/cudnn">cuDNN</a>, <a href="https://www.python.org/">Python</a>, and <a href="https://pytorch.org/">PyTorch</a>, facilitating a smooth start.</p><ul><li><strong>Free GPU Notebooks</strong>:<ul><li><a href="https://bit.ly/yolov5-paperspace-notebook"><img alt="Run on Gradient" src="https://assets.paperspace.io/img/gradient-badge.svg"/></a></li><li><a href="https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></li><li><a href="https://www.kaggle.com/models/ultralytics/yolov5"><img alt="Open In Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></li></ul></li><li><strong>Cloud Platforms</strong>:<ul><li><strong>Google Cloud</strong>: <a href="https://docs.ultralytics.com/integrations/google-colab/">GCP Quickstart Guide</a></li><li><strong>Amazon AWS</strong>: <a href="https://docs.ultralytics.com/integrations/amazon-sagemaker/">AWS Quickstart Guide</a></li><li><strong>Microsoft Azure</strong>: <a href="https://docs.ultralytics.com/guides/azureml-quickstart/">AzureML Quickstart Guide</a></li></ul></li><li><strong>Local Setup</strong>:<ul><li><strong>Docker</strong>: <a href="https://docs.ultralytics.com/guides/docker-quickstart/">Docker Quickstart Guide</a><a href="https://hub.docker.com/r/ultralytics/yolov5"><img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker"/></a></li></ul></li></ul><h2 id="project-status">Project Status</h2><p><a href="https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml"><img alt="YOLOv5 Continuous Integration Status Badge" src="https://github.com/ultralytics/yolov5/actions/workflows/ci-testing.yml/badge.svg"/></a></p><p>This badge indicates that all YOLOv5 <a href="https://github.com/ultralytics/yolov5/actions">GitHub Actions</a><a href="https://www.ultralytics.com/glossary/continuous-integration-ci">Continuous Integration (CI)</a> tests are passing successfully. These rigorous CI tests cover the core functionalities, including <a href="https://docs.ultralytics.com/modes/train/">training</a>, <a href="https://docs.ultralytics.com/modes/val/">validation</a>, <a href="https://docs.ultralytics.com/modes/predict/">inference</a>, <a href="https://docs.ultralytics.com/modes/export/">export</a>, and <a href="https://docs.ultralytics.com/modes/benchmark/">benchmarks</a>, across macOS, Windows, and Ubuntu operating systems. Tests are executed automatically every 24 hours and upon each code commit, ensuring consistent stability and optimal performance.</p><h2 id="faq">FAQ</h2><h3 id="how-do-i-train-yolov5-on-my-custom-dataset">How do I train YOLOv5 on my custom dataset?</h3><p>Training YOLOv5 on a custom dataset involves several key steps:</p><ol><li><strong>Prepare Your Dataset</strong>: Collect images and annotate them. Ensure annotations are in the required <a href="https://docs.ultralytics.com/datasets/detect/">YOLO format</a>. Organize images and labels into <code>train/</code> and <code>val/</code> (and optionally <code>test/</code>) directories. Consider using models like <a href="https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-use-google-gemini-models-for-object-detection-image-captioning-and-ocr.ipynb">Google Gemini</a>, <a href="https://docs.ultralytics.com/models/sam-2/">SAM2</a>, or <a href="https://docs.ultralytics.com/models/yolo-world/">YOLOWorld</a> to assist with or automate the labeling process (see Section 1.2).</li><li><strong>Set Up Your Environment</strong>: Clone the YOLOv5 repository and install dependencies using <code>pip install -r requirements.txt</code>. <div class="highlight"><pre><span></span><code><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ultralytics/yolov5
<span></span><span class="nb">cd</span><span class="w"> </span>yolov5
<span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</code></pre></div></li><li><strong>Create Dataset Configuration</strong>: Define dataset paths, number of classes, and class names in a <code>dataset.yaml</code> file.</li><li><strong>Start Training</strong>: Execute the <code>train.py</code> script, providing paths to your <code>dataset.yaml</code>, desired pretrained weights (e.g., <code>yolov5s.pt</code>), image size, batch size, and the number of epochs. <div class="highlight"><pre><span></span><code><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--img<span class="w"> </span><span class="m">640</span><span class="w"> </span>--batch<span class="w"> </span><span class="m">16</span><span class="w"> </span>--epochs<span class="w"> </span><span class="m">100</span><span class="w"> </span>--data<span class="w"> </span>path/to/your/dataset.yaml<span class="w"> </span>--weights<span class="w"> </span>yolov5s.pt
</code></pre></div></li></ol><h3 id="why-should-i-use-ultralytics-platform-for-training-my-yolo-models">Why should I use Ultralytics Platform for training my YOLO models?</h3><p><a href="https://docs.ultralytics.com/platform/">Ultralytics Platform</a> is a comprehensive platform designed to streamline the entire YOLO model development lifecycle, often without needing to write any code. Key benefits include:</p><ul><li><strong>Simplified Training</strong>: Easily train models using pre-configured environments and an intuitive user interface.</li><li><strong>Integrated Data Management</strong>: Upload, version control, and manage your datasets efficiently within the platform.</li><li><strong>Real-time Monitoring</strong>: Track training progress and visualize performance metrics using integrated tools like <a href="https://docs.ultralytics.com/integrations/comet/">Comet</a> or TensorBoard.</li><li><strong>Collaboration Features</strong>: Facilitates teamwork through shared resources, project management tools, and easy model sharing.</li><li><strong>No-Code Deployment</strong>: Deploy trained models directly to various targets.</li></ul><p>For a practical walkthrough, check out our blog post: <a href="https://www.ultralytics.com/blog/how-to-train-your-custom-models-with-ultralytics-hub">How to Train Your Custom Models with Ultralytics Platform</a>.</p><h3 id="how-do-i-convert-my-annotated-data-to-the-yolov5-format">How do I convert my annotated data to the YOLOv5 format?</h3><p>Whether you annotate manually or use automated tools (like those mentioned in Section 1.2), the final labels must be in the specific <strong>YOLO format</strong> required by YOLOv5:</p><ul><li>Create one <code>.txt</code> file for each image. The filename should match the image filename (e.g., <code>image1.jpg</code> corresponds to <code>image1.txt</code>). Place these files in a <code>labels/</code> directory parallel to your <code>images/</code> directory (e.g., <code>../datasets/mydataset/labels/train/</code>).</li><li>Each line within a <code>.txt</code> file represents one object annotation and follows the format: <code>class_index center_x center_y width height</code>.</li><li>Coordinates (<code>center_x</code>, <code>center_y</code>, <code>width</code>, <code>height</code>) must be <strong>normalized</strong> (values between 0.0 and 1.0) relative to the image's dimensions.</li><li>Class indices are <strong>zero-based</strong> (the first class is <code>0</code>, the second is <code>1</code>, etc.).</li></ul><p>Many manual annotation tools offer direct export to YOLO format. If using automated models, you will need scripts or processes to convert their output (e.g., bounding box coordinates, segmentation masks) into this specific normalized text format. Ensure your final dataset structure adheres to the example provided in the guide. For more details, see our <a href="https://docs.ultralytics.com/guides/data-collection-and-annotation/">Data Collection and Annotation Guide</a>.</p><h3 id="what-are-the-licensing-options-for-using-yolov5-in-commercial-applications">What are the licensing options for using YOLOv5 in commercial applications?</h3><p>Ultralytics provides flexible licensing tailored to different needs:</p><ul><li><strong>AGPL-3.0 License</strong>: This open-source license is suitable for academic research, personal projects, and situations where open-source compliance is acceptable. It mandates that modifications and derivative works also be open-sourced under AGPL-3.0. Review the <a href="https://www.ultralytics.com/legal/agpl-3-0-software-license">AGPL-3.0 License details</a>.</li><li><strong>Enterprise License</strong>: A commercial license designed for businesses integrating YOLOv5 into proprietary products or services. This license removes the open-source obligations of AGPL-3.0, allowing for closed-source distribution. Visit our <a href="https://www.ultralytics.com/license">Licensing page</a> for further details or to request an <a href="https://www.ultralytics.com/legal/enterprise-software-license">Enterprise License</a>.</li></ul><p>Select the license that aligns best with your project's requirements and distribution model.</p><br/><br/><div class="git-info"><div class="dates-container"><span class="date-item" title="This page was first created on November 12, 2023"><span class="hover-item">üìÖ</span> Created 2 years ago </span><span class="date-item" title="This page was last updated on January 20, 2026"><span class="hover-item">‚úèÔ∏è</span> Updated 3 days ago </span></div><div class="authors-container"><a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (28 changes)"><img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Laughing-q" title="Laughing-q (2 changes)"><img alt="Laughing-q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/61612323?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/UltralyticsAssistant" title="UltralyticsAssistant (2 changes)"><img alt="UltralyticsAssistant" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/135830346?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/leonnil" title="leonnil (1 change)"><img alt="leonnil" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/146309319?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/pderrenger" title="pderrenger (1 change)"><img alt="pderrenger" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/107626595?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/jk4e" title="jk4e (1 change)"><img alt="jk4e" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/116908874?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/MatthewNoyce" title="MatthewNoyce (1 change)"><img alt="MatthewNoyce" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/131261051?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/RizwanMunawar" title="RizwanMunawar (1 change)"><img alt="RizwanMunawar" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62513924?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/Burhan-Q" title="Burhan-Q (1 change)"><img alt="Burhan-Q" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/62214284?v=4&amp;s=96"/></a></div></div><div class="share-buttons"><button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https%3A%2F%2Fdocs.ultralytics.com%2Fyolov5%2Ftutorials%2Ftrain_custom_data%2F', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet </button><button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdocs.ultralytics.com%2Fyolov5%2Ftutorials%2Ftrain_custom_data%2F', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share </button></div><br/><h2 id="__comments">Comments</h2><div id="giscus-container"></div></article></div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div><button class="md-top md-icon" data-md-component="top" hidden="" type="button"><svg class="lucide lucide-circle-arrow-up" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><path d="m16 12-4-4-4 4M12 16V8"></path></svg> Back to top
</button></main><footer class="md-footer"><nav aria-label="Footer" class="md-footer__inner md-grid"><a aria-label="Previous: Docker Image" class="md-footer__link md-footer__link--prev" href="../../environments/docker_image_quickstart_tutorial/"><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-left" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12 19-7-7 7-7M19 12H5"></path></svg></div><div class="md-footer__title"><span class="md-footer__direction"> Previous </span><div class="md-ellipsis"> Docker Image </div></div></a><a aria-label="Next: Tips for Best Training Results" class="md-footer__link md-footer__link--next" href="../tips_for_best_training_results/"><div class="md-footer__title"><span class="md-footer__direction"> Next </span><div class="md-ellipsis"> Tips for Best Training Results </div></div><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-right" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 12h14M12 5l7 7-7 7"></path></svg></div></a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-copyright"><div class="md-copyright__highlight"><a href="https://www.ultralytics.com/" target="_blank">¬© 2026 Ultralytics Inc.</a> All rights reserved. </div> Made with <a href="https://zensical.org/" rel="noopener" target="_blank"> Zensical </a></div><div class="md-social"><a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg></a></div></div></div></footer></div><div class="md-dialog" data-md-component="dialog"><div class="md-dialog__inner md-typeset"></div></div><div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"annotate":null,"base":"../../..","features":["content.action.edit","content.code.annotate","content.code.copy","content.tooltips","toc.follow","navigation.top","navigation.tabs","navigation.tabs.sticky","navigation.prune","navigation.footer","navigation.tracking","navigation.instant","navigation.instant.progress","navigation.indexes","navigation.sections","content.tabs.link"],"search":"../../../assets/javascripts/workers/search.e2d2d235.min.js","tags":null,"translations":{"clipboard.copied":"Copied to clipboard","clipboard.copy":"Copy to clipboard","search.result.more.one":"1 more on this page","search.result.more.other":"# more on this page","search.result.none":"No matching documents","search.result.one":"1 matching document","search.result.other":"# matching documents","search.result.placeholder":"Type to start searching","search.result.term.missing":"Missing","select.version":"Select version"},"version":null}</script>
<script src="../../../assets/javascripts/bundle.8ffeb9c9.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ultralytics/llm@v0.1.8/js/chat.min.js"></script>
<script src="https://unpkg.com/tablesort@5.6.0/dist/tablesort.min.js"></script>
<script src="../../../javascript/extra.js"></script>
<script src="../../../javascript/giscus.js"></script>
<script src="../../../javascript/tablesort.js"></script>
<script>
            async function copyMarkdownForLLM(button) {
                const editBtn = document.querySelector('a[title="Edit this page"]');
                if (!editBtn) return;

                const originalHTML = button.innerHTML;
                const checkIcon = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19L21 7l-1.41-1.41L9 16.17z"></path></svg>';

                let rawUrl = editBtn.href.replace('github.com', 'raw.githubusercontent.com');
                rawUrl = rawUrl.replace('/blob/', '/').replace('/tree/', '/');

                try {
                    const response = await fetch(rawUrl);
                    let markdown = await response.text();

                    if (markdown.startsWith('---')) {
                        const frontMatterEnd = markdown.indexOf('\n---\n', 3);
                        if (frontMatterEnd !== -1) {
                            markdown = markdown.substring(frontMatterEnd + 5).trim();
                        }
                    }

                    const title = document.querySelector('h1')?.textContent || document.title;
                    const content = `# ${title}\n\nSource: ${window.location.href}\n\n---\n\n${markdown}`;

                    await navigator.clipboard.writeText(content);
                    button.innerHTML = checkIcon + ' Copied!';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                } catch (err) {
                    button.innerHTML = '‚ùå Failed';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                }
            }
            </script></body></html>