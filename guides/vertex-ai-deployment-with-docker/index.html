 <!DOCTYPE html><html class="no-js" lang="en"><head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="Learn how to deploy pretrained YOLO26 models on Google Cloud Vertex AI using Docker containers and FastAPI for scalable inference with complete control over preprocessing and postprocessing." name="description"/><meta content="Ultralytics" name="author"/><link href="https://docs.ultralytics.com/guides/vertex-ai-deployment-with-docker/" rel="canonical"/><link href="../defining-project-goals/" rel="prev"/><link href="../docker-quickstart/" rel="next"/><link href="/" hreflang="en" rel="alternate"/><link href="/zh/" hreflang="zh" rel="alternate"/><link href="/ko/" hreflang="ko" rel="alternate"/><link href="/ja/" hreflang="ja" rel="alternate"/><link href="/ru/" hreflang="ru" rel="alternate"/><link href="/de/" hreflang="de" rel="alternate"/><link href="/fr/" hreflang="fr" rel="alternate"/><link href="/es/" hreflang="es" rel="alternate"/><link href="/pt/" hreflang="pt" rel="alternate"/><link href="/it/" hreflang="it" rel="alternate"/><link href="/tr/" hreflang="tr" rel="alternate"/><link href="/vi/" hreflang="vi" rel="alternate"/><link href="/ar/" hreflang="ar" rel="alternate"/><link href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/logo/favicon-yolo.png" rel="icon"/><meta content="zensical-0.0.17" name="generator"/><title>Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference</title><link href="../../assets/stylesheets/modern/main.d4922b3c.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/modern/palette.dfe2e883.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,500,500i,700,700i%7CJetBrains+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style><link href="../../stylesheets/style.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,t)=>(e<<5)-e+t.charCodeAt(0)),0),__md_get=(e,t=localStorage,a=__md_scope)=>JSON.parse(t.getItem(a.pathname+"."+e)),__md_set=(e,t,a=localStorage,_=__md_scope)=>{try{a.setItem(_.pathname+"."+e,JSON.stringify(t))}catch(e){}},document.documentElement.setAttribute("data-platform",navigator.platform)</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2M5EHKC0BH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2M5EHKC0BH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2M5EHKC0BH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<style data-doc-kind="true">.doc-kind{display:inline-flex;align-items:center;gap:0.25em;padding:0.21em 0.59em;border-radius:999px;font-weight:700;font-size:0.81em;letter-spacing:0.06em;text-transform:uppercase;line-height:1;color:var(--doc-kind-color,#f8fafc);background:var(--doc-kind-bg,rgba(255,255,255,0.12));}.doc-kind-class{--doc-kind-color:#039dfc;--doc-kind-bg:rgba(3,157,252,0.22);}.doc-kind-function{--doc-kind-color:#fc9803;--doc-kind-bg:rgba(252,152,3,0.22);}.doc-kind-method{--doc-kind-color:#ef5eff;--doc-kind-bg:rgba(239,94,255,0.22);}.doc-kind-property{--doc-kind-color:#02e835;--doc-kind-bg:rgba(2,232,53,0.22);}</style><meta content="Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference" name="title"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet"/><meta content="website" property="og:type"/><meta content="https://docs.ultralytics.com/guides/vertex-ai-deployment-with-docker/" property="og:url"/><meta content="Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference" property="og:title"/><meta content="" property="og:description"/><meta content="https://github.com/lussebullar/temp-image-storage/releases/download/docs/create-artifact-registry-repo.png" property="og:image"/><meta content="summary_large_image" property="twitter:card"/><meta content="https://docs.ultralytics.com/guides/vertex-ai-deployment-with-docker/" property="twitter:url"/><meta content="Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference" property="twitter:title"/><meta content="" property="twitter:description"/><meta content="https://github.com/lussebullar/temp-image-storage/releases/download/docs/create-artifact-registry-repo.png" property="twitter:image"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": ["Article", "FAQPage"], "headline": "Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference", "image": ["https://github.com/lussebullar/temp-image-storage/releases/download/docs/create-artifact-registry-repo.png"], "datePublished": "2025-07-29 11:28:53 +0200", "dateModified": "2026-01-20 01:06:12 +0000", "author": [{"@type": "Organization", "name": "Ultralytics", "url": "https://ultralytics.com/"}], "abstract": "", "mainEntity": [{"@type": "Question", "name": "Can I use Ultralytics YOLO models on Vertex AI without Docker?", "acceptedAnswer": {"@type": "Answer", "text": "Yes; however, you will first need to export the model to a format compatible with Vertex AI, such as TensorFlow, Scikit-learn, or XGBoost. Google Cloud provides a guide on running .pt models on Vertex with a complete overview of the conversion process: Run PyTorch models on Vertex AI. Please note that the resulting setup will rely only on the Vertex AI standard serving layer and will not support the advanced Ultralytics framework features. Since Vertex AI fully supports containerized models and can scale them automatically according to your deployment configuration, it allows you to leverage the full capabilities of Ultralytics YOLO models without needing to convert them to a different format."}}, {"@type": "Question", "name": "Why is FastAPI a good choice for serving YOLO26 inference?", "acceptedAnswer": {"@type": "Answer", "text": "FastAPI provides high throughput for inference workloads. Async support allows handling multiple concurrent requests without blocking the main thread, which is important when serving computer vision models. Automatic request/response validation with FastAPI reduces runtime errors in production inference services. This is particularly valuable for object detection APIs where input format consistency is critical. FastAPI adds minimal computational overhead to your inference pipeline, leaving more resources available for model execution and image processing tasks. FastAPI also supports SSE (Server-Sent Events), which is useful for streaming inference scenarios."}}, {"@type": "Question", "name": "Why do I have to select a region so many times?", "acceptedAnswer": {"@type": "Answer", "text": "This is actually a versatility feature of Google Cloud Platform, where you need to select a region for every service you use. For the task of deploying a containerized model on Vertex AI, your most important region selection is the one for the Model Registry. It will determine the availability of machine types and quotas for your model deployment. Additionally, if you will be extending the setup and storing prediction data or results in Cloud Storage or BigQuery, you will need to use the same region as for Model Registry to minimize latency and ensure high throughput for data access."}}]}</script></head><body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" for="__drawer"></label><div data-md-component="skip"><a class="md-skip" href="#deploy-a-pretrained-yolo-model-with-ultralytics-on-vertex-ai-for-inference"> Skip to content </a></div><div data-md-component="announce"><aside class="md-banner"><div class="md-banner__inner md-grid md-typeset"><a class="banner-wrapper" href="https://docs.ultralytics.com/models/yolo26"><div class="banner-content-wrapper"><img alt="Ultralytics YOLO26" height="40" src="https://cdn.prod.website-files.com/680a070c3b99253410dd3dcf/6967372a0d67914985d322e7_Ultralytics%20YOLO26%201.svg"/><p>Built End-to-End. Built for the Edge.</p></div></a></div></aside></div><header class="md-header md-header--shadow md-header--lifted" data-md-component="header"><nav aria-label="Header" class="md-header__inner md-grid"><a aria-label="Ultralytics YOLO Docs" class="md-header__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a><label class="md-header__button md-icon" for="__drawer"><svg class="lucide lucide-menu" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 5h16M4 12h16M4 19h16"></path></svg></label><div class="md-header__title" data-md-component="header-title"><div class="md-header__ellipsis"><div class="md-header__topic"><span class="md-ellipsis"> Ultralytics YOLO Docs </span></div><div class="md-header__topic" data-md-component="header-topic"><span class="md-ellipsis"> Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference </span></div></div></div><form class="md-header__option" data-md-component="palette"><input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg></label><input aria-label="Switch to system preference" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to system preference"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label><input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/><label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to dark mode"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg></label></form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<div class="md-header__option"><div class="md-select"><button aria-label="Select language" class="md-header__button md-icon"><svg class="lucide lucide-languages" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m5 8 6 6M4 14l6-6 2-3M2 5h12M7 2h1M22 22l-5-10-5 10M14 18h6"></path></svg></button><div class="md-select__inner"><ul class="md-select__list"><li class="md-select__item"><a class="md-select__link" href="/" hreflang="en"> üá¨üáß English </a></li><li class="md-select__item"><a class="md-select__link" href="/zh/" hreflang="zh"> üá®üá≥ ÁÆÄ‰Ωì‰∏≠Êñá </a></li><li class="md-select__item"><a class="md-select__link" href="/ko/" hreflang="ko"> üá∞üá∑ ÌïúÍµ≠Ïñ¥ </a></li><li class="md-select__item"><a class="md-select__link" href="/ja/" hreflang="ja"> üáØüáµ Êó•Êú¨Ë™û </a></li><li class="md-select__item"><a class="md-select__link" href="/ru/" hreflang="ru"> üá∑üá∫ –†—É—Å—Å–∫–∏–π </a></li><li class="md-select__item"><a class="md-select__link" href="/de/" hreflang="de"> üá©üá™ Deutsch </a></li><li class="md-select__item"><a class="md-select__link" href="/fr/" hreflang="fr"> üá´üá∑ Fran√ßais </a></li><li class="md-select__item"><a class="md-select__link" href="/es/" hreflang="es"> üá™üá∏ Espa√±ol </a></li><li class="md-select__item"><a class="md-select__link" href="/pt/" hreflang="pt"> üáµüáπ Portugu√™s </a></li><li class="md-select__item"><a class="md-select__link" href="/it/" hreflang="it"> üáÆüáπ Italiano </a></li><li class="md-select__item"><a class="md-select__link" href="/tr/" hreflang="tr"> üáπüá∑ T√ºrk√ße </a></li><li class="md-select__item"><a class="md-select__link" href="/vi/" hreflang="vi"> üáªüá≥ Ti·∫øng Vi·ªát </a></li><li class="md-select__item"><a class="md-select__link" href="/ar/" hreflang="ar"> üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© </a></li></ul></div></div></div><div class="md-header__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div></nav><nav aria-label="Tabs" class="md-tabs" data-md-component="tabs"><div class="md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a class="md-tabs__link" href="../.."> Home </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../quickstart/"> Quickstart </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../modes/"> Modes </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../tasks/"> Tasks </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../models/"> Models </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../datasets/"> Datasets </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../solutions/"> Solutions </a></li><li class="md-tabs__item md-tabs__item--active"><a class="md-tabs__link" href="../"> Guides </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../integrations/"> Integrations </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../platform/"> Platform </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../reference/__init__/"> Reference </a></li><li class="md-tabs__item"><a class="md-tabs__link" href="../../help/"> Help </a></li></ul></div></nav></header><div class="md-container" data-md-component="container"><main class="md-main" data-md-component="main"><div class="md-main__inner md-grid"><div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0"><label class="md-nav__title" for="__drawer"><a aria-label="Ultralytics YOLO Docs" class="md-nav__button md-logo" data-md-component="logo" href="https://www.ultralytics.com/" title="Ultralytics YOLO Docs"><img alt="logo" src="https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Reverse.svg"/></a> Ultralytics YOLO Docs </label><div class="md-nav__source"><a class="md-source" data-md-component="source" href="https://github.com/ultralytics/ultralytics" title="Go to repository"><div class="md-source__icon md-icon"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></div><div class="md-source__repository"> ultralytics/ultralytics </div></a></div><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../.."><span class="md-ellipsis"> Home </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../quickstart/"><span class="md-ellipsis"> Quickstart </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../modes/"><span class="md-ellipsis"> Modes </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../tasks/"><span class="md-ellipsis"> Tasks </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../models/"><span class="md-ellipsis"> Models </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../datasets/"><span class="md-ellipsis"> Datasets </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../solutions/"><span class="md-ellipsis"> Solutions </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"><input checked="" class="md-nav__toggle md-toggle" id="__nav_8" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../"><span class="md-ellipsis"> Guides </span></a><label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="true" aria-labelledby="__nav_8_label" class="md-nav" data-md-level="1"><label class="md-nav__title" for="__nav_8"><span class="md-nav__icon md-icon"></span> Guides </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../model-testing/"><span class="md-ellipsis"> A Guide on Model Testing </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../azureml-quickstart/"><span class="md-ellipsis"> AzureML Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model-deployment-practices/"><span class="md-ellipsis"> Best Practices for Model Deployment </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../conda-quickstart/"><span class="md-ellipsis"> Conda Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../data-collection-and-annotation/"><span class="md-ellipsis"> Data Collection and Annotation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../deepstream-nvidia-jetson/"><span class="md-ellipsis"> DeepStream on NVIDIA Jetson </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../defining-project-goals/"><span class="md-ellipsis"> Defining A Computer Vision Project's Goals </span></a></li><li class="md-nav__item md-nav__item--active"><input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/><label class="md-nav__link md-nav__link--active" for="__toc"><span class="md-ellipsis"> Deploying YOLO on Vertex AI in Docker container </span><span class="md-nav__icon md-icon"></span></label><a class="md-nav__link md-nav__link--active" href="./"><span class="md-ellipsis"> Deploying YOLO on Vertex AI in Docker container </span></a><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#what-you-will-learn"><span class="md-ellipsis"> What you will learn </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#prerequisites"><span class="md-ellipsis"> Prerequisites </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#1-create-an-inference-backend-with-fastapi"><span class="md-ellipsis"> 1. Create an inference backend with FastAPI </span></a><nav aria-label="1. Create an inference backend with FastAPI" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#vertex-ai-compliance-fundamentals"><span class="md-ellipsis"> Vertex AI Compliance Fundamentals </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#project-folder-structure"><span class="md-ellipsis"> Project folder structure </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#create-pyprojecttoml-with-dependencies"><span class="md-ellipsis"> Create pyproject.toml with dependencies </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#create-inference-logic-with-ultralytics-yolo26"><span class="md-ellipsis"> Create inference logic with Ultralytics YOLO26 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#create-http-inference-server-with-fastapi"><span class="md-ellipsis"> Create HTTP inference server with FastAPI </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#2-extend-the-ultralytics-docker-image-with-your-application"><span class="md-ellipsis"> 2. Extend the Ultralytics Docker image with your application </span></a><nav aria-label="2. Extend the Ultralytics Docker image with your application" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#create-a-docker-image-for-your-application"><span class="md-ellipsis"> Create a Docker image for your application </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#build-and-test-the-docker-image"><span class="md-ellipsis"> Build and test the Docker image </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#3-upload-the-docker-image-to-gcp-artifact-registry"><span class="md-ellipsis"> 3. Upload the Docker image to GCP Artifact Registry </span></a><nav aria-label="3. Upload the Docker image to GCP Artifact Registry" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#create-a-repository-in-google-cloud-artifact-registry"><span class="md-ellipsis"> Create a repository in Google Cloud Artifact Registry </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#authenticate-docker-to-artifact-registry"><span class="md-ellipsis"> Authenticate Docker to Artifact Registry </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#tag-and-push-your-image-to-artifact-registry"><span class="md-ellipsis"> Tag and push your image to Artifact Registry </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#4-import-your-model-in-vertex-ai"><span class="md-ellipsis"> 4. Import your model in Vertex AI </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#5-create-a-vertex-ai-endpoint-and-deploy-your-model"><span class="md-ellipsis"> 5. Create a Vertex AI Endpoint and deploy your model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#6-test-your-deployed-model"><span class="md-ellipsis"> 6. Test your deployed model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#can-i-use-ultralytics-yolo-models-on-vertex-ai-without-docker"><span class="md-ellipsis"> Can I use Ultralytics YOLO models on Vertex AI without Docker? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#why-is-fastapi-a-good-choice-for-serving-yolo26-inference"><span class="md-ellipsis"> Why is FastAPI a good choice for serving YOLO26 inference? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#why-do-i-have-to-select-a-region-so-many-times"><span class="md-ellipsis"> Why do I have to select a region so many times? </span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="../docker-quickstart/"><span class="md-ellipsis"> Docker Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../coral-edge-tpu-on-raspberry-pi/"><span class="md-ellipsis"> Edge TPU on Raspberry Pi </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../hyperparameter-tuning/"><span class="md-ellipsis"> Hyperparameter Tuning </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model-evaluation-insights/"><span class="md-ellipsis"> Insights on Model Evaluation and Fine-Tuning </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../isolating-segmentation-objects/"><span class="md-ellipsis"> Isolating Segmentation Objects </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../kfold-cross-validation/"><span class="md-ellipsis"> K-Fold Cross Validation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model-monitoring-and-maintenance/"><span class="md-ellipsis"> Maintaining Your Computer Vision Model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model-deployment-options/"><span class="md-ellipsis"> Model Deployment Options </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model-yaml-config/"><span class="md-ellipsis"> Model YAML Configuration Guide </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../nvidia-dgx-spark/"><span class="md-ellipsis"> NVIDIA DGX Spark </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../nvidia-jetson/"><span class="md-ellipsis"> NVIDIA Jetson </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../optimizing-openvino-latency-vs-throughput-modes/"><span class="md-ellipsis"> OpenVINO Latency vs Throughput modes </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../preprocessing_annotated_data/"><span class="md-ellipsis"> Preprocessing Annotated Data </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../raspberry-pi/"><span class="md-ellipsis"> Raspberry Pi </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../ros-quickstart/"><span class="md-ellipsis"> ROS Quickstart </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../sahi-tiled-inference/"><span class="md-ellipsis"> SAHI Tiled Inference </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../steps-of-a-cv-project/"><span class="md-ellipsis"> Steps of a Computer Vision Project </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../model-training-tips/"><span class="md-ellipsis"> Tips for Model Training </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../triton-inference-server/"><span class="md-ellipsis"> Triton Inference Server </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../view-results-in-terminal/"><span class="md-ellipsis"> Viewing Inference Images in a Terminal </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo-common-issues/"><span class="md-ellipsis"> YOLO Common Issues </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo-data-augmentation/"><span class="md-ellipsis"> YOLO Data Augmentation </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo-performance-metrics/"><span class="md-ellipsis"> YOLO Performance Metrics </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../yolo-thread-safe-inference/"><span class="md-ellipsis"> YOLO Thread-Safe Inference </span></a></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_8_34" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../datasets/explorer/"><span class="md-ellipsis"> Explorer </span></a><label class="md-nav__link" for="__nav_8_34" id="__nav_8_34_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_8_34_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_8_34"><span class="md-nav__icon md-icon"></span> Explorer </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../datasets/explorer/api/"><span class="md-ellipsis"> Explorer API </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../datasets/explorer/dashboard/"><span class="md-ellipsis"> Explorer Dashboard Demo </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="../../datasets/explorer/explorer/"><span class="md-ellipsis"> VOC Exploration Example </span></a></li></ul></nav></li><li class="md-nav__item md-nav__item--section md-nav__item--nested"><input class="md-nav__toggle md-toggle" id="__nav_8_35" type="checkbox"/><div class="md-nav__link md-nav__container"><a class="md-nav__link" href="../../yolov5/"><span class="md-ellipsis"> YOLOv5 </span></a><label class="md-nav__link" for="__nav_8_35" id="__nav_8_35_label" tabindex=""><span class="md-nav__icon md-icon"></span></label></div><nav aria-expanded="false" aria-labelledby="__nav_8_35_label" class="md-nav" data-md-level="2"><label class="md-nav__title" for="__nav_8_35"><span class="md-nav__icon md-icon"></span> YOLOv5 </label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="../../yolov5/quickstart_tutorial/"><span class="md-ellipsis"> Quickstart </span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../yolov5/environments/aws_quickstart_tutorial/"><span class="md-ellipsis"> Environments </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../yolov5/tutorials/train_custom_data/"><span class="md-ellipsis"> Tutorials </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></li></ul></nav></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../integrations/"><span class="md-ellipsis"> Integrations </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../platform/"><span class="md-ellipsis"> Platform </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../reference/__init__/"><span class="md-ellipsis"> Reference </span><span class="md-nav__icon md-icon"></span></a></li><li class="md-nav__item md-nav__item--pruned md-nav__item--nested"><a class="md-nav__link" href="../../help/"><span class="md-ellipsis"> Help </span><span class="md-nav__icon md-icon"></span></a></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav aria-label="On this page" class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc"><span class="md-nav__icon md-icon"></span> On this page </label><ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""><li class="md-nav__item"><a class="md-nav__link" href="#what-you-will-learn"><span class="md-ellipsis"> What you will learn </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#prerequisites"><span class="md-ellipsis"> Prerequisites </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#1-create-an-inference-backend-with-fastapi"><span class="md-ellipsis"> 1. Create an inference backend with FastAPI </span></a><nav aria-label="1. Create an inference backend with FastAPI" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#vertex-ai-compliance-fundamentals"><span class="md-ellipsis"> Vertex AI Compliance Fundamentals </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#project-folder-structure"><span class="md-ellipsis"> Project folder structure </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#create-pyprojecttoml-with-dependencies"><span class="md-ellipsis"> Create pyproject.toml with dependencies </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#create-inference-logic-with-ultralytics-yolo26"><span class="md-ellipsis"> Create inference logic with Ultralytics YOLO26 </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#create-http-inference-server-with-fastapi"><span class="md-ellipsis"> Create HTTP inference server with FastAPI </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#2-extend-the-ultralytics-docker-image-with-your-application"><span class="md-ellipsis"> 2. Extend the Ultralytics Docker image with your application </span></a><nav aria-label="2. Extend the Ultralytics Docker image with your application" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#create-a-docker-image-for-your-application"><span class="md-ellipsis"> Create a Docker image for your application </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#build-and-test-the-docker-image"><span class="md-ellipsis"> Build and test the Docker image </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#3-upload-the-docker-image-to-gcp-artifact-registry"><span class="md-ellipsis"> 3. Upload the Docker image to GCP Artifact Registry </span></a><nav aria-label="3. Upload the Docker image to GCP Artifact Registry" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#create-a-repository-in-google-cloud-artifact-registry"><span class="md-ellipsis"> Create a repository in Google Cloud Artifact Registry </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#authenticate-docker-to-artifact-registry"><span class="md-ellipsis"> Authenticate Docker to Artifact Registry </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#tag-and-push-your-image-to-artifact-registry"><span class="md-ellipsis"> Tag and push your image to Artifact Registry </span></a></li></ul></nav></li><li class="md-nav__item"><a class="md-nav__link" href="#4-import-your-model-in-vertex-ai"><span class="md-ellipsis"> 4. Import your model in Vertex AI </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#5-create-a-vertex-ai-endpoint-and-deploy-your-model"><span class="md-ellipsis"> 5. Create a Vertex AI Endpoint and deploy your model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#6-test-your-deployed-model"><span class="md-ellipsis"> 6. Test your deployed model </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#faq"><span class="md-ellipsis"> FAQ </span></a><nav aria-label="FAQ" class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link" href="#can-i-use-ultralytics-yolo-models-on-vertex-ai-without-docker"><span class="md-ellipsis"> Can I use Ultralytics YOLO models on Vertex AI without Docker? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#why-is-fastapi-a-good-choice-for-serving-yolo26-inference"><span class="md-ellipsis"> Why is FastAPI a good choice for serving YOLO26 inference? </span></a></li><li class="md-nav__item"><a class="md-nav__link" href="#why-do-i-have-to-select-a-region-so-many-times"><span class="md-ellipsis"> Why do I have to select a region so many times? </span></a></li></ul></nav></li></ul></nav></div></div></div><div class="md-content" data-md-component="content"><article class="md-content__inner md-typeset"><a class="md-content__button md-icon" href="https://github.com/ultralytics/ultralytics/tree/main/docs/en/guides/vertex-ai-deployment-with-docker.md" rel="edit" title="Edit this page"><svg class="lucide lucide-file-pen" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12.659 22H18a2 2 0 0 0 2-2V8a2.4 2.4 0 0 0-.706-1.706l-3.588-3.588A2.4 2.4 0 0 0 14 2H6a2 2 0 0 0-2 2v9.34"></path><path d="M14 2v5a1 1 0 0 0 1 1h5M10.378 12.622a1 1 0 0 1 3 3.003L8.36 20.637a2 2 0 0 1-.854.506l-2.867.837a.5.5 0 0 1-.62-.62l.836-2.869a2 2 0 0 1 .506-.853z"></path></svg></a><a class="md-content__button md-icon" href="javascript:void(0)" onclick="copyMarkdownForLLM(this); return false;" title="Copy page in Markdown format"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg></a><h1 id="deploy-a-pretrained-yolo-model-with-ultralytics-on-vertex-ai-for-inference">Deploy a pretrained YOLO model with Ultralytics on Vertex AI for inference</h1><p>This guide will show you how to containerize a pretrained YOLO26 model with Ultralytics, build a FastAPI inference server for it, and deploy the model with inference server on Google Cloud Vertex AI. The example implementation will cover the object detection use case for YOLO26, but the same principles will apply for using <a href="../../modes/">other YOLO modes</a>.</p><p>Before we start, you will need to create a Google Cloud Platform (GCP) project. You get $300 in GCP credits to use for free as a new user, and this amount is enough to test a running setup that you can later extend for any other YOLO26 use case, including training, or batch and streaming inference.</p><h2 id="what-you-will-learn">What you will learn</h2><ol><li>Create an inference backend for Ultralytics YOLO26 model using FastAPI.</li><li>Create a GCP Artifact Registry repository to store your Docker image.</li><li>Build and push the Docker image with the model to Artifact Registry.</li><li>Import your model in Vertex AI.</li><li>Create a Vertex AI endpoint and deploy the model.</li></ol><div class="admonition tip"><p class="admonition-title">Why deploy a containerized model?</p><ul><li><strong>Full model control with Ultralytics</strong>: You can use custom inference logic with complete control over preprocessing, postprocessing, and response formatting.</li><li><strong>Vertex AI handles the rest</strong>: It auto-scales, yet gives flexibility in configuring compute resources, memory, and GPU configurations.</li><li><strong>Native GCP integrations and security</strong>: Seamless setup with Cloud Storage, BigQuery, Cloud Functions, VPC controls, IAM policies, and audit logs.</li></ul></div><h2 id="prerequisites">Prerequisites</h2><ol><li>Install <a href="https://docs.docker.com/engine/install/">Docker</a> on your machine.</li><li>Install the <a href="https://cloud.google.com/sdk/docs/install">Google Cloud SDK</a> and <a href="https://cloud.google.com/docs/authentication/gcloud">authenticate for using the gcloud CLI</a>.</li><li>It is highly recommended that you go through the <a href="https://docs.ultralytics.com/guides/docker-quickstart/">Docker Quickstart Guide for Ultralytics</a>, because you will need to extend one of the official Ultralytics Docker images while following this guide.</li></ol><h2 id="1-create-an-inference-backend-with-fastapi">1. Create an inference backend with FastAPI</h2><p>First, you need to create a FastAPI application that will serve the YOLO26 model inference requests. This application will handle the model loading, image preprocessing, and inference (prediction) logic.</p><h3 id="vertex-ai-compliance-fundamentals">Vertex AI Compliance Fundamentals</h3><p>Vertex AI expects your container to implement two specific endpoints:</p><ol><li><strong>Health</strong> endpoint (<code>/health</code>): Must return HTTP status <code>200 OK</code> when service is ready.</li><li><p><strong>Predict</strong> endpoint (<code>/predict</code>): Accepts structured prediction requests with <strong>base64-encoded</strong> images and optional parameters. <a href="https://docs.cloud.google.com/vertex-ai/docs/predictions/choose-endpoint-type">Payload size limits</a> apply depending on the endpoint type.</p><p>Request payloads for the <code>/predict</code> endpoint should follow this JSON structure:</p><div class="highlight"><pre><span></span><code><span></span><span class="p">{</span>
<span></span><span class="w">    </span><span class="nt">"instances"</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="w"> </span><span class="nt">"image"</span><span class="p">:</span><span class="w"> </span><span class="s2">"base64_encoded_image"</span><span class="w"> </span><span class="p">}],</span>
<span></span><span class="w">    </span><span class="nt">"parameters"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">"confidence"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="w"> </span><span class="p">}</span>
<span></span><span class="p">}</span>
</code></pre></div></li></ol><h3 id="project-folder-structure">Project folder structure</h3><p>The bulk of our build will be happening inside the Docker container, and Ultralytics will also load a pretrained YOLO26 model, so you can keep the local folder structure simple:</p><div class="highlight"><pre><span></span><code><span></span>YOUR_PROJECT/
<span></span>‚îú‚îÄ‚îÄ src/
<span></span>‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
<span></span>‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Core YOLO26 inference logic
<span></span>‚îÇ   ‚îî‚îÄ‚îÄ main.py             # FastAPI inference server
<span></span>‚îú‚îÄ‚îÄ tests/
<span></span>‚îú‚îÄ‚îÄ .env                    # Environment variables for local development
<span></span>‚îú‚îÄ‚îÄ Dockerfile              # Container configuration
<span></span>‚îú‚îÄ‚îÄ LICENSE                 # AGPL-3.0 License
<span></span>‚îî‚îÄ‚îÄ pyproject.toml          # Python dependencies and project config
</code></pre></div><div class="admonition note"><p class="admonition-title">Important license note</p><p>Ultralytics YOLO26 models and framework are licensed under AGPL-3.0, which has important compliance requirements. Make sure to read the Ultralytics docs on <a href="../../help/contributing/#how-to-comply-with-agpl-30">how to comply with the license terms</a>.</p></div><h3 id="create-pyprojecttoml-with-dependencies">Create pyproject.toml with dependencies</h3><p>To conveniently manage your project, create a <code>pyproject.toml</code> file with the following dependencies:</p><div class="highlight"><pre><span></span><code><span></span><span class="k">[project]</span>
<span></span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"YOUR_PROJECT_NAME"</span>
<span></span><span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"0.0.1"</span>
<span></span><span class="n">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"YOUR_PROJECT_DESCRIPTION"</span>
<span></span><span class="n">requires-python</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"&gt;=3.10,&lt;3.13"</span>
<span></span><span class="n">dependencies</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span></span><span class="w">   </span><span class="s2">"ultralytics&gt;=8.3.0"</span><span class="p">,</span>
<span></span><span class="w">   </span><span class="s2">"fastapi[all]&gt;=0.89.1"</span><span class="p">,</span>
<span></span><span class="w">   </span><span class="s2">"uvicorn[standard]&gt;=0.20.0"</span><span class="p">,</span>
<span></span><span class="w">   </span><span class="s2">"pillow&gt;=9.0.0"</span><span class="p">,</span>
<span></span><span class="p">]</span>
<span></span>
<span></span><span class="k">[build-system]</span>
<span></span><span class="n">requires</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">"setuptools&gt;=61.0"</span><span class="p">]</span>
<span></span><span class="n">build-backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"setuptools.build_meta"</span>
</code></pre></div><ul><li><code>uvicorn</code> will be used to run the FastAPI server.</li><li><code>pillow</code> will be used for image processing, but you are not limited to PIL images only ‚Äî Ultralytics supports <a href="../../modes/predict/#inference-sources">many other formats</a>.</li></ul><h3 id="create-inference-logic-with-ultralytics-yolo26">Create inference logic with Ultralytics YOLO26</h3><p>Now that you have the project structure and dependencies set up, you can implement the core YOLO26 inference logic. Create a <code>src/app.py</code> file that will handle model loading, image processing, and prediction, using Ultralytics Python API.</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># src/app.py</span>
<span></span>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span></span>
<span></span><span class="c1"># Model initialization and readiness state</span>
<span></span><span class="n">model_yolo</span> <span class="o">=</span> <span class="kc">None</span>
<span></span><span class="n">_model_ready</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>
<span></span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">_initialize_model</span><span class="p">():</span>
<span></span><span class="w">    </span><span class="sd">"""Initialize the YOLO model."""</span>
<span></span>    <span class="k">global</span> <span class="n">model_yolo</span><span class="p">,</span> <span class="n">_model_ready</span>
<span></span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="c1"># Use pretrained YOLO26n model from Ultralytics base image</span>
<span></span>        <span class="n">model_yolo</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">"yolo26n.pt"</span><span class="p">)</span>
<span></span>        <span class="n">_model_ready</span> <span class="o">=</span> <span class="kc">True</span>
<span></span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span></span>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error initializing YOLO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>        <span class="n">_model_ready</span> <span class="o">=</span> <span class="kc">False</span>
<span></span>        <span class="n">model_yolo</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>
<span></span>
<span></span><span class="c1"># Initialize model on module import</span>
<span></span><span class="n">_initialize_model</span><span class="p">()</span>
<span></span>
<span></span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">is_model_ready</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Check if the model is ready for inference."""</span>
<span></span>    <span class="k">return</span> <span class="n">_model_ready</span> <span class="ow">and</span> <span class="n">model_yolo</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</code></pre></div><p>This will load the model once when the container starts, and the model will be shared across all requests. If your model will be handling heavy inference load, it is recommended to select a machine type with more memory when importing a model in Vertex AI at a later step.</p><p>Next, create two utility functions for input and output image processing with <code>pillow</code>. YOLO26 supports PIL images natively.</p><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_image_from_bytes</span><span class="p">(</span><span class="n">binary_image</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Convert image from bytes to PIL RGB format."""</span>
<span></span>    <span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">binary_image</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">"RGB"</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">input_image</span>
</code></pre></div><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_bytes_from_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Convert PIL image to bytes."""</span>
<span></span>    <span class="n">return_image</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
<span></span>    <span class="n">image</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">return_image</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"JPEG"</span><span class="p">,</span> <span class="n">quality</span><span class="o">=</span><span class="mi">85</span><span class="p">)</span>
<span></span>    <span class="n">return_image</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="n">return_image</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
</code></pre></div><p>Finally, implement the <code>run_inference</code> function that will handle the object detection. In this example, we will extract bounding boxes, class names, and confidence scores from the model predictions. The function will return a dictionary with detections and raw results for further processing or annotation.</p><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_inference</span><span class="p">(</span><span class="n">input_image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">,</span> <span class="n">confidence_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span></span><span class="w">    </span><span class="sd">"""Run inference on an image using YOLO26n model."""</span>
<span></span>    <span class="k">global</span> <span class="n">model_yolo</span>
<span></span>
<span></span>    <span class="c1"># Check if model is ready</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_model_ready</span><span class="p">():</span>
<span></span>        <span class="nb">print</span><span class="p">(</span><span class="s2">"Model not ready for inference"</span><span class="p">)</span>
<span></span>        <span class="k">return</span> <span class="p">{</span><span class="s2">"detections"</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">"results"</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
<span></span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="c1"># Make predictions and get raw results</span>
<span></span>        <span class="n">results</span> <span class="o">=</span> <span class="n">model_yolo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
<span></span>            <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">input_image</span><span class="p">,</span> <span class="n">conf</span><span class="o">=</span><span class="n">confidence_threshold</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span></span>        <span class="p">)</span>
<span></span>
<span></span>        <span class="c1"># Extract detections (bounding boxes, class names, and confidences)</span>
<span></span>        <span class="n">detections</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>        <span class="k">if</span> <span class="n">results</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span></span>            <span class="n">result</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span></span>            <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">xyxy</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span></span>                <span class="n">boxes</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">boxes</span>
<span></span>
<span></span>                <span class="c1"># Convert tensors to numpy for processing</span>
<span></span>                <span class="n">xyxy</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">xyxy</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span></span>                <span class="n">conf</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span></span>                <span class="bp">cls</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span></span>
<span></span>                <span class="c1"># Create detection dictionaries</span>
<span></span>                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xyxy</span><span class="p">)):</span>
<span></span>                    <span class="n">detection</span> <span class="o">=</span> <span class="p">{</span>
<span></span>                        <span class="s2">"xmin"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">xyxy</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
<span></span>                        <span class="s2">"ymin"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">xyxy</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span>
<span></span>                        <span class="s2">"xmax"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">xyxy</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]),</span>
<span></span>                        <span class="s2">"ymax"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">xyxy</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">3</span><span class="p">]),</span>
<span></span>                        <span class="s2">"confidence"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">conf</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
<span></span>                        <span class="s2">"class"</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">cls</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
<span></span>                        <span class="s2">"name"</span><span class="p">:</span> <span class="n">model_yolo</span><span class="o">.</span><span class="n">names</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">cls</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="sa">f</span><span class="s2">"class_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">cls</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s2">"</span><span class="p">),</span>
<span></span>                    <span class="p">}</span>
<span></span>                    <span class="n">detections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">detection</span><span class="p">)</span>
<span></span>
<span></span>        <span class="k">return</span> <span class="p">{</span>
<span></span>            <span class="s2">"detections"</span><span class="p">:</span> <span class="n">detections</span><span class="p">,</span>
<span></span>            <span class="s2">"results"</span><span class="p">:</span> <span class="n">results</span><span class="p">,</span>  <span class="c1"># Keep raw results for annotation</span>
<span></span>        <span class="p">}</span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span></span>        <span class="c1"># If there's an error, return empty structure</span>
<span></span>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error in YOLO detection: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>        <span class="k">return</span> <span class="p">{</span><span class="s2">"detections"</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">"results"</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
</code></pre></div><p>Optionally, you can add a function to annotate the image with bounding boxes and labels using the Ultralytics built-in plotting method. This will be useful if you want to return annotated images in the prediction response.</p><div class="highlight"><pre><span></span><code><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_annotated_image</span><span class="p">(</span><span class="n">results</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">:</span>
<span></span><span class="w">    </span><span class="sd">"""Get annotated image using Ultralytics built-in plot method."""</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">results</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span></span>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"No results provided for annotation"</span><span class="p">)</span>
<span></span>
<span></span>    <span class="n">result</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span></span>    <span class="c1"># Use Ultralytics built-in plot method with PIL output</span>
<span></span>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pil</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div><h3 id="create-http-inference-server-with-fastapi">Create HTTP inference server with FastAPI</h3><p>Now that you have the core YOLO26 inference logic, you can create a FastAPI application to serve it. This will include the health check and prediction endpoints required by Vertex AI.</p><p>First, add the imports and configure logging for Vertex AI. Because Vertex AI treats stderr as error output, it makes sense to pipe the logs to stdout.</p><div class="highlight"><pre><span></span><code><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span></span>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span></span>
<span></span><span class="c1"># Configure logger</span>
<span></span><span class="n">logger</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
<span></span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
<span></span>    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span>
<span></span>    <span class="n">colorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span></span>    <span class="nb">format</span><span class="o">=</span><span class="s2">"&lt;green&gt;{time:HH:mm:ss}&lt;/green&gt; | &lt;level&gt;</span><span class="si">{message}</span><span class="s2">&lt;/level&gt;"</span><span class="p">,</span>
<span></span>    <span class="n">level</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span></span><span class="p">)</span>
<span></span><span class="n">logger</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">"log.log"</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">"1 MB"</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s2">"DEBUG"</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s2">"zip"</span><span class="p">)</span>
</code></pre></div><p>For a complete Vertex AI compliance, define the required endpoints in environment variables and set the size limit for requests. It is recommended to use <a href="https://docs.cloud.google.com/vertex-ai/docs/predictions/choose-endpoint-type">private Vertex AI endpoints</a> for production deployments. This way you will have a higher request payload limit (10 MB instead of 1.5 MB for public endpoints), together with robust security and access control.</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Vertex AI environment variables</span>
<span></span><span class="n">AIP_HTTP_PORT</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"AIP_HTTP_PORT"</span><span class="p">,</span> <span class="s2">"8080"</span><span class="p">))</span>
<span></span><span class="n">AIP_HEALTH_ROUTE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"AIP_HEALTH_ROUTE"</span><span class="p">,</span> <span class="s2">"/health"</span><span class="p">)</span>
<span></span><span class="n">AIP_PREDICT_ROUTE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"AIP_PREDICT_ROUTE"</span><span class="p">,</span> <span class="s2">"/predict"</span><span class="p">)</span>
<span></span>
<span></span><span class="c1"># Request size limit (10 MB for private endpoints, 1.5 MB for public)</span>
<span></span><span class="n">MAX_REQUEST_SIZE</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>  <span class="c1"># 10 MB in bytes</span>
</code></pre></div><p>Add two Pydantic models for validating your requests and responses:</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Pydantic models for request/response</span>
<span></span><span class="k">class</span><span class="w"> </span><span class="nc">PredictionRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span></span>    <span class="n">instances</span><span class="p">:</span> <span class="nb">list</span>
<span></span>    <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span></span>
<span></span>
<span></span><span class="k">class</span><span class="w"> </span><span class="nc">PredictionResponse</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span></span>    <span class="n">predictions</span><span class="p">:</span> <span class="nb">list</span>
</code></pre></div><p>Add the health check endpoint to verify your model readiness. <strong>This is important for Vertex AI</strong>, as without a dedicated health check its orchestrator will be pinging random sockets and will not be able to determine if the model is ready for inference. Your check must return <code>200 OK</code> for success and <code>503 Service Unavailable</code> for failure:</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Health check endpoint</span>
<span></span><span class="nd">@app</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">AIP_HEALTH_ROUTE</span><span class="p">,</span> <span class="n">status_code</span><span class="o">=</span><span class="n">status</span><span class="o">.</span><span class="n">HTTP_200_OK</span><span class="p">)</span>
<span></span><span class="k">def</span><span class="w"> </span><span class="nf">health_check</span><span class="p">():</span>
<span></span><span class="w">    </span><span class="sd">"""Health check endpoint for Vertex AI."""</span>
<span></span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_model_ready</span><span class="p">():</span>
<span></span>        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">503</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s2">"Model not ready"</span><span class="p">)</span>
<span></span>    <span class="k">return</span> <span class="p">{</span><span class="s2">"status"</span><span class="p">:</span> <span class="s2">"healthy"</span><span class="p">}</span>
</code></pre></div><p>You now have everything to implement the prediction endpoint that will handle the inference requests. It will accept an image file, run the inference, and return the results. Note that the image must be base64-encoded, which additionally increases the size of the payload by up to 33%.</p><div class="highlight"><pre><span></span><code><span></span><span class="nd">@app</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">AIP_PREDICT_ROUTE</span><span class="p">,</span> <span class="n">response_model</span><span class="o">=</span><span class="n">PredictionResponse</span><span class="p">)</span>
<span></span><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">PredictionRequest</span><span class="p">):</span>
<span></span><span class="w">    </span><span class="sd">"""Prediction endpoint for Vertex AI."""</span>
<span></span>    <span class="k">try</span><span class="p">:</span>
<span></span>        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>
<span></span>        <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">request</span><span class="o">.</span><span class="n">instances</span><span class="p">:</span>
<span></span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
<span></span>                <span class="k">if</span> <span class="s2">"image"</span> <span class="ow">in</span> <span class="n">instance</span><span class="p">:</span>
<span></span>                    <span class="n">image_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">instance</span><span class="p">[</span><span class="s2">"image"</span><span class="p">])</span>
<span></span>                    <span class="n">input_image</span> <span class="o">=</span> <span class="n">get_image_from_bytes</span><span class="p">(</span><span class="n">image_data</span><span class="p">)</span>
<span></span>                <span class="k">else</span><span class="p">:</span>
<span></span>                    <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s2">"Instance must contain 'image' field"</span><span class="p">)</span>
<span></span>            <span class="k">else</span><span class="p">:</span>
<span></span>                <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s2">"Invalid instance format"</span><span class="p">)</span>
<span></span>
<span></span>            <span class="c1"># Extract YOLO26 parameters if provided</span>
<span></span>            <span class="n">parameters</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">parameters</span> <span class="ow">or</span> <span class="p">{}</span>
<span></span>            <span class="n">confidence_threshold</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"confidence"</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span></span>            <span class="n">return_annotated_image</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"return_annotated_image"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span></span>
<span></span>            <span class="c1"># Run inference with YOLO26n model</span>
<span></span>            <span class="n">result</span> <span class="o">=</span> <span class="n">run_inference</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">confidence_threshold</span><span class="o">=</span><span class="n">confidence_threshold</span><span class="p">)</span>
<span></span>            <span class="n">detections_list</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"detections"</span><span class="p">]</span>
<span></span>
<span></span>            <span class="c1"># Format predictions for Vertex AI</span>
<span></span>            <span class="n">detections</span> <span class="o">=</span> <span class="p">[]</span>
<span></span>            <span class="k">for</span> <span class="n">detection</span> <span class="ow">in</span> <span class="n">detections_list</span><span class="p">:</span>
<span></span>                <span class="n">formatted_detection</span> <span class="o">=</span> <span class="p">{</span>
<span></span>                    <span class="s2">"class"</span><span class="p">:</span> <span class="n">detection</span><span class="p">[</span><span class="s2">"name"</span><span class="p">],</span>
<span></span>                    <span class="s2">"confidence"</span><span class="p">:</span> <span class="n">detection</span><span class="p">[</span><span class="s2">"confidence"</span><span class="p">],</span>
<span></span>                    <span class="s2">"bbox"</span><span class="p">:</span> <span class="p">{</span>
<span></span>                        <span class="s2">"xmin"</span><span class="p">:</span> <span class="n">detection</span><span class="p">[</span><span class="s2">"xmin"</span><span class="p">],</span>
<span></span>                        <span class="s2">"ymin"</span><span class="p">:</span> <span class="n">detection</span><span class="p">[</span><span class="s2">"ymin"</span><span class="p">],</span>
<span></span>                        <span class="s2">"xmax"</span><span class="p">:</span> <span class="n">detection</span><span class="p">[</span><span class="s2">"xmax"</span><span class="p">],</span>
<span></span>                        <span class="s2">"ymax"</span><span class="p">:</span> <span class="n">detection</span><span class="p">[</span><span class="s2">"ymax"</span><span class="p">],</span>
<span></span>                    <span class="p">},</span>
<span></span>                <span class="p">}</span>
<span></span>                <span class="n">detections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">formatted_detection</span><span class="p">)</span>
<span></span>
<span></span>            <span class="c1"># Build prediction response</span>
<span></span>            <span class="n">prediction</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"detections"</span><span class="p">:</span> <span class="n">detections</span><span class="p">,</span> <span class="s2">"detection_count"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">detections</span><span class="p">)}</span>
<span></span>
<span></span>            <span class="c1"># Add annotated image if requested and detections exist</span>
<span></span>            <span class="k">if</span> <span class="p">(</span>
<span></span>                <span class="n">return_annotated_image</span>
<span></span>                <span class="ow">and</span> <span class="n">result</span><span class="p">[</span><span class="s2">"results"</span><span class="p">]</span>
<span></span>                <span class="ow">and</span> <span class="n">result</span><span class="p">[</span><span class="s2">"results"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span></span>                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">"results"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span></span>            <span class="p">):</span>
<span></span>                <span class="kn">import</span><span class="w"> </span><span class="nn">base64</span>
<span></span>
<span></span>                <span class="n">annotated_image</span> <span class="o">=</span> <span class="n">get_annotated_image</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">"results"</span><span class="p">])</span>
<span></span>                <span class="n">img_bytes</span> <span class="o">=</span> <span class="n">get_bytes_from_image</span><span class="p">(</span><span class="n">annotated_image</span><span class="p">)</span>
<span></span>                <span class="n">prediction</span><span class="p">[</span><span class="s2">"annotated_image"</span><span class="p">]</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">img_bytes</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
<span></span>
<span></span>            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
<span></span>
<span></span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
<span></span>            <span class="sa">f</span><span class="s2">"Processed </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">instances</span><span class="p">)</span><span class="si">}</span><span class="s2"> instances, found </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s1">'detections'</span><span class="p">])</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">predictions</span><span class="p">)</span><span class="si">}</span><span class="s2"> total detections"</span>
<span></span>        <span class="p">)</span>
<span></span>
<span></span>        <span class="k">return</span> <span class="n">PredictionResponse</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
<span></span>
<span></span>    <span class="k">except</span> <span class="n">HTTPException</span><span class="p">:</span>
<span></span>        <span class="c1"># Re-raise HTTPException as-is (don't catch and convert to 500)</span>
<span></span>        <span class="k">raise</span>
<span></span>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span></span>        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Prediction failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div><p>Finally, add the application entry point to run the FastAPI server.</p><div class="highlight"><pre><span></span><code><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
<span></span>    <span class="kn">import</span><span class="w"> </span><span class="nn">uvicorn</span>
<span></span>
<span></span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Starting server on port </span><span class="si">{</span><span class="n">AIP_HTTP_PORT</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Health check route: </span><span class="si">{</span><span class="n">AIP_HEALTH_ROUTE</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predict route: </span><span class="si">{</span><span class="n">AIP_PREDICT_ROUTE</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span></span>    <span class="n">uvicorn</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="s2">"0.0.0.0"</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">AIP_HTTP_PORT</span><span class="p">)</span>
</code></pre></div><p>You now have a complete FastAPI application that can serve YOLO26 inference requests. You can test it locally by installing the dependencies and running the server, for example, with uv.</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Install dependencies</span>
<span></span>uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
<span></span>
<span></span><span class="c1"># Run the FastAPI server directly</span>
<span></span>uv<span class="w"> </span>run<span class="w"> </span>src/main.py
</code></pre></div><p>To test the server, you can query both the <code>/health</code> and <code>/predict</code> endpoints using cURL. Put a test image in the <code>tests</code> folder. Then, in your Terminal, run the following commands:</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Test health endpoint</span>
<span></span>curl<span class="w"> </span>http://localhost:8080/health
<span></span>
<span></span><span class="c1"># Test predict endpoint with base64 encoded image</span>
<span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">"Content-Type: application/json"</span><span class="w"> </span>-d<span class="w"> </span><span class="s2">"{\"instances\": [{\"image\": \"</span><span class="k">$(</span>base64<span class="w"> </span>-i<span class="w"> </span>tests/test_image.jpg<span class="k">)</span><span class="s2">\"}]}"</span><span class="w"> </span>http://localhost:8080/predict
</code></pre></div><p>You should receive a JSON response with the detected objects. On your first request, expect a short delay, as Ultralytics needs to pull and load the YOLO26 model.</p><h2 id="2-extend-the-ultralytics-docker-image-with-your-application">2. Extend the Ultralytics Docker image with your application</h2><p>Ultralytics provides several Docker images that you can use as a base for your application image. Docker will install Ultralytics and the necessary GPU drivers.</p><p>To use the full capabilities of Ultralytics YOLO models, you should select the CUDA-optimized image for GPU inference. However, if CPU inference is enough for your task, you can save computing resources by selecting the CPU-only image as well:</p><ul><li><a href="https://github.com/ultralytics/ultralytics/blob/main/docker/Dockerfile">Dockerfile</a>: CUDA-optimized image for YOLO26 single/multi-GPU training and inference.</li><li><a href="https://github.com/ultralytics/ultralytics/blob/main/docker/Dockerfile-cpu">Dockerfile-cpu</a>: CPU-only image for YOLO26 inference.</li></ul><h3 id="create-a-docker-image-for-your-application">Create a Docker image for your application</h3><p>Create a <code>Dockerfile</code> in the root of your project with the following content:</p><div class="highlight"><pre><span></span><code><span></span><span class="c"># Extends official Ultralytics Docker image for YOLO26</span>
<span></span><span class="k">FROM</span><span class="w"> </span><span class="s">ultralytics/ultralytics:latest</span>
<span></span>
<span></span><span class="k">ENV</span><span class="w"> </span><span class="nv">PYTHONUNBUFFERED</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span></span><span class="w">    </span><span class="nv">PYTHONDONTWRITEBYTECODE</span><span class="o">=</span><span class="m">1</span>
<span></span>
<span></span><span class="c"># Install FastAPI and dependencies</span>
<span></span><span class="k">RUN</span><span class="w"> </span>uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>fastapi<span class="o">[</span>all<span class="o">]</span><span class="w"> </span>uvicorn<span class="o">[</span>standard<span class="o">]</span><span class="w"> </span>loguru
<span></span>
<span></span><span class="k">WORKDIR</span><span class="w"> </span><span class="s">/app</span>
<span></span><span class="k">COPY</span><span class="w"> </span>src/<span class="w"> </span>./src/
<span></span><span class="k">COPY</span><span class="w"> </span>pyproject.toml<span class="w"> </span>./
<span></span>
<span></span><span class="c"># Install the application package</span>
<span></span><span class="k">RUN</span><span class="w"> </span>uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
<span></span>
<span></span><span class="k">RUN</span><span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/app/logs
<span></span><span class="k">ENV</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span>/app/src
<span></span>
<span></span><span class="c"># Port for Vertex AI</span>
<span></span><span class="k">EXPOSE</span><span class="w"> </span><span class="s">8080</span>
<span></span>
<span></span><span class="c"># Start the inference server</span>
<span></span><span class="k">ENTRYPOINT</span><span class="w"> </span><span class="p">[</span><span class="s2">"python"</span><span class="p">,</span><span class="w"> </span><span class="s2">"src/main.py"</span><span class="p">]</span>
</code></pre></div><p>In the example, the official Ultralytics Docker image <code>ultralytics:latest</code> is used as a base. It already contains the YOLO26 model and all necessary dependencies. The server's entrypoint is the same as we used to test the FastAPI application locally.</p><h3 id="build-and-test-the-docker-image">Build and test the Docker image</h3><p>Now you can build the Docker image with the following command:</p><div class="highlight"><pre><span></span><code><span></span>docker<span class="w"> </span>build<span class="w"> </span>--platform<span class="w"> </span>linux/amd64<span class="w"> </span>-t<span class="w"> </span>IMAGE_NAME:IMAGE_VERSION<span class="w"> </span>.
</code></pre></div><p>Replace <code>IMAGE_NAME</code> and <code>IMAGE_VERSION</code> with your desired values, for example, <code>yolo26-fastapi:0.1</code>. Note that you must build the image for the <code>linux/amd64</code> architecture if you are deploying on Vertex AI. The <code>--platform</code> parameter needs to be explicitly set if you are building the image on an Apple Silicon Mac or any other non-x86 architecture.</p><p>Once the image build is completed, you can test the Docker image locally:</p><div class="highlight"><pre><span></span><code><span></span>docker<span class="w"> </span>run<span class="w"> </span>--platform<span class="w"> </span>linux/amd64<span class="w"> </span>-p<span class="w"> </span><span class="m">8080</span>:8080<span class="w"> </span>IMAGE_NAME:IMAGE_VERSION
</code></pre></div><p>Your Docker container is now running a FastAPI server on port <code>8080</code>, ready to accept inference requests. You can test both the <code>/health</code> and the <code>/predict</code> endpoint with the same cURL commands as before:</p><div class="highlight"><pre><span></span><code><span></span><span class="c1"># Test health endpoint</span>
<span></span>curl<span class="w"> </span>http://localhost:8080/health
<span></span>
<span></span><span class="c1"># Test predict endpoint with base64 encoded image</span>
<span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">"Content-Type: application/json"</span><span class="w"> </span>-d<span class="w"> </span><span class="s2">"{\"instances\": [{\"image\": \"</span><span class="k">$(</span>base64<span class="w"> </span>-i<span class="w"> </span>tests/test_image.jpg<span class="k">)</span><span class="s2">\"}]}"</span><span class="w"> </span>http://localhost:8080/predict
</code></pre></div><h2 id="3-upload-the-docker-image-to-gcp-artifact-registry">3. Upload the Docker image to GCP Artifact Registry</h2><p>To import your containerized model in Vertex AI, you need to upload the Docker image to Google Cloud Artifact Registry. If you don't have an Artifact Registry repository yet, you will need to create one first.</p><h3 id="create-a-repository-in-google-cloud-artifact-registry">Create a repository in Google Cloud Artifact Registry</h3><p>Open the <a href="https://console.cloud.google.com/artifacts">Artifact Registry page</a> in the Google Cloud Console. If you are using the Artifact Registry for the first time, you may be prompted to enable the Artifact Registry API first.</p><p align="center"><img alt="Google Cloud Artifact Registry create repository interface showing repository name, region selection, and format options" src="https://github.com/lussebullar/temp-image-storage/releases/download/docs/create-artifact-registry-repo.png" width="70%"/></p><ol><li>Select Create Repository.</li><li>Enter the name of your repository. Select the desired region and use default settings for other options, unless you need to change them specifically.</li></ol><div class="admonition note"><p class="admonition-title">Note</p><p>Region selection may affect the availability of machines and certain compute limitations for non-Enterprise users. You can find more information in the Vertex AI official documentation: <a href="https://docs.cloud.google.com/vertex-ai/docs/quotas">Vertex AI quotas and limits</a></p></div><ol><li>Once the repository is created, save your PROJECT_ID, Location (Region), and Repository Name to your secrets vault or <code>.env</code> file. You will need them later to tag and push your Docker image to the Artifact Registry.</li></ol><h3 id="authenticate-docker-to-artifact-registry">Authenticate Docker to Artifact Registry</h3><p>Authenticate your Docker client to the Artifact Registry repository you just created. Run the following command in your terminal:</p><div class="highlight"><pre><span></span><code><span></span>gcloud<span class="w"> </span>auth<span class="w"> </span>configure-docker<span class="w"> </span>YOUR_REGION-docker.pkg.dev
</code></pre></div><h3 id="tag-and-push-your-image-to-artifact-registry">Tag and push your image to Artifact Registry</h3><p>Tag and push the Docker image to Google Artifact Registry.</p><div class="admonition note"><p class="admonition-title">Use unique tags for your images</p><p>It is recommended to use unique tags every time you will be updating your image. Most GCP services, including Vertex AI, rely on the image tags for automated versioning and scaling, so it is a good practice to use semantic versioning or date-based tags.</p></div><p>Tag your image with the Artifact Registry repository URL. Replace the placeholders with the values you saved earlier.</p><div class="highlight"><pre><span></span><code><span></span>docker<span class="w"> </span>tag<span class="w"> </span>IMAGE_NAME:IMAGE_VERSION<span class="w"> </span>YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/YOUR_REPOSITORY_NAME/IMAGE_NAME:IMAGE_VERSION
</code></pre></div><p>Push the tagged image to the Artifact Registry repository.</p><div class="highlight"><pre><span></span><code><span></span>docker<span class="w"> </span>push<span class="w"> </span>YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/YOUR_REPOSITORY_NAME/IMAGE_NAME:IMAGE_VERSION
</code></pre></div><p>Wait for the process to complete. You should now see the image in your Artifact Registry repository.</p><p>For more specific instructions on how to work with images in Artifact Registry, see the Artifact Registry documentation: <a href="https://cloud.google.com/artifact-registry/docs/docker/pushing-and-pulling">Push and pull images</a>.</p><h2 id="4-import-your-model-in-vertex-ai">4. Import your model in Vertex AI</h2><p>Using the Docker image you've just pushed, you can now import the model in Vertex AI.</p><ol><li><p>In Google Cloud navigation menu, go to Vertex AI &gt; Model Registry. Alternatively, search for "Vertex AI" in the search bar at the top of the Google Cloud Console. <p align="center"><img alt="Vertex AI Model Registry interface with Import button highlighted for importing a new model" src="https://github.com/lussebullar/temp-image-storage/releases/download/docs/vertex-ai-import.png" width="80%"/></p></p></li><li><p>Click Import.</p></li><li>Select Import as a new model.</li><li>Select the region. You can choose the same region as your Artifact Registry repository, but your selection should be dictated by the availability of machine types and quotas in your region.</li><li><p>Select Import an existing model container. <p align="center"><img alt="Vertex AI import model dialog showing container image selection and model configuration options" src="https://github.com/lussebullar/temp-image-storage/releases/download/docs/import-model.png" width="80%"/></p></p></li><li><p>In the Container image field, browse the Artifact Registry repository you created earlier and select the image you just pushed.</p></li><li><p>Scroll down to the Environment variables section and enter the predict and health endpoints, and the port that you defined in your FastAPI application. <p align="center"><img alt="Vertex AI environment variables configuration showing predict route, health route, and port settings for FastAPI endpoints" src="https://github.com/lussebullar/temp-image-storage/releases/download/docs/predict-health-port.png" width="60%"/></p></p></li><li><p>Click Import. Vertex AI will take several minutes to register the model and prepare it for deployment. You will receive an email notification once the import is complete.</p></li></ol><h2 id="5-create-a-vertex-ai-endpoint-and-deploy-your-model">5. Create a Vertex AI Endpoint and deploy your model</h2><div class="admonition note"><p class="admonition-title">Endpoints vs Models in Vertex AI</p><p>In Vertex AI terminology, <strong>endpoints</strong> refer to the <strong>deployed</strong> models, since they represent the HTTP endpoints where you send inference requests, whereas <strong>models</strong> are the trained ML artifacts stored in the Model Registry.</p></div><p>To deploy a model, you need to create an Endpoint in Vertex AI.</p><ol><li>In your Vertex AI navigation menu, go to Endpoints. Select your region you used when importing your model. Click Create.</li></ol><p align="center"><img alt="Vertex AI create endpoint interface showing endpoint name input field and access configuration options" src="https://github.com/lussebullar/temp-image-storage/releases/download/docs/endpoint-name.png" width="60%"/></p><ol><li>Enter the Endpoint name.</li><li>For Access, Vertex AI recommends using private Vertex AI endpoints. Apart from security benefits, you get a higher payload limit if you select a private endpoint, however you will need to configure your VPC network and firewall rules to allow access to the endpoint. Refer to the Vertex AI documentation for more instructions on <a href="https://docs.cloud.google.com/vertex-ai/docs/predictions/choose-endpoint-type">private endpoints</a>.</li><li>Click Continue.</li><li>On the Model settings dialog, select the model you imported earlier. Now you can configure the machine type, memory, and GPU settings for your model. Allow for ample memory if you are expecting high inference loads to ensure there are no I/O bottlenecks for the proper YOLO26 performance.</li><li><p>In Accelerator type, select the GPU type you want to use for inference. If you are not sure which GPU to select, you can start with NVIDIA T4, which is CUDA-supported.</p><div class="admonition note"><p class="admonition-title">Region and machine type quotas</p><p>Remember that certain regions have very limited compute quotas, so you may not be able to select certain machine types or GPUs in your region. If this is critical, change the region of your deployment to one with a bigger quota. Find more information in the Vertex AI official documentation: <a href="https://docs.cloud.google.com/vertex-ai/docs/quotas">Vertex AI quotas and limits</a>.</p></div></li><li><p>Once the machine type is selected, you can click Continue. At this point, you can choose to enable model monitoring in Vertex AI‚Äîan extra service that will track your model's performance and provide insights into its behavior. This is optional and incurs additional costs, so select according to your needs. Click Create.</p></li></ol><p>Vertex AI will take several minutes (up to 30 min in some regions) to deploy the model. You will receive an email notification once the deployment is complete.</p><h2 id="6-test-your-deployed-model">6. Test your deployed model</h2><p>Once the deployment is complete, Vertex AI will provide you with a sample API interface to test your model.</p><p>To test remote inference, you can use the provided cURL command or create another Python client library that will send requests to the deployed model. Remember that you need to encode your image to base64 before sending it to the <code>/predict</code> endpoint.</p><p align="center"><img alt="Vertex AI endpoint testing interface displaying sample cURL command for making prediction requests to deployed YOLO26 model" src="https://cdn.jsdelivr.net/gh/ultralytics/assets@main/docs/vertex-ai-endpoint-test-curl-yolo11.avif" width="50%"/></p><div class="admonition note"><p class="admonition-title">Expect a short delay on the first request</p><p>Similarly to the local testing, expect a short delay on the first request, as Ultralytics will need to pull and load the YOLO26 model in the running container.</p></div><p>You have successfully deployed a pretrained YOLO26 model with Ultralytics on Google Cloud Vertex AI.</p><h2 id="faq">FAQ</h2><h3 id="can-i-use-ultralytics-yolo-models-on-vertex-ai-without-docker">Can I use Ultralytics YOLO models on Vertex AI without Docker?</h3><p>Yes; however, you will first need to export the model to a format compatible with Vertex AI, such as TensorFlow, Scikit-learn, or XGBoost. Google Cloud provides a guide on running <code>.pt</code> models on Vertex with a complete overview of the conversion process: <a href="https://cloud.google.com/blog/topics/developers-practitioners/pytorch-google-cloud-how-deploy-pytorch-models-vertex-ai">Run PyTorch models on Vertex AI</a>.</p><p>Please note that the resulting setup will rely only on the Vertex AI standard serving layer and will not support the advanced Ultralytics framework features. Since Vertex AI fully supports containerized models and can scale them automatically according to your deployment configuration, it allows you to leverage the full capabilities of Ultralytics YOLO models without needing to convert them to a different format.</p><h3 id="why-is-fastapi-a-good-choice-for-serving-yolo26-inference">Why is FastAPI a good choice for serving YOLO26 inference?</h3><p>FastAPI provides high throughput for inference workloads. Async support allows handling multiple concurrent requests without blocking the main thread, which is important when serving computer vision models.</p><p>Automatic request/response validation with FastAPI reduces runtime errors in production inference services. This is particularly valuable for object detection APIs where input format consistency is critical.</p><p>FastAPI adds minimal computational overhead to your inference pipeline, leaving more resources available for model execution and image processing tasks.</p><p>FastAPI also supports SSE (Server-Sent Events), which is useful for streaming inference scenarios.</p><h3 id="why-do-i-have-to-select-a-region-so-many-times">Why do I have to select a region so many times?</h3><p>This is actually a versatility feature of Google Cloud Platform, where you need to select a region for every service you use. For the task of deploying a containerized model on Vertex AI, your most important region selection is the one for the Model Registry. It will determine the availability of machine types and quotas for your model deployment.</p><p>Additionally, if you will be extending the setup and storing prediction data or results in Cloud Storage or BigQuery, you will need to use the same region as for Model Registry to minimize latency and ensure high throughput for data access.</p><br/><br/><div class="git-info"><div class="dates-container"><span class="date-item" title="This page was first created on July 29, 2025"><span class="hover-item">üìÖ</span> Created 5 months ago </span><span class="date-item" title="This page was last updated on January 20, 2026"><span class="hover-item">‚úèÔ∏è</span> Updated 0 days ago </span></div><div class="authors-container"><a class="author-link" href="https://github.com/glenn-jocher" title="glenn-jocher (5 changes)"><img alt="glenn-jocher" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/26833433?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/pderrenger" title="pderrenger (1 change)"><img alt="pderrenger" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/107626595?v=4&amp;s=96"/></a><a class="author-link" href="https://github.com/ultralytics/ultralytics" title="vitali.lobanov@pm.me (1 change)"><img alt="vitali.lobanov@pm.me" class="hover-item" loading="lazy" src="https://avatars.githubusercontent.com/u/9919?v=4&amp;s=96"/></a></div></div><div class="share-buttons"><button class="share-button hover-item" onclick="window.open('https://twitter.com/intent/tweet?url=https%3A%2F%2Fdocs.ultralytics.com%2Fguides%2Fvertex-ai-deployment-with-docker%2F', 'TwitterShare', 'width=550,height=680,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-x-twitter"></i> Tweet </button><button class="share-button hover-item linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fdocs.ultralytics.com%2Fguides%2Fvertex-ai-deployment-with-docker%2F', 'LinkedinShare', 'width=550,height=730,menubar=no,toolbar=no'); return false;"><i class="fa-brands fa-linkedin-in"></i> Share </button></div><br/><h2 id="__comments">Comments</h2><div id="giscus-container"></div></article></div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div><button class="md-top md-icon" data-md-component="top" hidden="" type="button"><svg class="lucide lucide-circle-arrow-up" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><path d="m16 12-4-4-4 4M12 16V8"></path></svg> Back to top
</button></main><footer class="md-footer"><nav aria-label="Footer" class="md-footer__inner md-grid"><a aria-label="Previous: Defining A Computer Vision Project's Goals" class="md-footer__link md-footer__link--prev" href="../defining-project-goals/"><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-left" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m12 19-7-7 7-7M19 12H5"></path></svg></div><div class="md-footer__title"><span class="md-footer__direction"> Previous </span><div class="md-ellipsis"> Defining A Computer Vision Project's Goals </div></div></a><a aria-label="Next: Docker Quickstart" class="md-footer__link md-footer__link--next" href="../docker-quickstart/"><div class="md-footer__title"><span class="md-footer__direction"> Next </span><div class="md-ellipsis"> Docker Quickstart </div></div><div class="md-footer__button md-icon"><svg class="lucide lucide-arrow-right" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M5 12h14M12 5l7 7-7 7"></path></svg></div></a></nav><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-copyright"><div class="md-copyright__highlight"><a href="https://www.ultralytics.com/" target="_blank">¬© 2026 Ultralytics Inc.</a> All rights reserved. </div> Made with <a href="https://zensical.org/" rel="noopener" target="_blank"> Zensical </a></div><div class="md-social"><a class="md-social__link" href="https://github.com/ultralytics" rel="noopener" target="_blank" title="github.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://www.linkedin.com/company/ultralytics/" rel="noopener" target="_blank" title="www.linkedin.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://x.com/ultralytics" rel="noopener" target="_blank" title="x.com"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://youtube.com/ultralytics?sub_confirmation=1" rel="noopener" target="_blank" title="youtube.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://hub.docker.com/r/ultralytics/ultralytics/" rel="noopener" target="_blank" title="hub.docker.com"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://pypi.org/project/ultralytics/" rel="noopener" target="_blank" title="pypi.org"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://discord.com/invite/ultralytics" rel="noopener" target="_blank" title="discord.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://reddit.com/r/ultralytics" rel="noopener" target="_blank" title="reddit.com"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path d="M0 256C0 114.6 114.6 0 256 0s256 114.6 256 256-114.6 256-256 256H37.1c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256m349.6-102.4c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4v.2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1v-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8zm-172.5 93.3c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5S160.3 247 177 247zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9.8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1.3 5.1 3.6 3.9 6.5" fill="currentColor"></path></svg></a><a class="md-social__link" href="https://weixin.qq.com/r/mp/LxckPDfEgWr_rXNf90I9" rel="noopener" target="_blank" title="weixin.qq.com"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6" fill="currentColor"></path></svg></a></div></div></div></footer></div><div class="md-dialog" data-md-component="dialog"><div class="md-dialog__inner md-typeset"></div></div><div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"annotate":null,"base":"../..","features":["content.action.edit","content.code.annotate","content.code.copy","content.tooltips","toc.follow","navigation.top","navigation.tabs","navigation.tabs.sticky","navigation.prune","navigation.footer","navigation.tracking","navigation.instant","navigation.instant.progress","navigation.indexes","navigation.sections","content.tabs.link"],"search":"../../assets/javascripts/workers/search.e2d2d235.min.js","tags":null,"translations":{"clipboard.copied":"Copied to clipboard","clipboard.copy":"Copy to clipboard","search.result.more.one":"1 more on this page","search.result.more.other":"# more on this page","search.result.none":"No matching documents","search.result.one":"1 matching document","search.result.other":"# matching documents","search.result.placeholder":"Type to start searching","search.result.term.missing":"Missing","select.version":"Select version"},"version":null}</script>
<script src="../../assets/javascripts/bundle.8ffeb9c9.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ultralytics/llm@v0.1.8/js/chat.min.js"></script>
<script src="https://unpkg.com/tablesort@5.6.0/dist/tablesort.min.js"></script>
<script src="../../javascript/extra.js"></script>
<script src="../../javascript/giscus.js"></script>
<script src="../../javascript/tablesort.js"></script>
<script>
            async function copyMarkdownForLLM(button) {
                const editBtn = document.querySelector('a[title="Edit this page"]');
                if (!editBtn) return;

                const originalHTML = button.innerHTML;
                const checkIcon = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19L21 7l-1.41-1.41L9 16.17z"></path></svg>';

                let rawUrl = editBtn.href.replace('github.com', 'raw.githubusercontent.com');
                rawUrl = rawUrl.replace('/blob/', '/').replace('/tree/', '/');

                try {
                    const response = await fetch(rawUrl);
                    let markdown = await response.text();

                    if (markdown.startsWith('---')) {
                        const frontMatterEnd = markdown.indexOf('\n---\n', 3);
                        if (frontMatterEnd !== -1) {
                            markdown = markdown.substring(frontMatterEnd + 5).trim();
                        }
                    }

                    const title = document.querySelector('h1')?.textContent || document.title;
                    const content = `# ${title}\n\nSource: ${window.location.href}\n\n---\n\n${markdown}`;

                    await navigator.clipboard.writeText(content);
                    button.innerHTML = checkIcon + ' Copied!';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                } catch (err) {
                    button.innerHTML = '‚ùå Failed';
                    setTimeout(() => { button.innerHTML = originalHTML; }, 2000);
                }
            }
            </script></body></html>